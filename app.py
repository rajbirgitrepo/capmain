# !/usr/bin/env python
# coding: utf-8

# In[ ]:
#checking
from flask import (
    Flask,
    g,
    redirect,
    render_template,
    flash,
    request,
    session,
    url_for,
    send_file
)
from bson.regex import Regex
import pandas as pd
from flask import Flask,json
from datetime import datetime
import io
from pandas.io.json import json_normalize
import pandas as pd
import pycountry
import collections
# import mysql.connector
import numpy as np
from pandas import Timestamp
from flask_cors import CORS
from geolite2 import geolite2
import time
from textblob import TextBlob
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

from datetime import timedelta
import pymongo
from pymongo import MongoClient
from pprint import pprint
import urllib.parse
from pandas import DataFrame
from bson.objectid import ObjectId
import datetime
import dateutil.parser
from datetime import date
import calendar
import re
import math
import json
import urllib.request
from sort_dataframeby_monthorweek import *
from pytz import timezone
from six.moves import urllib
from numpyencoder import NumpyEncoder
from flask import Response
from flask import Flask, make_response

from flask import Flask,json, request, jsonify
from dateutil.relativedelta import relativedelta

#  new libraries to be imported 

from pandas.tseries.holiday import USFederalHolidayCalendar
from pandas.tseries.offsets import CustomBusinessDay
from sklearn.preprocessing import StandardScaler
import collections
import os

client_live= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@54.202.61.130:27017/')
db_live=client_live.compass



app = Flask(__name__)
CORS(app)


# from flask_login import logout_user
class User:
    def __init__(self, id, username, password,name,nameinitial):
        self.id = id
        self.username = username
        self.password = password
        self.name = name
        self.nameinitial = nameinitial

    def __repr__(self):
        return f'<User: {self.username}>'

users = []
users.append(User(id=1, username='admin@innerexplorer.org', password='datateam2020',name='Admin',nameinitial='A'))
users.append(User(id=2, username='paul@innerexplorer.org', password='capxp2020',name='Paul',nameinitial='P'))
users.append(User(id=3, username='harsh@innerexplorer.org', password='capxp2020',name='Harsh',nameinitial='H'))
users.append(User(id=4,username='laura@innerexplorer.org',password='capxp2020',name='Laura',nameinitial='L'))
users.append(User(id=5,username='janice@innerexplorer.org',password='capxp2020',name='Janice',nameinitial='J'))
users.append(User(id=6,username='lisa@innerexplorer.org',password='capxp2020',name='Lisa',nameinitial='L'))
users.append(User(id=7,username='tabitha@innerexplorer.org',password='capxp2020',name='Tabitha',nameinitial='T'))
users.append(User(id=8,username='laurie@innerexplorer.org',password='capxp2020',name='Laurie',nameinitial='L'))
users.append(User(id=9,username='victor@innerexplorer.org',password='capxp2020',name='Victor',nameinitial='V'))
users.append(User(id=10,username='mary@innerexplorer.org',password='capxp2020',name='Mary',nameinitial='M'))
users.append(User(id=11,username='iris@innerexplorer.org',password='capxp2020',name='Iris',nameinitial='I'))
users.append(User(id=12,username='travis@innerexplorer.org',password='capxp2020',name='Travis',nameinitial='T'))
users.append(User(id=13,username='pooja@1gen.io',password='capxp2020',name='Pooja',nameinitial='P'))
users.append(User(id=14,username='joan@innerexplorer.org',password='capxp2020',name='Joan',nameinitial='J'))
users.append(User(id=15,username='dennette@innerexplorer.org',password='capxp2020',name='Dennette',nameinitial='D'))
users.append(User(id=16,username='jhoulihan@innerexplorer.org',password='capxp2020',name='Janice',nameinitial='J'))
users.append(User(id=17,username='lcahill@innerexplorer.org',password='capxp2020',name='Lisa',nameinitial='L'))
users.append(User(id=18,username='ccassisa@innerexplorer.org',password='capxp2020',name='Christy',nameinitial='C'))
users.append(User(id=19,username='arice@innerexplorer.org',password='capxp2020',name='Anitra',nameinitial='A'))
users.append(User(id=20,username='vgonzalez@innerexplorer.org',password='capxp2020',name='Victoria',nameinitial='V'))
users.append(User(id=21,username='nina@innerexplorer.org',password='capxp2020',name='Nina',nameinitial='N'))

app = Flask(__name__)
app.secret_key = 'cap4g2020version10date8272020'

@app.before_request
def before_request():
    g.user = None

    if 'user_id' in session:
        user = [x for x in users if x.id == session['user_id']][0]
        g.user = user
        

@app.route('/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        session.pop('user_id', None)
        username = request.form['username']
        password = request.form['password']
        try:
            user = [x for x in users if x.username == username][0]
            if user and user.password == password:
                session['user_id'] = user.id
                return redirect(url_for('homepage'))
            else:
                flash('Invalid Credentials. Try again')
                return redirect(url_for('login'))
        except IndexError as error:
            flash('Invalid Credentials. Try again')
            return redirect(url_for('login'))
    return render_template('login.html')

@app.route('/')
def index():
    return redirect(url_for('login'))

@app.route('/homepage')
def homepage():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('homepage.html')


practice_cond_dictonary_list=[{'$project':{
            '_id':0,
            'USER_ID':'$USER_ID._id',
            'CREATED_DATE' :'$CREATED_DATE',
            'USER_EMAIL':'$USER_ID.EMAIL_ID',
            'SCHOOL_ID':'$USER_ID.schoolId._id',
            'SCHOOL_NAME':'$USER_ID.schoolId.NAME',
            'MODIFIED_DATE':'$MODIFIED_DATE',
            'AUDIO_LENGTH':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH',
            "DISTRICT_NAME":'$USER_ID.DISTRICT_ID.DISTRICT_NAME',
            'cursorStart':'$cursorStart',
            'CURSOR_END':'$CURSOR_END',
            'IS_DONE':'$IS_DONE',
            'LAST_EVENT':'$LAST_EVENT',
            'AUDIO_ID':'$PROGRAM_AUDIO_ID._id',
            'AUDIO_NAME':'$PROGRAM_AUDIO_ID.AUDIO_NAME',
            'PROGRAM_ID':'$PROGRAM_AUDIO_ID.PROGRAM_ID._id',
            'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}},


           {'$project': { '_id':0,
            'USER_ID':'$USER_ID',
            'CREATED_DATE' :'$CREATED_DATE',
            'USER_EMAIL':'$USER_EMAIL',
            'SCHOOL_ID':'$SCHOOL_ID',
            'SCHOOL_NAME':'$SCHOOL_NAME',
            'MODIFIED_DATE':'$MODIFIED_DATE',
            'AUDIO_LENGTH':'$AUDIO_LENGTH',
            "DISTRICT_NAME":"$DISTRICT_NAME",
            'cursorStart':'$cursorStart',
            'CURSOR_END':'$CURSOR_END',
            'IS_DONE':'$IS_DONE',
            'LAST_EVENT':'$LAST_EVENT',
            'AUDIO_ID':'$AUDIO_ID',
            'AUDIO_NAME':'$AUDIO_NAME',
            'PROGRAM_ID':'$PROGRAM_ID',
            'PROGRAM_NAME':'$PROGRAM_NAME',
            'Completion_Percentage':{'$round':
                [{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},
                '$AUDIO_LENGTH']},0]}
                }}
           ]


#changesdonebysadhna
disdic={
    '6045e4d007ead7744b125848':'Adams 12 Five Star Schools',
    '616d2865c35ee7525fb145d9':'Addison Northwest School District',
    '6167fe41282c502e1077c12f':'Anchorage',
    '6045e4d707ead7744b125854':'Adams County School District 14',
    '5f2609807a1c0000950bb475':'Agawam School district',
    '5f2609807a1c0000950bb481':'Alameda Unified School District',
    '5f2609807a1c0000950bb47a':'Alpine School District',
    '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
    '6045e4c907ead7744b12583d':'Apple Valley Unified School District',
    '619268dd81f00a4319a65a52':'Access Community',
    '789':'Attendance works',
    '6045e4d707ead7744b125855':'Aurora Public Schools',
    '5f2609807a1c0000950bb463':'Austin Independent School District',
    '5f59e4836451a9089d7d4007':'Belleville School District',
    '6045e4d107ead7744b125849':'Berkeley Public Schools',
    '5fe2e25d4d0ca68d7baf889d':'BGCA',
    '6045e4ca07ead7744b12583e':'Bishop Unified School District',
    '6045e4d107ead7744b12584a':'Bismarck Public Schools',
    '5fe318b14d0ca68d7baf889e':'BLUE',
    '6045e4c807ead7744b12583b':'Boston Public Schools',
    '6023a6d79e8e623753fc305c':'Boulder Valley School District',
    '60f7bf747cc8db72d772e465':'Bright Horizons Early Learning Centers',
    '5f2609807a1c0000950bb46d':'Broward County Public Schools',
    '617949a0fc72b63e0d1dc7d3':'Burlington School District',
    '6045e4ca07ead7744b12583f':'Canyons School District',
    '60473f8823e88e242074ebd2':'Champlain Valley School District',
    '6045e4d907ead7744b125858':'Chicago Public Schools',
    '5f2609807a1c0000950bb46c':'Chico Unified School District',
    '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
    '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
    '6045e4d907ead7744b125857':'Colton Joint Unified School District',
    '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
    '5f2609807a1c0000950bb45c':'Comox Valley School District',
    '5f2609807a1c0000950bb480':'Dell Texas',
    '6045e4da07ead7744b125859':'Dennis-Yarmouth Regional School District',
    '6045e4cb07ead7744b125840':'Denver Public Schools',
    '5f2609807a1c0000950bb46e':'District 25 New York Schools',
    '5f7413ef9387fd71ce6387cb':'Douglas County School District',
    '6045e4c707ead7744b12583a':'Durham Public Schools',
    '5f895191609e08b76029f641':'Early learning Sarasota',
    '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
    '5f2609807a1c0000950bb461':'Englewood Public School District',
    '5f2609807a1c0000950bb464':'Equity Education',
    '6045e4cc07ead7744b125841':'Fairfax County Public Schools',
    '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
    '6045e4cd07ead7744b125843':'Falmouth Public Schools',
    '6045e4da07ead7744b12585a':'FITCHBURG PUBLIC SCHOOLS',
    '5f2609807a1c0000950bb47d':'Flint Public Schools',
    '6023a7269e8e623753fc305e':'Fulton County School System',
    '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
    '617fae53ccd2dd76541ed5e7':'Glasgow Independent Schools',
    '6045e4d207ead7744b12584b':'Glenbard District 87',
    '5f2609807a1c0000950bb450':'Goleta District',
    '6045e4cd07ead7744b125844':'Granite School District',
    '5f2609807a1c0000950bb474':'Greenburgh North Castle Union Free School District',
    '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
    '60cb8971c5b0e89ed7ac0aa1':'Hall County School District',
    '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
    '6045e4c707ead7744b125839':'Hartford Public Schools',
    '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
    '6045e4ce07ead7744b125845':'Helena Public Schools',
    '61af3b75870dba387bcd86cd':'Holyoke Public Schools',
    '61aa08a4afeab44256f54074':'Benton Harbor',
    '6045e4db07ead7744b12585b':'HidalgoIndependent School district',
    '5f2609807a1c0000950bb476':'Hillsborough County',
    '6045e4db07ead7744b12585c':'Hopedale Public Schools',
    '6045e4cc07ead7744b125842':'Houston Independent School District',
    '60b872ce826cab06ebdf044e':'Kalamazoo Public Schools',
    '6045e4dc07ead7744b12585d':'Kearsarge Regional School District',
    '6045e4d307ead7744b12584d':'KIPP Public Schools',
    '5f2609807a1c0000950bb455':'Krum Independent School District',
    '5f2609807a1c0000950bb47e':'La Joya School District',
    '6045e4cf07ead7744b125846':'Lamar Consolidated Independent School District',
    '5f2609807a1c0000950bb45a':'LAUSD',
    '5f2609807a1c0000950bb467':'Lincolnshire Schools',
    '6045e4dc07ead7744b12585e':'Littleton Public Schools',
    '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
    '6023a7499e8e623753fc305f':'Manatee County School District',
    '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
    '6077e1b5eaa8bae0e2e04a64':'Medfield School District',
    '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
    '5f2609807a1c0000950bb465':'Middleton-Cross Plains Area School District',
    '6045e4d407ead7744b12584f':'Mill Valley School District',
    '6045e4d307ead7744b12584e':'Millard School District',
    '610d0837931db8cfdf500fef':'Mission Consolidated Independent School District',
    '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
    '6045e4cf07ead7744b125847':'Muscatine Community School District',
    '5fbcdf0ba84e48a64412a798':'Needham School District',
    '5f2609807a1c0000950bb459':'North Special School District',
    '6045e4c907ead7744b12583c':'Northside Independent School District',
    '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
    '5fd704da04a848e368de5dc6':'Oakland Unified School District',
    '5f6994386451a9089d7d4009':'Ogden school district',
    '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
    '6017ab3043ca9c39151838d4':'Oswego School District',
    '6045e4dd07ead7744b12585f':'Palm Beach County School District',
    '60913aaea5fd4b56a4bafa70':'Palm Springs Unified',
    '5f2609807a1c0000950bb479':'Panorama Education',
    '5f2609807a1c0000950bb46f':'Paradise Schools',
    '5f8fcd33609e08b76029f644':'Paradise Unified School District',
    '6045e4de07ead7744b125860':'Paterson School District',
    '6177e72d108b6ebefcfc1014':'Pasco County Schools',
    '5f2609807a1c0000950bb466':'Pinellas County Schools',
    '5f2609807a1c0000950bb471':'Racine Unified Schools',
    '6045e4d507ead7744b125850':'Rich School District',
    '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
    '5f2609807a1c0000950bb478':'San Diego Unified School District',
    '6045e4d507ead7744b125851':'San Francisco Unified School District',
    '6023a76f9e8e623753fc3060':'San Jose Unified School District',
    '5f2609807a1c0000950bb470':'San Leandro Unified School District',
    '6045e4df07ead7744b125862':'San Marcos Unified School District',
    '6045e4df07ead7744b125863':'San Marino Unified School District',
    '5f2609807a1c0000950bb477':'Sarasota County',
    '602e60e567d3e6c0a4eb4d99':'School District of Palm Beach County',
    '6045e4d807ead7744b125856':'School District of the Chathams',
    '6045e4de07ead7744b125861':'Sevier School District',
    '5f2609807a1c0000950bb473':'Skillman Foundation',
    '617fc552ccd2dd76541ed5eb': 'Shah Family Foundation & BPS',
    '123':'Skillman',
    '6045e4e007ead7744b125864':'South Summit School District',
    '60eea965ae7de54f57abf234':'Southfield Public Schools',
    '5f2609807a1c0000950bb46a':'Springfield Public School',
    '5f2609807a1c0000950bb46a':'Springfield Public Schools',
    '6045e4e007ead7744b125865':'Sudbury Public Schools',
    '6045e4e107ead7744b125866':'Tooele County School District',
    '60a7b03831afdba383052726':'United Way Of Santa Barbara',
    '6045e4d607ead7744b125852':'Upland Unified School District',
    '5f2609807a1c0000950bb468':'Utah Board of Education',
    '456':'UWBA',
    '6023a7949e8e623753fc3061':'Wasatch County School District',
    '6045e4e207ead7744b125867':'Washoe County School District',
    '5f698b826451a9089d7d4008':'Wayne Metro',
    '6045e4d607ead7744b125853':'West Contra Costa Unified School District',
    '5f2609807a1c0000950bb45b':'Westfield Public School District',
    '6045e4e207ead7744b125868':'Westford Public Schools',
    '6045e4d207ead7744b12584c':'White River School District',
    '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
    '5f2609807a1c0000950bb45d':'Youngstown'}

def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')
        

        return csy_date
    
    
def LSY_Date():

    LSY_Date=csy_first_date()-relativedelta(years=1)
    return LSY_Date

def LSYTOLSY_Date():

    LSYTOLSY_Date=csy_first_date()-relativedelta(years=2)
    return LSYTOLSY_Date


@app.route('/questtimeseries')
def questtimeseries():
    client_live= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@54.202.61.130:27017/')
    db_live=client_live.compass
    QUEST_OBTAINED_USER=pd.DataFrame(list(db_live.user_master.aggregate([{"$match":{
            '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'IS_DISABLED':{"$ne":'Y'}},
            {'IS_BLOCKED':{"$ne":'Y'}},
            {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
            {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'IS_QUEST_OBTAINED':'Y'}
            ]}},

            {'$project':{
                '_id':0,
                'USER_ID':'$_id',
                'QUEST_OBTAIN_DATE':'$QUEST_OBTAINED_DATE'
                }}
            ])))
    QUEST_OBTAINED_USER=QUEST_OBTAINED_USER[QUEST_OBTAINED_USER['QUEST_OBTAIN_DATE'].notnull()].reset_index(drop=True)
    quest_history=pd.DataFrame(list(db_live.user_quest_history.aggregate([{"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
                                        {'$project':{
                                            '_id':0,
                                            'USER_ID':'$USER_ID._id',                                         
                                            'QUEST_OBTAIN_DATE':'$QUEST_OBT_IN_DATE'
                                                                                }}
                                        ])))
    def date_to_string(dates):
        date_=dates.strftime('%Y-%m-%d')
        return date_
    def quest_last_day(dates):
        last_date=(dates+relativedelta(days=41)).strftime("%Y-%m-%d")
        return last_date
    QUEST_OBTAINED_USER['QUEST_START_DAY']=QUEST_OBTAINED_USER['QUEST_OBTAIN_DATE'].apply(date_to_string)
    QUEST_OBTAINED_USER['QUEST_FINISH_DAY']=QUEST_OBTAINED_USER['QUEST_OBTAIN_DATE'].apply(quest_last_day)
    quest_history['QUEST_START_DAY']=quest_history['QUEST_OBTAIN_DATE'].apply(date_to_string)
    quest_history['QUEST_FINISH_DAY']=quest_history['QUEST_OBTAIN_DATE'].apply(quest_last_day)    
    qh_no_entry=list(set(QUEST_OBTAINED_USER['USER_ID'])-set(quest_history['USER_ID']))
    quest_data=pd.concat([QUEST_OBTAINED_USER,quest_history],ignore_index=True)
    quest_data_final=quest_data.drop_duplicates(subset=['USER_ID','QUEST_START_DAY'],keep='first').reset_index(drop=True)
    qh_um=pd.DataFrame(list(db_live.user_master.aggregate([{'$match':{'$and':[
        {'_id':{'$in':list(quest_data_final['USER_ID'])}}
        ]}},{'$project':{'_id':0,
                        'USER_ID':'$_id',
                        'USER_NAME':'$USER_NAME',
                        'EMAIL_ID':'$EMAIL_ID',
                        'SCHOOL_ID':'$schoolId._id',
                        'SCHOOL_NAME':'$schoolId.NAME',
                        'CHANNEL':'$UTM_MEDIUM',
                        'SIGNUP':'$CREATED_DATE'
                        }}])))
    quest_history_data_new_final=quest_data_final.merge(qh_um,how='left',on='USER_ID')
    quest_history_data_new_final=quest_history_data_new_final[quest_history_data_new_final['SIGNUP'].notnull()].reset_index(drop=True)
    df=quest_history_data_new_final.copy()

    df['QUEST_START_DAY'] = pd.to_datetime(df['QUEST_START_DAY'])
    df1= df.groupby(df['QUEST_START_DAY'].dt.date)['USER_ID'].count().reset_index()
    df1['QUEST_START_DAY'] = pd.to_datetime(df1['QUEST_START_DAY'])
    df1['QUEST_START_DAY'] = df1['QUEST_START_DAY'].astype(np.int64) / int(1e6)
    df1['Cumulative_user'] = df1['USER_ID'].cumsum()
    total=df1['USER_ID'].sum()
    df2=df1[['QUEST_START_DAY','USER_ID']]
    user=df2.values.tolist()
    df3=df1[['QUEST_START_DAY','Cumulative_user']]
    Cumuser=df3.values.tolist()
    temp={"user":user,"Cumuser":Cumuser,"total":int(total)}
    return json.dumps(temp)

@app.route("/practice_duration_monthly")
def practice_duration_monthly():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    
    collection_practice=db.audio_track_master
    user_practice=[
    {
            "$match":
        {"$and":
            [           
            {"USER_ID.EMAIL_ID":{"$not":{"$regex":"test","$options":"i"}}},
            {"USER_ID.EMAIL_ID":{"$not":{"$regex":"1gen","$options":"i"}}},
            {"USER_ID.USER_NAME":{"$not":{"$regex":"test","$options":"i"}}},
            {"USER_ID.USER_NAME":{"$not":{"$regex":"user","$options":"i"}}},
            {"USER_ID.DISTRICT_ID.DISTRICT_NAME":{"$not":{"$regex":"test","$options":"i"}}},
            {"USER_ID.DISTRICT_ID.DISTRICT_NAME":{"$not":{"$regex":"user","$options":"i"}}},
            {"USER_ID.IS_BLOCKED" :{"$ne":"Y"}},
            {"USER_ID.IS_DISABLED" : {"$ne":"Y"}},
            {"USER_ID.INCOMPLETE_SIGNUP" : {"$ne":"Y"}}
            ]
        }
    },  
    {
        "$project":
            {   
            "_id":"$USER_ID._id",
            "USER_NAME":"$USER_ID.USER_NAME",  
            "LAST_PRACTICE_DATE":"$MODIFIED_DATE",
            "CREATED_DATE" :"$CREATED_DATE",
            } 
    }
    ]
    update_practice= list(collection_practice.aggregate(user_practice))
    df_practice=pd.DataFrame(update_practice)
    df_practice['last_time']=pd.to_datetime(df_practice["LAST_PRACTICE_DATE"]).dt.strftime('%H:%M:%S')
    df_practice['first_time']=pd.to_datetime(df_practice["CREATED_DATE"]).dt.strftime('%H:%M:%S')
    df_practice['last_date']=pd.to_datetime(df_practice["LAST_PRACTICE_DATE"]).dt.strftime('%Y-%m-%d')
    df_practice['first_date']=pd.to_datetime(df_practice["CREATED_DATE"]).dt.strftime('%Y-%m-%d')
    df_practice=df_practice.iloc[np.where(df_practice['last_date']==df_practice['first_date'])]
    df_practice=df_practice.reset_index()
    minutes=[]
    for i in np.arange(0,len(df_practice)):
        s1 = df_practice['first_time'][i]
        s2 =  df_practice['last_time'][i]
        FMT = '%H:%M:%S'
        tdelta = datetime.strptime(s2, FMT) - datetime.strptime(s1, FMT)
        minutes.append(tdelta.seconds / 60)
    df_practice['time_duration']=minutes
    df_practice['time_duration']=round(df_practice['time_duration'],2)
    df_practice = df_practice.drop(df_practice[df_practice.time_duration == 0.00].index)
    df_practice['time_interval'] = df_practice.groupby('USER_NAME')['CREATED_DATE'].diff() / np.timedelta64(1, 'm')
    df_practice=df_practice.reset_index()
    
#     --------------------------# time_duration=LAST_PRACTICE_DATE_time-CREATED_DATE_time--------------------------
#     --------------------------# time_interval=CREATED_DATE_time[i-1]-CREATED_DATE_time[i]--------------------------
    
    df_practice['signup_date_month']=pd.to_datetime(df_practice["first_date"]).dt.strftime('%Y-%m')
    df_practice['Practice_hours']=pd.to_datetime(df_practice["CREATED_DATE"]).dt.strftime('%H')
    df_practice_time_duration=df_practice.groupby(['signup_date_month']).agg({'USER_NAME': 'nunique','CREATED_DATE':'count','time_duration':'mean',
                                                                               'time_interval':'mean'}).reset_index()
    df_practice_time_duration.columns = ['signup_date_month','USER_count','practice_count','avg_practice_duration_minutes',
                                         'avg_practice_interval_minutes']
    df_practice_time_duration['avg_practice_interval_days']=(df_practice_time_duration['avg_practice_interval_minutes']/60)/24
    df_practice_time_duration['avg_practice_duration_minutes']=round(df_practice_time_duration['avg_practice_duration_minutes'],2)
    df_practice_time_duration['avg_practice_interval_minutes']=round(df_practice_time_duration['avg_practice_interval_minutes'],2)
    df_practice_time_duration['avg_practice_interval_days']=round(df_practice_time_duration['avg_practice_interval_days'],2)
    practice_duration_monthly=df_practice_time_duration
    # practice_duration_monthly
    dict_practice_duration_monthly={'total':
                   {
                        'yearly_month':practice_duration_monthly['signup_date_month'].to_list(),
                        'total_USER_count':practice_duration_monthly['USER_count'].to_list(),
                        'total_practice_count':practice_duration_monthly['practice_count'].to_list(),
                        'avg_practice_duration_in_minutes':practice_duration_monthly['avg_practice_duration_minutes'].to_list(),
                        'avg_practice_interval_in_minutes':practice_duration_monthly['avg_practice_interval_minutes'].to_list(),
                        'avg_practice_interval_in_days':practice_duration_monthly['avg_practice_interval_days'].to_list()
                   }
                    }
#     dict_practice_duration_monthly        
    return json.dumps(dict_practice_duration_monthly)

@app.route("/practice_duration_hourly")
def practice_duration_hourly():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    
    collection_practice=db.audio_track_master
    user_practice=[
    {
            "$match":
        {"$and":
            [           
            {"USER_ID.EMAIL_ID":{"$not":{"$regex":"test","$options":"i"}}},
            {"USER_ID.EMAIL_ID":{"$not":{"$regex":"1gen","$options":"i"}}},
            {"USER_ID.USER_NAME":{"$not":{"$regex":"test","$options":"i"}}},
            {"USER_ID.USER_NAME":{"$not":{"$regex":"user","$options":"i"}}},
            {"USER_ID.DISTRICT_ID.DISTRICT_NAME":{"$not":{"$regex":"test","$options":"i"}}},
            {"USER_ID.DISTRICT_ID.DISTRICT_NAME":{"$not":{"$regex":"user","$options":"i"}}},
            {"USER_ID.IS_BLOCKED" :{"$ne":"Y"}},
            {"USER_ID.IS_DISABLED" : {"$ne":"Y"}},
            {"USER_ID.INCOMPLETE_SIGNUP" : {"$ne":"Y"}}
            ]
        }
    },  
    {
        "$project":
            {   
            "_id":"$USER_ID._id",
            "USER_NAME":"$USER_ID.USER_NAME",  
            "LAST_PRACTICE_DATE":"$MODIFIED_DATE",
            "CREATED_DATE" :"$CREATED_DATE",
            } 
    }
    ]
    update_practice= list(collection_practice.aggregate(user_practice))
    df_practice=pd.DataFrame(update_practice)
    df_practice['last_time']=pd.to_datetime(df_practice["LAST_PRACTICE_DATE"]).dt.strftime('%H:%M:%S')
    df_practice['first_time']=pd.to_datetime(df_practice["CREATED_DATE"]).dt.strftime('%H:%M:%S')
    df_practice['last_date']=pd.to_datetime(df_practice["LAST_PRACTICE_DATE"]).dt.strftime('%Y-%m-%d')
    df_practice['first_date']=pd.to_datetime(df_practice["CREATED_DATE"]).dt.strftime('%Y-%m-%d')
    df_practice=df_practice.iloc[np.where(df_practice['last_date']==df_practice['first_date'])]
    df_practice=df_practice.reset_index()
    minutes=[]
    for i in np.arange(0,len(df_practice)):
        s1 = df_practice['first_time'][i]
        s2 =  df_practice['last_time'][i]
        FMT = '%H:%M:%S'
        tdelta = datetime.strptime(s2, FMT) - datetime.strptime(s1, FMT)
        minutes.append(tdelta.seconds / 60)
    df_practice['time_duration']=minutes
    df_practice['time_duration']=round(df_practice['time_duration'],2)
    df_practice = df_practice.drop(df_practice[df_practice.time_duration == 0.00].index)
    df_practice['time_interval'] = df_practice.groupby('USER_NAME')['CREATED_DATE'].diff() / np.timedelta64(1, 'm')
    df_practice=df_practice.reset_index()
    
#     --------------------------# time_duration=LAST_PRACTICE_DATE_time-CREATED_DATE_time--------------------------
#     --------------------------# time_interval=CREATED_DATE_time[i-1]-CREATED_DATE_time[i]--------------------------
    
    df_practice['signup_date_month']=pd.to_datetime(df_practice["first_date"]).dt.strftime('%Y-%m')
    df_practice['Practice_hours']=pd.to_datetime(df_practice["CREATED_DATE"]).dt.strftime('%H')
    df_practice_time_duration=df_practice.groupby(['Practice_hours']).agg({'USER_NAME': 'nunique','CREATED_DATE':'count','time_duration':'mean',
                                                                               'time_interval':'mean'}).reset_index()
    df_practice_time_duration.columns = ['Practice_hours','USER_count','practice_count','avg_practice_duration_minutes',
                                         'avg_practice_interval_minutes']
    df_practice_time_duration['avg_practice_interval_days']=(df_practice_time_duration['avg_practice_interval_minutes']/60)/24
    df_practice_time_duration['avg_practice_duration_minutes']=round(df_practice_time_duration['avg_practice_duration_minutes'],2)
    df_practice_time_duration['avg_practice_interval_minutes']=round(df_practice_time_duration['avg_practice_interval_minutes'],2)
    df_practice_time_duration['avg_practice_interval_days']=round(df_practice_time_duration['avg_practice_interval_days'],2)
    practice_duration_hourly=df_practice_time_duration
    # practice_duration_hourly
    dict_practice_duration_hourly={'total_1':
                {
                        'Practice_hours':practice_duration_hourly['Practice_hours'].to_list(),
                        'total_USER_count':practice_duration_hourly['USER_count'].to_list(),
                        'total_practice_count':practice_duration_hourly['practice_count'].to_list(),
                        'avg_practice_duration_in_minutes':practice_duration_hourly['avg_practice_duration_minutes'].to_list(),
                        'avg_practice_interval_in_minutes':practice_duration_hourly['avg_practice_interval_minutes'].to_list(),
                        'avg_practice_interval_in_days':practice_duration_hourly['avg_practice_interval_days'].to_list()                 
                }
                }
#     dict_practice_duration_hourly       
    return json.dumps(dict_practice_duration_hourly)

@app.route('/d1_chart')
def d1_chart_data():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1 = db.school_master.aggregate([
    {"$match":
        {"$and":[
    {'CATEGORY':{"$not":{"$regex":'null', '$options':'i'}}}]}},
    {"$project":{"ID":"$_id","school_name":"$NAME","district_name":"$CATEGORY"}}

    ])
    df67= DataFrame(list(collection1)).fillna(0)
    school_list=df67["ID"].tolist()
    collection = db.user_master.aggregate([
    {"$match":
        {"$and":[
        {"schoolId._id":{"$in":school_list}},
             {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}},
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME","USER_NAME":"$USER_NAME",
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME"}}

    ])
    df1= DataFrame(list(collection)).fillna(0)
    collection2 = db.user_master.aggregate([
    {"$match":
        {"$and":[
        {"schoolId._id":{"$in":school_list}},
            {'IS_DISABLED':{"$ne":'Y'}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
             {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
        {"$match":{"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}},
    {"$project":{"USER_IDf":"$_id","ID":"$schoolId._id"}}
    ])
    df12= DataFrame(list(collection2)).fillna(0)
    user_list=df1["USER_ID"].tolist()
    collection3d = db.audio_track_master
    query6d=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}       
              ]}},
              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},
             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_active_csy=list(collection3d.aggregate(query6d))
    school_prac_active_csy_df=pd.DataFrame(school_prac_active_csy)
    df34= pd.merge(school_prac_active_csy_df, df67,left_on='SCHOOL_ID', right_on='ID', how='right').fillna(0)
    df34=df34.groupby(["district_name"])["Active_User","Practice_Sessions","Mindful_Minutes"].sum().reset_index()
    final2 = pd.merge(df1, df67, on="ID", how='right').fillna(0)
    final23 = pd.merge(df12, df67, on="ID", how='right').fillna(0)
    df243=final23.groupby(["district_name"])["USER_IDf"].count().reset_index()
    df2=final2.groupby(["district_name_y","school_name_y"])["USER_ID"].count().reset_index()
    df3=df2.groupby('district_name_y').agg({'school_name_y':'count', 'USER_ID': 'sum'}).reset_index()
    final345 = pd.merge(df3, df243,left_on='district_name_y', right_on='district_name', how='left').fillna(0)
    final_to_final=final345[["district_name_y","school_name_y","USER_ID","USER_IDf"]]
    final_to_final.columns=["DISTRICT_NAME","SCHOOL_COUNT","USER_COUNT","PARENT"]
    final24524 = pd.merge(final_to_final, df34,left_on='DISTRICT_NAME', right_on='district_name', how='left').fillna(0)
    fi=final24524[["DISTRICT_NAME","SCHOOL_COUNT","USER_COUNT","PARENT","Active_User","Practice_Sessions","Mindful_Minutes"]]
    fgt=fi.groupby(["DISTRICT_NAME"], sort=False)["SCHOOL_COUNT","USER_COUNT","PARENT","Active_User","Practice_Sessions","Mindful_Minutes"].max().reset_index()
    micro_list=["Adams 12 Five Star Schools","Adams County School District 14","Ann Arbor Public Schools","Apple Valley Unified School District","Aurora Public Schools","Austin Independent School District","Berkeley Public Schools","Bishop Unified School District","Bismarck Public Schools","Boston Public Schools","Boulder Valley School District","Canyons School District","Chicago Public Schools","Colton Joint Unified School District","Dennis-Yarmouth Regional School District","Denver Public Schools","Durham Public Schools","FITCHBURG PUBLIC SCHOOLS","Fairfax County Public Schools","Falmouth Public Schools","Fulton County School System","Glenbard District 87","Granite School District","Greenburgh North Castle Union Free School District","Griffin-Spalding County School System","Hartford Public Schools","Helena Public Schools","HidalgoIndependent School district","Hopedale Public Schools","Houston Independent School District","KIPP Public Schools","Kearsarge Regional School District","Lamar Consolidated Independent School District","Lincolnshire Schools","Littleton Public Schools","Manatee County School District","Miami-Dade County Public Schools","Middleton-Cross Plains Area School District","Mill Valley School District","Millard School District","Muscatine Community School District","Northside Independent School District","Paterson School District","Rich School District","San Francisco Unified School District","San Jose Unified School District","San Marcos Unified School District","San Marino Unified School District","School District of Palm Beach County","School District of the Chathams","Sevier School District","South Summit School District","Sudbury Public Schools","Tooele County School District","Upland Unified School District","Wasatch County School District","Washoe County School District","West Contra Costa Unified School District","Westford Public Schools","White River School District"]
    non_micro1=["Agawam School district","Belleville School District","Broward County Public Schools","Champlain Valley School District","Chico Unified School District","Chula Vista Elementary School District","Clarksville-Montgomery County School System","Community Consolidated School District 89","Comox Valley School District","Douglas County School District","Early learning Sarasota","Englewood Public School District","Fairfield-Suisun Unified School District","Flint Public Schools","Goleta District","Hillsborough County","Krum Independent School District","LAUSD","LSF-Head Start","La Joya School District","Mt. Lebanon School District","NYC - Queens South","Needham School District","Oakland Unified School District","Ogden school district","Oroville City Elementary School District","Oswego School District","Paradise Unified School District","Pinellas County Schools","Racine Unified Schools","Salt Lake City School District","San Diego Unified School District","San Leandro Unified School District","Sarasota County","Springfield Public School","Wayne Metro","Westfield Public School District","Wichita Falls Independent School District","Youngstown"]
    TOTAL=[*micro_list ,*non_micro1]
    fi=fi[fi.DISTRICT_NAME.isin(TOTAL)]
    collection1 = db.school_master.aggregate([ {"$match":{'$and':[
            {"_id":{"$in":db.user_master.distinct( "schoolId._id" )}},
            {'CATEGORY':{'$exists':1}},    
            ]}
                },
            {"$project":{"_id":1,"CATEGORY":1
                       }}])
    df67C= DataFrame(list(collection1)).fillna(0)
    df67CC=fi[df67C.CATEGORY.isin(TOTAL)]
    df243C=df67C.groupby(["CATEGORY"])["_id"].count().reset_index()
    df243Cd=df243C[df243C.CATEGORY.isin(TOTAL)]
    dffine=pd.merge(fi, df243Cd, how='left', left_on=['DISTRICT_NAME'], right_on=['CATEGORY']).fillna(0)
    microdf=dffine[dffine.DISTRICT_NAME.isin(micro_list)]
    non_micro=dffine[dffine.DISTRICT_NAME.isin(non_micro1)]
    azs=str(sum(microdf["SCHOOL_COUNT"]))
    asdd=str(sum(non_micro["SCHOOL_COUNT"]))
    microname=microdf["DISTRICT_NAME"].to_list()
    microcount=microdf["SCHOOL_COUNT"].to_list()
    no_micro=non_micro["DISTRICT_NAME"].to_list()
    no_microcount=non_micro["SCHOOL_COUNT"].to_list()
    temp={
    "total_d1_practice":int(sum(dffine["Practice_Sessions"])),
    "total_d1_school":int(sum(dffine["SCHOOL_COUNT"])),
    "total_teacher_count":str(int(sum(dffine["USER_COUNT"]))),
    "total_parents_count":str(int(sum(dffine["PARENT"]))),

    "micro_teacher_count":str(int(sum(microdf["USER_COUNT"]))),
    "micro_parents_count":str(int(sum(microdf["PARENT"]))),
    
    "non_micro_teacher_count":str(int(sum(non_micro["USER_COUNT"]))),
    "non_micro_parents_count":str(int(sum(non_micro["PARENT"]))),
          
    "non_micro_school_practice":str(int(sum(non_micro["Practice_Sessions"]))),
          
    "micro_school_practice":str(int(sum(microdf["Practice_Sessions"]))),
    "micro_school_count":azs,
    "non_micro_school_count":asdd, 
    'micro_name':microname,"micro_count":microcount,"no_micro":no_micro,"no_micro_count":no_microcount}
    return json.dumps(temp)

@app.route('/d1_admin/<district>')
def d1_admin_table(district):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.subscription_master
    qr1=[{'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'USER_ID.schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{'_id':'$USER_ID.schoolId._id' , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}}
    },
         {'$project':{'_id':1, 'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}
                     }
    ]
    collection2= db.audio_track_master
    qrB= [
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'USER_ID.schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{'_id':'$USER_ID.schoolId._id','SCHOOL_PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
          {'$project':{'_id':1,'SCHOOL_PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date": "$practice_date" }}}}
    ]
    
    collection3= db.user_master
    qrC=[
        {'$match':{"schoolId":{'$exists':True}}},
    {'$match':{"schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},{'IS_ADMIN':{'$eq':'Y'}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{'_id':'$schoolId._id','STATE':{'$first':'$schoolId.STATE'}
              }},
    {'$project':{'_id':1, 'STATE':1}}
     ]
    
    collection30= db.user_master
    qrC0=[
        {'$match':{"schoolId":{'$exists':True}}},
    {'$match':{"schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'schoolId._id':{'$in':db.school_master.distinct('_id',{'CATEGORY':{'$regex':district,'$options':'i'}})}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{'_id':'$schoolId._id','USER_COUNT':{'$addToSet':'$_id'}
              }},
    {'$project':{'_id':1, 'USER_COUNT':{'$size':'$USER_COUNT'}}}
     ]
    
    
    
    list1= list(collection1.aggregate(qr1))
    df_sub= DataFrame(list1)
    print(len(df_sub),"sub")
    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    print(len(df_atma),"sub")
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    print(len(df_um),"um")
    list30= list(collection30.aggregate(qrC0))
    df_um30= DataFrame(list30)
    print(len(df_um30),"um30")
    
    join1= pd.merge(df_sub, df_atma, how='left', on='_id')
    join2= pd.merge(df_um, df_um30, how='left', on='_id')
    join_final1= pd.merge(join1, join2, how='left', on='_id')
    
    
    collection11= db.user_master
    qr11=[
    {'$match':{"schoolId":{'$exists':True}}},
        
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'schoolId._id':{'$in':db.school_master.distinct('_id',{'CATEGORY':{'$regex':district,'$options':'i'}})}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},{'IS_ADMIN':{'$eq':'Y'}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},

    {'$group':{'_id':'$schoolId._id','ADMIN_NAME':{'$first':'$USER_NAME'},'user_id':{'$first':'$_id'},
    'SCHOOL_NAME':{'$first':'$schoolId.NAME'}, 'ADMIN_EMAIL':{'$first':'$EMAIL_ID'}
    }}
        ]
    
    
    collection12=db.audio_track_master
    qr12=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'USER_ID.schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
        
    {'$group':{'_id':'$USER_ID.schoolId._id', 'user_id':{'$first':'$USER_ID._id'}
    }}
        ]
    collection13= db.subscription_master
    qr13=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'USER_ID.schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},
    {'USER_ID.schoolId._id':{'$in':db.school_master.distinct('_id',{'CATEGORY':{'$regex':district,'$options':'i'}})}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{'_id':'$USER_ID.schoolId._id'
               , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}
              }},
        {'$project':{'_id':1,
                     'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}}
    ]
    list11= list(collection11.aggregate(qr11))
    df_um= DataFrame(list11)
    list12=list(collection12.aggregate(qr12))
    df_atm= DataFrame(list12)
    list13= list(collection13.aggregate(qr13))
    df_sbm= DataFrame(list13)
    join12= pd.merge(df_sbm, df_atm, how='left', on='_id')
    join_final12= pd.merge(join12,df_um, how='left', on='_id')
    inner_join_df= pd.merge(join_final1, join_final12,  on='_id', how='inner')
    inner_join_df['SCHOOL_NAME'].fillna('NO SCHOOL FOUND', inplace=True)
    inner_join_df['ADMIN_NAME'].fillna('NO USER INFO', inplace=True)
    inner_join_df['SCHOOL_PRACTICE_COUNT'].fillna('NO PRACTICE', inplace=True)
    inner_join_df['STATE'].fillna('NO INFO', inplace=True)
    inner_join_df['ADMIN_EMAIL'].fillna('NO INFO', inplace=True)
    inner_join_df['USER_COUNT'].fillna('NO USER', inplace=True)
    inner_join_df['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
#     inner_join_df['RENEWAL_DATE'].fillna('NO SUBSCRIPTION', inplace=True)
# inner_join_df
    data_final1= inner_join_df[['SCHOOL_NAME','ADMIN_NAME','ADMIN_EMAIL','RENEWAL_DATE_x','SCHOOL_PRACTICE_COUNT','LAST_PRACTICE_DATE','USER_COUNT']]
#     final_group=data_final1.groupby(data_final1['ADMIN_NAME'])
#     data1 = pd.DataFrame(final_group)
    temp={'data':data_final1.values.tolist()}
    return json.dumps(temp)


@app.route("/spanish_narrator_usage")
def spanish_narrator_usage_detail():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    
    collection_home=db.user_master
    user= [
    {
        "$match":{"$and":
        [
        {"_id":{"$in": db.audio_track_master.distinct("USER_ID._id",
                                                      {"PROGRAM_AUDIO_ID.LANGUAGE":{"$regex":"spanish","$options":"i"}})}},
        {"DEVICE_USED" : "webApp"},
        {"EMAIL_ID":{"$not":{"$regex":"test","$options":"i"}}},
        {"EMAIL_ID":{"$not":{"$regex":"1gen","$options":"i"}}},
        {"USER_NAME":{"$not":{"$regex":"test","$options":"i"}}},
        {"USER_NAME":{"$not":{"$regex":"user","$options":"i"}}},
        {"DISTRICT_ID.DISTRICT_NAME":{"$not":{"$regex":"test","$options":"i"}}},
        {"DISTRICT_ID.DISTRICT_NAME":{"$not":{"$regex":"user","$options":"i"}}},
        {"IS_BLOCKED" :{"$ne":"Y"}},
        {"IS_DISABLED" : {"$ne":"Y"}},
        {"INCOMPLETE_SIGNUP" : {"$ne":"Y"}},
        ]}
    },
    {
    "$project":
    {
   
    "created date":"$CREATED_DATE",
    "user name":"$USER_NAME",
    "EMAIL ID":"$EMAIL_ID",
    "ROLE_ID":"$ROLE_ID.ROLE_ID",
    "DISTRICT_NAME" :"$DISTRICT_ID.DISTRICT_NAME",
    "school id":"$schoolId._id",
    "school name":"$schoolId.NAME",
    "school address":"$schoolId.ADDRESS",
    "school city":"$schoolId.CITY",
    "school state":"$schoolId.STATE",        
    "school country":"$schoolId.COUNTRY"
    }
    }
    ]
    update=list(collection_home.aggregate(user))
    df_home=pd.DataFrame(update)
    df_home=df_home[(df_home['created date'] >= '2019-03-01')]
    list_names=df_home['_id'].tolist()
    collection_practice=db.audio_track_master
    user_practice=[
    {
    "$match":{"$and":
        [
        {"USER_ID._id":{"$in": list_names}},
        ]} 
    },
    {
        "$group":
        {
        "_id":"$USER_ID._id","USER_PRACTICE_COUNT":{"$sum":1},
        "USER_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}},
        "LAST_PRACTICE_DATE":{"$first":"$MODIFIED_DATE"},
        "NARRATED_BY" :{"$first":"$PROGRAM_AUDIO_ID.NARRATEDBY"}
        }
    },
    {
    "$project":
    {
        "USER_PRACTICE_COUNT":1,
        "USER_MINDFUL_MINUTES":1,
        "LAST_PRACTICE_DATE":1,
        "NARRATED_BY" : 1
    } 
    }
     ]
    update_practice= list(collection_practice.aggregate(user_practice))
    df_practice=pd.DataFrame(update_practice)
    
    collection_feed=db.audio_feedback
    user_feed=[
    {
    "$match":{"$and":
        [
        {"USER._id":{"$in": list_names}},
        {"RATING":{"$exists":1}},
        {"RATING":{"$ne":0}}
        ]} 
    },
    {
        "$group":
        {
        "_id":"$USER._id",
        "MODIFIED_DATE":{"$max":"$MODIFIED_DATE"},
        "RATING":{"$max":"$RATING"},        
        "AUDIO_NAME" : {"$first":"$AUDIO_ID.AUDIO_TITLE"}
        }
    },
    {
    "$project":
        {
            "RATING" : 1,
            "MODIFIED_DATE": 1,
            "AUDIO_NAME" : 1
        } 
    }
    ]
    
    update_feed= list(collection_feed.aggregate(user_feed))
    df_feed=pd.DataFrame(update_feed)
    df_merge=pd.merge(df_home,df_practice,on="_id",how="left")
    final_df=pd.merge(df_merge,df_feed,on="_id",how="inner")
    final_df['created date']=pd.to_datetime(final_df["created date"]).dt.strftime('%Y')
    final_df['MODIFIED_DATE']=pd.to_datetime(final_df["MODIFIED_DATE"]).dt.strftime('%Y-%m-%d')
    
    df_narrator = final_df.groupby(['NARRATED_BY','RATING',"AUDIO_NAME"])["MODIFIED_DATE"].agg(['max']).reset_index()
    df_narrator.columns = ['NARRATED_BY','RATING',"AUDIO_NAME","MODIFIED_DATE"]
    df_narrator_narrator=df_narrator['NARRATED_BY'].to_list()
    df_narrator_audio=df_narrator['AUDIO_NAME'].to_list()
    df_narrator_RATING=df_narrator['RATING'].to_list()
    df_narrator_date=df_narrator['MODIFIED_DATE'].to_list()
    dict_narrator={'total':
                {'df_narrator_narrator':df_narrator_narrator,
                'df_narrator_audio':df_narrator_audio,
                'df_narrator_RATING':df_narrator_RATING,
                'df_narrator_date':df_narrator_date}
                }
        
    return json.dumps(dict_narrator)

@app.route('/quest_activation_by_district')
def activation_district():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    df_user= DataFrame(list(db.user_master.aggregate([
    {"$match":{'$and':[
    {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_NAME":{ "$ne": ""}},{"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
    {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
    {"EMAIL_ID":{ "$ne": ""}},{'IS_BLOCKED':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'schoolId._id':{'$in':db.school_master.distinct('_id',{'CATEGORY':{'$exists':1}})}},
    {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_QUEST_OBTAINED':'Y'},
    {'QUEST_OBTAINED_DATE':{'$gte':datetime.datetime(2021,8,1)}}

    ]}},

    {'$group':{'_id':'$schoolId._id', 'district_name':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
              'user_count':{'$sum':1}
              }}

    ])))
    schoolids=df_user['_id'].tolist()

    df_school= DataFrame(list(db.school_master.aggregate([
        {"$match":
            {"$and":[
        {'IS_PORTAL':'Y'},
        {'CATEGORY':{"$exists":1}}]}},
        {"$group":{"_id":"$_id","school_name":{'$first':"$NAME"},"district_name":{'$first':"$CATEGORY"}}}
    ])))

    merge1=pd.merge(df_user,df_school, on='_id', how='left')

    merge1.fillna(0,inplace=True)

    merge2=merge1.loc[merge1['district_name_x']!=0]


    merge3=merge2.groupby(['district_name_x'],as_index=False).sum()
    merge4=merge3.nlargest(20,['user_count'])


    temp={'district':merge4['district_name_x'].tolist(), 'users':merge4['user_count'].tolist()}
    return json.dumps(temp)



@app.route('/queststreak')
def queststreakss():
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.user_master.aggregate([
    {"$match":
        {"$and":[ 
           {"IS_QUEST_OBTAINED":"Y"},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'QUEST_OBTAINED_DATE':{'$gte':datetime.datetime(2021,8,1)}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"_id":0,"USER_ID":"$_id",
                "QUEST_OBTAINED_DATE":{"$dateToString": { "format": "%Y-%m-%d", "date": "$QUEST_OBTAINED_DATE"}}}}
    ])
    df= DataFrame(list(collection)).fillna(0)
    user_list=df["USER_ID"].tolist()

    collection1 =db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list
                        }}},
        {"$match":
            {"$and":[
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":datetime.datetime(2021,1,14)}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}
    ]}}
        ,
        {"$group":{"_id":{"USER_ID":"$USER_ID._id",'MODIFIED_DATE':'$MODIFIED_DATE'},
                "NEW":{"$addToSet":"$USER_ID._id"},
                "count":{"$sum":1},
                "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
                }},
            {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","MODIFIED_DATE":{ "$dateToString": { "format": "%Y-%m-%d", "date":"$_id.MODIFIED_DATE"}},"practice_count12":"$count"}}
        ])

    df1= DataFrame(list(collection1)).fillna(0)
    df3=pd.merge(df, df1, on='USER_ID',how='right').fillna(0)


    df3.loc[(df3['MODIFIED_DATE'] >= df3['QUEST_OBTAINED_DATE']) & (df3['USER_ID'] == df3['USER_ID']), 'hex'] = '#00a651'  #ACTIVE

    df3.drop(df3[df3['hex'] != "#00a651"].index, inplace = True) 
    df4=df3.groupby(["USER_ID","MODIFIED_DATE"])["practice_count12"].count().reset_index()
    df4['Dates'] = pd.to_datetime(df4["MODIFIED_DATE"]).dt.day
    df4['MODIFIED_DATE'] = pd.to_datetime(df4["MODIFIED_DATE"])

    min_practice=df4.groupby(['USER_ID'])['MODIFIED_DATE'].min().reset_index()

    min_practice['30_days_ahead']= min_practice['MODIFIED_DATE'] +datetime.timedelta(days=30)
    min_practice['30_days_ahead'] = pd.to_datetime(min_practice["30_days_ahead"])

    dfff=pd.merge(df4,min_practice, on='USER_ID', how='left')


    dfff1=dfff.loc[dfff['30_days_ahead'] >= dfff['MODIFIED_DATE_x']]


    s = dfff1.groupby(['USER_ID'])['MODIFIED_DATE_x'].diff().dt.days.ne(1).cumsum()
    df5=dfff1.groupby(['USER_ID', s]).size().reset_index(level=1, drop=True)
    streak=df5.reset_index()
    streak.columns=["USER_ID","STREAK"]
    user_streak=streak.groupby(["USER_ID"])["STREAK"].sum().reset_index()
    user_streak1=user_streak.groupby(["STREAK"]).count().reset_index()
    created_date= [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30]
    df2static = pd.DataFrame(created_date,columns =['STREAK'])
    finalstreak = pd.merge(df2static, user_streak1, on="STREAK", how='left').fillna(0)
    temp={"STREAK":finalstreak["USER_ID"].tolist(),"streak_count":int(finalstreak["USER_ID"].sum())}
    return json.dumps(temp)



@app.route('/quest_cards')
def card_questtt():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    df= DataFrame(list(db.user_master.aggregate([
    {"$match":{'$and':[
    {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_NAME":{ "$ne": ""}},{"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
    {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
    {"EMAIL_ID":{ "$ne": ""}},{'IS_BLOCKED':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_QUEST_OBTAINED':'Y'},

#     {'QUEST_OBTAINED_DATE':{'$gte':datetime.datetime(2022,1,17), '$lte':datetime.datetime(2022,2,10)}}

    ]}},
    { "$group": {'_id':'$_id', 'email':{'$first':'$EMAIL_ID'}, 'username':{'$first':'$USER_NAME'},
                 'quest_obtained':{'$first':'$QUEST_OBTAINED_DATE'},
    'school':{'$first':'$schoolId.NAME'}, 'schoolid':{'$first':'$schoolId._id'},
    'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}                                    
                                       }}
     ])))
    schoolidss=df['schoolid'].tolist()
    userids=df['_id'].tolist()
    dfschool=DataFrame(list(db.school_master.aggregate([
        {'$match':{'$and':[
         {'_id':{'$in':schoolidss}}
    ]}},
    {'$group':{'_id': '$_id', 'category':{'$first':'$CATEGORY'}  
              }}                                                  

         ]                                                )))
    merge1=pd.merge(df, dfschool, left_on='schoolid', right_on='_id', how='left')
    practice = DataFrame(list(db.audio_track_master.aggregate([
    {"$match":{
    '$and':[
    { "USER_ID._id":{"$in":userids}},
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    ]}},

    # {'$group':{'_id':'$USER_ID._id', 'pc':{'$sum':1}}}

    {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
                'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}
                }}


    ]))    )       
    merge2=pd.merge(merge1,practice, left_on='_id_x', right_on='_id', how='left')
    merge2=merge2[merge2['modified_date']>= merge2['quest_obtained']]
    merge3=merge2[['_id_x','email','quest_obtained','school','schoolid','category','modified_date', 'mindful_minutes']]
    merge3['quest_obtained']=merge3['quest_obtained'].dt.strftime("%Y-%m-%d")
    merge3['modified_date']=merge3['modified_date'].dt.strftime("%Y-%m-%d")
    merge5= merge3.groupby(['_id_x','email','modified_date'], as_index=False).size()
    merge44=pd.merge(merge5, merge1, on='_id_x', how='left')
    merge44=merge44.drop_duplicates(subset=['email_x'])
    merge44=merge44.rename(columns={'email_x':'EMAIL ID', 'username':'USER NAME', 'quest_obtained':'QUEST OBTAINED ON', 'school':'SCHOOL NAME',
    'category':'DISTRICT'                       
                           })
    merge55=merge44[['SCHOOL NAME', 'EMAIL ID', 'USER NAME', 'QUEST OBTAINED ON', 'DISTRICT']]
    merge55['DISTRICT']=merge55['DISTRICT'].replace({'NULL':'NOT FOUND'})
    merge55['QUEST OBTAINED ON']=merge55['QUEST OBTAINED ON'].dt.strftime("%Y-%m-%d")


    pc=merge3.groupby(['_id_x'], as_index=False).count()
    pc['modified_date'].sum()


    users_activated=len(df)
    users_practiced= len(merge44)

    practice_sessions= len(merge3)
    mindful_minutes=round(merge3['mindful_minutes'].sum())
    
    
    
    collection__ = db.user_quest_history.aggregate([{"$match":
    {"$and":[ {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},{'IS_QUEST_COMPLETED':'Y'},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    
    {"$match":{"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}},
    
    {'$group':{'_id':"$USER_ID._id",'Practice_Sessions':{'$sum':1}}}    
                                                 ])

    df__= DataFrame(list(collection__)).fillna(0)
    idss=df__['_id'].tolist()

    collection1__ = db.user_master.aggregate([
    {"$match":
    {"$and":[ 
    {"IS_QUEST_OBTAINED":"Y"},{'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'QUEST_OBTAINED_DATE':{'$gte':datetime.datetime(2021,8,1)}},
    {'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},{'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
    {'_id':{'$in':idss}}    
    ]}},
    {'$group':{'_id':'$_id','Practice_Sessions':{'$sum':1}
    }},
    # {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","COUNT":"$Practice_Sessions"}}


    ])
    df1__= DataFrame(list(collection1__)).fillna(0)
    completed= len(df1__)
    
    temp={'total_users_activated':int(users_activated), 'users_practiced':int(users_practiced), 'Practice_sessions':int(practice_sessions),'Mindful_minutes':int(mindful_minutes),
    'Total_users_completed':   int(completed)  
         }
    return json.dumps(temp) 


@app.route('/questactivestreak')
def questactivestreak():
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.user_master.aggregate([
    {"$match":
        {"$and":[ 
           {"IS_QUEST_OBTAINED":"Y"},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"_id":0,"USER_ID":"$_id",
                "QUEST_OBTAINED_DATE":{"$dateToString": { "format": "%Y-%m-%d", "date": "$QUEST_OBTAINED_DATE"}}}}
    ])
    df= DataFrame(list(collection)).fillna(0)
    user_list=df["USER_ID"].tolist()
    collection1 =db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list
                        }}},
        {"$match":
            {"$and":[
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":datetime.datetime(2021,1,14)}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
        {"$match":
        {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        {"$group":{"_id":{"USER_ID":"$USER_ID._id",'MODIFIED_DATE':'$MODIFIED_DATE'},
                "NEW":{"$addToSet":"$USER_ID._id"},
                "count":{"$sum":1},
                "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
                }},
            {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","MODIFIED_DATE":{ "$dateToString": { "format": "%Y-%m-%d", "date":"$_id.MODIFIED_DATE"}},"practice_count12":"$count"}}
        ])
    df1= DataFrame(list(collection1)).fillna(0)
    df3=pd.merge(df, df1, on='USER_ID',how='right').fillna(0)
    df3.loc[(df3['MODIFIED_DATE'] >= df3['QUEST_OBTAINED_DATE']) & (df3['USER_ID'] == df3['USER_ID']), 'hex'] = '#00a651'  #ACTIVE
    df3.drop(df3[df3['hex'] != "#00a651"].index, inplace = True) 
    df4=df3.groupby(["USER_ID","MODIFIED_DATE"])["practice_count12"].count().reset_index()
    df4['Dates'] = pd.to_datetime(df4["MODIFIED_DATE"]).dt.day
    df4['MODIFIED_DATE'] = pd.to_datetime(df4["MODIFIED_DATE"])
    s = df4.groupby('USER_ID').MODIFIED_DATE.diff().dt.days.ne(1).cumsum()
    df5=df4.groupby(['USER_ID', s]).size().reset_index(level=1, drop=True)
    streak=df5.reset_index()
    streak.columns=["USER_ID","STREAK"]
    user_streak=streak.groupby(["USER_ID"])["STREAK"].max().reset_index()
    #################################Time_Diffrence#############################
    df3T=pd.merge(df, df1, on='USER_ID',how='right').fillna(0)
    df3T.loc[(df3T['MODIFIED_DATE'] == df3T['QUEST_OBTAINED_DATE']) & (df3T['USER_ID'] == df3T['USER_ID']), 'hex'] = '#00a651'  #ACTIVE
    df3T.drop(df3T[df3T['hex'] != "#00a651"].index, inplace = True) 
    df4T=df3T.groupby(["USER_ID","MODIFIED_DATE"])["practice_count12"].count().reset_index()
    df4T['Dates'] = pd.to_datetime(df4T["MODIFIED_DATE"]).dt.day
    df4T['MODIFIED_DATE'] = pd.to_datetime(df4T["MODIFIED_DATE"])
    df4T['Time_diff']= pd.to_datetime(df4T["MODIFIED_DATE"], errors='coerce') - pd.Timestamp.now().normalize()
    df4T['Time_diff']=df4T['Time_diff'].dt.days
    df4T['Time_diff'] = df4T['Time_diff'].abs()
    df6=pd.merge(df4T,user_streak,on="USER_ID",how="left")
    df6.drop(df6[df6['Time_diff'] != df6['STREAK']].index, inplace = True)
    user_Active_streak=df6.groupby(["STREAK"]).count().reset_index()
    created_date= [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]
    df2static = pd.DataFrame(created_date,columns =['STREAK'])
    finalstreak = pd.merge(df2static, user_Active_streak, on="STREAK", how='left').fillna(0)
    temp={"astreak":finalstreak["USER_ID"].tolist(),"astreak_count":int(finalstreak["USER_ID"].sum())}
    return json.dumps(temp)

@app.route('/questusercounts')
def questusercounts():
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.4527017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.user_quest_history.aggregate([{"$match":
        {"$and":[ 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}},
                                                {'$group':{
                    
                '_id':{"USER_ID":"$USER_ID._id"},
                'Practice_Sessions':{'$sum':1}
                }},
                {"$match":{"Practice_Sessions":{"$gte":2}}},
                {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","COUNT":"$Practice_Sessions"}}
                    
                ])
    df= DataFrame(list(collection)).fillna(0)
    collection1 = db.user_master.aggregate([
    {"$match":
        {"$and":[ 
        {"IS_QUEST_OBTAINED":"Y"},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {'$group':{

            '_id':{"USER_ID":"$_id"},
            'Practice_Sessions':{'$sum':1}
            }},
            {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","COUNT":"$Practice_Sessions"}}


    ])
    df1= DataFrame(list(collection1)).fillna(0)
    df3=pd.merge(df,df1,on="USER_ID",how="right").fillna(1)
    df4=df3.groupby("COUNT_x").count().reset_index()
    df5=pd.DataFrame(df4)
    temp={"name":df5["COUNT_x"].ravel().tolist(),"count":df5["USER_ID"].ravel().tolist()}
    return json.dumps(temp)

@app.route('/executive_count_productwise_lelo')
def executive_count_productwise_d3():    
    client_live= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@54.202.61.130:27017/')
    db_live=client_live.compass
    d3_users=pd.DataFrame(list(db_live.user_master.aggregate([
        {"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                    {'schoolId._id':{'$in':
                                    db_live.school_master.distinct('_id',{'DASH_CATEGORY':'D3'})                               

                                    }}

                    ]}},
        {'$project':{'_id':0,

            'userid':'$_id',
                     'email':'$EMAIL_ID',
                     'schoolid':'$schoolId._id'

        }}


    ])))

    user_masterd3=pd.DataFrame({'schoolid':list(set(d3_users['schoolid'])),
                               'status':1

                               })

    d3_user_sub_master=pd.DataFrame(list(db_live.subscription_master.aggregate([{'$match':{'$and':[
        {'USER_ID._id':{'$in':list(d3_users['userid'])}}


    ]}},                                  {'$project':{'_id':0,
                                           'userid':'$USER_ID._id',
                                           'PLAN_ID':'$PLAN_ID.PLAN_ID'

                                          }}

                                          ])))

    d3_plan_ids=d3_users.merge(d3_user_sub_master,how='left',on='userid')

    x=d3_plan_ids.groupby(['schoolid','PLAN_ID'])['userid'].count().reset_index()

    xx=x.groupby(['schoolid']).agg(School_Count=('schoolid','count'),
                             max_plan=('PLAN_ID','max')

                             ).reset_index()

    xx['PLAN_NAME']=''

    for i in range(len(xx)):
        if (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==18):
            xx['PLAN_NAME'][i]='Explorer'
        elif (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==19):
            xx['PLAN_NAME'][i]='Community'
        elif (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==20):
            xx['PLAN_NAME'][i]='Cloud'
        elif (xx['School_Count'][i]>1) &(xx['max_plan'][i]==17):
            xx['PLAN_NAME'][i]='Schoolapp'


    if len(xx[(xx['School_Count']>=1) & (xx['max_plan']==16)])>1:
        db_live.school_master.update_many({'_id':{'$in':list(xx[(xx['School_Count']>=1) & (xx['max_plan']==16)]['schoolid'])}},
                                         {'$set':{
                                             'DASH_CATEGORY':'Schoolapp'


                                         }}

                                         )

    elif len(xx[(xx['School_Count']==1) & (xx['max_plan']==17)])>1:
        db_live.school_master.update_many({'_id':{'$in':list(xx[(xx['School_Count']==1) & (xx['max_plan']==17)]['schoolid'])}},
                                         {'$set':{
                                             'DASH_CATEGORY':'Homeapp'

                                         }}

                                         )
    else:
        pass

    final_cloud_count=len(xx[xx['PLAN_NAME']=='Cloud'])
    final_com_count=len(xx[xx['PLAN_NAME']=='Community'])
    final_exp_count=len(xx[xx['PLAN_NAME']=='Explorer'])


    execount={"clound":str(final_cloud_count),"community":str(final_com_count),"explorer":str(final_exp_count)}
    
    
    return json.dumps(execount)

@app.route('/communitytabled3')
def communityexectable_D3():
    client_live= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@54.202.61.130:27017/')
    db_live=client_live.compass
    d3_users=pd.DataFrame(list(db_live.user_master.aggregate([
        {"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                    {'schoolId._id':{'$in':
                                    db_live.school_master.distinct('_id',{'DASH_CATEGORY':'D3'})                               
                                    }}
                    ]}},
        {'$project':{'_id':0,
            'userid':'$_id',
                     'USER NAME':'$USER_NAME',
                     'email':'$EMAIL_ID',
                     'SIGN UP':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}},
                     'schoolid':'$schoolId._id',
                     'STATE':'$schoolId.STATE',
                     'CITY':'$schoolId.CITY'
        }}
    ])))
    user_masterd3=pd.DataFrame({'schoolid':list(set(d3_users['schoolid'])),
                               'status':1
                               })
    d3_user_sub_master=pd.DataFrame(list(db_live.subscription_master.aggregate([{'$match':{'$and':[
        {'USER_ID._id':{'$in':list(d3_users['userid'])}}
    ]}},                                  {'$project':{'_id':0,
                                           'userid':'$USER_ID._id',
                                           'RENEWAL DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":'$SUBSCRIPTION_EXPIRE_DATE'}},
                                           'PLAN_ID':'$PLAN_ID.PLAN_ID'
                                          }}
                                          ])))
    d3_plan_ids=d3_users.merge(d3_user_sub_master,how='left',on='userid')
    # print(d3_plan_ids.columns)
    x=d3_plan_ids.groupby(['schoolid','PLAN_ID'])['userid','USER NAME', 'email', 'SIGN UP', 'STATE', 'CITY',
           'RENEWAL DATE'].count().reset_index()
    # print(x)
    xx=x.groupby(['schoolid']).agg(School_Count=('schoolid','count'),
                             max_plan=('PLAN_ID','max')
                             ).reset_index()
    # print(xx)

    xx['PLAN_NAME']=''
    for i in range(len(xx)):
        if (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==18):
            xx['PLAN_NAME'][i]='Explorer'
        elif (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==19):
            xx['PLAN_NAME'][i]='Community'
        elif (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==20):
            xx['PLAN_NAME'][i]='Cloud'
        elif (xx['School_Count'][i]>1) &(xx['max_plan'][i]==17):
            xx['PLAN_NAME'][i]='Schoolapp'
    if len(xx[(xx['School_Count']>1) & (xx['max_plan']==17)])>1:
        db_live.school_master.update_many({'_id':{'$in':list(xx[(xx['School_Count']>=1) & (xx['max_plan']==17)]['schoolid'])}},
                                         {'$set':{
                                             'DASH_CATEGORY':'Schoolapp'
                                         }}
                                         )
    elif len(xx[(xx['School_Count']==1) & (xx['max_plan']==17)])>1:
        db_live.school_master.update_many({'_id':{'$in':list(xx[(xx['School_Count']==1) & (xx['max_plan']==17)]['schoolid'])}},
                                         {'$set':{
                                             'DASH_CATEGORY':'Homaapp'
                                         }}
                                         )
    else:
        pass
    final_cloud_count=xx[xx['PLAN_NAME']=='Cloud']
    final_com_count=xx[xx['PLAN_NAME']=='Community']
    final_exp_count=xx[xx['PLAN_NAME']=='Explorer']
    execount={"clound":str(final_cloud_count),"community":str(final_com_count),"explorer":str(final_exp_count)}






    dflife=final_com_count
    # lifelist=list(dflife["0"])
    lifetimelist=final_com_count["schoolid"].to_list()
    # from bson import ObjectId
    # for i in lifelist:
    #     lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    overallum=pd.DataFrame(list(collection.aggregate([{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }   
    },
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    #   {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #   {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
    #   {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'IS_ADMIN':'Y'}

    ]
    }},

    {"$project":{"_id":0,
    'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
    "UMEMAIL":'$EMAIL_ID',  
    "CREATED_DATE":'$CREATED_DATE',
    "UMSCHOOLID":'$schoolId._id',
                 "UMSCHOOLNAME":'$schoolId.NAME',
                 "CITY":'$schoolId.CITY',
                 "STATE":'$schoolId.STATE',
                 "COUNTRY":'$schoolId.COUNTRY',
                }},
    ])))
    overallum["CREATED_DATE"]=overallum["CREATED_DATE"].dt.strftime('%d %b %Y')
    #     overallum.to_csv("expcheck.csv")
    email=list(overallum["UMUSER_ID"])
    schoolid=list(overallum["UMSCHOOLID"])
    ################################sub_master################################

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # db.subscription_master.ensureIndex("USER_ID._id", 1) 
    collection = db.subscription_master
    qr=[
    {"$match":{"$and":[{'USER_ID._id':{"$in":email}},
    {'PLAN_ID.PLAN_NAME':"Explorer"}
    ]}},
    {"$project":{"_id":0,
    'SMUSER_ID':'$USER_ID._id',
    "SMEMAIL":'$USER_ID.EMAIL_ID',
    "PLANID":"$PLAN_ID.PLAN_NAME",
    "comment":"$COMMENT_BY_DS_TEAM",
    "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
    }},]
    merge=list(collection.aggregate(qr))
    overall=pd.DataFrame(merge)
    overall["RENEWAL_DATE"]=overall["RENEWAL_DATE"].dt.strftime('%d %b %Y')
    #     mergeddf=pd.merge(overallum, overall, how='left', left_on='UMEMAIL', right_on='SMEMAIL')
    mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
    db=client.compass
    collection = db.audio_track_master
    qra=[
    {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 
    'atdLastpractice':{'$max':'$MODIFIED_DATE'},
    'atdPracticecount':{'$sum':1},
    'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}]
    merge11=list(collection.aggregate(qra))
    atd=pd.DataFrame(merge11)
    atd["atdLastpractice"]=atd["atdLastpractice"].dt.strftime('%d %b %Y')
    finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
    finalmerge['atdLastpractice'].fillna("NO PRACTICE", inplace=True)
    finalmerge['atdPracticecount'].fillna(0, inplace=True)
    finalmerge.fillna("NO INFO AVAILABLE", inplace=True)
    finaldata=finalmerge[["UMSCHOOLNAME","STATE","CITY","USER_NAME","UMEMAIL","CREATED_DATE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')
    print(len(lifetimelist),len(finaldata))
    return json.dumps({"data":finaldata.values.tolist()})

# return json.dumps(execount)




@app.route('/explorertabled3')
def explorerexectable_D3():
    client_live= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@54.202.61.130:27017/')
    db_live=client_live.compass
    d3_users=pd.DataFrame(list(db_live.user_master.aggregate([
        {"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                    {'schoolId._id':{'$in':
                                    db_live.school_master.distinct('_id',{'DASH_CATEGORY':'D3'})                               
                                    }}
                    ]}},
        {'$project':{'_id':0,
            'userid':'$_id',
                     'USER NAME':'$USER_NAME',
                     'email':'$EMAIL_ID',
                     'SIGN UP':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}},
                     'schoolid':'$schoolId._id',
                     'STATE':'$schoolId.STATE',
                     'CITY':'$schoolId.CITY'
        }}
    ])))
    user_masterd3=pd.DataFrame({'schoolid':list(set(d3_users['schoolid'])),
                               'status':1
                               })
    d3_user_sub_master=pd.DataFrame(list(db_live.subscription_master.aggregate([{'$match':{'$and':[
        {'USER_ID._id':{'$in':list(d3_users['userid'])}}
    ]}},                                  {'$project':{'_id':0,
                                           'userid':'$USER_ID._id',
                                           'RENEWAL DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":'$SUBSCRIPTION_EXPIRE_DATE'}},
                                           'PLAN_ID':'$PLAN_ID.PLAN_ID'
                                          }}
                                          ])))
    d3_plan_ids=d3_users.merge(d3_user_sub_master,how='left',on='userid')
    # print(d3_plan_ids.columns)
    x=d3_plan_ids.groupby(['schoolid','PLAN_ID'])['userid','USER NAME', 'email', 'SIGN UP', 'STATE', 'CITY',
           'RENEWAL DATE'].count().reset_index()
    # print(x)
    xx=x.groupby(['schoolid']).agg(School_Count=('schoolid','count'),
                             max_plan=('PLAN_ID','max')
                             ).reset_index()
    # print(xx)

    xx['PLAN_NAME']=''
    for i in range(len(xx)):
        if (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==18):
            xx['PLAN_NAME'][i]='Explorer'
        elif (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==19):
            xx['PLAN_NAME'][i]='Community'
        elif (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==20):
            xx['PLAN_NAME'][i]='Cloud'
        elif (xx['School_Count'][i]>1) &(xx['max_plan'][i]==17):
            xx['PLAN_NAME'][i]='Schoolapp'
    if len(xx[(xx['School_Count']>1) & (xx['max_plan']==17)])>1:
        db_live.school_master.update_many({'_id':{'$in':list(xx[(xx['School_Count']>=1) & (xx['max_plan']==17)]['schoolid'])}},
                                         {'$set':{
                                             'DASH_CATEGORY':'Schoolapp'
                                         }}
                                         )
    elif len(xx[(xx['School_Count']==1) & (xx['max_plan']==17)])>1:
        db_live.school_master.update_many({'_id':{'$in':list(xx[(xx['School_Count']==1) & (xx['max_plan']==17)]['schoolid'])}},
                                         {'$set':{
                                             'DASH_CATEGORY':'Homaapp'
                                         }}
                                         )
    else:
        pass
    final_cloud_count=xx[xx['PLAN_NAME']=='Cloud']
    final_com_count=xx[xx['PLAN_NAME']=='Community']
    final_exp_count=xx[xx['PLAN_NAME']=='Explorer']
    execount={"clound":str(final_cloud_count),"community":str(final_com_count),"explorer":str(final_exp_count)}






    dflife=final_exp_count
    # lifelist=list(dflife["0"])
    lifetimelist=final_exp_count["schoolid"].to_list()
    # from bson import ObjectId
    # for i in lifelist:
    #     lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    overallum=pd.DataFrame(list(collection.aggregate([{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }   
    },
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    #   {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #   {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
    #   {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'IS_ADMIN':'Y'}

    ]
    }},

    {"$project":{"_id":0,
    'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
    "UMEMAIL":'$EMAIL_ID',  
    "CREATED_DATE":'$CREATED_DATE',
    "UMSCHOOLID":'$schoolId._id',
                 "UMSCHOOLNAME":'$schoolId.NAME',
                 "CITY":'$schoolId.CITY',
                 "STATE":'$schoolId.STATE',
                 "COUNTRY":'$schoolId.COUNTRY',
                }},
    ])))
    overallum["CREATED_DATE"]=overallum["CREATED_DATE"].dt.strftime('%d %b %Y')
    #     overallum.to_csv("expcheck.csv")
    email=list(overallum["UMUSER_ID"])
    schoolid=list(overallum["UMSCHOOLID"])
    ################################sub_master################################

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # db.subscription_master.ensureIndex("USER_ID._id", 1) 
    collection = db.subscription_master
    qr=[
    {"$match":{"$and":[{'USER_ID._id':{"$in":email}},
    {'PLAN_ID.PLAN_NAME':"Explorer"}
    ]}},
    {"$project":{"_id":0,
    'SMUSER_ID':'$USER_ID._id',
    "SMEMAIL":'$USER_ID.EMAIL_ID',
    "PLANID":"$PLAN_ID.PLAN_NAME",
    "comment":"$COMMENT_BY_DS_TEAM",
    "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
    }},]
    merge=list(collection.aggregate(qr))
    overall=pd.DataFrame(merge)
    overall["RENEWAL_DATE"]=overall["RENEWAL_DATE"].dt.strftime('%d %b %Y')
    #     mergeddf=pd.merge(overallum, overall, how='left', left_on='UMEMAIL', right_on='SMEMAIL')
    mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
    db=client.compass
    collection = db.audio_track_master
    qra=[
    {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 
    'atdLastpractice':{'$max':'$MODIFIED_DATE'},
    'atdPracticecount':{'$sum':1},
    'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}]
    merge11=list(collection.aggregate(qra))
    atd=pd.DataFrame(merge11)
    atd["atdLastpractice"]=atd["atdLastpractice"].dt.strftime('%d %b %Y')
    finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
    finalmerge['atdLastpractice'].fillna("NO PRACTICE", inplace=True)
    finalmerge['atdPracticecount'].fillna(0, inplace=True)
    finalmerge.fillna("NO INFO AVAILABLE", inplace=True)
    finaldata=finalmerge[["UMSCHOOLNAME","STATE","CITY","USER_NAME","UMEMAIL","CREATED_DATE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')
    print(len(lifetimelist),len(finaldata))
    return json.dumps({"data":finaldata.values.tolist()})

# return json.dumps(execount)




@app.route('/cloudtabled3')
def cloud_table_d3():
    client_live= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@54.202.61.130:27017/')
    db_live=client_live.compass
    d3_users=pd.DataFrame(list(db_live.user_master.aggregate([
        {"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                    {'schoolId._id':{'$in':
                                    db_live.school_master.distinct('_id',{'DASH_CATEGORY':'D3'})                               
                                    }}
                    ]}},
        {'$project':{'_id':0,
            'userid':'$_id',
                     'USER NAME':'$USER_NAME',
                     'email':'$EMAIL_ID',
                     'SIGN UP':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}},
                     'schoolid':'$schoolId._id',
                     'STATE':'$schoolId.STATE',
                     'CITY':'$schoolId.CITY'
        }}
    ])))
    user_masterd3=pd.DataFrame({'schoolid':list(set(d3_users['schoolid'])),
                               'status':1
                               })
    d3_user_sub_master=pd.DataFrame(list(db_live.subscription_master.aggregate([{'$match':{'$and':[
        {'USER_ID._id':{'$in':list(d3_users['userid'])}}
    ]}},                                  {'$project':{'_id':0,
                                           'userid':'$USER_ID._id',
                                           'RENEWAL DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":'$SUBSCRIPTION_EXPIRE_DATE'}},
                                           'PLAN_ID':'$PLAN_ID.PLAN_ID'
                                          }}
                                          ])))
    d3_plan_ids=d3_users.merge(d3_user_sub_master,how='left',on='userid')
    # print(d3_plan_ids.columns)
    x=d3_plan_ids.groupby(['schoolid','PLAN_ID'])['userid','USER NAME', 'email', 'SIGN UP', 'STATE', 'CITY',
           'RENEWAL DATE'].count().reset_index()
    # print(x)
    xx=x.groupby(['schoolid']).agg(School_Count=('schoolid','count'),
                             max_plan=('PLAN_ID','max')
                             ).reset_index()
    # print(xx)

    xx['PLAN_NAME']=''
    for i in range(len(xx)):
        if (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==18):
            xx['PLAN_NAME'][i]='Explorer'
        elif (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==19):
            xx['PLAN_NAME'][i]='Community'
        elif (xx['School_Count'][i]>=1) &(xx['max_plan'][i]==20):
            xx['PLAN_NAME'][i]='Cloud'
        elif (xx['School_Count'][i]>1) &(xx['max_plan'][i]==17):
            xx['PLAN_NAME'][i]='Schoolapp'
    if len(xx[(xx['School_Count']>1) & (xx['max_plan']==17)])>1:
        db_live.school_master.update_many({'_id':{'$in':list(xx[(xx['School_Count']>=1) & (xx['max_plan']==17)]['schoolid'])}},
                                         {'$set':{
                                             'DASH_CATEGORY':'Schoolapp'
                                         }}
                                         )
    elif len(xx[(xx['School_Count']==1) & (xx['max_plan']==17)])>1:
        db_live.school_master.update_many({'_id':{'$in':list(xx[(xx['School_Count']==1) & (xx['max_plan']==17)]['schoolid'])}},
                                         {'$set':{
                                             'DASH_CATEGORY':'Homaapp'
                                         }}
                                         )
    else:
        pass
    final_cloud_count=xx[xx['PLAN_NAME']=='Cloud']
    final_com_count=xx[xx['PLAN_NAME']=='Community']
    final_exp_count=xx[xx['PLAN_NAME']=='Explorer']
    execount={"clound":str(final_cloud_count),"community":str(final_com_count),"explorer":str(final_exp_count)}






    dflife=final_cloud_count
    # lifelist=list(dflife["0"])
    lifetimelist=final_cloud_count["schoolid"].to_list()
    # from bson import ObjectId
    # for i in lifelist:
    #     lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    overallum=pd.DataFrame(list(collection.aggregate([{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }   
    },
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    #   {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #   {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
    #   {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'IS_ADMIN':'Y'}

    ]
    }},

    {"$project":{"_id":0,
    'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
    "UMEMAIL":'$EMAIL_ID',  
    "CREATED_DATE":'$CREATED_DATE',
    "UMSCHOOLID":'$schoolId._id',
                 "UMSCHOOLNAME":'$schoolId.NAME',
                 "CITY":'$schoolId.CITY',
                 "STATE":'$schoolId.STATE',
                 "COUNTRY":'$schoolId.COUNTRY',
                }},
    ])))
    overallum["CREATED_DATE"]=overallum["CREATED_DATE"].dt.strftime('%d %b %Y')
    #     overallum.to_csv("expcheck.csv")
    email=list(overallum["UMUSER_ID"])
    schoolid=list(overallum["UMSCHOOLID"])
    ################################sub_master################################

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # db.subscription_master.ensureIndex("USER_ID._id", 1) 
    collection = db.subscription_master
    qr=[
    {"$match":{"$and":[{'USER_ID._id':{"$in":email}},
    {'PLAN_ID.PLAN_NAME':"Explorer"}
    ]}},
    {"$project":{"_id":0,
    'SMUSER_ID':'$USER_ID._id',
    "SMEMAIL":'$USER_ID.EMAIL_ID',
    "PLANID":"$PLAN_ID.PLAN_NAME",
    "comment":"$COMMENT_BY_DS_TEAM",
    "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
    }},]
    merge=list(collection.aggregate(qr))
    overall=pd.DataFrame(merge)
    overall["RENEWAL_DATE"]=overall["RENEWAL_DATE"].dt.strftime('%d %b %Y')
    #     mergeddf=pd.merge(overallum, overall, how='left', left_on='UMEMAIL', right_on='SMEMAIL')
    mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
    db=client.compass
    collection = db.audio_track_master
    qra=[
    {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 
    'atdLastpractice':{'$max':'$MODIFIED_DATE'},
    'atdPracticecount':{'$sum':1},
    'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}]
    merge11=list(collection.aggregate(qra))
    atd=pd.DataFrame(merge11)
    atd["atdLastpractice"]=atd["atdLastpractice"].dt.strftime('%d %b %Y')
    finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
    finalmerge['atdLastpractice'].fillna("NO PRACTICE", inplace=True)
    finalmerge['atdPracticecount'].fillna(0, inplace=True)
    finalmerge.fillna("NO INFO AVAILABLE", inplace=True)
    finaldata=finalmerge[["UMSCHOOLNAME","STATE","CITY","USER_NAME","UMEMAIL","CREATED_DATE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')
    print(len(lifetimelist),len(finaldata))
    return json.dumps({"data":finaldata.values.tolist()})

# return json.dumps(execount)



@app.route('/portal_test_new_api/<smcategory>')
def portal_testing_new_api(smcategory):
    if not g.user:     
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('test!_2o20')
        client = MongoClient("mongodb://%s:%s@52.37.152.224:27017/" % (username, password))
        db=client.compass
        collection = db.school_master
        from bson.objectid import ObjectId
    #     smcategory="Agawam School district"
        query=[{'$match':{'$and':[
        { 'CATEGORY':{"$regex":""+smcategory+"",'$options':'i'}},
        {'IS_PORTAL':'Y'},
        
        ]
        }},
        {"$project":{"_id":0,
        "UMSCHOOLID":'$_id',
        "UMSCHOOLNAME":'$NAME',
        "is_paid":"$FULL_EXPERIENCE",
                    }},
        ]
        merge11=list(collection.aggregate(query))

        overallum11=pd.DataFrame(merge11)
        print(overallum11,"helloooooooooooo1achsdkjcbsdkjcbsdku")
        # print(len(set(list(overallum11["UMSCHOOLID"]))),"school_count")
        lifetimelist=[]
        try:
            
            lifetimelist=list(set(overallum11["UMSCHOOLID"]))
        except:
            pass
        total_school=len(lifetimelist)
        collection = db.user_master
        query=[{'$match':{'$and':[{
        "schoolId._id": {
        "$in":lifetimelist
        }   
        },
        { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
        ]
        }},
        {"$project":{"_id":0,
        'ROLE':'$ROLE_ID.ROLE_NAME',
        'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
        "UMSCHOOLID":'$schoolId._id',
        "DISTRICT_NAME":"$DISTRICT_ID.DISTRICT_NAME",
                    "UMSCHOOLNAME":'$schoolId.NAME',
                    }},
        ]
        merge1=list(collection.aggregate(query))
        overallum=pd.DataFrame(merge1)
    #     print(overallum,"overallum")
        email=""
        schoolid=[]
        try:
            email=list(overallum["UMUSER_ID"])
            schoolid=list(overallum["UMSCHOOLID"])
        except:
            pass
        ################################sub_master################################
        collection = db.subscription_master
        qr=[
        {"$match":{"$and":[{'USER_ID._id':{"$in":email}},]}},
        {"$project":{"_id":0,
        'SMUSER_ID':'$USER_ID._id',
        "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
        }},]
        merge=[]
        overall=[]
        mergeddf=[]
        try:
            merge=list(collection.aggregate(qr))
            overall=pd.DataFrame(merge)
            mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
        except:
            pass
        db=client.compass
        collection = db.audio_track_master
        qra=[
        {"$match":{'$and':[
            {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'USER_ID.schoolId._id':{'$in':schoolid}},
        ]}},
        {'$group':{'_id':'$USER_ID.schoolId._id', 
        'atdLastpractice':{'$max':'$MODIFIED_DATE'},
        'atdPracticecount':{'$sum':1},
        'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}]
        merge110=[]
        atd=[]
        mmm=0
        try:
            merge110=list(collection.aggregate(qra))
            atd=pd.DataFrame(merge110)
            mmm=str(round(sum(atd["atdTotal_Mindful_Minutes"])))
            finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
            finaldata=finalmerge[["DISTRICT_NAME","UMSCHOOLID","UMSCHOOLNAME","UMUSER_ID","ROLE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
            finaldata["atdPracticecount"] = finaldata['atdPracticecount'].fillna(0)
            finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
            finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')
        except:
            pass
    #     print(finaldata)
        usercount=0
        try:
            usercount=len(finaldata[finaldata["ROLE"]=='user'])
        except:
            pass
        familycount=0
        try:
            familycount=len(finaldata[finaldata["ROLE"]=='PRESENT'])
        except:
            pass

        data2=[]
        totschnew=len(overallum11[overallum11["is_paid"]=="Y"])
        overallum11["UMSCHOOLID"] = overallum11["UMSCHOOLID"].astype('str')
        overallum11=overallum11.sort_values(by=['UMSCHOOLNAME'], ascending=True)
        for i in range(len(overallum11)):
            data2.append({"school_id":overallum11["UMSCHOOLID"][i],"school_name":overallum11["UMSCHOOLNAME"][i],"is_paid":overallum11["is_paid"][i]})
        finaldata={"data":data2,"total_school":totschnew,"user_count":usercount,"family_count":familycount,"mindful_minutes":mmm}
        return json.dumps(finaldata)
    return "try again"

@app.route('/cloud_new_chart')
def cloud_new_chart():
    #school summary df
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    d3schoollist=[]
    d3df=pd.read_csv("cloud_exec.csv")
    from bson import ObjectId
    d3id=list(d3df["0"])
    for i in d3id:
        d3schoollist.append(ObjectId(i))
    from bson.objectid import ObjectId
    query=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
    # //       {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId._id':{'$in':d3schoollist}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          
              {'$group':{
                  '_id':'$schoolId._id',
                  'schoolname':{'$first':'$schoolId.NAME'},
                  'CITY':{'$first':'$schoolId.CITY'},
                  'STATE':{'$first':'$schoolId.STATE'},
                  'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                  'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                  'CREATED_DATE':{'$min':'$CREATED_DATE'},
                  'USER_COUNT':{'$addToSet':'$_id'}}},
              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'SCHOOL_NAME':'$schoolname',
                  'CITY':'$CITY',
                  'STATE':'$STATE',
                  'COUNTRY':'$COUNTRY',
                  'ROLE_ID':'$ROLE_ID',
                  'CREATED_DATE':'$CREATED_DATE',
                  'USER_COUNT':{'$size':'$USER_COUNT'}
                  }}]
    school_summary=list(collection.aggregate(query))
    school_summary_df=pd.DataFrame(school_summary)

    #admin summary info

    query2=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
          {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
             {'IS_ADMIN':'Y'},
            {'schoolId._id':{'$in':d3schoollist}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$schoolId._id',
                  'SCHOOL_NAME':'$schoolId.NAME',
                  'ADMIN_ID':'$_id',
                  'ADMIN_NAME':'$USER_NAME',
                  'ADMIN_EMAIL':'$EMAIL_ID',
                  'DISTRICT_ID':'$DISTRICT_ID._id',
                  'DISTRICT_NAME':'$DISTRICT_ID.DISTRICT_NAME',
                  'ROLE_ID':'$ROLE_ID.ROLE_ID',
                  'D_CATEGORY':'$D_CATEGORY'         
                  }}]
    admin_summary=list(collection.aggregate(query2))
    admin_summary_df=pd.DataFrame(admin_summary)

    #school_Subscription_master summary
    collection2 = db.subscription_master
    query3=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_ID'},
                  }},

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan'
                  }}]
    school_sm_summary=list(collection2.aggregate(query3))
    school_sm_summary_df=pd.DataFrame(school_sm_summary)

    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y'})
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)


    #school summary audio_track_master

    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_summary=list(collection3.aggregate(query5))
    school_prac_summary_df=pd.DataFrame(school_prac_summary)
    query6=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}       


              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_active_csy=list(collection3.aggregate(query6))
    school_prac_active_csy_df=pd.DataFrame(school_prac_active_csy)

            # <<<<<<<<<<<---------------------------------------------------->>>>>>>>>>>>>

    school_with_admin=school_summary_df.merge(admin_summary_df[['SCHOOL_ID',
                                                        'SCHOOL_NAME','ADMIN_ID','ADMIN_NAME','D_CATEGORY',
                                                        'ADMIN_EMAIL','ROLE_ID','DISTRICT_ID','DISTRICT_NAME']],
                                      how='left',on='SCHOOL_ID')
    school_with_admin.loc[school_with_admin['ADMIN_ID'].notnull(), 'SCHOOL_NAME_x'] = school_with_admin['SCHOOL_NAME_y']
    school_with_admin.rename({'SCHOOL_NAME_x': 'SCHOOL_NAME'}, axis=1, inplace=True)
    school_with_admin.drop(['SCHOOL_NAME_y'],axis=1,inplace=True)
    school_with_admin.loc[school_with_admin['ADMIN_ID'].notnull(), 'ROLE_ID_x'] = school_with_admin['ROLE_ID_y']
    school_with_admin.rename({'ROLE_ID_x': 'ROLE_ID'}, axis=1, inplace=True)
    school_with_admin.drop(['ROLE_ID_y'],axis=1,inplace=True)
    school_renewal_info_df=school_with_admin.merge(admin_sm_summary_df[['ADMIN_ID', 'Renewal_Date', 'PLAN_ID', 'PLAN_NAME']]
                                                   ,how='left',on='ADMIN_ID')
    school_renewal_info1=school_renewal_info_df.merge(school_sm_summary_df,how='left',on='SCHOOL_ID')
    school_renewal_info1.loc[school_renewal_info1['ADMIN_ID'].isnull(), 
                             'Renewal_Date'] = school_renewal_info1['MAX_RENEWAL_DATE']
    school_renewal_info1.drop(['MAX_RENEWAL_DATE'],axis=1,inplace=True)
    school_renewal_info1.loc[school_renewal_info1['ADMIN_ID'].isnull(), 'PLAN_ID'] = school_renewal_info1['MAX_PLAN']
    school_renewal_info1.drop(['MAX_PLAN'],axis=1,inplace=True)
    school_complete_info=school_renewal_info1.merge(school_prac_summary_df,how='left',on='SCHOOL_ID')
    school_complete_info1=school_complete_info.merge(school_prac_active_csy_df[['SCHOOL_ID','Last_Practice_Date']],how='left',on='SCHOOL_ID')
    school_complete_info1.loc[school_complete_info1['Last_Practice_Date_y'].notnull(), 'Active_CSY'] = 'Yes'
    school_complete_info1.drop(['Last_Practice_Date_y'],axis=1,inplace=True)
    school_complete_info1.rename({'Last_Practice_Date_x': 'Last_Practice_Date'}, axis=1, inplace=True)
    school_complete_info1.Active_User.fillna(0,inplace=True)
    school_complete_info1.Active_CSY.fillna('No',inplace=True)
    school_complete_info1.Practice_Sessions.fillna(0,inplace=True)
    school_complete_info1.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_info1.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    last_prac_date=school_complete_info1['Last_Practice_Date'].tolist()
    created_date=school_complete_info1['CREATED_DATE'].tolist()
    renewal_date=school_complete_info1['Renewal_Date'].tolist()

    webapp_schools=school_complete_info1[school_complete_info1.PLAN_ID!=16]
    webapp_schools_final=webapp_schools[webapp_schools.ADMIN_ID.notnull() & 
                                                webapp_schools.Renewal_Date.notnull()]
#     webapp_schools_final_D3=webapp_schools_final[webapp_schools_final['D_CATEGORY']=='D3']
    webapp_schools_final_D3=webapp_schools_final
    webapp_schools_final_D3_csy_active=webapp_schools_final_D3[webapp_schools_final_D3['Active_CSY']=='Yes']

    D3_Schools=webapp_schools_final_D3['Renewal_Date'].groupby([webapp_schools_final_D3.Renewal_Date.dt.year.rename('year'), 
                                       webapp_schools_final_D3.Renewal_Date.dt.month.rename('month')]).agg('count').reset_index().rename({'Renewal_Date':'Total_Schools'},axis=1)
    D3_Schools_active_csy=webapp_schools_final_D3_csy_active['Renewal_Date'].groupby([webapp_schools_final_D3_csy_active.Renewal_Date.dt.year.rename('year'), 
                                       webapp_schools_final_D3_csy_active.Renewal_Date.dt.month.rename('month')]).agg('count').reset_index().rename({'Renewal_Date':'Active_Schools'},axis=1)
    D3_chart_Data=D3_Schools.merge(D3_Schools_active_csy,on=['year','month'],how='left').fillna(0)
    D3_chart_Data['Month_Name'] = pd.to_datetime(D3_chart_Data['month'], format='%m').dt.month_name().str.slice(stop=3)
    Month_Name = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
    month_df=pd.DataFrame({'Month_Name':Month_Name})
    D3_chart_Data_2020=D3_chart_Data[D3_chart_Data['year']==2020]
    D3_chart_Data_2021=D3_chart_Data[D3_chart_Data['year']==2021]
    D3_chart_Data_2022=D3_chart_Data[D3_chart_Data['year']==2022]
    D3_chart_Data_2023=D3_chart_Data[D3_chart_Data['year']==2023]

    D3_chart_Data_2020_mothwise=month_df.merge(D3_chart_Data_2020,on='Month_Name',how='left').fillna(0)
    D3_chart_Data_2021_mothwise=month_df.merge(D3_chart_Data_2021,on='Month_Name',how='left').fillna(0)
    D3_chart_Data_2022_mothwise=month_df.merge(D3_chart_Data_2022,on='Month_Name',how='left').fillna(0)
    D3_chart_Data_2023_mothwise=month_df.merge(D3_chart_Data_2023,on='Month_Name',how='left').fillna(0)
    mnth=D3_chart_Data_2020_mothwise.Month_Name.tolist()
    expsch=D3_chart_Data_2020_mothwise.Total_Schools.to_list()
    actsch=D3_chart_Data_2020_mothwise.Active_Schools.to_list()
    temp={'Data_2020':{'Month_Name':mnth[6:12],
                        'Expiring_Schools':expsch[6:12],
                         'Active_Schools_csy':actsch[6:12]
                        },
#           ,
                        'Data_2021':{
                         'Month_Name':D3_chart_Data_2021_mothwise.Month_Name.tolist(),
                        'Expiring_Schools':D3_chart_Data_2021_mothwise.Total_Schools.to_list(),
                         'Active_Schools_csy':D3_chart_Data_2021_mothwise.Active_Schools.to_list()   
                        }
#                         'Data_2022':{
#                          'Month_Name':D3_chart_Data_2022_mothwise.Month_Name.tolist(),
#                         'Expiring_Schools':D3_chart_Data_2022_mothwise.Total_Schools.to_list(),
#                          'Active_Schools_csy':D3_chart_Data_2022_mothwise.Active_Schools.to_list()   
#                         },
#                         'Data_2023':{
#                          'Month_Name':D3_chart_Data_2023_mothwise.Month_Name.tolist(),
#                         'Expiring_Schools':D3_chart_Data_2023_mothwise.Total_Schools.to_list(),
#                          'Active_Schools_csy':D3_chart_Data_2023_mothwise.Active_Schools.to_list()   
                        }

    return json.dumps(temp)

@app.route('/d3_new_chart')
def d3_new_chart():
    #school summary df
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    d3schoollist=[]
    d3df=pd.read_csv("d325feb.csv")
    d3id=list(d3df["_id"])
    from bson import ObjectId
    for i in d3id:
        d3schoollist.append(ObjectId(i))
    from bson.objectid import ObjectId
    query=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
    # //       {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId._id':{'$in':d3schoollist}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          
              {'$group':{
                  '_id':'$schoolId._id',
                  'schoolname':{'$first':'$schoolId.NAME'},
                  'CITY':{'$first':'$schoolId.CITY'},
                  'STATE':{'$first':'$schoolId.STATE'},
                  'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                  'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                  'CREATED_DATE':{'$min':'$CREATED_DATE'},
                  'USER_COUNT':{'$addToSet':'$_id'}}},
              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'SCHOOL_NAME':'$schoolname',
                  'CITY':'$CITY',
                  'STATE':'$STATE',
                  'COUNTRY':'$COUNTRY',
                  'ROLE_ID':'$ROLE_ID',
                  'CREATED_DATE':'$CREATED_DATE',
                  'USER_COUNT':{'$size':'$USER_COUNT'}
                  }}]
    school_summary=list(collection.aggregate(query))
    school_summary_df=pd.DataFrame(school_summary)

    #admin summary info

    query2=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
          {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
             {'IS_ADMIN':'Y'},
            {'schoolId._id':{'$in':d3schoollist}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$schoolId._id',
                  'SCHOOL_NAME':'$schoolId.NAME',
                  'ADMIN_ID':'$_id',
                  'ADMIN_NAME':'$USER_NAME',
                  'ADMIN_EMAIL':'$EMAIL_ID',
                  'DISTRICT_ID':'$DISTRICT_ID._id',
                  'DISTRICT_NAME':'$DISTRICT_ID.DISTRICT_NAME',
                  'ROLE_ID':'$ROLE_ID.ROLE_ID',
                  'D_CATEGORY':'$D_CATEGORY'         
                  }}]
    admin_summary=list(collection.aggregate(query2))
    admin_summary_df=pd.DataFrame(admin_summary)

    #school_Subscription_master summary
    collection2 = db.subscription_master
    query3=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_ID'},
                  }},

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan'
                  }}]
    school_sm_summary=list(collection2.aggregate(query3))
    school_sm_summary_df=pd.DataFrame(school_sm_summary)

    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y'})
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)


    #school summary audio_track_master

    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_summary=list(collection3.aggregate(query5))
    school_prac_summary_df=pd.DataFrame(school_prac_summary)
    query6=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}       


              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_active_csy=list(collection3.aggregate(query6))
    school_prac_active_csy_df=pd.DataFrame(school_prac_active_csy)

            # <<<<<<<<<<<---------------------------------------------------->>>>>>>>>>>>>

    school_with_admin=school_summary_df.merge(admin_summary_df[['SCHOOL_ID',
                                                        'SCHOOL_NAME','ADMIN_ID','ADMIN_NAME','D_CATEGORY',
                                                        'ADMIN_EMAIL','ROLE_ID','DISTRICT_ID','DISTRICT_NAME']],
                                      how='left',on='SCHOOL_ID')
    school_with_admin.loc[school_with_admin['ADMIN_ID'].notnull(), 'SCHOOL_NAME_x'] = school_with_admin['SCHOOL_NAME_y']
    school_with_admin.rename({'SCHOOL_NAME_x': 'SCHOOL_NAME'}, axis=1, inplace=True)
    school_with_admin.drop(['SCHOOL_NAME_y'],axis=1,inplace=True)
    school_with_admin.loc[school_with_admin['ADMIN_ID'].notnull(), 'ROLE_ID_x'] = school_with_admin['ROLE_ID_y']
    school_with_admin.rename({'ROLE_ID_x': 'ROLE_ID'}, axis=1, inplace=True)
    school_with_admin.drop(['ROLE_ID_y'],axis=1,inplace=True)
    school_renewal_info_df=school_with_admin.merge(admin_sm_summary_df[['ADMIN_ID', 'Renewal_Date', 'PLAN_ID', 'PLAN_NAME']]
                                                   ,how='left',on='ADMIN_ID')
    school_renewal_info1=school_renewal_info_df.merge(school_sm_summary_df,how='left',on='SCHOOL_ID')
    school_renewal_info1.loc[school_renewal_info1['ADMIN_ID'].isnull(), 
                             'Renewal_Date'] = school_renewal_info1['MAX_RENEWAL_DATE']
    school_renewal_info1.drop(['MAX_RENEWAL_DATE'],axis=1,inplace=True)
    school_renewal_info1.loc[school_renewal_info1['ADMIN_ID'].isnull(), 'PLAN_ID'] = school_renewal_info1['MAX_PLAN']
    school_renewal_info1.drop(['MAX_PLAN'],axis=1,inplace=True)
    school_complete_info=school_renewal_info1.merge(school_prac_summary_df,how='left',on='SCHOOL_ID')
    school_complete_info1=school_complete_info.merge(school_prac_active_csy_df[['SCHOOL_ID','Last_Practice_Date']],how='left',on='SCHOOL_ID')
    school_complete_info1.loc[school_complete_info1['Last_Practice_Date_y'].notnull(), 'Active_CSY'] = 'Yes'
    school_complete_info1.drop(['Last_Practice_Date_y'],axis=1,inplace=True)
    school_complete_info1.rename({'Last_Practice_Date_x': 'Last_Practice_Date'}, axis=1, inplace=True)
    school_complete_info1.Active_User.fillna(0,inplace=True)
    school_complete_info1.Active_CSY.fillna('No',inplace=True)
    school_complete_info1.Practice_Sessions.fillna(0,inplace=True)
    school_complete_info1.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_info1.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    last_prac_date=school_complete_info1['Last_Practice_Date'].tolist()
    created_date=school_complete_info1['CREATED_DATE'].tolist()
    renewal_date=school_complete_info1['Renewal_Date'].tolist()

    webapp_schools=school_complete_info1[school_complete_info1.PLAN_ID!=16]
    webapp_schools_final=webapp_schools[webapp_schools.ADMIN_ID.notnull() & 
                                                webapp_schools.Renewal_Date.notnull()]
#     webapp_schools_final_D3=webapp_schools_final[webapp_schools_final['D_CATEGORY']=='D3']
    webapp_schools_final_D3=webapp_schools_final
    webapp_schools_final_D3_csy_active=webapp_schools_final_D3[webapp_schools_final_D3['Active_CSY']=='Yes']

    D3_Schools=webapp_schools_final_D3['Renewal_Date'].groupby([webapp_schools_final_D3.Renewal_Date.dt.year.rename('year'), 
                                       webapp_schools_final_D3.Renewal_Date.dt.month.rename('month')]).agg('count').reset_index().rename({'Renewal_Date':'Total_Schools'},axis=1)
    D3_Schools_active_csy=webapp_schools_final_D3_csy_active['Renewal_Date'].groupby([webapp_schools_final_D3_csy_active.Renewal_Date.dt.year.rename('year'), 
                                       webapp_schools_final_D3_csy_active.Renewal_Date.dt.month.rename('month')]).agg('count').reset_index().rename({'Renewal_Date':'Active_Schools'},axis=1)
    D3_chart_Data=D3_Schools.merge(D3_Schools_active_csy,on=['year','month'],how='left').fillna(0)
    D3_chart_Data['Month_Name'] = pd.to_datetime(D3_chart_Data['month'], format='%m').dt.month_name().str.slice(stop=3)
    Month_Name = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
    month_df=pd.DataFrame({'Month_Name':Month_Name})
    D3_chart_Data_2020=D3_chart_Data[D3_chart_Data['year']==2020]
    D3_chart_Data_2021=D3_chart_Data[D3_chart_Data['year']==2021]
    D3_chart_Data_2022=D3_chart_Data[D3_chart_Data['year']==2022]
    D3_chart_Data_2023=D3_chart_Data[D3_chart_Data['year']==2023]

    D3_chart_Data_2020_mothwise=month_df.merge(D3_chart_Data_2020,on='Month_Name',how='left').fillna(0)
    D3_chart_Data_2021_mothwise=month_df.merge(D3_chart_Data_2021,on='Month_Name',how='left').fillna(0)
    D3_chart_Data_2022_mothwise=month_df.merge(D3_chart_Data_2022,on='Month_Name',how='left').fillna(0)
    D3_chart_Data_2023_mothwise=month_df.merge(D3_chart_Data_2023,on='Month_Name',how='left').fillna(0)
    mnth=D3_chart_Data_2020_mothwise.Month_Name.tolist()
    expsch=D3_chart_Data_2020_mothwise.Total_Schools.to_list()
    actsch=D3_chart_Data_2020_mothwise.Active_Schools.to_list()
    temp={'Data_2020':{'Month_Name':mnth[6:12],
                        'Expiring_Schools':expsch[6:12],
                         'Active_Schools_csy':actsch[6:12]
                        },
#           ,
                        'Data_2021':{
                         'Month_Name':D3_chart_Data_2021_mothwise.Month_Name.tolist(),
                        'Expiring_Schools':D3_chart_Data_2021_mothwise.Total_Schools.to_list(),
                         'Active_Schools_csy':D3_chart_Data_2021_mothwise.Active_Schools.to_list()   
                        }
#                         'Data_2022':{
#                          'Month_Name':D3_chart_Data_2022_mothwise.Month_Name.tolist(),
#                         'Expiring_Schools':D3_chart_Data_2022_mothwise.Total_Schools.to_list(),
#                          'Active_Schools_csy':D3_chart_Data_2022_mothwise.Active_Schools.to_list()   
#                         },
#                         'Data_2023':{
#                          'Month_Name':D3_chart_Data_2023_mothwise.Month_Name.tolist(),
#                         'Expiring_Schools':D3_chart_Data_2023_mothwise.Total_Schools.to_list(),
#                          'Active_Schools_csy':D3_chart_Data_2023_mothwise.Active_Schools.to_list()   
                        }

    return json.dumps(temp)



# ============LOGIN DASHBOARD
@app.route("/tempasscode_streak")
def temp_streak():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.Temp_Access
    from datetime import datetime

    df=DataFrame(list(collection.aggregate([
    {"$match":{"$and":[
    # // #              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
               {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {'CREATED_DATE':{'$gte':datetime(2021,8,16,11,0,0,0)}},
                 {'USER_ID.EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com',
                     'north3elem@gmail.com']}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]
         }},


        {'$project':{'_id':1,'user_name':'$USER_ID.USER_NAME','userid':'$USER_ID._id','email':'$USER_ID.EMAIL_ID','CREATED_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}},'TEMP_PASSWORD':'$TEMP_PASSWORD'}},

        {'$group':{'_id':'$email','CREATED_DATE':{'$addToSet':'$CREATED_DATE'},'sum':{'$sum':1}}},
        {'$project':{'_id':1,'CREATED_DATE':'$CREATED_DATE','No_of_days_of_temp_passcode':{'$size':'$CREATED_DATE'},'count':'$sum'}},
        {'$group':{'_id':'$count','streak':{'$sum':1},'email':{'$addToSet':'$_id'}}},
        {'$project':{'_id':1,'streak':'$streak','email':{'$size':'$email'}}},
        {'$sort':{'_id':1}},

    ])))
    df

    streak=df['_id'].tolist()
    streak_count=df['streak'].tolist()

    data={'streak':streak,'streak_count':streak_count}
    return json.dumps(data)

@app.route("/tempasscode_table/<n>")
def temp_table(n):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.Temp_Access
    from datetime import datetime

    df=DataFrame(list(collection.aggregate([
    {"$match":{"$and":[
    # // #              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
               {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {'CREATED_DATE':{'$gte':datetime(2021,8,16,11,0,0,0)}},
                 {'USER_ID.EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com',
                     'north3elem@gmail.com']}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]
         }},


        {'$project':{'_id':1,'user_name':'$USER_ID.USER_NAME','userid':'$USER_ID._id','email':'$USER_ID.EMAIL_ID','CREATED_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}},'TEMP_PASSWORD':'$TEMP_PASSWORD'}},

        {'$group':{'_id':'$userid','email':{'$first':'$email'},'CREATED_DATE':{'$addToSet':'$CREATED_DATE'},'sum':{'$sum':1}}},
        {'$project':{'_id':1,'email':'$email','CREATED_DATE':'$CREATED_DATE','No_of_days_of_temp_passcode':{'$size':'$CREATED_DATE'},'count':'$sum'}},
        {'$match':{'count':int(""+n+"")}},
        {'$project':{'_id':1}}
    ])))
#     df.rename(columns = { '_id': 'EMAIL_ID'}, inplace = True)
        
    email=df['_id'].tolist()
        
        
    df1=DataFrame(list(db.user_master.aggregate([
    {"$match":{"$and":[
         {'_id' :{'$in':email}},
       
    ]}},
    {'$project':{'_id':1,'USER_NAME':'$USER_NAME','EMAIL_ID':'$EMAIL_ID','SCHOOL_NAME':'$schoolId.NAME','ROLE':'$ROLE_ID.ROLE_NAME'}}
        
        
    ])))
        
    df2=DataFrame(list(db.audio_track_master.aggregate([
    {"$match":{"$and":[
         {'USER_ID._id' :{'$in':email}},
         {'MODIFIED_DATE':{'$gte':datetime(2021,8,1)}},
    ]}},
    {'$group':{'_id':'$USER_ID._id','pc':{'$sum':1},'last_prac':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date": '$MODIFIED_DATE'}}}}},
    {'$project':{'_id':1,'playbacks_csy':'$pc','last_practice_date':'$last_prac'}}    
    ])))
    df3=DataFrame(list(db.Temp_Access.aggregate([
    {"$match":{"$and":[
         {'USER_ID._id' :{'$in':email}},
     
    ]}},
    {'$group':{'_id':'$USER_ID._id','last_TEMP':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date": '$CREATED_DATE'}}}}},
    {'$project':{'_id':1,'LAST_TEMP_DATE':'$last_TEMP'}}    
    ])))
    
    
    
    
    
    
    dff=pd.merge(df,df1,on='_id',how='left').fillna('')
    DF=pd.merge(dff,df2,on='_id',how='left').fillna('')
    dfff=pd.merge(DF,df3,on='_id',how='left').fillna('')
    dfff=dfff[['USER_NAME','EMAIL_ID','SCHOOL_NAME','playbacks_csy','last_practice_date','LAST_TEMP_DATE']]
    data=dfff.values.tolist()
    return json.dumps({'data':data})

@app.route("/login_cards")
def login_card():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.Temp_Access
    from datetime import datetime


    df=DataFrame(list(collection.aggregate([
    {"$match":{"$and":[
    # // #              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
               {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {'CREATED_DATE':{'$gte':datetime(2021,8,16,11,0,0,0)}},
                 {'USER_ID.EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com',
                     'north3elem@gmail.com']}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]
         }},
         {'$group':{
             '_id':{},
             'users':{'$addToSet':'$USER_ID._id'},'total':{'$sum':1},
             'schools':{'$addToSet':'$USER_ID.schoolId._id'},

             }},
           {'$project':{
               '_id':0,
               'unique_user_temp':{'$size':'$users'},'total_user':'$total',
               'school_login':{'$size':'$schools'}
               }}      
    ])))

    unique_user_temp=df['unique_user_temp'][0]
    total_temp_count=df['total_user'][0]



    df1=DataFrame(list(db.login_logs.aggregate([
        {"$match":
         {
            '$and':[
    #      {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    #          {"USER_ID.DEVICE_USED" : "webApp"},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    #             {"USER_ID._id":{"$in":db.login_tracking.distinct( "_id", {  "IS_SUCCESS" : "Y"})}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},

                  {'LAST_LOGGED_IN':{'$gte':datetime(2021,8,16,11,0,0,0),



                                    }},
                 {'USER_ID.EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com']}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]

         }},
        {'$group':{'_id':'','pc':{'$sum':1},'uc':{'$addToSet':'$USER_ID._id'}}},

        {'$project':{'_id':1, 'login_count':'$pc','login_user':{'$size':'$uc'}}}])))

    logins=df1['login_user'][0]
    df2=DataFrame(list(db.login_tracking.aggregate([
        {"$match":
         {
            '$and':[
    #      {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    #          {"USER_ID.DEVICE_USED" : "webApp"},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    #             {"USER_ID._id":{"$in":db.login_tracking.distinct( "_id", {  "IS_SUCCESS" : "Y"})}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},
                {  "IS_SUCCESS" : "Y"},
                  {'CREATED_DATE':{'$gte':datetime(2021,8,16,11,0,0,0)}},
                 {'USER_ID.EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com']}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}
            ]

         }},
        {'$group':{'_id':'','pc':{'$sum':1},'uc':{'$addToSet':'$USER_ID._id'}}},

        {'$project':{'_id':1, 'login_count':'$pc','login_user':{'$size':'$uc'}}}])))


    unique_success_logins=df2['login_user'][0]


    df3=DataFrame(list(db.email_logging.aggregate([
        {"$match":
         {
            '$and':[
              {'PURPOSE':{'$regex':'Inner Explorer Login Help','$options':'i'}},
                  {'CREATED_DATE':{'$gte':datetime(2021,8,16,11,0,0,0)}},
                 {'RECEIVER_EMAIL':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com']}},

            ]

         }},
        {'$group':{'_id':'','pc':{'$sum':1},'uc':{'$addToSet':'$_id'}}},

        {'$project':{'_id':1, 'login_count':'$pc','new_passcode_email_count':{'$size':'$uc'}}}]
             )))

    new_passcode_email_count=df3['new_passcode_email_count'][0]

    data={'totalsuccesslogins':str(logins),'new_passcode_email_count':str(new_passcode_email_count),'unique_user_temp':str(unique_user_temp), 
         'total_temp_count':str(total_temp_count)}
    return json.dumps(data)


@app.route("/daily_logins")
def date_wise_login():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    from datetime import datetime
    # collection = db.Temp_Access

    d1=DataFrame(list(db.login_tracking.aggregate([
        {"$match":
         {
            '$and':[
                {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{'$not':{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
           {"USER_ID._id":{"$nin":db.subscription_master.distinct( "USER_ID._id", { "PLAN_ID.PLAN_ID":{'$in':[16,17]}})}},   
             {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
             {"USER_ID.DEVICE_USED" : {'$regex':"webApp",'$options':'i'}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},
    #             {  "IS_SUCCESS" : "N"},
                  {'CREATED_DATE':{'$gte':datetime(2021,8,16,11,0,0,0)}},
                 {'USER_ID.EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com']}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}},'pc':{'$sum':1},'uc':{'$addToSet':'$USER_ID._id'}}},
        {'$project':{'_id':1, 'login_count':'$pc','login_user_webapp':{'$size':'$uc'}}},
        {'$sort':{'_id':1}}])))
   


    # if d1.empty is True:
    #     login_user_webapp=0
    # else:
    #     login_user_webapp=d1['login_user_webapp'][0]

    d2=DataFrame(list(db.login_tracking.aggregate([
        {"$match":
         {
            '$and':[
    #             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{'$not':{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
           {"USER_ID._id":{"$in":db.subscription_master.distinct( "USER_ID._id", { "PLAN_ID.PLAN_ID":16})}},   
             {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    #          {"USER_ID.DEVICE_USED" : "webApp"},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},
    #             {  "IS_SUCCESS" : "N"},
                  {'CREATED_DATE':{'$gte':datetime(2021,8,16,11,0,0,0)}},
                 {'USER_ID.EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com']}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}},'pc':{'$sum':1},'uc':{'$addToSet':'$USER_ID._id'}}},
        {'$project':{'_id':1, 'login_count':'$pc','login_user_classroom':{'$size':'$uc'}}}
        ,{'$sort':{'_id':1}}])))
   
    # login_user_classroom=d2['login_user_classroom'][0]
    # if d2.empty is True:
    #     login_user_classroom=0
    # else:
    #     login_user_classroom=d2['login_user_classroom'][0]

    d3=DataFrame(list(db.login_tracking.aggregate([
        {"$match":
         {
            '$and':[
                {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                {"USER_ID._id":{'$not':{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
    #        {"USER_ID._id":{"$nin":db.subscription_master.distinct( "USER_ID._id", { "PLAN_ID.PLAN_ID":{'$in':[16,17]}})}},   
             {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    #          {"USER_ID.DEVICE_USED" : "webApp"},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},
    #             {  "IS_SUCCESS" : "N"},
                  {'CREATED_DATE':{'$gte':datetime(2021,8,16,11,0,0,0)}},
                 {'USER_ID.EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com']}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}},'pc':{'$sum':1},'uc':{'$addToSet':'$USER_ID._id'}}},
        {'$project':{'_id':1, 'login_count':'$pc','login_user_clever':{'$size':'$uc'}}},
        {'$sort':{'_id':1}}])))
  
    # if d3.empty is True:
    #     login_user_clever=0
    # else:
    #     login_user_clever=d3['login_user_clever'][0]


    d4=DataFrame(list(db.login_tracking.aggregate([
        {"$match":
         {
            '$and':[
                {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{'$not':{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
    #        {"USER_ID._id":{"$nin":db.subscription_master.distinct( "USER_ID._id", { "PLAN_ID.PLAN_ID":{'$in':[16,17]}})}},   
             {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    #          {"USER_ID.DEVICE_USED" : "webApp"},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},
    #             {  "IS_SUCCESS" : "N"},
                  {'CREATED_DATE':{'$gte':datetime(2021,8,16,11,0,0,0)}},
                 {'USER_ID.EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com']}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}},'pc':{'$sum':1},'uc':{'$addToSet':'$USER_ID._id'}}},
        {'$project':{'_id':1, 'login_count':'$pc','login_user_schoology':{'$size':'$uc'}}},
        {'$sort':{'_id':1}}])))
    if d4.empty is True:
        login_user_schoology=0
        d4=pd.DataFrame({'_id':['2021-08-16','2021-08-17','2021-08-18','2021-08-19'],'login_count':[0,0,0,0],'login_user_schoology':[0,0,0,0]})
        d4=d4.astype(str)
    #     pd.to_dateime['_id']
    else:
        d4
        
        
    d6=DataFrame(list(db.login_tracking.aggregate([
        {"$match":
         {
            '$and':[
                {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}},
                {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
    #        {"USER_ID._id":{"$nin":db.subscription_master.distinct( "USER_ID._id", { "PLAN_ID.PLAN_ID":{'$in':[16,17]}})}},   
             {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    #          {"USER_ID.DEVICE_USED" : "webApp"},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},
    #             {  "IS_SUCCESS" : "N"},
                  {'CREATED_DATE':{'$gte':datetime(2021,8,16,11,0,0,0)}},
                 {'USER_ID.EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com']}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}},'pc':{'$sum':1},'uc':{'$addToSet':'$USER_ID._id'}}},
        {'$project':{'_id':1, 'login_count':'$pc','login_user_canvas':{'$size':'$uc'}}},
        {'$sort':{'_id':1}}])))
    
#     print(d6)    
        
        
        
        
    d5=DataFrame(list(db.login_tracking.aggregate([
        {"$match":
         {
            '$and':[
    #             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{'$not':{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
           {"USER_ID._id":{"$in":db.subscription_master.distinct( "USER_ID._id", { "PLAN_ID.PLAN_ID":17})}},   
             {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    #          {"USER_ID.DEVICE_USED" : "webApp"},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},
    #             {  "IS_SUCCESS" : "N"},
                  {'CREATED_DATE':{'$gte':datetime(2021,8,16,11,0,0,0)}},
                 {'USER_ID.EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
                                            'north1high@gmail.com',
                                            'north3ele@gmail.com',
                                            'north4prek@gmail.com',
                                            'north2middle@gmail.com']}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}},'pc':{'$sum':1},'uc':{'$addToSet':'$USER_ID._id'}}},
        {'$project':{'_id':1, 'login_count':'$pc','login_user_homeapp':{'$size':'$uc'}}},
        {'$sort':{'_id':1}}


    ])))
   

    a=pd.merge(d1,d2 , on='_id', how='outer')
    b=pd.merge(a,d3 , on='_id', how='outer')
    c1=pd.merge(b,d4 , on='_id', how='outer')
    c=pd.merge(c1,d6 , on='_id', how='outer')
    d=pd.merge(c,d5 , on='_id', how='outer')
    
#     print(d)


    d=d.fillna(0)

    d.sort_values(by="_id")
    final_df=d[['_id','login_user_webapp','login_user_classroom','login_user_clever','login_user_schoology','login_user_canvas','login_user_homeapp']]
    final_df


    date=final_df['_id'].tolist()
    webapp_success_login=final_df['login_user_webapp'].tolist()
    classroom_success_login=final_df['login_user_classroom'].tolist()
    homeapp_success_login=final_df['login_user_homeapp'].tolist()
    clever_success_login=final_df['login_user_clever'].tolist()
    schoology_success_login=final_df['login_user_schoology'].tolist()
    canvas_success_login=final_df['login_user_canvas'].tolist()

    data={'date':date,'webapp_success_login':webapp_success_login,'classroom_success_login':classroom_success_login,
         'homeapp_success_login':homeapp_success_login,'clever_success_login':clever_success_login,'schoology_success_login':
         schoology_success_login,'canvas_success_login':canvas_success_login}
    return json.dumps(data)



@app.route('/new_dash_count')
def new_dash_count_():
    
    client_live= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@54.202.61.130:27017/')
    db_live=client_live.compass
    schools=pd.DataFrame(list(db_live.school_master.aggregate([{'$match':{'$and':[
            {'DASH_CATEGORY':{'$exists':1}},
        {'BLOCKED_BY_CAP':{'$exists':0}},
        {'NAME':{'$not':{'$regex':'test','$options':'i'}}}


        ]}},
        {'$project':{
            '_id':0,
            'schoolid':'$_id',
            'schoolname':'$NAME',
            'DASH_CATEGORY':'$DASH_CATEGORY'


        }}])))


    total_schools_wo_D_category=pd.DataFrame(list(db_live.user_master.aggregate(
    [{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.NAME':{'$not':{"$regex":'TEST','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                     {'schoolId._id':{'$in':
                                     db_live.school_master.distinct('_id',{
                                         'DASH_CATEGORY':{'$exists':0}

                                     })

                                     }},
                     {'schoolId._id':{'$exists':1}}
                    ]}},


              {'$group':{
                  '_id':'$schoolId._id',
                  'NAME':{'$first':'$schoolId.NAME'},
                  'USER_COUNT':{'$sum':1}



                  }}


              ])))

    D1=schools[schools['DASH_CATEGORY']=='D1'].reset_index(drop=True)
    D2=schools[schools['DASH_CATEGORY']=='D2'].reset_index(drop=True)
    D3=schools[schools['DASH_CATEGORY']=='D3'].reset_index(drop=True)
    Homeapp=schools[schools['DASH_CATEGORY']=='Homeapp'].reset_index(drop=True)
    Schoolapp=schools[schools['DASH_CATEGORY']=='Schoolapp'].reset_index(drop=True)
    lifetime=schools[schools['DASH_CATEGORY']=='lifetime'].reset_index(drop=True)

    other=len(total_schools_wo_D_category)
    total_schools_D_categorised=len(D1)+len(D2)+len(D3)+len(Homeapp)+len(Schoolapp)+len(lifetime)+other



    data={"total_school":total_schools_D_categorised,"D1":len(D1),"D2":len(D2),"D3":len(D3),"Lifetime":len(lifetime),"mobile":len(Schoolapp)+len(Homeapp),
        "other":other
         }
    return json.dumps(data)



@app.route('/skillpartnercardsinfo_/')
def partner_count_cards():
    from datetime import datetime
    from datetime import timedelta
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection1 = db.user_master
    collection2=db.audio_track_master
    collection3=db.login_logs
#     district=disdic[districtid]
#     print(district)
    df1 = DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                  {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
#                  {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
             {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
    #              {'DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','ID':{'$addToSet':'$schoolId._id'},'dn':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'school_count':{'$size':'$ID'},'district':'$dn'}}
                  ])))
    df2 = DataFrame(list(collection1.aggregate([ {"$match":
         {'$and': [
              {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2a")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                  {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
#                  {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','ID':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':1,'teacher_count':{'$size':'$ID'}}}
                  ])))
    df5 = DataFrame(list(collection1.aggregate([ {"$match":
         {'$and': [
              {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                  {'IS_PORTAL':'Y'},
                  {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
                 {'EMAIL_ID':{'$ne':''}},
#                  {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','ID':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':1,'family_count':{'$size':'$ID'}}}
                  ])))
    today1= datetime.utcnow()
    tod1= today1+ timedelta(hours=4)
    start1= tod1-timedelta(days=30)
    df3=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
    # //          {'ROLE_ID._id' :{'$':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
                 {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions':'$pc','MINDFUL_MINUTES':'$MINDFUL_MINUTES'}}])))
   

    df4=DataFrame(list(collection3.aggregate([{"$match":
         {'$and': [
    #           {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                 {'LAST_LOGGED_IN':{'$gte':start1}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1}}},
                  {'$project':{'_id':1,'logins':'$pc'}}])))
    df6=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
                 {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions_t':'$pc'}}])))
   
    df7=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
             {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
                 {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions_p':'$pc'}}])))
   

    sc=[0]
    try:
        sc=df1['school_count']
    except:
        sc=[0]
        
    tc=[0]
    try:
        tc=df2['teacher_count']
    except:
        tc=[0]
    
    pct=[0]
    try:
        pct=df6['practice_sessions_t']
    except:
        pct=[0]
    pcp=[0]
    try:
        pcp=df7['practice_sessions_p']
    except:
        pcp=[0]
    mm=[0]
    try:
        mm=df3['MINDFUL_MINUTES']
    except:
        mm=[0]
    
    lc=[0]
    try:
        lc=df4['logins']
    except:
        lc=[0]
        
    fc=[0]
    try:
        fc=df5['family_count']
    except:
        fc=[0]
    
    
    
    
    dn=[0]
    try:
        dn=df1['district']
    except:
        dn=[0]
 
    
    data={"schoolcount":str(sc[0]),"teachercount":str(tc[0]),"familycount":str(fc[0]),"teacherpracticecount":str(pct[0]),"parentspracticecount":str(pcp[0]),"logincount":str(lc[0]),
          'MINDFUL_MINUTES':str(mm[0]),'district':'Skillman'}
    return json.dumps(data)


@app.route('/oms')
def oms_records():
    from numpyencoder import NumpyEncoder
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # collection = db.Temp_Access
    d4=DataFrame(list(db.oms_master.aggregate([
        {"$match":
         {
            '$and':[
               { "ADMIN_EMAIL" : {'$not':{'$regex':"1gen",'$options':'i'}}},
                {"ADMIN_EMAIL" : {'$not':{'$regex':"north5special@gmail.com",'$options':'i'}}},
                {"SCHOOL_NAME" : {'$not':{'$regex':"North Special School",'$options':'i'}}},

               ]}},
    #     {'$group':{'_id':'$FOUNDATION','pc':{'$sum':1},}},
        {'$project':{'_id':1, 'OMS_ORDER_ID':'$OMS_ORDER_ID','FOUNDATION':'$FOUNDATION','LICENSE_TYPE':'$LICENSE_TYPE','DISTRICT':'$DISTRICT_NAME',
                    'school':'$SCHOOL_NAME','CREATED_DATE':'$CREATED_DATE','ORDER_TYPE':'$ORDER_TYPE','status':'$STATUS'}}
        ,{'$sort':{"CREATED_DATE":1}}
    ])))

    d5=DataFrame(list(db.oms_invoice.aggregate([
        {"$match":
         {
            '$and':[
               { "OMS_MASTER_ID.ADMIN_EMAIL" : {'$not':{'$regex':"1gen",'$options':'i'}}},
                {"OMS_MASTER_ID.ADMIN_EMAIL" : {'$not':{'$regex':"north5special@gmail.com",'$options':'i'}}},
                {"OMS_MASTER_ID.SCHOOL_NAME" : {'$not':{'$regex':"North Special School",'$options':'i'}}},

               ]}},
    #     {'$group':{'_id':'$FOUNDATION','pc':{'$sum':1},}},
        {'$project':{'_id':1, "TOTAL_AMOUNT":'$TOTAL_AMOUNT','OMS_ORDER_ID':'$ORDER_ID','EMAIL':'$EMAIL',
                  'INVOICE DATE':'$START_DATE','oms_upload_status':'$oms_upload_status','oms_master':'$OMS_MASTER_ID._id'}}
    ])))
    d6= pd.merge(d4,d5, on='OMS_ORDER_ID', how='outer')
    d6=d6.replace({'ORDER_TYPE': {'R': 'RENEW', 'N': 'NEW ORDER'}})

    d6['TOTAL_AMOUNT']=pd.to_numeric(d6['TOTAL_AMOUNT'])

    Total_orders=d6['_id_x'].count()
    Total_orders
    Invoice_sent=d6['_id_y'].count()
    Total_revenue=int(d6['TOTAL_AMOUNT'].sum())
    Total_revenue

    D1=d6.groupby('FOUNDATION').agg({'_id_x': ['count'], 'TOTAL_AMOUNT': ['sum']})
    D1=D1.reset_index('inplace'==True)
    D1.columns = D1.columns.get_level_values(0)
    District=int(D1['TOTAL_AMOUNT'][0])
    School=int(D1['TOTAL_AMOUNT'][1])


    D2=d6.groupby('INVOICE DATE').agg({'_id_y': ['count'], 'TOTAL_AMOUNT': ['sum']})
    D2=D2.reset_index('inplace'==True)
    D2.columns = D2.columns.get_level_values(0)
    D2['INVOICE DATE'] = pd.to_datetime(D2['INVOICE DATE'])
    D2['INVOICE DATE'] = D2['INVOICE DATE'].astype(np.int64) / int(1e6)
    D2['Cumulative_Amount'] = D2['TOTAL_AMOUNT'].cumsum()
    DF1=D2[['INVOICE DATE','TOTAL_AMOUNT']]
    TOTAL_AMOUNT=DF1.values.tolist()
    DF2=D2[['INVOICE DATE','Cumulative_Amount']]
    Cumulative=DF2.values.tolist()

    Cards={'Total_revenue':Total_revenue,'Total_orders':Total_orders,'Invoice_sent':Invoice_sent,'School':School,'District':District}


    Timeseries={'TOTAL_AMOUNT':TOTAL_AMOUNT,'Cumulative':Cumulative}


    D3=d6.groupby('ORDER_TYPE').agg({'_id_x': ['count'], 'TOTAL_AMOUNT': ['sum']})
    D3=D3.reset_index('inplace'==True)
    D3.columns = D3.columns.get_level_values(0)
    D3['TOTAL_AMOUNT']=D3['TOTAL_AMOUNT'].astype(int)
#     D3=D3.astype(str)
    Order_type=D3['ORDER_TYPE'].tolist()
    TOTAL_AMOUNT=D3['TOTAL_AMOUNT'].tolist()
    chart2 ={'Order_type':Order_type,'TOTAL_AMOUNT':TOTAL_AMOUNT}
    data={'cards':Cards,'Timeseries':Timeseries,'chart2':chart2}
    return json.dumps(data,cls=NumpyEncoder)


@app.route('/oms_table')
def oms_table():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # collection = db.Temp_Access
    d4=DataFrame(list(db.oms_master.aggregate([
        {"$match":
         {
            '$and':[
               { "ADMIN_EMAIL" : {'$not':{'$regex':"1gen",'$options':'i'}}},
                {"ADMIN_EMAIL" : {'$not':{'$regex':"north5special@gmail.com",'$options':'i'}}},
                {"SCHOOL_NAME" : {'$not':{'$regex':"North Special School",'$options':'i'}}},

               ]}},
    #     {'$group':{'_id':'$FOUNDATION','pc':{'$sum':1},}},
        {'$project':{'_id':1, 'OMS_ORDER_ID':'$OMS_ORDER_ID','FOUNDATION':'$FOUNDATION','LICENSE_TYPE':'$LICENSE_TYPE','DISTRICT':'$DISTRICT_NAME',
                    'school':'$SCHOOL_NAME','CREATED_DATE':'$CREATED_DATE','ORDER_TYPE':'$ORDER_TYPE','status':'$STATUS'}}
        ,{'$sort':{"CREATED_DATE":1}}
    ])))

    d5=DataFrame(list(db.oms_invoice.aggregate([
        {"$match":
         {
            '$and':[
               { "OMS_MASTER_ID.ADMIN_EMAIL" : {'$not':{'$regex':"1gen",'$options':'i'}}},
                {"OMS_MASTER_ID.ADMIN_EMAIL" : {'$not':{'$regex':"north5special@gmail.com",'$options':'i'}}},
                {"OMS_MASTER_ID.SCHOOL_NAME" : {'$not':{'$regex':"North Special School",'$options':'i'}}},

               ]}},
    #     {'$group':{'_id':'$FOUNDATION','pc':{'$sum':1},}},
        {'$project':{'_id':1, "TOTAL_AMOUNT":'$TOTAL_AMOUNT','OMS_ORDER_ID':'$ORDER_ID','EMAIL':'$EMAIL',
                  'INVOICE DATE':'$START_DATE','oms_upload_status':'$oms_upload_status','oms_master':'$OMS_MASTER_ID._id'}}
    ])))
    d6= pd.merge(d4,d5, on='OMS_ORDER_ID', how='outer')
    d6=d6.replace({'ORDER_TYPE': {'R': 'RENEW', 'N': 'NEW ORDER'}})

    d6['TOTAL_AMOUNT']=pd.to_numeric(d6['TOTAL_AMOUNT'])

    d6["NAME"] = d6["DISTRICT"] + d6["school"]
    d7=d6[['FOUNDATION','NAME','CREATED_DATE','TOTAL_AMOUNT','LICENSE_TYPE','ORDER_TYPE','EMAIL']]



    d7=d6[['FOUNDATION','NAME','CREATED_DATE','TOTAL_AMOUNT','LICENSE_TYPE','ORDER_TYPE','EMAIL']]
    # d7['TOTAL_AMOUNT']=d7['TOTAL_AMOUNT'].fillna('')

    d7=d7.fillna('')
    data=d7.values.tolist()
    
    return json.dumps({'data':data})













@app.route('/partner_schoolwisefamilypracticecount_/')
def PARTNER_schppcfamily():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass  
    collection = db.audio_track_master
    collection1 = db.user_master
#     district=disdic[districtid]
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {'USER_ID.schoolId._id':{'$ne':None}},
                      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#               {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},

    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'practice_count':'$pc'}},
            { '$sort' : { 'practice_count' : -1}}
    # //               {'$count':'count'}
                  ])))
    df2=DataFrame(list(collection1.aggregate([{"$match":
     {'$and': [
           {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                  {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},

             {'EMAIL_ID':{'$ne':''}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'name':{'$first':'$schoolId.NAME'},'user_name':{'$first':'$USER_NAME'}
                  }},


        {'$project':{'_id':1,'name':1}},])))

    df=pd.merge(df1,df2, how='left', on='_id')
    
    if df.empty == True:
        
        schname=[]
        pc=[]
      
    else:
        schname=df['name'].tolist()
        pc=df['practice_count'].tolist()
    data={'schname':schname[0:20],'Familypracticecount':pc[0:20]}
    
    return json.dumps(data)

# ================Quarter

 



    # ===========================

@app.route('/partner_schoolwisefamilycount_/')
def partner__schpuc():
   
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection=db.user_master
#     district=disdic[districtid]
    df = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                      {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
                 {'EMAIL_ID':{'$ne':''}},
#                    {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'user_count':{'$size':'$ID'},'name':'$NAME','district':'$district'}},
                   { '$sort' : { 'user_count' : -1}}
    # //               {'$count':'count'}
                  ])))

    # df['SCH_CREATED_DATE']=pd.to_datetime(df['SCH_CREATED_DATE'])

#     df=df.nlargest(20,'user_count')
#     df= df.groupby(df['district'])
#     df= df.get_group(''+district+'')


    if df.empty == True:
        
        schname=[]
        uc=[]
      
    else:
        schname=df['name'].tolist()
        uc=df['user_count'].tolist()
    
    

    data={'schname':schname[0:20],'Familycount':uc[0:20]}
    
    return json.dumps(data)




@app.route('/partner_schoolwisepracticecounttop20_/')
def partnerschwisepc():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection1 = db.user_master
#     district=disdic[districtid]
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {'USER_ID.schoolId._id':{'$ne':None}},
                      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#               {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},

    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'practice_count':'$pc'}},
            { '$sort' : { 'practice_count' : -1}}
    # //               {'$count':'count'}
                  ])))
    df2=DataFrame(list(collection1.aggregate([{"$match":
     {'$and': [
           {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                  {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},

             {'EMAIL_ID':{'$ne':''}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'name':{'$first':'$schoolId.NAME'},'user_name':{'$first':'$USER_NAME'}
                  }},


        {'$project':{'_id':1,'name':1}},])))

    df=pd.merge(df1,df2, how='left', on='_id')
#     print(df)
    if df.empty == True:
        
        schname=[]
        pc=[]
      
    else:
        schname=df['name'].tolist()
        pc=df['practice_count'].tolist()
    data={'schname':schname[0:20],'Familypracticecount':pc[0:20]}
    
    return json.dumps(data)

@app.route('/partner_top20userspractisinginfo_/')
def partner_topusers_practice():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
#     district=disdic[districtid]


    collection1 = db.user_master
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
    #           {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
             {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},

             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':'$USER_ID._id','pc':{'$sum':1}}},
              {'$project':{'_id':1,'practice_count':'$pc'}},
    { '$sort' : { 'practice_count' : -1} }



    # //               {'$count':'count'}
              ])))
    df1

    df2=DataFrame(list(collection1.aggregate([{"$match":
     {'$and': [
    #         {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                  {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},

             {'EMAIL_ID':{'$ne':''}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$_id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'user_name':{'$first':'$USER_NAME'}
                  }},


        {'$project':{'_id':1,'user_name':1,'school_name':1}},])))

    df=pd.merge(df1,df2, how='left', on='_id')
    df
    if df.empty == True:

        schname=[]
        pc=[]

    else:
        df["users"] = df["user_name"] +','+' ' + df["school_name"]
        schname=df['users'].tolist()
        pc=df['practice_count'].tolist()



    #     data=[]    
    #     for i,k in zip(schname,uc):

    #         data.append([i,k])

    #     for i in range(len(schname)):
    #             schname[i] = schname[i]
    data={'schname':schname[0:20],'practicecount':pc[0:20]}

    return json.dumps(data)



@app.route('/schoolwiseusercounttop20_/')
def partner__schwiseuc():
   
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass  
    collection = db.user_master
#     district=disdic[districtid]
    df = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                      {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
#                    {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'user_count':{'$size':'$ID'},'name':'$NAME','district':'$district'}},
                   { '$sort' : { 'user_count' : -1}}
    # //               {'$count':'count'}
                  ])))

    # df['SCH_CREATED_DATE']=pd.to_datetime(df['SCH_CREATED_DATE'])

#     df=df.nlargest(20,'user_count')
#     df= df.groupby(df['district'])
#     df= df.get_group(''+district+'')

    if df.empty == True:
        
        schname=[]
        pc=[]
      
    else:
        schname=df['name'].tolist()
        uc=df['user_count'].tolist()
   
    data={'schname':schname[0:20],'usercount':uc[0:20]}
    
    return json.dumps(data)


@app.route('/partner_heatmappractice_/')

def heatmap_prac_partner():

    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},

                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},

                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'}}},
                      {'$project':{'_id':1,'schools':'$ID'}},

                      ])))

    ids=list(df['_id'])
    
    
    df3=DataFrame(list(collection.aggregate([
{"$match":
    {'$and': [

         
        {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
{'USER_ID.schoolId._id':{'$in':ids}},


 {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,1,1)}},]}},


        {'$group':{'_id':'$USER_ID.schoolId._id','uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
              {'$project':{'_id':1,'active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
    { '$sort' : { 'active_user_count' : -1} },
    {'$limit':30}])))
    top=list(df3['_id'])
#     print(df3)
#     df3.to_csv('file1.csv')
    df2=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            
#              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':top}},
    # {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
  
     {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,1,1)}},]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'school':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    # df2

    df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        finaldf = pd.concat(result)
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =practice_count
    data=collections.OrderedDict(sorted(data.items()))
    data={'meanTemp':data}

    
    return json.dumps(data)    










@app.route('/portal_new_api/<smcategory>')
def portal_new_api(smcategory):
    if not g.user:    
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
        client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
        db=client.compass
        collection = db.school_master
        from bson.objectid import ObjectId
    #     smcategory="Agawam School district"
        query=[{'$match':{'$and':[
        { 'CATEGORY':{"$regex":""+smcategory+"",'$options':'i'}},
        {'IS_PORTAL':'Y'},
        ]
        }},
        {"$project":{"_id":0,
        "UMSCHOOLID":'$_id',
        "UMSCHOOLNAME":'$NAME',
        "is_paid":"$FULL_EXPERIENCE",
                    }},
        ]
        merge11=list(collection.aggregate(query))

        overallum11=pd.DataFrame(merge11)
    #     print(overallum11,"helloooooooooooo1achsdkjcbsdkjcbsdku")
        # print(len(set(list(overallum11["UMSCHOOLID"]))),"school_count")
        lifetimelist=list(set(overallum11["UMSCHOOLID"]))
        total_school=len(lifetimelist)
        collection = db.user_master
        query=[{'$match':{'$and':[{
        "schoolId._id": {
        "$in":lifetimelist
        }   
        },
        { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
        ]
        }},
        {"$project":{"_id":0,
        'ROLE':'$ROLE_ID.ROLE_NAME',
        'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
        "UMSCHOOLID":'$schoolId._id',
        "DISTRICT_NAME":"$DISTRICT_ID.DISTRICT_NAME",
                    "UMSCHOOLNAME":'$schoolId.NAME',
                    }},
        ]
        merge1=list(collection.aggregate(query))
        overallum=pd.DataFrame(merge1)
    #     print(overallum,"overallum")
        email=""
        schoolid=[]
        try:
            email=list(overallum["UMUSER_ID"])
            schoolid=list(overallum["UMSCHOOLID"])
        except:
            pass
        ################################sub_master################################
        collection = db.subscription_master
        qr=[
        {"$match":{"$and":[{'USER_ID._id':{"$in":email}},]}},
        {"$project":{"_id":0,
        'SMUSER_ID':'$USER_ID._id',
        "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
        }},]
        merge=[]
        overall=[]
        mergeddf=[]
        try:
            merge=list(collection.aggregate(qr))
            overall=pd.DataFrame(merge)
            mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
        except:
            pass
        db=client.compass
        collection = db.audio_track_master
        qra=[
        {"$match":{'$and':[
            {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'USER_ID.schoolId._id':{'$in':schoolid}},
        ]}},
        {'$group':{'_id':'$USER_ID.schoolId._id', 
        'atdLastpractice':{'$max':'$MODIFIED_DATE'},
        'atdPracticecount':{'$sum':1},
        'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}]
        merge110=[]
        atd=[]
        mmm=0
        try:
            merge110=list(collection.aggregate(qra))
            atd=pd.DataFrame(merge110)
            mmm=str(round(sum(atd["atdTotal_Mindful_Minutes"])))
            finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
            finaldata=finalmerge[["DISTRICT_NAME","UMSCHOOLID","UMSCHOOLNAME","UMUSER_ID","ROLE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
            finaldata["atdPracticecount"] = finaldata['atdPracticecount'].fillna(0)
            finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
            finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')
        except:
            pass
    #     print(finaldata)
        usercount=0
        try:
            usercount=len(finaldata[finaldata["ROLE"]=='user'])
        except:
            pass
        familycount=0
        try:
            familycount=len(finaldata[finaldata["ROLE"]=='PRESENT'])
        except:
            pass

        data2=[]
        totschnew=len(overallum11[overallum11["is_paid"]=="Y"])
        overallum11["UMSCHOOLID"] = overallum11["UMSCHOOLID"].astype('str')
        overallum11=overallum11.sort_values(by=['UMSCHOOLNAME'], ascending=True)
        for i in range(len(overallum11)):
            data2.append({"school_id":overallum11["UMSCHOOLID"][i],"school_name":overallum11["UMSCHOOLNAME"][i],"is_paid":overallum11["is_paid"][i]})
        finaldata={"data":data2,"total_school":totschnew,"user_count":usercount,"family_count":familycount,"mindful_minutes":mmm}
        return json.dumps(finaldata)
    return "no no no"
@app.route('/Executive_Dashboard')
def Executive_Dashboard():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Executive_Dashboard.html')

@app.route('/leadGeneration')
def leadGeneration():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('leadGeneration.html')

@app.route('/oms_dashboard')
def oms_dashboard():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('oms_dashboard.html')


@app.route('/School_Analytics')
def School_Analytics():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('School_Analytics.html')

@app.route('/Family_School_Search')
def Family_School_Search():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Family_School_Search.html')

@app.route('/School_Search')
def School_Search():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('School_Search.html')



@app.route('/Practice_Analytics')
def Practice_Analytics():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Practice_Analytics.html')


@app.route('/Subscription_Expired')
def Subscription_Expired():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Subscription_Expired.html')


@app.route('/feedback_Analyitcs')
def feedback_Analyitcs():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('feedback_Analyitcs.html')


@app.route('/feedback_Trends')
def feedback_Trends():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('feedback_Trends.html')


@app.route('/aws')
def aws():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('aws.html')


@app.route('/Upcoming_Renewals')
def Upcoming_Renewals():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Upcoming_Renewals.html')

@app.route('/IOS_Analytics')
def IOS_Analytics():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('IOS_Analytics.html')

@app.route('/Android_analytics')
def Android_analytics():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Android_analytics.html')

@app.route('/Sms_analytics')
def Sms_analytics():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Sms_analytics.html')

@app.route('/Daily_Analytics')
def Daily_Analytics():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Daily_Analytics.html')

@app.route('/District_level_view_SKILLMAN')
def District_level_view_SKILLMAN():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('District_level_view_SKILLMAN.html')

@app.route('/Parents_map_view')
def Parents_map_view():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Parents_map_view.html')

@app.route('/Transaction_Reporting')
def Transaction_Reporting():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('Transaction_Reporting.html')

@app.route('/Progarm_wise_Analytics')
def Progarm_wise_Analytics():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Progarm_wise_Analytics.html')

@app.route('/Family_practice_analytics')
def Family_practice_analytics():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Family_practice_analytics.html')

@app.route('/Familyapp_school')
def Familyapp_school():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Familyapp_school.html')

@app.route('/District_level_Parent_view')
def District_level_Parent_view():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('District_level_Parent_view.html')


@app.route('/Parents_Analytics')
def Parents_Analytics():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Parents_Analytics.html')

@app.route('/District_level_view_RUSD')
def District_level_view_RUSD():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('District_level_view_RUSD.html')

@app.route('/District_level_view_HILLSBOROUGH')
def District_level_view_HILLSBOROUGH():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('District_level_view_HILLSBOROUGH.html')

@app.route('/District_level_view_FAIRFIELD')
def District_level_view_FAIRFIELD():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('District_level_view_FAIRFIELD.html')

@app.route('/District_level_view_LAUSD')
def District_level_view_LAUSD():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('District_level_view_LAUSD.html')
@app.route('/District_level_view_Search')
def District_level_view_Search():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('District_level_view_Search.html')

@app.route('/District_level_view_BROWARD')
def District_level_view_BROWARD():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('District_level_view_BROWARD.html')

@app.route('/District_level_view_SARASOTA')
def District_level_view_SARASOTA():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('District_level_view_SARASOTA.html')


@app.route('/District_level_view_youngstown')
def District_level_view_youngstown():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('District_level_view_youngstown.html')

@app.route('/District_level_view_Englewood')
def District_level_view_Englewood():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('District_level_view_Englewood.html')

@app.route('/Schoolsearch_Email')
def Schoolsearch_Email():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('Schoolsearch_Email.html')

# @app.route('/Journey_score', methods=['GET', 'POST'])
# def popup1():
#     if request.method == 'POST':
#         try:
                
#             editorname = request.form['NAME']
#         except:
#             pass
#         try:    
#             statename = request.form['myBrowser1']
#         except:
#             pass
#         try:
#             cityname = request.form['myBrowser']
#         except:
#             pass
#         try:

#             email = request.form['email']
#         except:
#             pass
#         try:

#             district = request.form['myBrowser3']
#         except:
#             pass
#         try:
                
#             partner = request.form['myBrowser4']
#         except:
#             pass
#         # print(email)
#         # print(statename)
#         # print(editorname)
#         # print(cityname)
#         # print(district)
#         # print(partner)
#         db = mysql.connector.connect(
#         host="54.184.165.106",
#         user="IE-tech",
#         passwd="IE-tech@2O2O",
#         database="compassJul")



#         mycursor = db.cursor()

#         DICTDIS={"Test District":"1","Los Angeles Unified School District":"2","Westfield Public School District":"3","Comox Valley School District(sd71)":"4","Youngstown":"5","Fairfield-Suisun Unified School District":"6","Griffin-Spalding County School System":"7","Clarksville-Montgomery County School System":"8","Englewood Public School District":"9","Englewood Cliffs Public Schools":"10","Austin Independent School District":"11","Equity Education":"12","_x000D_Middleton - Cross Plains Area School District":"13","Pinellas County Schools":"14","Lincolnshire Schools":"15","Utah Board of Education":"16","LSF -  Head Start":"17","Springfield Public Schools":"18","FundaciÃ³n La Puerta":"19","Chico Unified School District":"20","Broward County Public Schools":"21","District 25 New York Schools":"22","Paradise Schools":"23","San Leandro Unified School District":"24","Racine Unified Schools":"25","Oroville City Elementary School District":"27","Skillman Foundation":"28","Greenburgh-North Castle (GNC) Union Free School District":"29","Agawam School district":"30","Hillsborough County":"31","Sarasota County":"32","San Diego Unified School District":"33","Panorama Education":"34","Alpine School District":"35","Ann Arbor Public Schools":"36","Hawaii Public Schools":"37","Flint Public Schools":"38"}
#         try:

#             inputdict=str(DICTDIS[district])
#         except:
#             pass

#         Partnerdict={"Hemera":"1","Aetna":"5","CRIM":"6","Calmer Choice":"8","Summer Schools":"9","San JosÃ© Unified School District":"10","hillsborough":"11","LG":"12","Character Day":"30"}
#         try:

#             partnerinput=Partnerdict[partner]
#         except:
#             pass
#         qr="""SELECT um.user_id ,up.school_id FROM user_master um 
#         inner join user_profile up on up.user_id=um.user_id
#         where um.email_id like '%"""+email+"""%' """
#         df=pd.read_sql(qr, con=db)
#         schoolid=str(int(df[0:1]['school_id'][0]))
#         userid=str(df[0:1]['user_id'][0])



#         # UPDATE `compassFeb`.`user_master` SET `PARTNER_ID` = '1' WHERE (`USER_ID` = '11');
#         if editorname=='':
#             print('Empty')
#         else:
#             ucomment= editorname + ' updated through cap4g ' 
#         try:
#           if statename=='':
#               print('Empty')
#           else:
#             sql ="""UPDATE `school_master` SET `STATE` = '"""+statename+"""' WHERE `ID` = """+schoolid+""" """
#             mycursor.execute(sql)

#             db.commit()
#         except:
#             print("1")
#             pass
#         try:
#          if cityname=='':
#             print('Empty')
#          else:
#             sql ="""UPDATE `school_master` SET `CITY` = '"""+cityname+"""' WHERE `ID` = """+schoolid+""" """
#             mycursor.execute(sql)

#             db.commit()
#         except:
#             print("2")
#             pass
#         try:
          
#             sql ="""UPDATE `user_master` SET `DS_UM_COMMENTS` = '"""+ucomment+"""' WHERE `USER_ID` = """+userid+""" """
#             mycursor.execute(sql)

#             db.commit()
#         except:
#             print("3")
#             pass
#         try:

#             sql ="""UPDATE `user_master` SET  `DISTRICT_ID` = '"""+inputdict+"""' WHERE `USER_ID` = """+userid+""" """
#             mycursor.execute(sql)

#             db.commit()
#         except:
#             print("4")
#             pass
#         try:

#             sql ="""UPDATE `user_master` SET `PARTNER_ID` = '"""+partnerinput+"""' WHERE `USER_ID` = """+userid+""" """
#             mycursor.execute(sql)

#             db.commit()
#         except:
#             print("5")
#             pass
    
#         print(mycursor.rowcount, "record(s) affected")
       
#     return render_template('Journey_score.html')

@app.route('/pml')
def PAY_ME_LATER():
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dfdb = DataFrame(list(db.subscription_master.aggregate([
        {"$match":{"USER_ID.IS_BLOCKED" :{"$ne": "Y"},
            "USER_ID.IS_DISABLED" :{"$ne": "Y"},
            "USER_ID.INCOMPLETE_SIGNUP" : {"$ne": "Y"},
            "USER_ID.DEVICE_USED" : {'$regex' : 'Webapp', '$options' : 'i'},
            "MODE_OF_PAYMENT" :{'$regex' : 'later', '$options' : 'i'},
            "LAST_PAYMENT_AMOUNT" :{'$gt' :100},
            "$and":[
            {"USER_ID.EMAIL_ID" :{"$not": {'$regex' : 'test', '$options' : 'i'}}},
            {"USER_ID.EMAIL_ID" :{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
            {"USER_ID.USER_NAME" :{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {"USER_ID.USER_NAME" :{"$not": {'$regex' : '1gen', '$options' : 'i'}}}
            ]}},
        {"$project":{"_id":0,"EMAIL_ID":"$USER_ID.EMAIL_ID","NAME":"$USER_ID.USER_NAME",
            "SUBSCRIPTION_DATE": { "$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_DATE" } },
            "SUBSCRIPTION_EXPIRE_DATE" : { "$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_EXPIRE_DATE" } },
            "MODE_OF_PAYMENT" :1,"LAST_PAYMENT_AMOUNT":1}},
        ])))

    googleSheetId = '15kYZU_cXkkdeZtmk2EQccKSt8ksYWNoxm3-Lchh8Xbo'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    email=dff["EMAIL_ID"].tolist()
    df2 = dfdb[~dfdb['EMAIL_ID'].isin(email)]
    df=dff.append(df2) 

    df1=df[['SUBSCRIPTION_DATE','LAST_PAYMENT_AMOUNT']]
    df1['SUBSCRIPTION_DATE'] = pd.to_datetime(df1['SUBSCRIPTION_DATE'])
    df2 = df1.groupby(df1['SUBSCRIPTION_DATE'].dt.date).sum().reset_index()
    df2['SUBSCRIPTION_DATE'] = pd.to_datetime(df2['SUBSCRIPTION_DATE'])
    df2['SUBSCRIPTION_DATE'] = df2['SUBSCRIPTION_DATE'].astype(np.int64) / int(1e6)
    df2['Total_Amount'] = df2['LAST_PAYMENT_AMOUNT'].cumsum()
    df3=df2[['SUBSCRIPTION_DATE','LAST_PAYMENT_AMOUNT']]
    Amount=df3.values.tolist()
    df4=df2[['SUBSCRIPTION_DATE','Total_Amount']]
    TAmount=df4.values.tolist()
    temp={'bar':Amount,'line':TAmount}
    return(json.dumps(temp))

@app.route('/aws_releases')
def aws_releases():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('aws_releases.html')
@app.route('/Scoology')
def Scoology():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Scoology.html')


@app.route('/journeyprachis/<schoolid>')
# def journeyprachischart(schoolid):
def journeyprachischart(schoolid):    
    import datetime
    from datetime import timedelta
    from dateutil.relativedelta import relativedelta
    def csy_first_date():
            date_today =datetime.date.today()
        #     print(date_today)
        #     date_today='2024-07-01'
        #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
            initial_date='2020-08-01'
            day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
            # Check if leap year in the calculation
            if ((day1.year+1) % 4) == 0:
                if ((day1.year+1) % 100) == 0:
                    if ((day1.year+1) % 400) == 0:
                        days_diff=1
                    else:
                        days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=0
            if ((date_today-day1).days<(365+days_diff)):
                day_1=day1
            else:
                day1=day1+timedelta(days=(365+days_diff))
                day_1=day1

            csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

            return csy_date
                # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
        #     print("LSY", LSY_Date)
        #     print("CSY",csy_first_date())




    mongo_uri = "mongodb://admin:" + urllib.parse.quote('F5tMazRj47cYqm33e') + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.audio_track_master_all
    collection2 = db.audio_track_master
    ########## FOR DF ###########################
    dateStr = str(LSY_Date.date())
    myDatetime = dateutil.parser.parse(dateStr)
    datestr1 = str(csy_first_date())
    myDatetime1 = dateutil.parser.parse(datestr1)
    ########### FOR DF1 ############################
    dateStr2 = str(csy_first_date().date())
    myDatetime2 = dateutil.parser.parse(dateStr2)
    ########################## FOR DF2 ###############
    dateStr3 = "2020-03-17T00:00:00.000Z"
    myDatetime3 = dateutil.parser.parse(dateStr3)
    ##################################
    ##################################
    dateStr4 = str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1))
    myDatetime4 = dateutil.parser.parse(dateStr4)
    
    
    
    Email = DataFrame(list(db.user_master.aggregate([
        {"$match":{'$and':[{"schoolId._id":ObjectId(""+schoolid+"")},
#              {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'EMAIL_ID':{"$ne":''}},
        {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
          {'schoolId.NAME':{"$not":{"$regex":'test', '$options':'i'}}},
             {'EMAIL_ID':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{"$not":{"$regex":"TEST",'$options':'i'}}},
        {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}
            ]}},
#                   {"$group": {"_id": '$schoolId._id'}},
            {'$project':{'_id':'$_id','school':"$schoolId._id"}}
            ])))
    ID=Email["_id"].tolist()

   ######################  USER PRACTICE 2019-2020(LSY) ############################################
    




    df1 = DataFrame(list(collection2.aggregate([{"$match":
        {"$and" :[
            {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.EMAIL_ID':{'$ne':""}},
            {'USER_ID._id':{'$in':ID}},

            {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"MODIFIED_DATE":{"$gte": myDatetime2
#                                      ,"$lte" : myDatetime4
                                }},
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},


            {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
            {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Users_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    if df1.empty == True:
        df1=pd.DataFrame({'Practice_date':[],'Users_Practice_CSY':[]})
    else:
        df1
    ##################### PARENTS ##########################################
    df2 = DataFrame(list(collection2.aggregate([{"$match":
        {"$and" :[
            {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.EMAIL_ID':{'$ne':""}},
            {'USER_ID._id':{'$in':ID}},

            {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"MODIFIED_DATE":{"$gte": myDatetime2
#                                      ,"$lte" : myDatetime4
                                }},
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},


            {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
            {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}},                
        ]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    if df2.empty == True:
        df2=pd.DataFrame({'Practice_date':[],'Parents_Practice_CSY':[]})
    else:
        df2




    ########schoology################################

    schoology = DataFrame(list(collection2.aggregate([{"$match":
                {"$and" :[
                    {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                        {'USER_ID.EMAIL_ID':{'$ne':""}},
                         { "USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                       {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                        {"MODIFIED_DATE":{"$gte": myDatetime2
        #                                      ,"$lte" : myDatetime4
                                        }},
                    {'USER_ID._id':{'$in':ID}},
                    {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                          {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

            ]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    if schoology.empty == True:
        schoology=pd.DataFrame({'Practice_date':[],'Parents_Practice_CSY':[]})
    else:
        schoology
    #     print(schoology,"schoology")
    ########clever################################
    clever = DataFrame(list(collection2.aggregate([{"$match":
                {"$and" :[
                    {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                        {'USER_ID.EMAIL_ID':{'$ne':""}},
                         { "USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                       {"USER_ID._id":{"$nin":db.schoology_master.distinct( "USER_ID._id")}},
                        {"MODIFIED_DATE":{"$gte": myDatetime2
        #                                      ,"$lte" : myDatetime4
                                        }},
                    {'USER_ID._id':{'$in':ID}},
                    {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                          {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

            ]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    if clever.empty == True:
        clever=pd.DataFrame({'Practice_date':[],'Parents_Practice_CSY':[]})
    else:
        clever


    ###################### TOTAL LSY ##############################
    df3 = DataFrame(list(collection2.aggregate([{"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                   {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                       {'USER_ID._id':{'$in':ID}},
                    {'MODIFIED_DATE':{"$gte":myDatetime,"$lt": myDatetime1}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'}, 
                        'Total_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Total_Practice_LSY':'$Total_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    if df3.empty == True:
        df3=pd.DataFrame({'Practice_date':[],'Total_Practice_LSY':[]})
    else:
        schoology


    df_last_to_lsy = DataFrame(list(collection2.aggregate([{"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                          {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                            {'USER_ID._id':{'$in':ID}},                                  
                        {'MODIFIED_DATE':{"$gte":myDatetime-relativedelta(years=1),"$lt": myDatetime}}]}},

                {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                                'month':{'$month':'$MODIFIED_DATE'}},
                            'date':{'$first':'$MODIFIED_DATE'}, 
                            'Total_Practice_CSY':{'$sum':1}}},
                {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                            'Total_Practice_LSY':'$Total_Practice_CSY'}}, 
                {"$sort":{'Practice_date':1}}])))
    if df_last_to_lsy.empty == True:
        df_last_to_lsy=pd.DataFrame({'Practice_date':[],'Total_Practice_LSY':[]})
    else:
        schoology


    #user_CSY
    df1['Practice_date'] = pd.to_datetime(df1['Practice_date'])


    df5=df1.sort_values(by='Practice_date')
    #df5['Practice_date']=df5['Practice_date'].astype(np.int64)/int(1e6)
    #uscy=df5.values.tolist()
    df7=pd.date_range(start=str(csy_first_date().date()), end=str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1)))
    df9 = pd.DataFrame(df7,columns = ["Practice_date"])
    df9['value'] = 0

    uscy1= df5.merge(df9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    uscy1['Practice_date']=uscy1['Practice_date'].astype(np.int64)/int(1e6)
    uscy=uscy1[["Practice_date","Users_Practice_CSY"]].values.tolist()

    #clever csy
    if 'Practice_date' in list(clever.columns):
        clever['Practice_date'] = pd.to_datetime(clever['Practice_date'])
        df6c=clever.sort_values(by='Practice_date')
    else:
        dates=pd.date_range(start=str(csy_first_date().date()), end=str(datetime.date.today()))
        clever=pd.DataFrame(dates,columns = ["Practice_date"])
        clever['Parents_Practice_CSY'] = 0
        df6c=clever.sort_values(by='Practice_date')



    #schoology csy

    if 'Practice_date' in list(schoology.columns):
        schoology['Practice_date'] = pd.to_datetime(schoology['Practice_date'])
        df6s=schoology.sort_values(by='Practice_date')
    else:
        dates=pd.date_range(start=str(csy_first_date().date()), end=str(datetime.date.today()))
        schoology=pd.DataFrame(dates,columns = ["Practice_date"])
        schoology['Parents_Practice_CSY'] = 0
        df6s=schoology.sort_values(by='Practice_date')




    #Parent_CSY
    df2['Practice_date'] = pd.to_datetime(df2['Practice_date'])
    df6=df2.sort_values(by='Practice_date')
    dfp=pd.date_range(start=str(csy_first_date().date()), end=str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1)))
    dfp9 = pd.DataFrame(dfp,columns = ["Practice_date"])
    dfp9['value'] = 0

    pscy1= df6.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    pscy1['Practice_date']=pscy1['Practice_date'].astype(np.int64)/int(1e6)
    pscy=pscy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()


    ####clever
    ccsy1= df6c.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')


    ccsy1['Practice_date']=ccsy1['Practice_date'].astype(np.int64)/int(1e6)
    ccsy=ccsy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()




    ####schoology
    scsy1= df6s.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    scsy1['Practice_date']=scsy1['Practice_date'].astype(np.int64)/int(1e6)
    scsy=scsy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()
    #practice_Lsy
    df3['Practice_date'] = pd.to_datetime(df3['Practice_date'])
    df4=df3.sort_values(by='Practice_date')
    dfl=pd.date_range(start=str(csy_first_date().date()-relativedelta(years=1)), end=str(csy_first_date().date()-relativedelta(days=1)))
    dfl9 = pd.DataFrame(dfl,columns = ["Practice_date"])
    dfl9['value'] = 0
    plcy1= df4.merge(dfl9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    plcy1['Practice_date']=plcy1['Practice_date'].astype(np.int64)/int(1e6)
    plcy=plcy1[["Practice_date","Total_Practice_LSY"]].values.tolist()

    #practice_Lsy_to_Lsy

    df_last_to_lsy['Practice_date'] = pd.to_datetime(df_last_to_lsy['Practice_date'])
    df44=df_last_to_lsy.sort_values(by='Practice_date')
    dfk=pd.date_range(start=str(myDatetime-relativedelta(years=1)), end=str(myDatetime-relativedelta(days=1)))
    dfk9 = pd.DataFrame(dfk,columns = ["Practice_date"])
    dfk9['value'] = 0
    plcy111= df44.merge(dfk9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    plcy111['Practice_date']=plcy111['Practice_date'].astype(np.int64)/int(1e6)
    plcy_lsy=plcy111[["Practice_date","Total_Practice_LSY"]].values.tolist()

    temp={'data':{'csy':uscy,'pcsy':pscy,'lsy':plcy,'clever':ccsy,'schoology':scsy}}

    return json.dumps(temp)



# @app.route('/journeyprachis/<email>')
# def journeyprachischart(email):
#     mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
#     client = pymongo.MongoClient(mongo_uri)
#     db = client.compass
#     collection = db.audio_track_master
#     collection2 = db.user_master
#     ##############EMAIL##############
#     Email = DataFrame(list(collection2.aggregate([{"$match":{"$or":[ {'EMAIL_ID':{'$regex' :""+email+"", '$options' : 'i'}},
#                     {"EMAIL_ID":""+email+""}]}},{"$match":{'$and':[{'USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
#                     {'IS_DISABLED':{"$ne":'Y'}},{'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#                     {'IS_BLOCKED':{"$ne":'Y'}},
#                     {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}]}}
#                     ,{"$group": {"_id": '$schoolId._id'}},
#             {'$project':{'schoolId':'$_id',"_id":0}}
#             ])))
#     ID=Email["schoolId"].tolist()
#     ######################  SCHOOL PRACTICE 2019-2021 ############################################
#     df1 = DataFrame(list(collection.aggregate([{
#             '$match':{"$and" :[{'USER_ID.IS_DISABLED':{'$ne':'Y'}},
#                    { 'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
#                    { 'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#                    { 'USER_ID.EMAIL_ID':{'$ne':""}},
#                    { 'USER_ID.schoolId._id':{"$in":ID}},
#                    {'MODIFIED_DATE':{'$gte':csy_first_date()}} ,
#                     {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}]}},
#             {"$match":
#             {"$and" :[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
#                     {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
#                     {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
#                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
#             {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
#                             'month':{'$month':'$MODIFIED_DATE'}},
#                     'date':{'$first':'$MODIFIED_DATE'}, 
#                     'Users_Practice_CSY':{'$sum':1}}},
#             {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
#                         'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
#             {"$sort":{'Practice_date':1}}])))
#     #school_practice_history
#     if df1.empty:
#         shp =0
#     else:
#         df1['Practice_date'] = pd.to_datetime(df1['Practice_date'])
#         df5=df1.sort_values(by='Practice_date')
#         df5['Practice_date']=df5['Practice_date'].astype(np.int64)/int(1e6)
#         shp=df5[["Practice_date","Users_Practice_CSY"]].values.tolist()
#         df5['Cumulative_Amount'] = df5['Users_Practice_CSY'].cumsum()
#         df3=df5[['Practice_date','Cumulative_Amount']]
#         shpcum=df3.values.tolist()
#         temp={'data':{'shp':shp,'shpcum':shpcum}}
#         return json.dumps(temp)

@app.route('/family_table')
def famtablenew():
    reader = geolite2.reader()
    mongo_uri = "mongodb://admin:" + urllib.parse.quote('F5tMazRj47cYqm33e') + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.user_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    qr1=[{"$match":{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b"), 
        "IS_DISABLED":{"$ne":"Y"},
        "INCOMPLETE_SIGNUP":{"$ne":"Y"},
        "EMAIL_ID":{'$not':{'$regex':'test', '$options':'i'}},
        "EMAIL_ID":{"$ne": ""},
        "EMAIL_ID":{'$not':{'$regex':'1gen', '$options':'i'}},
        "USER_NAME":{'$not':{'$regex':'test', '$options':'i'}},
        "CREATED_DATE":{"$gt":myDatetime}}}, 
    {'$group':{'_id':'$_id','Parents_Id':{'$first':'$_id'},'name':{'$first':'$schoolId.NAME'},'city':{'$first':'$schoolId.CITY'},'state':{'$first':'$schoolId.STATE'},
    'country':{'$first':'$schoolId.COUNTRY'},
    'ip_address':{'$first':'$IP_ADDRESS'}, 'Parents_Name':{'$first':'$USER_NAME'}, 'Parents_Email':{'$first':'$EMAIL_ID'}, 
    'contact_number':{'$first':'$CONTACT_NUMBER'}, 'user_type':{'$first':'$USER_TYPE'}, 'Sign_Up_Date':{'$first':'$CREATED_DATE'}
    }}
    ]
    collection2= db.audio_track_master
    qr2= [
        {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}, 
    {'USER_ID.CREATED_DATE':{'$gt':myDatetime}}, 
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}}
    ]}},
    {"$match":
    {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}
    ]
    }}, 
    {'$group':{'_id':'$USER_ID._id', 
    'Practice_Count':{'$sum':1},'Last_Practice_Date':{'$max':'$MODIFIED_DATE'},'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}
    }} 
        ]
    collection3= db.login_logs
    qr3=[
        {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}, 
    {'USER_ID.CREATED_DATE':{'$gt':myDatetime}}, {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}}
    ]}},
    {"$match":
    {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}
    ]
    }}, 
    {'$group':{'_id':'$USER_ID._id', 'Last_Login_Date':{'$max':'$LAST_LOGGED_IN'},
    }}     
        ]
    um= list(collection.aggregate(qr1))
    df_um= pd.DataFrame(um)
    atd= list(collection2.aggregate(qr2))
    df_atd= pd.DataFrame(atd)
    ll= list(collection3.aggregate(qr3))
    df_ll=pd.DataFrame(ll)
    join=pd.merge(df_um, df_atd, how='left', on='_id')
    df= pd.merge(join, df_ll, how='left', on='_id')
    df.mindful_minutes=df.mindful_minutes.fillna(0)
    df.mindful_minutes=df.mindful_minutes.astype('int64')
    df['Last_Practice_Date']=pd.to_datetime(df['Last_Practice_Date'])
    df['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    df['Last_Login_Date']=pd.to_datetime(df['Last_Login_Date'])
    df['Last_Login_Date'].fillna("NO LOGIN", inplace=True)
    df['Sign_Up_Date']=pd.to_datetime(df['Sign_Up_Date'])
    df['name'].fillna("NO SCHOOL INFO", inplace=True)
    def country1(i):
        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=df['ip_address'].tolist()
    phone_number=df['contact_number'].tolist()
    Parents_Name=df['Parents_Name'].tolist()
    Parents_Email=df.Parents_Email.tolist()
    School_Name=df['name'].tolist()
    state=df['state'].tolist()
    country=df['country'].tolist()
    city=df['city'].tolist()
    sign_up_date=df['Sign_Up_Date'].tolist()
    last_prac_date=df['Last_Practice_Date'].tolist()
    last_login_date=df['Last_Login_Date'].tolist()
    practice_count=df['Practice_Count'].tolist()
    mindful_minutes=df['mindful_minutes'].tolist()
    for i in range(len(ip)):
        if country[i] is None:
            try:
                country[i]=country1(ip[i])
            except:
                pass
        elif country[i]=='null':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if city[i] is None:
            try:
                city[i]=city1(ip[i])
            except:
                pass
        elif city[i]=='null':
            try:
                city[i]=city1(ip[i])
            except:
                pass
        if state[i] is None:
            try:
                state[i]=state1(ip[i])
            except:
                pass
        elif state[i] =='NO state info':
            try:
                state[i]=state1(ip[i])
            except:
                pass    
        if country[i] is None:
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] is None:
            country[i]=''
        if state[i] is None:
            state[i]=''
        if  last_prac_date[i] != 'NO PRACTICE' :
            last_prac_date[i]=(last_prac_date[i]- timedelta(hours=4)).strftime('%d %b %Y')
        else:
            last_prac_date[i]="NO PRACTICE"
        if  last_login_date[i] != 'NO LOGIN' :
            last_login_date[i]=(last_login_date[i]- timedelta(hours=4)).strftime('%d %b %Y')

        else:
            last_login_date[i]="NO LOGIN"
        if sign_up_date[i] is not None:

            sign_up_date[i]=(sign_up_date[i]- timedelta(hours=4)).strftime('%d %b %Y')
    #             print(sign_up_date[i])
    state12 =  [each_string.lower() for each_string in state]
    cv={'pnn':Parents_Name,'pe':Parents_Email,'co':country,'pn':phone_number,'sn':School_Name,'ct':city,
                            'st':state12,'sp':sign_up_date,
                            'll':last_login_date,'lp':last_prac_date,'pc':practice_count}
    dftry = pd.DataFrame.from_dict(cv).fillna(0)
    dftry= dftry.drop("co", axis=1) 
    dftry1=dftry
    print(len(dftry),"lenght")
    return json.dumps({"data":dftry1.values.tolist()})


@app.route('/bubble_dataframe.csv')
def buble_district12():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.user_master
    qraaa=[
        {"$match":{'$and':[
        {'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" } )}},
        {'DISTRICT_ID':{'$exists':1}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'CREATED_DATE':{"$gte":myDatetime}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$DISTRICT_ID._id',"month":{"$month": "$CREATED_DATE"}},
        'NAME_DISTRICT':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
        'usercount':{'$sum':1}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","MONTH":"$_id.month","NAME_DISTRICT":1,"usercount":1,
                        }}]
    merge11=list(collection.aggregate(qraaa))
    df1=pd.DataFrame(merge11)
    #######################################################
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.user_master
    qra=[
        {"$match":{'$and':[
        {'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" } )}},
        {'DISTRICT_ID':{'$exists':1}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'CREATED_DATE':{"$lt":myDatetime}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$DISTRICT_ID._id'},
        'NAME_DISTRICT':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
        'usercount':{'$sum':1}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","NAME_DISTRICT":1,"usercount":1,
                        }}]
    merge11233=list(collection.aggregate(qra))
    dfCV=pd.DataFrame(merge11233)
    #########################################################################
    df1=df1.sort_values(by=['NAME_DISTRICT'], ascending=True)
    x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    x["usercount"].sum()
    dislist=list(set(df1["NAME_DISTRICT"]))
    df2=df1[["NAME_DISTRICT","MONTH","usercount"]]
    overall=pd.DataFrame(columns=["NAME_DISTRICT","MONTH","usercount"])
    # dislist
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["NAME_DISTRICT"]==k]
        df45.reset_index()
        for i in range(1,13):
            if i in list(df45["MONTH"]):
                pass
    #              print("month_present",i)
            else:
                df45.loc[i+len(df45)] = [k] +[i]+[0]
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).reset_index()
        df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).sum().groupby(level=0).cumsum().reset_index()
    #     print(df46)
        sorted_df =df46.sort_values(by=['MONTH'], ascending=True)
        sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
    buubleusercount = pd.concat(result)
    ######family ########
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.user_master
    qraaa=[
        {"$match":{'$and':[
        {'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" } )}},
        {'DISTRICT_ID':{'$exists':1}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'CREATED_DATE':{"$gte":myDatetime}},
        {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$DISTRICT_ID._id',"month":{"$month": "$CREATED_DATE"}},
        'NAME_DISTRICT':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
        'famcount':{'$sum':1}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","MONTH":"$_id.month","NAME_DISTRICT":1,"famcount":1,
                        }}]
    merge11=list(collection.aggregate(qraaa))
    df1=pd.DataFrame(merge11)
    #######################################################
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.user_master
    qra=[
        {"$match":{'$and':[
        {'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" } )}},
        {'DISTRICT_ID':{'$exists':1}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'CREATED_DATE':{"$lt":myDatetime}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$DISTRICT_ID._id'},
        'NAME_DISTRICT':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
        'usercount19':{'$sum':1}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","NAME_DISTRICT":1,"usercount19":1,
                        }}]
    merge11233=list(collection.aggregate(qra))
    dfCV=pd.DataFrame(merge11233)
    #########################################################################
    df1=df1.sort_values(by=['NAME_DISTRICT'], ascending=True)
    x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    x["famcount"].sum()
    dislist=list(set(df1["NAME_DISTRICT"]))
    df2=df1[["NAME_DISTRICT","MONTH","famcount"]]
    overall=pd.DataFrame(columns=["NAME_DISTRICT","MONTH","famcount"])
    # dislist
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["NAME_DISTRICT"]==k]
        df45.reset_index()
        for i in range(1,13):
            if i in list(df45["MONTH"]):
                pass
    #              print("month_present",i)
            else:
                df45.loc[i+len(df45)] = [k] +[i]+[0]
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).reset_index()
        df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).sum().groupby(level=0).cumsum().reset_index()
    #     print(df46)
        sorted_df =df46.sort_values(by=['MONTH'], ascending=True)
        sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
    buublefamily = pd.concat(result)
    buubleusercount["idu"]=buubleusercount["NAME_DISTRICT"]+buubleusercount["MONTH"].map(str)
    buublefamily["idf"]=buublefamily["NAME_DISTRICT"]+buublefamily["MONTH"].map(str)
    mergeucfc=pd.merge(buubleusercount, buublefamily, how='left', left_on='idu', right_on='idf')
    mergeucfc=mergeucfc.fillna(0)
    mergeucfc1=pd.merge(mergeucfc, dfCV, how='left', left_on='NAME_DISTRICT_x', right_on='NAME_DISTRICT')
    mergeucfc12=mergeucfc1.fillna(0)
    mergeucfc12["totaluser"]=mergeucfc12["usercount"]+mergeucfc12["usercount19"]
    finmerge=mergeucfc12[["NAME_DISTRICT_x","MONTH_x","idu","totaluser","famcount"]]
    ###ACTIVE USER
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.audio_track_master
    qra12=[
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" } )}},
        {'USER_ID.DISTRICT_ID':{'$exists':1}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'MODIFIED_DATE':{"$gte":myDatetime}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$USER_ID.DISTRICT_ID._id',"year":{"$year": "$MODIFIED_DATE"},"month":{"$month": "$MODIFIED_DATE"}},
        'NAME_DISTRICT':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'},
        'PRACTICE':{'$sum':1},
        "ACTIVE_USER":{'$addToSet':"$USER_ID._id"},
        'Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","MONTH":"$_id.month","YEAR":"$_id.year","NAME_DISTRICT":1,"PRACTICE":1,"ACTIVE_USER":{"$size":"$ACTIVE_USER"},
                       "Mindful_Minutes":1 }}]
    merge121=list(collection.aggregate(qra12))
    df1=pd.DataFrame(merge121)
    df1=df1.sort_values(by=['NAME_DISTRICT'], ascending=True)
    # print(df1)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["NAME_DISTRICT"]))
    df2=df1[["NAME_DISTRICT","MONTH","ACTIVE_USER"]]
    overall=pd.DataFrame(columns=["NAME_DISTRICT","MONTH","ACTIVE_USER"])
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["NAME_DISTRICT"]==k]
        df45.reset_index()
        for i in range(1,13):
            if i in list(df45["MONTH"]):
                pass
    #              print("month_present",i)
            else:
                df45.loc[i+len(df45)] = [k] +[i]+[0]
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).reset_index()
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).sum().groupby(level=0).cumsum().reset_index()
    #     print(df46)
        sorted_df =df45.sort_values(by=['MONTH'], ascending=True)
        sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
    buubleactuser = pd.concat(result)
    buubleactuser["acuid"]=buubleactuser["NAME_DISTRICT"]+buubleactuser["MONTH"].map(str)
    # buubleactuser
    finmergeu=pd.merge(finmerge, buubleactuser, how='left', left_on='idu', right_on='acuid')
    ###ACTIVE FAMILY
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.audio_track_master
    qra12=[
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" } )}},
        {'USER_ID.DISTRICT_ID':{'$exists':1}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'MODIFIED_DATE':{"$gte":myDatetime}},
        {'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$USER_ID.DISTRICT_ID._id',"year":{"$year": "$MODIFIED_DATE"},"month":{"$month": "$MODIFIED_DATE"}},
        'NAME_DISTRICT':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'},
        'PRACTICE':{'$sum':1},
        "ACTIVE_FAM":{'$addToSet':"$USER_ID._id"},
        'Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","MONTH":"$_id.month","YEAR":"$_id.year","NAME_DISTRICT":1,"PRACTICE":1,"ACTIVE_FAM":{"$size":"$ACTIVE_FAM"},
                       "Mindful_Minutes":1 }}]
    merge121=list(collection.aggregate(qra12))
    df1=pd.DataFrame(merge121)
    df1=df1.sort_values(by=['NAME_DISTRICT'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["NAME_DISTRICT"]))
    df2=df1[["NAME_DISTRICT","MONTH","ACTIVE_FAM"]]
    overall=pd.DataFrame(columns=["NAME_DISTRICT","MONTH","ACTIVE_FAM"])
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["NAME_DISTRICT"]==k]
        df45.reset_index()
        for i in range(1,13):
            if i in list(df45["MONTH"]):
                pass
    #              print("month_present",i)
            else:
                df45.loc[i+len(df45)] = [k] +[i]+[0]
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).reset_index()
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).sum().groupby(level=0).cumsum().reset_index()
    #     print(df46)
        sorted_df =df45.sort_values(by=['MONTH'], ascending=True)
        sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
    buubleactfam = pd.concat(result)
    buubleactfam["acuidf"]=buubleactfam["NAME_DISTRICT"]+buubleactfam["MONTH"].map(str)
    finmergeuf=pd.merge(finmergeu, buubleactfam, how='left', left_on='idu', right_on='acuidf')
    finmergeuf["USER ENGAGEMENT"]=round((finmergeuf["ACTIVE_USER"]/finmergeuf["totaluser"])*100)
    finmergeuf["FAMILY ENGAGEMENT"]=round((finmergeuf["ACTIVE_FAM"]/finmergeuf["famcount"])*100)
    finmergeufo=finmergeuf[["NAME_DISTRICT_x","MONTH_x","USER ENGAGEMENT","FAMILY ENGAGEMENT"]]
    finmergeufo=finmergeufo.fillna(0)
    finmergeufo=finmergeufo.loc[:,~finmergeufo.columns.duplicated()]
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.audio_track_master
    qra12=[
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" } )}},
        {'USER_ID.DISTRICT_ID':{'$exists':1}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    #     {'MODIFIED_DATE':{"$gte":myDatetime}},
    #     {'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$USER_ID.DISTRICT_ID._id'},
        'NAME_DISTRICT':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'},
        'PRACTICE':{'$sum':1},
                  }},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","NAME_DISTRICT":1,"PRACTICE":1 }}]
    merge1211=list(collection.aggregate(qra12))
    df1111=pd.DataFrame(merge1211)
    df1111=df1111.sort_values(by=['NAME_DISTRICT'], ascending=True)
    DISPRACTO=df1111[["NAME_DISTRICT","PRACTICE"]]
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.user_master
    qra12=[
        {"$match":{'$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" } )}},
        {'DISTRICT_ID':{'$exists':1}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    #     {'MODIFIED_DATE':{"$gte":myDatetime}},
    #     {'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$DISTRICT_ID._id'},
        'NAME_DISTRICT':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
        "SCHOOL COUNT":{'$addToSet':"$schoolId._id"},
                  }},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","NAME_DISTRICT":1,"SCHOOL COUNT":{"$size":"$SCHOOL COUNT"} }}]
    merge1211=list(collection.aggregate(qra12))
    df1111=pd.DataFrame(merge1211)
    df1111=df1111.sort_values(by=['NAME_DISTRICT'], ascending=True)
    DISSCHOOL=df1111[["NAME_DISTRICT","SCHOOL COUNT"]]
    finmergeufosch=pd.merge(finmergeufo, DISSCHOOL, how='left', left_on='NAME_DISTRICT_x', right_on='NAME_DISTRICT')
    finmergeufoschprac=pd.merge(finmergeufosch, DISPRACTO, how='left', left_on='NAME_DISTRICT_x', right_on='NAME_DISTRICT')
    final_buuble_data=finmergeufoschprac[["NAME_DISTRICT_x","MONTH_x","USER ENGAGEMENT","FAMILY ENGAGEMENT","SCHOOL COUNT","PRACTICE"]]
    finaldata=final_buuble_data.rename(columns={"NAME_DISTRICT_x": "DISTRICT_NAME","USER ENGAGEMENT":"USER_ENGAGEMENT","SCHOOL COUNT":"SCHOOL_COUNT", "FAMILY ENGAGEMENT":"FAMILY_ENGAGEMENT","MONTH_x": "MONTH"})
    finaldata=finaldata.loc[:,~finaldata.columns.duplicated()]
    # findict=finaldata.T.to_dict().values()
    # response = make_response(finaldata.to_csv())
    # response.headers['Content-Type'] = 'text/csv'
    li = [finaldata.columns.values.tolist()] + finaldata.values.tolist() 
    sheet = pe.Sheet(li)
    print(sheet,"sheet")
    print(type(sheet),"sheet type")
    ioO = io.StringIO()
    sheet.save_to_memory("csv", ioO)
    output = make_response(ioO.getvalue())
    # output.headers["Content-Disposition"] = "attachment; filename=export.csv"
    output.headers["Content-type"] = "text/csv"
    return output
    # return Response(finaldata.to_csv())
# py2.7, for python3, please use import io

# app = Flask(__name__)

@app.route('/rtusercount')
def realtimeusercount():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'MODIFIED_DATE': {'$gte': datetime.datetime.utcnow()-datetime.timedelta(seconds=60)}}
              ]}},
           {'$group':
           {'_id':'$USER_ID._id',
               'State':{'$first':'$USER_ID.schoolId.STATE'},
               'Country':{'$first':'$USER_ID.schoolId.COUNTRY'}
               }}
           ]
    realtime=list(collection.aggregate(query4))
    realtimeuserpractising=pd.DataFrame(realtime)
    #####################family######################
    query=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
#               {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'MODIFIED_DATE': {'$gte': datetime.datetime.utcnow()-datetime.timedelta(seconds=60)}}
              ]}},
           {'$group':
           {'_id':'$USER_ID._id',
               'State':{'$first':'$USER_ID.schoolId.STATE'},
               'Country':{'$first':'$USER_ID.schoolId.COUNTRY'}
               }}
           ]
    realtimeparent=list(collection.aggregate(query))
    realtimeparentpractising=pd.DataFrame(realtimeparent)
    temp={'userpracticing':len(realtimeuserpractising),'parentrpracticing':len(realtimeparentpractising)}
    return json.dumps(temp)

@app.route('/rtmapcount')
def realtimemaprcount():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
            #   {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            #   {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'MODIFIED_DATE': {'$gte': datetime.datetime.utcnow()-datetime.timedelta(seconds=300)}}
              ]}},
           {'$group':
           {'_id':'$USER_ID._id',
               'State':{'$first':'$USER_ID.schoolId.STATE'},
               'Country':{'$first':'$USER_ID.schoolId.COUNTRY'}
               }}
           ]
    realtime=list(collection.aggregate(query4))
    realtimeuserpractising=pd.DataFrame(realtime)
    if realtimeuserpractising.empty:
        df = pd.DataFrame(columns=['State', 'STATE_SHOT','text','_id'])
        for i in range(1):
            df.loc[i] = ['none'] +['none'] +['NO USER PRACTICING RIGHT NOW']+ [0]
            df1=df[["State","_id","STATE_SHOT",'text']]
            links0 =df1.rename(columns={'STATE_SHOT' : 'code', '_id' : 'value','State':'name','text':'text'}).to_dict('r')
    else:
        us_state_shot = {
            'Alabama': 'AL',
            'Alaska': 'AK',
            'American Samoa': 'AS',
            'Arizona': 'AZ',
            'Arkansas': 'AR',
            'California': 'CA',
            'Colorado': 'CO',
            'Connecticut': 'CT',
            'Delaware': 'DE',
            'District of Columbia': 'DC',
            'Florida': 'FL',
            'Georgia': 'GA',
            'Guam': 'GU',
            'Hawaii': 'HI',
            'Idaho': 'ID',
            'Illinois': 'IL',
            'Indiana': 'IN',
            'Iowa': 'IA',
            'Kansas': 'KS',
            'Kentucky': 'KY',
            'Louisiana': 'LA',
            'Maine': 'ME',
            'Maryland': 'MD',
            'Massachusetts': 'MA',
            'Michigan': 'MI',
            'Minnesota': 'MN',
            'Mississippi': 'MS',
            'Missouri': 'MO',
            'Montana': 'MT',
            'Nebraska': 'NE',
            'Nevada': 'NV',
            'New Hampshire': 'NH',
            'New Jersey': 'NJ',
            'New Mexico': 'NM',
            'New York': 'NY',
            'North Carolina': 'NC',
            'North Dakota': 'ND',
            'Northern Mariana Islands':'MP',
            'Ohio': 'OH',
            'Oklahoma': 'OK',
            'Oregon': 'OR',
            'Pennsylvania': 'PA',
            'Puerto Rico': 'PR',
            'Rhode Island': 'RI',
            'South Carolina': 'SC',
            'South Dakota': 'SD',
            'Tennessee': 'TN',
            'Texas': 'TX',
            'Utah': 'UT',
            'Vermont': 'VT',
            'Virgin Islands': 'VI',
            'Virginia': 'VA',
            'Washington': 'WA',
            'West Virginia': 'WV',
            'Wisconsin': 'WI',
            'Wyoming': 'WY'
        }
        realtimeuserpractising["STATE_SHOT"] = realtimeuserpractising["State"].map(us_state_shot) 
        df1=realtimeuserpractising.groupby(["State","STATE_SHOT"]).count().reset_index()
        df2=df1[["State","_id","STATE_SHOT"]]
        links0 =df2.rename(columns={'STATE_SHOT' : 'code', '_id' : 'value','State':'name'}).to_dict('r')
    return json.dumps(links0)


@app.route('/audiowisetrend')
def audiowise_trend():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    query=[{"$match":{
         '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
          {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
          {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #       {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #       {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
          {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{
      '_id':{'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
          'Age_Group':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
          'AUDIO_ID':'$PROGRAM_AUDIO_ID.AUDIO_ID',
          'AUDIO_NAME':'$PROGRAM_AUDIO_ID.AUDIO_NAME'
      },
      'Audio_length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'},
        'Narrator':{'$first':'$PROGRAM_AUDIO_ID.NARRATEDBY'},
        'Distinct_User_Practised':{'$addToSet':'$USER_ID._id'},
        'Distinct_School_Practised':{'$addToSet':'$USER_ID.schoolId._id'},
      'Total_Sessions':{'$sum':1},
      'MM':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
      }
      },
    {'$project':{
    '_id':0,
    'Program_Name':'$_id.Program_Name',
    'Age_Group':'$_id.Age_Group',
    'AUDIO_ID':'$_id.AUDIO_ID',
    'Audio_Name':'$_id.AUDIO_NAME',
    'Narrator':'$Narrator',
    'User_Practised':{'$size':'$Distinct_User_Practised'},
    'School_Practised':{'$size':'$Distinct_School_Practised'},
    'Audio_Length':'$Audio_length',
    'Total_Sessions':'$Total_Sessions',
    'Mindful_Minutes':'$MM'
    }},
    {'$sort':{
    'Mindful_Minutes':-1
    }
    }]
    practice=list(collection.aggregate(query))
    practicing_content_df=pd.DataFrame(practice)
    collection2=db.audio_feedback
    query2=[{"$match":{
         '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
          {'USER.IS_DISABLED':{"$ne":'Y'}},
          {'USER.IS_BLOCKED':{"$ne":'Y'}},
    # //       {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //       {'USER.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
          {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
          {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
          {'$group':{
              '_id':'$AUDIO_ID.AUDIO_ID',
              '_5_STAR' :  {'$sum':{'$cond':[{'$eq': ['$RATING'
         , 5 ] }, 1, 0 ]}},
         '_4_STAR' :  {'$sum':{'$cond':[{'$eq': ['$RATING'
         , 4 ] }, 1, 0 ]}},
         '_3_STAR' :  {'$sum':{'$cond':[{'$eq': ['$RATING'
         , 3 ] }, 1, 0 ]}},
         '_2_STAR' :  {'$sum':{'$cond':[{'$eq': ['$RATING'
         , 2 ] }, 1, 0 ]}},
         '_1_STAR' :  {'$sum':{'$cond':[{'$eq': ['$RATING'
         , 0 ] }, 1, 0 ]}},
         '_0_STAR' :  {'$sum':{'$cond':[{'$eq': ['$RATING'
         , 0 ] }, 1, 0 ]}}
         ,
        'Distinct_User_Rated':{'$addToSet':'$USER._id'},
        'Distinct_School_Rated':{'$addToSet':'$USER.schoolId._id'}}},
        {'$project':{'_id':0,
            'AUDIO_ID':'$_id',
            'User_Rated':{'$size':'$Distinct_User_Rated'},
            'School_Rated':{'$size':'$Distinct_School_Rated'},
            '_5_Star':'$_5_STAR',
            '_4_Star':'$_4_STAR',
            '_3_Star':'$_3_STAR',
            '_2_Star':'$_2_STAR',
            '_1_Star':'$_1_STAR',
            '_0_Star':'$_0_STAR'
            }
            }]
    feedback=list(collection2.aggregate(query2))
    feedback_df=pd.DataFrame(feedback)
    final_df_1=practicing_content_df.merge(feedback_df,on='AUDIO_ID',how='left')
    final_df_1.update(final_df_1[['User_Rated', 'School_Rated', '_5_Star', '_4_Star',
                                  '_3_Star', '_2_Star', '_1_Star', '_0_Star']].fillna(0))
    final_df_2=final_df_1[(final_df_1['User_Practised']!=0) & (final_df_1['School_Practised']!=0)].reset_index(drop=True)
    final_df_2.loc[(final_df_2['User_Rated']!=0) &(final_df_2['School_Rated']==0) ,'School_Rated'] = 1
    final_df_2.dropna(inplace=True)
    col=['AUDIO_ID','User_Practised', 'School_Practised', 'Audio_Length', 'Total_Sessions',
         'Mindful_Minutes', 'User_Rated', 'School_Rated', '_5_Star', '_4_Star',
         '_3_Star', '_2_Star', '_1_Star', '_0_Star']
    final_df_2[col] = final_df_2[col].apply(pd.to_numeric,axis=1)
    elem=final_df_2[final_df_2['Program_Name']=='Exploring Originality Elementary'].reset_index(drop=True)
    pre_k=final_df_2[final_df_2.Program_Name=='Exploring Me Pre-k-Kindergarten'].reset_index(drop=True)
    middle=final_df_2[final_df_2.Program_Name=='Exploring Potential Middle'].reset_index(drop=True)
    high=final_df_2[final_df_2.Program_Name=='Exploring Relevance High'].reset_index(drop=True)
    sound=final_df_2[final_df_2.Program_Name=='Sound Practices'].reset_index(drop=True)
    elem.sort_values('AUDIO_ID',inplace=True)
    pre_k.sort_values('AUDIO_ID',inplace=True)
    middle.sort_values('AUDIO_ID',inplace=True)
    high.sort_values('AUDIO_ID',inplace=True)
    sound.sort_values('AUDIO_ID',inplace=True)
    temp={'elem':{
        'audio_id':elem.AUDIO_ID.astype(str).tolist(),
        'audio_name':elem.Audio_Name.tolist(),
        'user':elem.User_Practised.tolist()
        },
          'pre_k':{
        'audio_id':pre_k.AUDIO_ID.astype(str).tolist(),
        'audio_name':pre_k.Audio_Name.tolist(),
        'user':pre_k.User_Practised.tolist()},
          'middle':{
        'audio_id':middle.AUDIO_ID.astype(str).tolist(),
        'audio_name':middle.Audio_Name.tolist(),
        'user':middle.User_Practised.tolist()},
          'high':{
        'audio_id':high.AUDIO_ID.astype(str).tolist(),
        'audio_name':high.Audio_Name.tolist(),
        'user':high.User_Practised.tolist()},
          'sound':{
        'audio_id':sound.AUDIO_ID.astype(str).tolist(),
        'audio_name':sound.Audio_Name.tolist(),
        'user':sound.User_Practised.tolist()}
         }
    
    return json.dumps(temp)

@app.route('/racebardis')   
def Race_BAR():
    #####################USER#####################################
    googleSheetId = '1yDlLYtw2y85G2cXbxj1XoGc_73ihucet73D4IoxHxWg'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    df=pd.read_csv(URL).fillna("NO INFO.")
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    dateStr = "2019-08-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    dateStr1 = "2020-12-31T00:00:00.000Z"
    myDatetime1 = dateutil.parser.parse(dateStr1)
    collection = db.audio_track_master
    qra=[
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" } )}},
        {'USER_ID.DISTRICT_ID':{'$exists':1}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'MODIFIED_DATE':{"$gte":myDatetime,"$lte":myDatetime1}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$USER_ID.DISTRICT_ID._id',"year":{"$year": "$MODIFIED_DATE"},"month":{"$month": "$MODIFIED_DATE"}},
        'NAME_DISTRICT':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'},
        'PRACTICE':{'$sum':1},
        'Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","MONTH":"$_id.month","YEAR":"$_id.year","NAME_DISTRICT":1,"PRACTICE":1,
                       "Mindful_Minutes":1 }}]
    merge11=list(collection.aggregate(qra))
    df1=pd.DataFrame(merge11)
    df1["DISTRICT_ID"]=df1["DISTRICT_ID"].astype(str)
    df1.sort_values(by=['NAME_DISTRICT'], inplace=True)
    district_list=df1["DISTRICT_ID"].unique().tolist()
    district_name=df1["NAME_DISTRICT"].unique().tolist()
    dfstatic=df[df['DISTRICT_ID'].isin(district_list)]
    df2= dfstatic.merge(right=df1,left_on=[dfstatic.NAME_DISTRICT,dfstatic.MONTH,dfstatic.YEAR],right_on=[df1.NAME_DISTRICT,df1.MONTH,df1.YEAR], indicator=True, how='left')
    df3=df2[["NAME_DISTRICT_x","MONTH_x","YEAR_x","PRACTICE_y","Mindful_Minutes_y"]].fillna(0)
    df4=df3.groupby(['NAME_DISTRICT_x',"YEAR_x", 'MONTH_x']).sum().groupby(level=0).cumsum().reset_index()
    df5=df4[["MONTH_x","YEAR_x","NAME_DISTRICT_x","PRACTICE_y"]]
    district_list1=df5["NAME_DISTRICT_x"].unique().tolist()
    df12=[]
    # for i in range(1,12):
    #     for j in range(2019,2020):
    #         for k in range(len(df5.index)):
    #             if df5["MONTH_x"][k]==1 and df5["YEAR_x"][k]==2019:
    #                 df12.append(df5["PRACTICE_y"][k].tolist())
    # for i in range(len(df5.index)):
    #     if df5["MONTH_x"][i]==1 and df5["YEAR_x"][i]==2019:
    #         df12.append(df5["PRACTICE_y"][i].tolist())   
    # jan2019 = df5.loc[(df5["MONTH_x"]== 1) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # feb2019 = df5.loc[(df5["MONTH_x"]== 2) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # mar2019 = df5.loc[(df5["MONTH_x"]== 3) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # apr2019 = df5.loc[(df5["MONTH_x"]== 4) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # may2019 = df5.loc[(df5["MONTH_x"]== 5) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # jun2019 = df5.loc[(df5["MONTH_x"]== 6) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # jul2019 = df5.loc[(df5["MONTH_x"]== 7) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    aug2019 = df5.loc[(df5["MONTH_x"]== 8) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    sep2019 = df5.loc[(df5["MONTH_x"]== 9) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    oct2019 = df5.loc[(df5["MONTH_x"]== 10) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    nov2019 = df5.loc[(df5["MONTH_x"]== 11) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    dec2019 = df5.loc[(df5["MONTH_x"]== 12) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    jan2020 = df5.loc[(df5["MONTH_x"]== 1) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    feb2020 = df5.loc[(df5["MONTH_x"]== 2) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    mar2020 = df5.loc[(df5["MONTH_x"]== 3) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    apr2020 = df5.loc[(df5["MONTH_x"]== 4) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    may2020 = df5.loc[(df5["MONTH_x"]== 5) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    jun2020 = df5.loc[(df5["MONTH_x"]== 6) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    jul2020 = df5.loc[(df5["MONTH_x"]== 7) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    aug2020 = df5.loc[(df5["MONTH_x"]== 8) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    sep2020 = df5.loc[(df5["MONTH_x"]== 9) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    oct2020 = df5.loc[(df5["MONTH_x"]== 10) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    nov2020 = df5.loc[(df5["MONTH_x"]== 11) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    dec2020 = df5.loc[(df5["MONTH_x"]== 12) & (df5["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()

    ################FAMILY####################
    qraf=[
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" } )}},
        {'USER_ID.DISTRICT_ID':{'$exists':1}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
       {'MODIFIED_DATE':{"$gte":myDatetime,"$lte":myDatetime1}},
        {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    #     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$USER_ID.DISTRICT_ID._id',"year":{"$year": "$MODIFIED_DATE"},"month":{"$month": "$MODIFIED_DATE"}},
        'NAME_DISTRICT':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'},
        'PRACTICE':{'$sum':1},
        'Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","MONTH":"$_id.month","YEAR":"$_id.year","NAME_DISTRICT":1,"PRACTICE":1,
                       "Mindful_Minutes":1 }}]
    merge11f=list(collection.aggregate(qraf))
    df1f=pd.DataFrame(merge11f)
    df1f["DISTRICT_ID"]=df1f["DISTRICT_ID"].astype(str)
    df1f.sort_values(by=['NAME_DISTRICT'], inplace=True)
    df2f= dfstatic.merge(right=df1f,left_on=[dfstatic.NAME_DISTRICT,dfstatic.MONTH,dfstatic.YEAR],right_on=[df1f.NAME_DISTRICT,df1f.MONTH,df1f.YEAR], indicator=True, how='left')
    df3f=df2f[["NAME_DISTRICT_x","MONTH_x","YEAR_x","PRACTICE_y","Mindful_Minutes_y"]].fillna(0)
    df4f=df3f.groupby(['NAME_DISTRICT_x',"YEAR_x", 'MONTH_x']).sum().groupby(level=0).cumsum().reset_index()
    df5f=df4f[["MONTH_x","YEAR_x","NAME_DISTRICT_x","PRACTICE_y"]]
    # district_list1=df5["NAME_DISTRICT_x"].unique().tolist()
    # df12=[]
    # for i in range(1,12):
    #     for j in range(2019,2020):
    #         for k in range(len(df5.index)):
    #             if df5["MONTH_x"][k]==1 and df5["YEAR_x"][k]==2019:
    #                 df12.append(df5["PRACTICE_y"][k].tolist())
    # for i in range(len(df5.index)):
    #     if df5["MONTH_x"][i]==1 and df5["YEAR_x"][i]==2019:
    #         df12.append(df5["PRACTICE_y"][i].tolist())   
    # jan2019 = df5.loc[(df5["MONTH_x"]== 1) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # feb2019 = df5.loc[(df5["MONTH_x"]== 2) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # mar2019 = df5.loc[(df5["MONTH_x"]== 3) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # apr2019 = df5.loc[(df5["MONTH_x"]== 4) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # may2019 = df5.loc[(df5["MONTH_x"]== 5) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # jun2019 = df5.loc[(df5["MONTH_x"]== 6) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    # jul2019 = df5.loc[(df5["MONTH_x"]== 7) & (df5["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    aug2019f = df5f.loc[(df5f["MONTH_x"]== 8) & (df5f["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    sep2019f = df5f.loc[(df5f["MONTH_x"]== 9) & (df5f["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    oct2019f = df5f.loc[(df5f["MONTH_x"]== 10) & (df5f["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    nov2019f = df5f.loc[(df5f["MONTH_x"]== 11) & (df5f["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    dec2019f = df5f.loc[(df5f["MONTH_x"]== 12) & (df5f["YEAR_x"]== 2019)]["PRACTICE_y"].tolist()
    jan2020f = df5f.loc[(df5f["MONTH_x"]== 1) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    feb2020f = df5f.loc[(df5f["MONTH_x"]== 2) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    mar2020f = df5f.loc[(df5f["MONTH_x"]== 3) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    apr2020f = df5f.loc[(df5f["MONTH_x"]== 4) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    may2020f = df5f.loc[(df5f["MONTH_x"]== 5) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    jun2020f = df5f.loc[(df5f["MONTH_x"]== 6) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    jul2020f = df5f.loc[(df5f["MONTH_x"]== 7) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    aug2020f = df5f.loc[(df5f["MONTH_x"]== 8) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    sep2020f = df5f.loc[(df5f["MONTH_x"]== 9) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    oct2020f = df5f.loc[(df5f["MONTH_x"]== 10) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    nov2020f = df5f.loc[(df5f["MONTH_x"]== 11) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    dec2020f = df5f.loc[(df5f["MONTH_x"]== 12) & (df5f["YEAR_x"]== 2020)]["PRACTICE_y"].tolist()
    temp={"data":{"name":district_name,"user":[
    #     {'name': 'JAN 2019',"data":jan2019},{'name': 'FEB 2019',"data":feb2019},{'name': 'MAR 2019',"data":mar2019}
    #     ,{'name': 'APR 2019',"data":apr2019},{'name': 'MAY 2019',"data":may2019},{'name': 'JUN 2019',"data":jun2019}
    #     ,{'name': 'JUL 2019',"data":jul2019},
        {'name': 'AUG 2019',"data":aug2019},{'name': 'SEP 2019',"data":sep2019}
        ,{'name': 'OCT 2019',"data":oct2019},{'name': 'NOV 2019',"data":nov2019},{'name': 'DEC 2019',"data":dec2019}
        ,{'name': 'JAN 2020',"data":jan2020},{'name': 'FEB 2020',"data":feb2020},{'name': 'MAR 2020',"data":mar2020}
        ,{'name': 'APR 2020',"data":apr2020},{'name': 'MAY 2020',"data":may2020},{'name': 'JUN 2020',"data":jun2020}
        ,{'name': 'JUL 2020',"data":jul2020},{'name': 'AUG 2020',"data":aug2020},{'name': 'SEP 2020',"data":sep2020}
        ,{'name': 'OCT 2020',"data":oct2020},{'name': 'NOV 2020',"data":nov2020},{'name': 'DEC 2020',"data":dec2020}],
         "family":[
    #     {'name': 'JAN 2019',"data":jan2019},{'name': 'FEB 2019',"data":feb2019},{'name': 'MAR 2019',"data":mar2019}
    #     ,{'name': 'APR 2019',"data":apr2019},{'name': 'MAY 2019',"data":may2019},{'name': 'JUN 2019',"data":jun2019}
    #     ,{'name': 'JUL 2019',"data":jul2019},
        {'name': 'AUG 2019',"data":aug2019f},{'name': 'SEP 2019',"data":sep2019f}
        ,{'name': 'OCT 2019',"data":oct2019f},{'name': 'NOV 2019',"data":nov2019f},{'name': 'DEC 2019',"data":dec2019f}
        ,{'name': 'JAN 2020',"data":jan2020f},{'name': 'FEB 2020',"data":feb2020f},{'name': 'MAR 2020',"data":mar2020f}
        ,{'name': 'APR 2020',"data":apr2020f},{'name': 'MAY 2020',"data":may2020f},{'name': 'JUN 2020',"data":jun2020f}
        ,{'name': 'JUL 2020',"data":jul2020f},{'name': 'AUG 2020',"data":aug2020f},{'name': 'SEP 2020',"data":sep2020f}
        ,{'name': 'OCT 2020',"data":oct2020f},{'name': 'NOV 2020',"data":nov2020f},{'name': 'DEC 2020',"data":dec2020f}]}}
    return(json.dumps(temp))

@app.route('/audcompdistribution')
def averagecompletion():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    query4=[{"$match":{
         '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
          {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
          {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #       {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #       {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
          {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{
        '_id':{'userid':'$USER_ID._id',
            'audio_id':'$PROGRAM_AUDIO_ID.AUDIO_ID',
            'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
            'Audio_Name':'$PROGRAM_AUDIO_ID.AUDIO_NAME'
        },
        'Audio_Length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'},
        'start':{'$min':'$cursorStart'},
        'end':{'$max':'$CURSOR_END'}
        }},
        {'$project':{
            '_id':0,
            'USER_ID':'$_id.userid',
            'AUDIO_ID':'$_id.audio_id',
            'Program_Name':'$_id.Program_Name',
            'Audio_Name':'$_id.Audio_Name',
            'Audio_Length':'$Audio_Length',
            'start':'$start',
            'end':'$end',
            }}]
    usersprac=list(collection.aggregate(query4))
    userprac_trend=pd.DataFrame(usersprac)
    userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']
    userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)
    userprac_trend_1=userprac_trend[userprac_trend.completed_precentage>0]
    d=userprac_trend_1.groupby('AUDIO_ID')['completed_precentage'].mean().reset_index()
    d['completed_precentage']=round(d['completed_precentage'],0)
    dd=d.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)
    data=[]
    for i,j in zip(dd.completed_precentage.tolist(),dd.Audio_Count.tolist()):
        data.append([i,j])
    temp={'data':data}
    return(json.dumps(temp))


@app.route('/bubble/<disid>/csv')
def schdistrictghgh(disid):  
    disdic={
    '60a7b03831afdba383052726' : "United Way Of Santa Barbara",    
    '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
    '5f2609807a1c0000950bb475':'Agawam School district',
    '5f2609807a1c0000950bb481':'Alameda Unified School District',
    '5f2609807a1c0000950bb47a':'Alpine School District',
    '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
    '5f2609807a1c0000950bb463':'Austin Independent School District',
    '5f59e4836451a9089d7d4007':'Belleville School District',
    '5f2609807a1c0000950bb46d':'Broward County Public Schools',
    '5f2609807a1c0000950bb46c':'Chico Unified School District',
    '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
    '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
    '5f2609807a1c0000950bb45c':'Comox Valley School District(sd71)',
    '5f2609807a1c0000950bb480':'Dell Texas',
    '5f7413ef9387fd71ce6387cb':'Douglas County School District',
    '5f895191609e08b76029f641':'Early learning Sarasota',
    '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
    '5f2609807a1c0000950bb461':'Englewood Public School District',
    '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
    '5f2609807a1c0000950bb47d':'Flint Public Schools',
    '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
    '5f2609807a1c0000950bb450':'Goleta District',
    '5f2609807a1c0000950bb474':'Greenburgh-North Castle (GNC) Union Free School District',
    '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
    '5f2609807a1c0000950bb476':'Hillsborough County',
    '5f2609807a1c0000950bb455':'Krum Independent School District',
    '5f2609807a1c0000950bb47e':'La Joya School District',
    '5f2609807a1c0000950bb467':'Lincolnshire Schools',
    '5f2609807a1c0000950bb45a':'LAUSD',
    '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
    '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
    '5fbcdf0ba84e48a64412a798':'Needham School District',
    '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
    '5f6994386451a9089d7d4009':'Ogden school district',
    '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
    '5fd704da04a848e368de5dc6':'Oakland Unified School District',
    '5f8fcd33609e08b76029f644':'Paradise Unified School District',
    '5f2609807a1c0000950bb466':'Pinellas County Schools',
    '5f2609807a1c0000950bb471':'Racine Unified Schools',
    '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
    '5f2609807a1c0000950bb478':'San Diego Unified School District',
    '5f2609807a1c0000950bb470':'San Leandro Unified School District',
    '5f2609807a1c0000950bb477':'Sarasota County',
    '5f2609807a1c0000950bb473':'Skillman Foundation',
    '5f2609807a1c0000950bb46a':'Springfield Public Schools',
    '5f2609807a1c0000950bb468':'Utah Board of Education',
    '5f698b826451a9089d7d4008':'Wayne Metro',
    '5f2609807a1c0000950bb45b':'Westfield Public School District',
    '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
    '5f2609807a1c0000950bb45d':'Youngstown',
    '5f2609807a1c0000950bb464':'Equity Education',
    '5f2609807a1c0000950bb469':'LSF -  Head Start',
    '5f2609807a1c0000950bb46e':'District 25 New York Schools',
    '5f2609807a1c0000950bb46f':'Paradise Schools',
    '5f2609807a1c0000950bb479':'Panorama Education',
    '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
    '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
    '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
    '5fe2e25d4d0ca68d7baf889d':'BGCA',
    '5fe318b14d0ca68d7baf889e':'BLUE',
    '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
    '6017ab3043ca9c39151838d4':'Oswego School District',
    '60239a84e57dc27613699d57':'Austin Independent School District',
    '6023a6d79e8e623753fc305c':'Boulder Valley School District',
    '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
    '6023a7269e8e623753fc305e':'Fulton County School System',
    '6023a7499e8e623753fc305f':'Manatee County School District',
    '6023a76f9e8e623753fc3060':'San Jose Unified School District',
    '6023a7949e8e623753fc3061':'Wasatch County School District',}

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.user_master
    district=disdic[disid]
    qraaa=[
        {"$match":{'$and':[
        {'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y","CATEGORY":{'$regex':district, '$options':'i'} } )}},
        {'DISTRICT_ID':{'$exists':1}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'CREATED_DATE':{"$gte":myDatetime}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$schoolId._id',"month":{"$month": "$CREATED_DATE"}},
        'NAME_DISTRICT':{'$first':'$schoolId.NAME'},
        'usercount':{'$sum':1}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","MONTH":"$_id.month","NAME_DISTRICT":1,"usercount":1,
                        }}]
    merge11=list(collection.aggregate(qraaa))
    df1=pd.DataFrame(merge11)
    # df1
    #######################################################
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.user_master
    qra=[
        {"$match":{'$and':[
        {'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y","CATEGORY":{'$regex':district, '$options':'i'} } )}},
        {'DISTRICT_ID':{'$exists':1}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'CREATED_DATE':{"$lt":myDatetime}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$schoolId._id'},
        'NAME_DISTRICT':{'$first':'$schoolId.NAME'},
        'usercount':{'$sum':1}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","NAME_DISTRICT":1,"usercount":1,
                        }}]
    merge11233=list(collection.aggregate(qra))
    dfCV=pd.DataFrame(merge11233)
    # print(dfCV)
    #########################################################################
    df1=df1.sort_values(by=['NAME_DISTRICT'], ascending=True)
    x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    x["usercount"].sum()
    dislist=list(set(df1["NAME_DISTRICT"]))
    df2=df1[["NAME_DISTRICT","MONTH","usercount"]]
    overall=pd.DataFrame(columns=["NAME_DISTRICT","MONTH","usercount"])
    # dislist
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["NAME_DISTRICT"]==k]
        df45.reset_index()
        for i in range(1,13):
            if i in list(df45["MONTH"]):
                pass
    #              print("month_present",i)
            else:
                df45.loc[i+len(df45)] = [k] +[i]+[0]
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).reset_index()
        df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).sum().groupby(level=0).cumsum().reset_index()
    #     print(df46)
        sorted_df =df46.sort_values(by=['MONTH'], ascending=True)
        sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
    buubleusercount = pd.concat(result)
    # buubleusercount
    ######family ########
    # username = urllib.parse.quote_plus('admin')
    # password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    # client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.user_master
    qraaa=[
        {"$match":{'$and':[
        {'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y","CATEGORY":{'$regex':district, '$options':'i'} } )}},
        {'DISTRICT_ID':{'$exists':1}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'CREATED_DATE':{"$gte":myDatetime}},
        {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$schoolId._id',"month":{"$month": "$CREATED_DATE"}},
        'NAME_DISTRICT':{'$first':'$schoolId.NAME'},
        'famcount':{'$sum':1}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","MONTH":"$_id.month","NAME_DISTRICT":1,"famcount":1,
                        }}]
    merge11=list(collection.aggregate(qraaa))
    df1=pd.DataFrame(merge11)
    # print(df1)
    #######################################################
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.user_master
    qra=[
        {"$match":{'$and':[
        {'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y","CATEGORY":{'$regex':district, '$options':'i'} } )}},
        {'DISTRICT_ID':{'$exists':1}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'CREATED_DATE':{"$lt":myDatetime}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$schoolId._id'},
        'NAME_DISTRICT':{'$first':'$schoolId.NAME'},
        'usercount19':{'$sum':1}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","NAME_DISTRICT":1,"usercount19":1,
                        }}]
    merge11233=list(collection.aggregate(qra))
    dfCV=pd.DataFrame(merge11233)
    # dfCV
    # #########################################################################
    df1=df1.sort_values(by=['NAME_DISTRICT'], ascending=True)
    x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    x["famcount"].sum()
    dislist=list(set(df1["NAME_DISTRICT"]))
    df2=df1[["NAME_DISTRICT","MONTH","famcount"]]
    overall=pd.DataFrame(columns=["NAME_DISTRICT","MONTH","famcount"])
    # dislist
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["NAME_DISTRICT"]==k]
        df45.reset_index()
        for i in range(1,13):
            if i in list(df45["MONTH"]):
                pass
    #              print("month_present",i)
            else:
                df45.loc[i+len(df45)] = [k] +[i]+[0]
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).reset_index()
        df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).sum().groupby(level=0).cumsum().reset_index()
    #     print(df46)
        sorted_df =df46.sort_values(by=['MONTH'], ascending=True)
        sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
    buublefamily = pd.concat(result)
    buubleusercount["idu"]=buubleusercount["NAME_DISTRICT"]+buubleusercount["MONTH"].map(str)
    buublefamily["idf"]=buublefamily["NAME_DISTRICT"]+buublefamily["MONTH"].map(str)
    mergeucfc=pd.merge(buubleusercount, buublefamily, how='left', left_on='idu', right_on='idf')
    mergeucfc=mergeucfc.fillna(0)
    mergeucfc1=pd.merge(mergeucfc, dfCV, how='left', left_on='NAME_DISTRICT_x', right_on='NAME_DISTRICT')
    mergeucfc12=mergeucfc1.fillna(0)
    mergeucfc12["totaluser"]=mergeucfc12["usercount"]+mergeucfc12["usercount19"]
    finmerge=mergeucfc12[["NAME_DISTRICT_x","MONTH_x","idu","totaluser","famcount"]]
    # finmerge
    ###ACTIVE USER
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.audio_track_master
    qra12=[
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y","CATEGORY":{'$regex':district, '$options':'i'} } )}},
        {'USER_ID.DISTRICT_ID':{'$exists':1}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'MODIFIED_DATE':{"$gte":myDatetime}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$USER_ID.schoolId._id',"month":{"$month": "$MODIFIED_DATE"}},
        'NAME_DISTRICT':{'$first':'$USER_ID.schoolId.NAME'},
        "ACTIVE_USER":{'$addToSet':"$USER_ID._id"},}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","MONTH":"$_id.month","NAME_DISTRICT":1,"ACTIVE_USER":{"$size":"$ACTIVE_USER"}}}]
    merge121=list(collection.aggregate(qra12))
    df1=pd.DataFrame(merge121)
    # print(df1)
    df1=df1.sort_values(by=['NAME_DISTRICT'], ascending=True)
    # df1
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["NAME_DISTRICT"]))
    df2=df1[["NAME_DISTRICT","MONTH","ACTIVE_USER"]]
    overall=pd.DataFrame(columns=["NAME_DISTRICT","MONTH","ACTIVE_USER"])
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["NAME_DISTRICT"]==k]
        df45.reset_index()
        for i in range(1,13):
            if i in list(df45["MONTH"]):
                pass
    #              print("month_present",i)
            else:
                df45.loc[i+len(df45)] = [k] +[i]+[0]
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).reset_index()
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).sum().groupby(level=0).cumsum().reset_index()
    #     print(df46)
        sorted_df =df45.sort_values(by=['MONTH'], ascending=True)
        sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
    buubleactuser = pd.concat(result)
    buubleactuser["acuid"]=buubleactuser["NAME_DISTRICT"]+buubleactuser["MONTH"].map(str)
    # buubleactuser
    finmergeu=pd.merge(finmerge, buubleactuser, how='left', left_on='idu', right_on='acuid')
    ###ACTIVE FAMILY
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.audio_track_master
    qra12=[
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y","CATEGORY":{'$regex':district, '$options':'i'} } )}},
        {'USER_ID.DISTRICT_ID':{'$exists':1}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'MODIFIED_DATE':{"$gte":myDatetime}},
        {'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$USER_ID.schoolId._id',"year":{"$year": "$MODIFIED_DATE"},"month":{"$month": "$MODIFIED_DATE"}},
        'NAME_DISTRICT':{'$first':'$USER_ID.schoolId.NAME'},
        'PRACTICE':{'$sum':1},
        "ACTIVE_FAM":{'$addToSet':"$USER_ID._id"},
        'Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","MONTH":"$_id.month","YEAR":"$_id.year","NAME_DISTRICT":1,"PRACTICE":1,"ACTIVE_FAM":{"$size":"$ACTIVE_FAM"},
                       "Mindful_Minutes":1 }}]
    merge121=list(collection.aggregate(qra12))
    df1=pd.DataFrame(merge121)
    df1=df1.sort_values(by=['NAME_DISTRICT'], ascending=True)
    df1
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["NAME_DISTRICT"]))
    df2=df1[["NAME_DISTRICT","MONTH","ACTIVE_FAM"]]
    overall=pd.DataFrame(columns=["NAME_DISTRICT","MONTH","ACTIVE_FAM"])
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["NAME_DISTRICT"]==k]
        df45.reset_index()
        for i in range(1,13):
            if i in list(df45["MONTH"]):
                pass
    #              print("month_present",i)
            else:
                df45.loc[i+len(df45)] = [k] +[i]+[0]
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).reset_index()
    #     df46=df45.groupby(['NAME_DISTRICT', 'MONTH']).sum().groupby(level=0).cumsum().reset_index()
    #     print(df46)
        sorted_df =df45.sort_values(by=['MONTH'], ascending=True)
        sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
    buubleactfam = pd.concat(result)
    buubleactfam["acuidf"]=buubleactfam["NAME_DISTRICT"]+buubleactfam["MONTH"].map(str)
    finmergeuf=pd.merge(finmergeu, buubleactfam, how='left', left_on='idu', right_on='acuidf')
    finmergeuf["USER ENGAGEMENT"]=round((finmergeuf["ACTIVE_USER"]/finmergeuf["totaluser"])*100)
    finmergeuf["FAMILY ENGAGEMENT"]=round((finmergeuf["ACTIVE_FAM"]/finmergeuf["famcount"])*100)
    finmergeufo=finmergeuf[["NAME_DISTRICT_x","MONTH_x","USER ENGAGEMENT","FAMILY ENGAGEMENT"]]
    finmergeufo=finmergeufo.fillna(0)
    finmergeufo=finmergeufo.loc[:,~finmergeufo.columns.duplicated()]
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.audio_track_master
    qra12=[
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y","CATEGORY":{'$regex':district, '$options':'i'} } )}},
        {'USER_ID.DISTRICT_ID':{'$exists':1}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    #     {'MODIFIED_DATE':{"$gte":myDatetime}},
    #     {'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$USER_ID.schoolId._id'},
        'NAME_DISTRICT':{'$first':'$USER_ID.schoolId.NAME'},
        'PRACTICE':{'$sum':1},
                  }},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","NAME_DISTRICT":1,"PRACTICE":1 }}]
    merge1211=list(collection.aggregate(qra12))
    df1111=pd.DataFrame(merge1211)
    # print("check1")
    df1111=df1111.sort_values(by=['NAME_DISTRICT'], ascending=True)
    DISPRACTO=df1111[["NAME_DISTRICT","PRACTICE"]]
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # dateStr = "2020-01-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    collection = db.user_master
    qra12=[
        {"$match":{'$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'DISTRICT_ID.DISTRICT_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y","CATEGORY":{'$regex':district, '$options':'i'} } )}},
        {'DISTRICT_ID':{'$exists':1}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    #     {'MODIFIED_DATE':{"$gte":myDatetime}},
    #     {'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':{"district":'$schoolId._id'},
        'NAME_DISTRICT':{'$first':'$schoolId.NAME'},
        "USER COUNT":{'$addToSet':"$_id"},
                  }},
            {"$project":{"_id":0,"DISTRICT_ID":"$_id.district","NAME_DISTRICT":1,"USER COUNT":{"$size":"$USER COUNT"} }}]
    merge1211=list(collection.aggregate(qra12))
    df1111=pd.DataFrame(merge1211)
    df1111=df1111.sort_values(by=['NAME_DISTRICT'], ascending=True)
    DISSCHOOL=df1111[["NAME_DISTRICT","USER COUNT"]]
    finmergeufosch=pd.merge(finmergeufo, DISSCHOOL, how='left', left_on='NAME_DISTRICT_x', right_on='NAME_DISTRICT')
    finmergeufoschprac=pd.merge(finmergeufosch, DISPRACTO, how='left', left_on='NAME_DISTRICT_x', right_on='NAME_DISTRICT')
    finmergeufoschprac=finmergeufoschprac.fillna(0)
    final_buuble_data=finmergeufoschprac[["NAME_DISTRICT_x","MONTH_x","USER ENGAGEMENT","FAMILY ENGAGEMENT","USER COUNT","PRACTICE"]]
    finaldata=final_buuble_data.rename(columns={"NAME_DISTRICT_x": "DISTRICT_NAME","USER ENGAGEMENT":"USER_ENGAGEMENT","USER COUNT":"USER_COUNT", "FAMILY ENGAGEMENT":"FAMILY_ENGAGEMENT","MONTH_x": "MONTH"})
    finaldata=finaldata.loc[:,~finaldata.columns.duplicated()]
    li = [finaldata.columns.values.tolist()] + finaldata.values.tolist() 
    sheet = pe.Sheet(li)
    print(sheet,"sheet")
    print(type(sheet),"sheet type")
    ioO = io.StringIO()
    sheet.save_to_memory("csv", ioO)
    output = make_response(ioO.getvalue())
    # output.headers["Content-Disposition"] = "attachment; filename=export.csv"
    output.headers["Content-type"] = "text/csv"
    return output
@app.route('/executivecount_productwise')
def executive_count_productwise():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
#     collection = db["school_master"]
#     query = {}
#     query["CATEGORY"] = Regex(u".*LAUSD.*", "i")
#     query["_id"]={"$in":db.user_master.distinct('schoolId._id')}
#     projection = {}
#     projection["_id"] = 1.0
#     cursor = collection.find(query, projection = projection)
#     dfum=(list(cursor))
#     dfum1=pd.DataFrame(dfum)
#     comadd=1299-len(dfum1)
    collection1 = db.school_master
    qr=[
    {"$match":{"$and":[
    {'CATEGORY':{"$regex":'LAUSD','$options':'i'}},
     {'_id':{'$in':db.user_master.distinct('schoolId._id',{'schoolId._id':{'$exists':1}})}
                    }]}},
    {"$project":{"_id":1}},]
    merge1=list(collection1.aggregate(qr))
    dfum1=pd.DataFrame(merge1)
    
    qr2=[
    {"$match":{"$and":[
    {'CATEGORY':{"$regex":'LAUSD','$options':'i'}},
     ]}},
    {"$project":{"_id":1}},]
    merge11=list(collection1.aggregate(qr2))
    lausd=pd.DataFrame(merge11)
    comadd=len(lausd)-len(dfum1)
    print(comadd)
    
    
    collection2 = db.user_master
    qr=[
    {"$match":{"$and":[{'USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'EMAIL_ID':{"$ne":""}}, {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
#     {"EMAIL_ID" :{"$regex":'@','$options':'i'}},
    {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
    {'schoolId.NAME':{'$not':{"$regex":'TEST','$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'schoolId._id':{'$exists':1}},
    {'schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]
    }},

    {"$project":{"_id":0,
    'UMUSER_ID':'$_id',
    "UMEMAIL":'$EMAIL_ID',        
    "UMSCHOOL":'$schoolId._id',
    }},]
    merge1=list(collection2.aggregate(qr))
    overallum=pd.DataFrame(merge1)
    umem=list(overallum["UMUSER_ID"])

    ################################sub_master################################

    
    # db.subscription_master.ensureIndex("USER_ID._id", 1) 
    collection = db.subscription_master
    qr=[
    {"$match":{"$and":[{'USER_ID._id':{"$in":umem}},]
    }},
    {"$project":{"_id":0,
    'SMUSER_ID':'$USER_ID._id',
    "SMEMAIL":'$USER_ID.EMAIL_ID',        
    "SMSCHOOL":'$USER_ID.schoolId._id',
    "PLANID":"$PLAN_ID.PLAN_NAME",
     "comment":"$COMMENT_BY_DS_TEAM",
    }},
    ]
    merge=list(collection.aggregate(qr))
    overall=pd.DataFrame(merge)
#     mergeddf=pd.merge(overall, overallum, how='left', left_on='SMEMAIL', right_on='UMEMAIL')
    mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
    mergeddf.to_csv("checkpoint.csv")
    cloud=mergeddf[mergeddf["PLANID"]=="Cloud"]
    cloud1=list(set(list(cloud["UMSCHOOL"])))
    lifetime=cloud[cloud["comment"]=="CONVERTED TO ACTUAL LIFETIME ON 30TH OCT CLEANUP"]
    lifetime1=list(set(list(lifetime["UMSCHOOL"])))
    final_lifetime_count=len(lifetime1)               #lifetime count
    final_cloud = np.setdiff1d(cloud1,lifetime1)
    final_cloud_count=len(final_cloud)                   #cloud count
    com=mergeddf[mergeddf["PLANID"]=="Community"]
    com1=list(set(list(com["UMSCHOOL"])))
    final_com = np.setdiff1d(com1,cloud1)
#     final_comm=pd.concat(final_com,)
    final_com_count=len(final_com)+comadd                #community count
    exp=mergeddf[mergeddf["PLANID"]=="Explorer"]
    exp1=list(set(list(exp["UMSCHOOL"])))
    final_exp1 = np.setdiff1d(exp1,cloud1)
    final_exp2 = np.setdiff1d(final_exp1,final_com)
    final_exp_count=len(final_exp2)                       #explorer count
    #IE School App
    sch=mergeddf[mergeddf["PLANID"]=="IE School App"]
    sch1=list(set(list(sch["UMSCHOOL"])))
    final_sch1 = np.setdiff1d(sch1,cloud1)
    final_sch2 = np.setdiff1d(final_sch1,final_com)
    final_sch3 = np.setdiff1d(final_sch2,final_exp2)
    final_sch_count=len(final_sch3)                      #school app count
    #IE Home App
    home=mergeddf[mergeddf["PLANID"]=="IE Home App"]
    home1=list(set(list(home["UMSCHOOL"])))
    final_home1 = np.setdiff1d(home1,cloud1)
    final_home2 = np.setdiff1d(final_home1,final_com)
    final_home3 = np.setdiff1d(final_home2,final_exp2)
    final_home4 = np.setdiff1d(final_home3,final_sch3)
    final_home_count=len(final_home4)                     #home app count
    tot_sch=set(list(mergeddf["UMSCHOOL"]))
    tot_sch2=final_home_count+final_sch_count+final_exp_count+final_com_count+final_cloud_count+final_lifetime_count
    execount={"totalschool":str(tot_sch2),"clound":str(final_cloud_count),"lifetime":str(final_lifetime_count),"community":str(final_com_count),"explorer":str(final_exp_count),
    "schoolapp":str(final_sch_count),"homeapp":str(final_home_count)}

    
    #################. FOR TABLE PURPOSE ########################
    DFL=pd.DataFrame(lifetime1)
    DFL.to_csv("lifetime_exec1.csv")
    DFC=pd.DataFrame(final_cloud)
    DFC.to_csv("cloud_exec1.csv")
    DFE=pd.DataFrame(final_exp2)
    DFE.to_csv("exp_exec1.csv")
    DFcco=pd.DataFrame(final_com)
    DFcco.to_csv("com_exec1.csv")
    DFsch=pd.DataFrame(final_sch3)
    DFsch.to_csv("sch_exec1.csv")
    DFhom=pd.DataFrame(final_home4)
    DFhom.to_csv("hom_exec1.csv")
    
    return json.dumps(execount)
# executive_count_productwise()
    

@app.route('/executive_lifetime')
def lifetimeexectable():
    dflife=pd.read_csv("lifetime_exec.csv")
    lifelist=list(dflife["0"])
    lifetimelist=[]
    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }   
    },
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    #   {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #   {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
    #   {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'IS_ADMIN':'Y'}

    ]
    }},

    {"$project":{"_id":0,
    'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
    "UMEMAIL":'$EMAIL_ID',  
    "CREATED_DATE":'$CREATED_DATE',
    "UMSCHOOLID":'$schoolId._id',
                 "UMSCHOOLNAME":'$schoolId.NAME',
                 "CITY":'$schoolId.CITY',
                 "STATE":'$schoolId.STATE',
                 "COUNTRY":'$schoolId.COUNTRY',
                }},
    ]
    merge1=list(collection.aggregate(query))
    overallum=pd.DataFrame(merge1)
#     
    overallum["CREATED_DATE"]=overallum["CREATED_DATE"].dt.strftime('%d %b %Y')
    email=list(overallum["UMUSER_ID"])
    schoolid=list(overallum["UMSCHOOLID"])
#     overallum.to_csv("lifetimecheck.csv")
    
    ################################sub_master################################
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # db.subscription_master.ensureIndex("USER_ID._id", 1) 
    collection = db.subscription_master
    qr=[
    {"$match":{"$and":[{'USER_ID._id':{"$in":email}},
    {'PLAN_ID.PLAN_NAME':"Cloud"}
    ]}},
    {"$project":{"_id":0,
    'SMUSER_ID':'$USER_ID._id',
    "SMEMAIL":'$USER_ID.EMAIL_ID',
    "PLANID":"$PLAN_ID.PLAN_NAME",
    "comment":"$COMMENT_BY_DS_TEAM",
    "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
    }},]
    merge=list(collection.aggregate(qr))
    overall=pd.DataFrame(merge)
    overall["RENEWAL_DATE"]=overall["RENEWAL_DATE"].dt.strftime('%d %b %Y')
    mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
    db=client.compass
    collection = db.audio_track_master
    qra=[
    {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 
    'atdLastpractice':{'$max':'$MODIFIED_DATE'},
    'atdPracticecount':{'$sum':1},
    'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}]
    merge11=list(collection.aggregate(qra))
    atd=pd.DataFrame(merge11)
    atd["atdLastpractice"]=atd["atdLastpractice"].dt.strftime('%d %b %Y')
    finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
    finalmerge['atdLastpractice'].fillna("NO PRACTICE", inplace=True)
    finalmerge['atdPracticecount'].fillna(0, inplace=True)
    finalmerge.fillna("NO INFO AVAILABLE", inplace=True)
    finaldata=finalmerge[["UMSCHOOLNAME","STATE","CITY","USER_NAME","UMEMAIL","CREATED_DATE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')
    print(len(lifetimelist),len(finaldata))
    return json.dumps({"data":finaldata.values.tolist()})


# In[213]:


# lifetimeexectable()


# In[212]:


@app.route('/executive_community')
def communityexectable():
    dflife=pd.read_csv("com_exec.csv")
    lifelist=list(dflife["0"])
    lifetimelist=[]
    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }   
    },
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    #   {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #   {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
    #   {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'IS_ADMIN':'Y'}

    ]
    }},

    {"$project":{"_id":0,
    'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
    "UMEMAIL":'$EMAIL_ID',  
    "CREATED_DATE":'$CREATED_DATE',
    "UMSCHOOLID":'$schoolId._id',
                 "UMSCHOOLNAME":'$schoolId.NAME',
                 "CITY":'$schoolId.CITY',
                 "STATE":'$schoolId.STATE',
                 "COUNTRY":'$schoolId.COUNTRY',
                }},
    ]
    merge1=list(collection.aggregate(query))
    overallum=pd.DataFrame(merge1)
    overallum["CREATED_DATE"]=overallum["CREATED_DATE"].dt.strftime('%d %b %Y')
#     overallum.to_csv("comcheck12.csv")
    email=list(overallum["UMUSER_ID"])
    schoolid=list(overallum["UMSCHOOLID"])
    ################################sub_master################################

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    # db.subscription_master.ensureIndex("USER_ID._id", 1) 
    collection = db.subscription_master
    qr=[
    {"$match":{"$and":[{'USER_ID._id':{"$in":email}},
    {'PLAN_ID.PLAN_NAME':"Community"}
    ]}},
    {"$project":{"_id":0,
    'SMUSER_ID':'$USER_ID._id',
    "SMEMAIL":'$USER_ID.EMAIL_ID',
    "PLANID":"$PLAN_ID.PLAN_NAME",
    "comment":"$COMMENT_BY_DS_TEAM",
    "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
    }},]
    merge=list(collection.aggregate(qr))
    overall=pd.DataFrame(merge)
    overall["RENEWAL_DATE"]=overall["RENEWAL_DATE"].dt.strftime('%d %b %Y')
#     mergeddf=pd.merge(overallum, overall, how='left', left_on='UMEMAIL', right_on='SMEMAIL')
    mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
    db=client.compass
    collection = db.audio_track_master
    qra=[
    {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 
    'atdLastpractice':{'$max':'$MODIFIED_DATE'},
    'atdPracticecount':{'$sum':1},
    'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}]
    merge11=list(collection.aggregate(qra))
    atd=pd.DataFrame(merge11)
    atd["atdLastpractice"]=atd["atdLastpractice"].dt.strftime('%d %b %Y')
    finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
    finalmerge['atdLastpractice'].fillna("NO PRACTICE", inplace=True)
    finalmerge['atdPracticecount'].fillna(0, inplace=True)
    finalmerge.fillna("NO INFO AVAILABLE", inplace=True)
    finaldata=finalmerge[["UMSCHOOLNAME","STATE","CITY","USER_NAME","UMEMAIL","CREATED_DATE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')
    print(len(lifetimelist),len(finaldata))
    return json.dumps({"data":finaldata.values.tolist()})


# In[218]:


# communityexectable()


# In[204]:


@app.route('/executive_explorer')
def explorerexectable():
    client_live= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@54.202.61.130:27017/')
    db_live=client_live.compass    
    schools=pd.DataFrame(list(db_live.school_master.aggregate([{'$match':{'$and':[
        
        {'DASH_CATEGORY':{'$exists':1}},
    {'BLOCKED_BY_CAP':{'$exists':0}},
    {'NAME':{'$not':{'$regex':'test','$options':'i'}}},
    {'DASH_CATEGORY':'D3'}
    ]}},
    {'$project':{
        '_id':0,
        'schoolid':'$_id',
        'schoolname':'$NAME',
        'DASH_CATEGORY':'$DASH_CATEGORY'
    }}])))


    lifelist=list(schools["schoolid"])

    lifetimelist=lifelist

    overallum=pd.DataFrame(list(db_live.user_master.aggregate([{'$match':{'$and':[{

        "schoolId._id": {
        "$in":lifetimelist
        }   
        },
        { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
     
          {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
        {'IS_ADMIN':'Y'},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'schoolId.NAME':{'$not':{"$regex":'TEST','$options':'i'}}}    

        ]
        }},

        {"$project":{"_id":0,
        'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
        "UMEMAIL":'$EMAIL_ID',  
        "CREATED_DATE":'$CREATED_DATE',
        "UMSCHOOLID":'$schoolId._id',
                     "UMSCHOOLNAME":'$schoolId.NAME',
                     "CITY":'$schoolId.CITY',
                     "STATE":'$schoolId.STATE',
                     "COUNTRY":'$schoolId.COUNTRY',
                    }},
        ])))


    overallum["CREATED_DATE"]=overallum["CREATED_DATE"].dt.strftime('%d %b %Y')
    #     overallum.to_csv("comcheck12.csv")
    email=list(overallum["UMUSER_ID"])
    schoolid=list(overallum["UMSCHOOLID"])


    overall=pd.DataFrame(list(db_live.subscription_master.aggregate([
    {"$match":{"$and":[{'USER_ID._id':{"$in":email}},
    ]}},
    {"$project":{"_id":0,
    'SMUSER_ID':'$USER_ID._id',
    "SMEMAIL":'$USER_ID.EMAIL_ID',
    "PLANID":"$PLAN_ID.PLAN_NAME",
    "comment":"$COMMENT_BY_DS_TEAM",
    "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
    }}])))
    overall["RENEWAL_DATE"]=overall["RENEWAL_DATE"].dt.strftime('%d %b %Y')

    mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
    atd=pd.DataFrame(list(db_live.audio_track_master.aggregate([
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'USER_ID.schoolId._id':{'$in':schoolid}},
        ]}},
        {'$group':{'_id':'$USER_ID.schoolId._id', 
        'atdLastpractice':{'$max':'$MODIFIED_DATE'},
        'atdPracticecount':{'$sum':1},
        'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}])))


    atd["atdLastpractice"]=atd["atdLastpractice"].dt.strftime('%d %b %Y')
    finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
    finalmerge['atdLastpractice'].fillna("NO PRACTICE", inplace=True)
    finalmerge['atdPracticecount'].fillna(0, inplace=True)
    finalmerge.fillna("NO INFO AVAILABLE", inplace=True)
    finalmerge.drop_duplicates(subset=['UMSCHOOLID'], keep='last',inplace=True)
    finalmerge.reset_index(drop=True,inplace=True)
    finaldata=finalmerge[["UMSCHOOLNAME","STATE","CITY","USER_NAME","UMEMAIL","CREATED_DATE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')    
    
    return json.dumps({"data":finaldata.values.tolist()})


# In[214]:


# explorerexectable()


# In[206]:


@app.route('/executive_cloud')

def cloudexectable():
    client_live= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@54.202.61.130:27017/')
    db_live=client_live.compass
    schools=pd.DataFrame(list(db_live.school_master.aggregate([{'$match':{'$and':[
        {'DASH_CATEGORY':{'$exists':1}},
    {'BLOCKED_BY_CAP':{'$exists':0}},
    {'NAME':{'$not':{'$regex':'test','$options':'i'}}},
    {'DASH_CATEGORY':'D2'}
    ]}},
    {'$project':{
        '_id':0,
        'schoolid':'$_id',
        'schoolname':'$NAME',
        'DASH_CATEGORY':'$DASH_CATEGORY'
    }}])))


    lifelist=list(schools["schoolid"])

    lifetimelist=lifelist

    overallum=pd.DataFrame(list(db_live.user_master.aggregate([{'$match':{'$and':[{

        "schoolId._id": {
        "$in":lifetimelist
        }   
        },
        { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
        #   {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        #   {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
        #   {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
        {'IS_ADMIN':'Y'},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'schoolId.NAME':{'$not':{"$regex":'TEST','$options':'i'}}}    

        ]
        }},

        {"$project":{"_id":0,
        'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
        "UMEMAIL":'$EMAIL_ID',  
        "CREATED_DATE":'$CREATED_DATE',
        "UMSCHOOLID":'$schoolId._id',
                     "UMSCHOOLNAME":'$schoolId.NAME',
                     "CITY":'$schoolId.CITY',
                     "STATE":'$schoolId.STATE',
                     "COUNTRY":'$schoolId.COUNTRY',
                    }},
        ])))


    overallum["CREATED_DATE"]=overallum["CREATED_DATE"].dt.strftime('%d %b %Y')
    #     overallum.to_csv("comcheck12.csv")
    email=list(overallum["UMUSER_ID"])
    schoolid=list(overallum["UMSCHOOLID"])


    overall=pd.DataFrame(list(db_live.subscription_master.aggregate([
    {"$match":{"$and":[{'USER_ID._id':{"$in":email}},
    ]}},
    {"$project":{"_id":0,
    'SMUSER_ID':'$USER_ID._id',
    "SMEMAIL":'$USER_ID.EMAIL_ID',
    "PLANID":"$PLAN_ID.PLAN_NAME",
    "comment":"$COMMENT_BY_DS_TEAM",
    "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
    }}])))
    overall["RENEWAL_DATE"]=overall["RENEWAL_DATE"].dt.strftime('%d %b %Y')

    mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
    atd=pd.DataFrame(list(db_live.audio_track_master.aggregate([
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'USER_ID.schoolId._id':{'$in':schoolid}},
        ]}},
        {'$group':{'_id':'$USER_ID.schoolId._id', 
        'atdLastpractice':{'$max':'$MODIFIED_DATE'},
        'atdPracticecount':{'$sum':1},
        'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}])))


    atd["atdLastpractice"]=atd["atdLastpractice"].dt.strftime('%d %b %Y')
    finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
    finalmerge['atdLastpractice'].fillna("NO PRACTICE", inplace=True)
    finalmerge['atdPracticecount'].fillna(0, inplace=True)
    finalmerge.fillna("NO INFO AVAILABLE", inplace=True)
    finalmerge.drop_duplicates(subset=['UMSCHOOLID'], keep='last',inplace=True)
    finalmerge.reset_index(drop=True,inplace=True)
    finaldata=finalmerge[["UMSCHOOLNAME","STATE","CITY","USER_NAME","UMEMAIL","CREATED_DATE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')
    
    return json.dumps({"data":finaldata.values.tolist()})


# In[215]:


# cloudexectable()


# In[208]:


@app.route('/executive_home')
def homeexectable():
    dflife=pd.read_csv("hom_exec.csv")
    lifelist=list(dflife["0"])
    lifetimelist=[]
    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }   
    },
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    #   {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #   {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
    #   {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
#     {'IS_ADMIN':'Y'}

    ]
    }},

    {"$project":{"_id":0,
    'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
    "UMEMAIL":'$EMAIL_ID',  
    "CREATED_DATE":'$CREATED_DATE',
    "UMSCHOOLID":'$schoolId._id',
                 "UMSCHOOLNAME":'$schoolId.NAME',
                 "CITY":'$schoolId.CITY',
                 "STATE":'$schoolId.STATE',
                 "COUNTRY":'$schoolId.COUNTRY',
                }},
    ]
    merge1=list(collection.aggregate(query))
    overallum=pd.DataFrame(merge1)
    overallum["CREATED_DATE"]=overallum["CREATED_DATE"].dt.strftime('%d %b %Y')
#     overallum.to_csv("cloudcheck.csv")
    email=list(overallum["UMUSER_ID"])
    schoolid=list(overallum["UMSCHOOLID"])
    ################################sub_master################################

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # db.subscription_master.ensureIndex("USER_ID._id", 1) 
    collection = db.subscription_master
    qr=[
    {"$match":{"$and":[{'USER_ID._id':{"$in":email}},]}},
    {"$project":{"_id":0,
    'SMUSER_ID':'$USER_ID._id',
    "SMEMAIL":'$USER_ID.EMAIL_ID',
    "PLANID":"$PLAN_ID.PLAN_NAME",
    "comment":"$COMMENT_BY_DS_TEAM",
    "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
    }},]
    merge=list(collection.aggregate(qr))
    overall=pd.DataFrame(merge)
    overall["RENEWAL_DATE"]=overall["RENEWAL_DATE"].dt.strftime('%d %b %Y')
#     mergeddf=pd.merge(overallum, overall, how='left', left_on='UMEMAIL', right_on='SMEMAIL')
    mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
    db=client.compass
    collection = db.audio_track_master
    qra=[
    {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 
    'atdLastpractice':{'$max':'$MODIFIED_DATE'},
    'atdPracticecount':{'$sum':1},
    'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}]
    merge11=list(collection.aggregate(qra))
    atd=pd.DataFrame(merge11)
    atd["atdLastpractice"]=atd["atdLastpractice"].dt.strftime('%d %b %Y')
    finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
    finalmerge['atdLastpractice'].fillna("NO PRACTICE", inplace=True)
    finalmerge['atdPracticecount'].fillna(0, inplace=True)
    finalmerge.fillna("NO INFO AVAILABLE", inplace=True)
    finaldata=finalmerge[["UMSCHOOLNAME","STATE","CITY","USER_NAME","UMEMAIL","CREATED_DATE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')
    print(len(lifetimelist),len(set(list(finaldata["UMSCHOOLNAME"]))))
    return json.dumps({"data":finaldata.values.tolist()})


# In[216]:


# homeexectable()


# In[210]:


@app.route('/executive_school')

def schoolexectable():
    dflife=pd.read_csv("sch_exec.csv")
    lifelist=list(dflife["0"])
    lifetimelist=[]
    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }   
    },
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    #   {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #   {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
    #   {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
#     {'IS_ADMIN':'Y'}

    ]
    }},

    {"$project":{"_id":0,
    'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
    "UMEMAIL":'$EMAIL_ID',  
    "CREATED_DATE":'$CREATED_DATE',
    "UMSCHOOLID":'$schoolId._id',
                 "UMSCHOOLNAME":'$schoolId.NAME',
                 "CITY":'$schoolId.CITY',
                 "STATE":'$schoolId.STATE',
                 "COUNTRY":'$schoolId.COUNTRY',
                }},
    ]
    merge1=list(collection.aggregate(query))
    overallum=pd.DataFrame(merge1)
    overallum["CREATED_DATE"]=overallum["CREATED_DATE"].dt.strftime('%d %b %Y')
#     overallum.to_csv("homecheck.csv")
    email=list(overallum["UMUSER_ID"])
    schoolid=list(overallum["UMSCHOOLID"])
    ################################sub_master################################

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    # db.subscription_master.ensureIndex("USER_ID._id", 1) 
    collection = db.subscription_master
    qr=[
    {"$match":{"$and":[{'USER_ID._id':{"$in":email}},]}},
    {"$project":{"_id":0,
    'SMUSER_ID':'$USER_ID._id',
    "SMEMAIL":'$USER_ID.EMAIL_ID',
    "PLANID":"$PLAN_ID.PLAN_NAME",
    "comment":"$COMMENT_BY_DS_TEAM",
    "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
    }},]
    merge=list(collection.aggregate(qr))
    overall=pd.DataFrame(merge)
    overall["RENEWAL_DATE"]=overall["RENEWAL_DATE"].dt.strftime('%d %b %Y')
#     mergeddf=pd.merge(overallum, overall, how='left', left_on='UMEMAIL', right_on='SMEMAIL')
    mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
    db=client.compass
    collection = db.audio_track_master
    qra=[
    {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 
    'atdLastpractice':{'$max':'$MODIFIED_DATE'},
    'atdPracticecount':{'$sum':1},
    'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}]
    merge11=list(collection.aggregate(qra))
    atd=pd.DataFrame(merge11)
    atd["atdLastpractice"]=atd["atdLastpractice"].dt.strftime('%d %b %Y')
    finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
    finalmerge['atdLastpractice'].fillna("NO PRACTICE", inplace=True)
    finalmerge['atdPracticecount'].fillna(0, inplace=True)
    finalmerge.fillna("NO INFO AVAILABLE", inplace=True)
    finaldata=finalmerge[["UMSCHOOLNAME","STATE","CITY","USER_NAME","UMEMAIL","CREATED_DATE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')
    print(len(lifetimelist),len(set(list(finaldata["UMSCHOOLNAME"]))))
    return json.dumps({"data":finaldata.values.tolist()})






@app.route('/_executive_dashbaord_')
def _excecutivecount_():
    
    client= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@35.88.43.45:27017/')
    db=client.compass
    school_um=db.user_master.distinct('schoolId._id',{'$and':[{"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #     {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "CAP_PROGRAM":{'$exists': True} })}},

                    { "schoolId._id":{'$exists': True} },
    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]})

    total_school=len(set(school_um+db.school_master.distinct('_id',{'CATEGORY':{'$regex':'LAUSD','$options':'i'}})))


    users=db.user_master.distinct('_id',{'$and':[{"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #     {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "CAP_PROGRAM":{'$exists': True} })}},

    #                 { "schoolId._id":{'$exists': True} },
    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]})

    Total_user=len(users)


    Total_classroom=Total_user+total_school

    # print(Total_classroom)
    df_cap=pd.DataFrame(list(db.school_master.aggregate([{"$group":{"_id":"$CAP_PROGRAM","TOTAL_SCHOOLS":{"$sum":1}}},
    {"$project":{"_id":0,"CAP_PROGRAM":"$_id","SCHOOL_COUNT":"$TOTAL_SCHOOLS"}}])))
    data={"CAP_PROGRAM":['PRE-K','ELEMENTARY','MIDDLE','HIGH','OTHER'],"IE_REACH":[99,297,396,594,264]}
    df_students = pd.DataFrame(data)
    df_cap['STUDENTS_PER_CLASS'] = df_cap['CAP_PROGRAM'].map(df_students.set_index('CAP_PROGRAM')['IE_REACH'])
    df_cap['STUDENTS_PER_CLASS'].fillna(0,inplace=True)
    df_cap["TOTAL_STUDENTS"] = df_cap["SCHOOL_COUNT"]*df_cap["STUDENTS_PER_CLASS"]
    # df_cap
    total=df_cap["TOTAL_STUDENTS"].to_list()
    total1 = int(sum(total))

    Total_students=total1

    Never_logged_in=Total_user-len(db.login_logs.distinct('USER_ID._id',{'$and':[{'USER_ID._id':{'$in':users}}]}))

    practice_count=db.audio_track_master.find({
        'USER_ID._id':{'$in':users},'MODIFIED_DATE':{'$gte':csy_first_date()}                  
                        }).count()
    Total_mindful_minutes=int(practice_count*7.5)


    active_user_ever=db.audio_track_master.distinct('USER_ID._id',{'$and':[
        {'USER_ID._id':{'$in':users}}]})

    active_school=len(db.user_master.distinct('schoolId._id',{'_id':{'$in':active_user_ever}}))


    Teachers=len(db.user_master.distinct('_id',{'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")},
                                                           '_id':{'$in':users}}))


    Parents=len(db.user_master.distinct('_id',{'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")},
                                                           '_id':{'$in':users}}))

    df44 = DataFrame(list(db.audio_feedback.aggregate([
    {"$match":
     {'$and':[
            {'MODIFIED_DATE':{'$gte':csy_first_date()}},
            {'USER._id':{'$in':users}},
         {'RATING':{'$nin':[0]}}

                      ]

     }},
    {'$group':{'_id':{},'rating':{'$avg':'$RATING'}}},
    {'$project':{'_id':0, 'rating':'$rating'}}

    ])))

    avg_rating=df44['rating'][0]

    temp={"total_school":str(total_school),
             "user_count":str(Total_user),
            "total_classrooms":str(Total_classroom),
              "total_students":str(Total_students),
              "mindful_minutes":str(Total_mindful_minutes),
              "active_school":str(active_school),
             "never_logged_in":str(Never_logged_in),
             "practice_count":str(practice_count),
             'Techers':str(Teachers),
              'avg_rating':str(round(avg_rating)),
              'Homeappusers':str(Parents)}
    
    return json.dumps(temp,sort_keys=False)


@app.route('/proguserexclusively')
def programe_users_exclusively():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 

    collection2=db.school_master
    collection1=db.user_master
    collection3=db.audio_track_master
    df1=DataFrame(list(collection2.aggregate([{'$match':{'$and':[{'CAP_PROGRAM':{'$exists':True}},
                                                                 {'BLOCKED_BY_CAP':{'$exists':False}},
                                                                 {'NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                                                 {'CAP_PROGRAM':{'$ne':'NULL'}},
                                                                  {'CAP_PROGRAM':{'$ne':''}}


    ]}},
    #     {'$match':{'$or':[
    #           {'COUNTRY':{"$regex":"UNITED STATES",'$options':'i'}},
    #         {'COUNTRY':{"$regex":"USA",'$options':'i'}},
    #         {'COUNTRY':{"$regex":"America",'$options':'i'}},

    #        {'COUNTRY':{"$regex":"US",'$options':'i'}}]}},

    # {'$group':{'_id':'$_id','school':{'$addToSet':'$_id'},'CAP_PROGRAM':{'$first':'$CAP_PROGRAM'}}},
    {'$project':{'_id':0,'CAP_PROGRAM':'$CAP_PROGRAM','school':'$_id'}},
    #       {'$sort':{'_id':1}}

    ])))
    school=df1['school'].tolist()

    df = DataFrame(list(collection1.aggregate([{"$match":
    {'$and':[
    # {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},

    {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'schoolId._id':{'$in':school}},
         {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "CAP_PROGRAM":{'$exists':True} } )}},


    # //               {'IS_ADMIN':'Y'},
             {'EMAIL_ID':{'$ne':''}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},



    # {"$group":{'_id':'$_id','user': {'$addToSet': "$_id"}}},
    {"$project":{'_id':1,'school':'$schoolId._id'}}
                                              ])))


    collection3=db.audio_track_master
    df4 = DataFrame(list(collection3.aggregate([
        {"$match":
         {
            '$and':[
    #             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'USER_ID.EMAIL_ID':{'$ne':''}},  
                 {'USER_ID.schoolId._id':{'$in':school}},
             {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "CAP_PROGRAM":{'$exists':True} } )}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    #             {'MODIFIED_DATE':{'$gte':csy_first_date()}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]

         }},
        {'$group':{'_id':'$USER_ID._id','pc':{'$sum':1}}},
        {'$project':{'_id':1, 'practice_count':'$pc'}}

        ])))


    df4=df4.loc[(df4['practice_count']>=5)] 




    df2=pd.merge(df1,df,on='school',how='left')
    df5=pd.merge(df2,df4,on='_id',how='left')


    dff=df5.groupby(['CAP_PROGRAM']).agg({'_id': ['count'], 'practice_count': ['count']})
    dff.reset_index(inplace=True)
    dff.columns = dff.columns.get_level_values(0)


    capprog=dff['CAP_PROGRAM'].tolist()
    users=dff['_id'].tolist()
    playbacks=dff['practice_count'].tolist()

    data={'type':capprog,'total_users':users,'total_user_atleast_5_playbacks':playbacks}
    return json.dumps(data)




@app.route('/progschoolexclusivelylgpartner')
def programe_exclusively_LG():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection2=db.school_master
    df=DataFrame(list(collection2.aggregate([{'$match':{'$and':[{'CAP_PROGRAM':{'$exists':True}},
                                                                 {'BLOCKED_BY_CAP':{'$exists':False}},
                                                                 {'NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                                                {'CAP_PROGRAM':{'$ne':'NULL'}},
                                                                {'CAP_PROGRAM':{'$ne':''}}
#       {"_id":{"$in":db.user_master.distinct( "schoolId._id", {'PARTNER_ID.PARTNER_ID':{'$eq':'12'}})}},
    ]}},
#     {'$match':{'$or':[
#           {'COUNTRY':{"$regex":"UNITED STATES",'$options':'i'}},
#         {'COUNTRY':{"$regex":"USA",'$options':'i'}},
#         {'COUNTRY':{"$regex":"America",'$options':'i'}},
#        {'COUNTRY':{"$regex":"US",'$options':'i'}}]}},
    {'$group':{'_id':'$CAP_PROGRAM','school':{'$addToSet':'$_id'}}},
    {'$project':{'_id':1,'total':{'$size':'$school'}}},
      {'$sort':{'_id':1}}
                                             
    ])))
    df1=DataFrame(list(collection2.aggregate([{'$match':{'$and':[{'CAP_PROGRAM':{'$exists':True}},
                                                                 {'BLOCKED_BY_CAP':{'$exists':False}},
                                                                 {'NAME':{"$not":{"$regex":"test",'$options':'i'}}},
      {"_id":{"$in":db.user_master.distinct( "schoolId._id", {'PARTNER_ID.PARTNER_ID':{'$eq':'12'}})}},
    ]}},
    {'$group':{'_id':'$CAP_PROGRAM','school':{'$addToSet':'$_id'}}},
    {'$project':{'_id':1,'lg':{'$size':'$school'}}}
    ])))
    df2=DataFrame(list(collection2.aggregate([{'$match':{'$and':[{'CAP_PROGRAM':{'$exists':True}},
                                                                 {'BLOCKED_BY_CAP':{'$exists':False}},
                                                                 {'NAME':{"$not":{"$regex":"test",'$options':'i'}}},
      {"_id":{"$nin":db.user_master.distinct( "schoolId._id", {'PARTNER_ID.PARTNER_ID':{'$eq':'12'}})}},
    ]}},
    {'$group':{'_id':'$CAP_PROGRAM','school':{'$addToSet':'$_id'}}},
    {'$project':{'_id':1,'school':{'$size':'$school'}}}
    ])))
    DF=pd.merge(df,df1, how='left',on='_id')
    DATA=pd.merge(DF,df2, how='left',on='_id')
    
    DATA.dropna()
    lg=DATA['lg'].tolist()
    schools=DATA['school'].tolist()
    prog=DATA['_id'].tolist()
    data={'programe':prog,'school':schools,'Lg':lg}
    return json.dumps(data)

@app.route('/progschoolexclusivelystate/<state>')
def programe_exclusively_state(state):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection2=db.school_master
    collection=db.user_master
    df1=DataFrame(list(collection2.aggregate([{'$match':{'$and':[{'CAP_PROGRAM':{'$exists':True}},
                                                                 {'BLOCKED_BY_CAP':{'$exists':False}},
                                                                 {'NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                                                {'CAP_PROGRAM':{'$ne':'NULL'}},
                                                                  {'CAP_PROGRAM':{'$ne':''}}
#                                                                 {'STATE':{"$eq":""+state+""}}

    ]}},
#     {'$match':{'$or':[
#           {'COUNTRY':{"$regex":"UNITED STATES",'$options':'i'}},
#         {'COUNTRY':{"$regex":"USA",'$options':'i'}},
#         {'COUNTRY':{"$regex":"America",'$options':'i'}},
#        {'COUNTRY':{"$regex":"US",'$options':'i'}}]}},
    {'$group':{'_id':'$_id','school':{'$addToSet':'$_id'},'cap':{'$first':'$CAP_PROGRAM'}}},
    {'$project':{'_id':1,'total':'$school','cap':'$cap'}}
    ])))
    ids=list(df1['_id'])
    
    df2 = DataFrame(list(collection.aggregate([
{"$match":
     {'$and': [
#              {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
         {'schoolId._id': {'$in':ids}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
             {'schoolId.STATE':{'$regex':state, '$options':'i'}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'state':{'$first':'$schoolId.STATE'},'date':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}}}},
              {'$project':{'_id':1,'ID':'$ID','state':'$state'}}
              
# //               {'$count':'count'}
              ])))
    df=pd.merge(df1,df2, on='_id', how='inner')
    df=df.groupby(['cap']).count()
    
    df.reset_index(inplace=True)
    df.columns = ['type','id','total','ID','STATE']
    df.sort_values(by=['type'])
    cap=df['type'].tolist()
    count=df['total'].tolist()
 
    data={'type':cap,'school':count}
    return json.dumps(data)


@app.route('/progschoolexclusivelybeforeafter')
def school_type_before_after():
    
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())

#     from datetime import datetime
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection2=db.school_master
    collection=db.user_master
    
    df=DataFrame(list(collection2.aggregate([{'$match':{'$and':[{'CAP_PROGRAM':{'$exists':True}},
                                                                 {'BLOCKED_BY_CAP':{'$exists':False}},
                                                                 {'NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                                                {'CAP_PROGRAM':{'$ne':'NULL'}},
                                                                 {'CAP_PROGRAM':{'$ne':''}}
    #       {"_id":{"$in":db.user_master.distinct( "schoolId._id", {'PARTNER_ID.PARTNER_ID':{'$eq':'12'}})}},
    ]}},
    #     {'$match':{'$or':[
    #           {'COUNTRY':{"$regex":"UNITED STATES",'$options':'i'}},
    #         {'COUNTRY':{"$regex":"USA",'$options':'i'}},
    #         {'COUNTRY':{"$regex":"America",'$options':'i'}},
    #        {'COUNTRY':{"$regex":"US",'$options':'i'}}]}},
    {'$group':{'_id':'$_id','school':{'$addToSet':'$_id'},'type':{'$first':'$CAP_PROGRAM'}}},
    {'$project':{'_id':1,'total':'$school','type':'$type'}}
    ])))
    ids=list(df['_id'])

    df1 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
    #              {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {'schoolId._id':{'$in':ids}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'NAME':{'$first':'$schoolId.NAME'},'date':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}}}},
                  {'$project':{'_id':1,'user_count':'$ID','name':'$NAME','created_date':'$date'}},
                   { '$sort' : { 'user_count' : -1}}
    # //               {'$count':'count'}
                  ])))

    DF=pd.merge(df,df1, how='left',on='_id')
    # print(DF)
    DF.sort_values(by=['type'])

    # group = df["created_date"]
    # # group by that period
    # agg = df.groupby([group])
    # for type, group in agg:
    #     print(group)
    split_date =str(csy_first_date().date())
    BEFORE = DF.loc[DF['created_date'] < split_date]
    AFTER = DF.loc[DF['created_date'] >= split_date]


    DF_BEFORE=BEFORE.groupby(by=["type"]).count()
    DF_BEFORE.reset_index(inplace=True)
    DF_BEFORE.columns=['type','before_csy','c','d','e','f']

    # DF1=DF_BEFORE[['total']]
    # DF=DF1.reset_index(inplace=True)
    # DF.columns = ['type','total']
    # DF




    DF_AFTER=AFTER.groupby(by=["type"]).count()
    DF_AFTER.reset_index(inplace=True)
    DF_AFTER.columns=['type','after_csy','c','d','e','f']
#     print(DF_AFTER)

    count_A=DF_AFTER['after_csy'].tolist()
    count_B=DF_BEFORE['before_csy'].tolist()
    type_B=DF_BEFORE['type'].tolist()
    type_A=DF_AFTER['type'].tolist()



    data={'after_csy':count_A,'before_csy':count_B,'type_A':type_B}
    return json.dumps(data)





@app.route('/progschoolexclusivelyunitedstates')

def programe_unitedstates_exclusively():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 

    collection2=db.school_master

    df1=DataFrame(list(collection2.aggregate([{'$match':{'$and':[{'CAP_PROGRAM':{'$exists':True}},
                                                                 {'BLOCKED_BY_CAP':{'$exists':False}},
                                                                 {'NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                                                 {'CAP_PROGRAM':{'$ne':'NULL'}},
                                                                  {'CAP_PROGRAM':{'$ne':''}}
                                                               

    ]}},
    {'$match':{'$or':[
          {'COUNTRY':{"$regex":"UNITED STATES",'$options':'i'}},
        {'COUNTRY':{"$regex":"USA",'$options':'i'}},
        {'COUNTRY':{"$regex":"America",'$options':'i'}},

       {'COUNTRY':{"$regex":"US",'$options':'i'}}]}},
                                            
    {'$group':{'_id':'$CAP_PROGRAM','school':{'$addToSet':'$_id'}}},
    {'$project':{'_id':1,'schoolid':{'$size':'$school'}}},
      {'$sort':{'_id':1}}

    ])))



#     df1
    capprog=df1['_id'].tolist()
    schoolcount=df1['schoolid'].tolist()

    data={'programe':capprog,'schoolcount':schoolcount}
    return json.dumps(data)




@app.route('/progschooltable/<prog>')
def progtable(prog):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 

    collection2=db.school_master
    collection=db.user_master
    collection1=db.audio_track_master


    df1=DataFrame(list(collection2.aggregate([{'$match':{'$and':[{'CAP_PROGRAM':{"$eq":""+prog+""}},
                                                                 {'BLOCKED_BY_CAP':{'$exists':False}},
                                                                 {'NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                                                 {'CAP_PROGRAM':{'$ne':'NULL'}},
                                                                  {'CAP_PROGRAM':{'$ne':''}}

                                                                ]}},


    {'$group':{'_id':'$_id','school':{'$addToSet':'$_id'},'prog':{'$first':'$CAP_PROGRAM'},'category':{'$first':'$CATEGORY'}}},
    {'$project':{'_id':1,'schoolid':'$school','prog':1,'category':1}}

    ])))
    # print(df1)
    school=list(df1['_id'])
    # print(len(school))

    df2=DataFrame(list(collection.aggregate([{"$match":
         {'$and': [

                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},

                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'date':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
                      'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},

    #         {'$match':{'$and':[
    #          {'CREATED_DATE':{'$gte':datetime.datetime(2020,8,1)}}]}},
    # #         {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'date':{'$min':'$CREATED_DATE'}}},

            {'$project':{'_id':1,'usercount':{'$size':'$ID'},'Created_date':'$date','country':1,'State':1,'school_name':1,'city':1}},



    #  {'$group':{'_id':'$state','school':{'$sum':1}}},
    #     {'$project':{'_id':1,'school':1}}
                                            ])))


    df3 = DataFrame(list(collection1.aggregate([
    {"$match":
         {'$and': [
    #          {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //        
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','ID':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},'prog':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}}},
                  {'$project':{'_id':1,'Practice_Count':'$ID','program':1,'last_practice_date':'$last_practice_date'}},
                   ])))
    

    df5=pd.merge(df1,df2, how='left', on='_id')
    df=pd.merge(df5,df3, how='left', on='_id')
    df.rename(columns = { '_id': 'schoolid_'}, inplace = True)
    df[["schoolid_", "schoolid"]]=df[["schoolid_", "schoolid"]].astype(str) 
#     print(df)
    # df4.fillna(0)
#     print(df)
    df['school_name'].fillna("NO INFO", inplace=True)
    df['country'].fillna("NO INFO", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
    df.usercount=df.usercount.fillna(0)
    df.usercount=df.usercount.astype('int64')   
    df['school_name'].replace("",'NO INFO', inplace=True)
    df['city'].replace("",'NO INFO', inplace=True)
    df['State'].replace("",'NO INFO', inplace=True)
    df['country'].replace("",'NO INFO', inplace=True)
    df['category'].replace("",'NO INFO', inplace=True)
    df['city'].fillna("NO INFO", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['State'].fillna("NO INFO", inplace=True)
    df['State'].replace("NULL","NO INFO", inplace=True)
   


    df['Created_date']=df['Created_date'].fillna(0)
    df['last_practice_date']=df['last_practice_date'].fillna('NO PRACTICE')

    data=[]
    for i,j,k,l,m,n,o,p,r,s in zip(df['schoolid_'].tolist(),df['school_name'].tolist(),df['country'].tolist(),df['State'].tolist(),df['city'].tolist(),df['Practice_Count'].tolist(),df['usercount'].tolist(),df['Created_date'].tolist(),df['last_practice_date'].tolist(),df['prog'].tolist()):
        data.append([i,j,k,l,m,n,o,p,r,s])
    temp={"data":data}
    return json.dumps(temp)


@app.route('/progschooltableusa/<prog>')
def progtable_usa(prog):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 

    collection2=db.school_master
    collection=db.user_master
    collection1=db.audio_track_master


    df1=DataFrame(list(collection2.aggregate([{'$match':{'$and':[{'CAP_PROGRAM':{"$eq":""+prog+""}},
                                                                 {'BLOCKED_BY_CAP':{'$exists':False}},
                                                                 {'NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                                                 {'CAP_PROGRAM':{'$ne':'NULL'}},
                                                                  {'CAP_PROGRAM':{'$ne':''}}

                                                                ]}},
                                               {'$match':{'$or':[
                                                             {'COUNTRY':{"$regex":"UNITED STATES",'$options':'i'}},
                                                               {'COUNTRY':{"$regex":"USA",'$options':'i'}},

                                                          {'COUNTRY':{"$regex":"US",'$options':'i'}},
                                               {'COUNTRY':{"$regex":"America",'$options':'i'}}]}},


    {'$group':{'_id':'$_id','school':{'$addToSet':'$_id'},'prog':{'$first':'$CAP_PROGRAM'},'category':{'$first':'$CATEGORY'}}},
    {'$project':{'_id':1,'schoolid':'$school','prog':1,'category':1}}

    ])))
    # print(df1)
    school=list(df1['_id'])
    # print(len(school))

    df2=DataFrame(list(collection.aggregate([{"$match":
         {'$and': [

                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},

                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'date':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
                      'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},

    #         {'$match':{'$and':[
    #          {'CREATED_DATE':{'$gte':datetime.datetime(2020,8,1)}}]}},
    # #         {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'date':{'$min':'$CREATED_DATE'}}},

            {'$project':{'_id':1,'usercount':{'$size':'$ID'},'Created_date':'$date','country':1,'State':1,'school_name':1,'city':1}},



    #  {'$group':{'_id':'$state','school':{'$sum':1}}},
    #     {'$project':{'_id':1,'school':1}}
                                            ])))


    df3 = DataFrame(list(collection1.aggregate([
    {"$match":
         {'$and': [
    #          {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //        
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','ID':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},'prog':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}}},
                  {'$project':{'_id':1,'Practice_Count':'$ID','program':1,'last_practice_date':'$last_practice_date'}},
                   ])))
    

    df5=pd.merge(df1,df2, how='left', on='_id')
    df=pd.merge(df5,df3, how='left', on='_id')
    df.rename(columns = { '_id': 'schoolid_'}, inplace = True)
    df[["schoolid_", "schoolid"]]=df[["schoolid_", "schoolid"]].astype(str) 

    # df4.fillna(0)
#     print(df)
    df['school_name'].fillna("NO INFO", inplace=True)
    df['country'].fillna("NO INFO", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
    df.usercount=df.usercount.fillna(0)
    df.usercount=df.usercount.astype('int64')   
    df['school_name'].replace("",'NO INFO', inplace=True)
    df['city'].replace("",'NO INFO', inplace=True)
    df['State'].replace("",'NO INFO', inplace=True)
    df['country'].replace("",'NO INFO', inplace=True)
    df['category'].replace("",'NO INFO', inplace=True)
    df['city'].fillna("NO INFO", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['State'].fillna("NO INFO", inplace=True)
    df['State'].replace("NULL","NO INFO", inplace=True)
   


    df['Created_date']=df['Created_date'].fillna(0)
    df['last_practice_date']=df['last_practice_date'].fillna('NO PRACTICE')

    data=[]
    for i,j,k,l,m,n,o,p,r,s in zip(df['schoolid_'].tolist(),df['school_name'].tolist(),df['country'].tolist(),df['State'].tolist(),df['city'].tolist(),df['Practice_Count'].tolist(),df['usercount'].tolist(),df['Created_date'].tolist(),df['last_practice_date'].tolist(),df['prog'].tolist()):
        data.append([i,j,k,l,m,n,o,p,r,s])
    temp={"data":data}
    return json.dumps(temp)





    





@app.route('/executiveschoolcount')
def newexecutive_count(): 
       
    from bson.regex import Regex
    from pymongo import MongoClient
    import urllib 
    #  54.184.165.106:27017 [direct]
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    database = client["compass"]
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"$and": [
                    {
                        u"USER_ID.IS_BLOCKED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.IS_DISABLED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.INCOMPLETE_SIGNUP": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.USER_NAME": {
                            u"$not": Regex(u"^.*test.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.schoolId.NAME": {
                            u"$not": Regex(u"^.*blocked.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*TEST.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*1gen.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.ROLE_ID.ROLE_NAME": Regex(u"^.*PRESENT.*$", "i")
                    }
                ]
            }
        }, 
        {
            "$group": {
                "_id": 
                    u"$USER_ID.schoolId._id",

                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {

            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"objectid": u"$_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    import pandas as pd

    dfiamp=pd.DataFrame(list(cursor))
    # dfiamp1[['First']] = dfiamp1.USER_ID.str.split(" ",expand=True)


    # In[520]:


    dfiamp


    # In[521]:


    #school with webapp excluding iampresent 3835


    # In[522]:


    from bson.regex import Regex
    from pymongo import MongoClient


    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"$and": [
                    {
                        u"USER_ID.IS_BLOCKED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.IS_DISABLED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.INCOMPLETE_SIGNUP": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.USER_NAME": {
                            u"$not": Regex(u"^.*test.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.schoolId.NAME": {
                            u"$not": Regex(u"^.*blocked.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*TEST.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*1gen.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.ROLE_ID.ROLE_NAME": {
                            u"$not": Regex(u"^.*PRESENT.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.DEVICE_USED": Regex(u"^.*webapp.*$", "i")
                    }
                ]
            }
        }, 
        {
            "$group": {
                "_id": 
                    u"$USER_ID.schoolId._id",

                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {

            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"objectid": u"$_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    import pandas as pd

    dfwebapp=pd.DataFrame(list(cursor))


    # In[523]:


    dfwebapp


    # In[524]:


    ##green app 638 


    # In[525]:


    from bson.regex import Regex
    from pymongo import MongoClient

    pipeline = [
        {
            u"$match": {
                u"$and": [
                    {
                        u"USER_ID.IS_BLOCKED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.IS_DISABLED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.INCOMPLETE_SIGNUP": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.USER_NAME": {
                            u"$not": Regex(u"^.*test.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.schoolId.NAME": {
                            u"$not": Regex(u"^.*blocked.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*TEST.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*1gen.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.ROLE_ID.ROLE_NAME": {
                            u"$not": Regex(u"^.*PRESENT.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.DEVICE_USED": {
                            u"$not": Regex(u"^.*webapp.*$", "i")
                        }
                    }
                ]
            }
        }, 
        {
            "$group": {
                "_id": 
                    u"$USER_ID.schoolId._id",

                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {

            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"objectid": u"$_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    import pandas as pd

    dfgreen=pd.DataFrame(list(cursor))


    # In[526]:


    dfgreenfinal=dfgreen[~dfgreen['objectid'].isin(dfwebapp['objectid'])]


    # In[527]:


    dfgreenfinal


    # In[528]:


    dfiamp1=dfiamp[~dfiamp['objectid'].isin(dfwebapp['objectid'])]


    # In[529]:


    dfiampfinal=dfiamp1[~dfiamp1['objectid'].isin(dfgreen['objectid'])]


    # In[530]:


    iampresent=len(dfiampfinal)


    # In[531]:


    greenapp=len(dfgreenfinal)


    # In[621]:


    webapp=len(dfwebapp)


    # In[539]:


    ###total cloud


    # In[540]:


    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"$or": [
                    {
                        u"$and": [
                            {
                                u"USER_ID.IS_BLOCKED": {
                                    u"$ne": u"Y"
                                }
                            },
                            {
                                u"USER_ID.IS_DISABLED": {
                                    u"$ne": u"Y"
                                }
                            },
                            {
                                u"USER_ID.INCOMPLETE_SIGNUP": {
                                    u"$ne": u"Y"
                                }
                            },
                            {
                                u"USER_ID.USER_NAME": {
                                    u"$not": Regex(u"^.*test.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.schoolId.NAME": {
                                    u"$not": Regex(u"^.*blocked.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.EMAIL_ID": {
                                    u"$not": Regex(u"^.*TEST.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.EMAIL_ID": {
                                    u"$not": Regex(u"^.*1gen.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.ROLE_ID.ROLE_NAME": {
                                    u"$not": Regex(u"^.*PRESENT.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.DEVICE_USED": Regex(u"^.*webapp.*$", "i")
                            },
                            {
                                u"USER_ID.PLAN_ID.PLAN_NAME": Regex(u"^.*CLOUD.*$", "i")
                            }
                        ]
                    },
                    {
                        u"DS_SM_COMMENTS": Regex(u"^.*AUGUST 2020 EARLIER TRIAL webapp USER ON PAUL'S REQUEST.*$", "i")
                    },
                    {
                        u"DS_SM_COMMENTS": Regex(u"^.*MADE CLOUD USER ON 14 AUGUST 2020 LIFETIME USER ON PAUL'S REQUEST.*$", "i")
                    }
                ]
            }
        },
        {
            "$group": {
                "_id": 
                    u"$USER_ID.schoolId._id",

                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {

            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"objectid": u"$_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfcloud=pd.DataFrame(list(cursor))


    # In[541]:


    totalcloud=len(dfcloud)


    # In[543]:


    ####trial


    # In[544]:


    database = client["compass"]
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"$and": [
                    {
                        u"USER_ID.IS_BLOCKED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.IS_DISABLED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.INCOMPLETE_SIGNUP": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.USER_NAME": {
                            u"$not": Regex(u"^.*test.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.schoolId.NAME": {
                            u"$not": Regex(u"^.*blocked.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*TEST.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*1gen.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.ROLE_ID.ROLE_NAME": {
                            u"$not": Regex(u"^.*PRESENT.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.DEVICE_USED": Regex(u"^.*webapp.*$", "i")
                    },
                    {
                        u"DS_SM_COMMENTS": Regex(u"^.*AUGUST 2020 EARLIER TRIAL webapp USER ON PAUL'S REQUEST.*$", "i")
                    },
                    {
                        u"DS_SM_COMMENTS": {
                            u"$not": Regex(u"^.*MADE CLOUD USER ON 14 AUGUST 2020 LIFETIME USER ON PAUL'S REQUEST.*$", "i")
                        }}
                ]
            }
        }, 
        {
            "$group": {
                "_id": 
                    u"$USER_ID.schoolId._id",

                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {

            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"objectid": u"$_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    import pandas as pd

    dftrial=pd.DataFrame(list(cursor))


    # In[545]:


    totaltrial=len(dftrial)


    # In[548]:


    database = client["compass"]
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"$and": [
                    {
                        u"USER_ID.IS_BLOCKED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.IS_DISABLED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.INCOMPLETE_SIGNUP": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.USER_NAME": {
                            u"$not": Regex(u"^.*test.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.schoolId.NAME": {
                            u"$not": Regex(u"^.*blocked.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*TEST.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*1gen.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.ROLE_ID.ROLE_NAME": {
                            u"$not": Regex(u"^.*PRESENT.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.DEVICE_USED": Regex(u"^.*webapp.*$", "i")
                    },
                    {
                        u"DS_SM_COMMENTS": {
                            u"$not": Regex(u"^.*AUGUST 2020 EARLIER TRIAL webapp USER ON PAUL'S REQUEST.*$", "i")
                        }
                    },
                    {
                        u"DS_SM_COMMENTS": Regex(u"^.*MADE CLOUD USER ON 14 AUGUST 2020 LIFETIME USER ON PAUL'S REQUEST.*$", "i")
                    }
                ]
            }
        }, 
        {
            "$group": {
                "_id": 
                    u"$USER_ID.schoolId._id",

                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {

            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"objectid": u"$_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )

    dflifetime=pd.DataFrame(list(cursor))


    # In[549]:


    lifetime=len(dflifetime)


    # In[550]:


    lifetime


    # In[551]:


    dfcloud1=dfcloud[~dfcloud['objectid'].isin(dftrial['objectid'])]


    # In[552]:


    dfcloud1


    # In[553]:


    dfcloud2=dfcloud1[~dfcloud1['objectid'].isin(dflifetime['objectid'])]


    # In[554]:


    newcloud=len(dfcloud2)


    # In[555]:


    #####passive subscriber r2


    # In[556]:


    database = client["compass"]
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"$or": [
                    {
                        u"$and": [
                            {
                                u"USER_ID.IS_BLOCKED": {
                                    u"$ne": u"Y"
                                }
                            },
                            {
                                u"USER_ID.IS_DISABLED": {
                                    u"$ne": u"Y"
                                }
                            },
                            {
                                u"USER_ID.INCOMPLETE_SIGNUP": {
                                    u"$ne": u"Y"
                                }
                            },
                            {
                                u"USER_ID.USER_NAME": {
                                    u"$not": Regex(u"^.*test.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.schoolId.NAME": {
                                    u"$not": Regex(u"^.*blocked.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.EMAIL_ID": {
                                    u"$not": Regex(u"^.*TEST.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.EMAIL_ID": {
                                    u"$not": Regex(u"^.*1gen.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.ROLE_ID.ROLE_NAME": {
                                    u"$not": Regex(u"^.*PRESENT.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.DEVICE_USED": Regex(u"^.*webapp.*$", "i")
                            },
                            {
                                u"DS_SM_COMMENTS": Regex(u"^.*MADE Explorer USER ON 13 AUGUST 2020 EARLIER expired before July 2019 USER ON PAUL'S REQUEST.*$", "i")
                            }
                        ]
                    },
                    {
                        u"DS_SM_COMMENTS": Regex(u"^.*MADE Explorer USER ON 19 AUGUST 2020 EARLIER expired before July 2019 district USER ON PAUL'S REQUEST.*$", "i")
                    }
                ]
            }
        }, 
        {
            "$group": {
                "_id": 
                    u"$USER_ID.schoolId._id",

                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {

            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"objectid": u"$_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfpassive_r2=pd.DataFrame(list(cursor))


    # In[558]:


    dfpassive_r21=dfpassive_r2[~dfpassive_r2['objectid'].isin(dfcloud['objectid'])]


    # In[559]:


    passive_r2_count=len(dfpassive_r21)


    # In[561]:


    database = client["compass"]
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"$or": [
                    {
                        u"$and": [
                            {
                                u"USER_ID.IS_BLOCKED": {
                                    u"$ne": u"Y"
                                }
                            },
                            {
                                u"USER_ID.IS_DISABLED": {
                                    u"$ne": u"Y"
                                }
                            },
                            {
                                u"USER_ID.INCOMPLETE_SIGNUP": {
                                    u"$ne": u"Y"
                                }
                            },
                            {
                                u"USER_ID.USER_NAME": {
                                    u"$not": Regex(u"^.*test.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.schoolId.NAME": {
                                    u"$not": Regex(u"^.*blocked.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.EMAIL_ID": {
                                    u"$not": Regex(u"^.*TEST.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.EMAIL_ID": {
                                    u"$not": Regex(u"^.*1gen.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.ROLE_ID.ROLE_NAME": {
                                    u"$not": Regex(u"^.*PRESENT.*$", "i")
                                }
                            },
                            {
                                u"USER_ID.DEVICE_USED": Regex(u"^.*webapp.*$", "i")
                            },
                            {
                                u"DS_SM_COMMENTS": Regex(u"^.*MADE Explorer USER ON 13 AUGUST 2020 EARLIER expired school Year 19-20 USER ON PAUL'S REQUEST.*$", "i")
                            }
                        ]
                    },
                    {
                        u"DS_SM_COMMENTS": Regex(u"^.*MADE EXPLORER USER ON 20 AUGUST 2020 EARLIER expired School Year 2019-2020 webapp USER ON PAUL'S REQUEST.*$", "i")
                    }
                ]
            }
        }, 
        {
            "$group": {
                "_id": 
                    u"$USER_ID.schoolId._id",

                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {

            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"objectid": u"$_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfactive_r3=pd.DataFrame(list(cursor))


    # In[562]:


    dfactive_r31=dfactive_r3[~dfactive_r3['objectid'].isin(dfcloud['objectid'])]


    # In[564]:


    dfactive_r312=dfactive_r31[~dfactive_r31['objectid'].isin(dfpassive_r2['objectid'])]


    # In[565]:


    active_r3_count=len(dfactive_r312)


    # In[567]:


    database = client["compass"]
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"$and": [
                    {
                        u"USER_ID.IS_BLOCKED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.IS_DISABLED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.INCOMPLETE_SIGNUP": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.USER_NAME": {
                            u"$not": Regex(u"^.*test.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.schoolId.NAME": {
                            u"$not": Regex(u"^.*blocked.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*TEST.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*1gen.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.ROLE_ID.ROLE_NAME": {
                            u"$not": Regex(u"^.*PRESENT.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.DEVICE_USED": Regex(u"^.*webapp.*$", "i")
                    },
                    {
                        u"DS_SM_COMMENTS": Regex(u"^.*MADE Community.*$", "i")
                    }
                ]
            }
        }, 
        {
            "$group": {
                "_id": 
                    u"$USER_ID.schoolId._id",

                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {

            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"objectid": u"$_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfactive_district_r3=pd.DataFrame(list(cursor))


    # In[568]:


    dfactive_district_r3_count=len(dfactive_district_r3)


    # In[571]:


    from bson.tz_util import FixedOffset
    from datetime import datetime
    database = client["compass"]
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {

            u"$match": {
                u"$and": [
                    {
                        u"USER_ID.IS_BLOCKED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.IS_DISABLED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                    "SUBSCRIPTION_EXPIRE_DATE" : {
                    "$lt" : datetime.strptime("2021-01-01 15:32:04.177000", "%Y-%m-%d %H:%M:%S.%f").replace(tzinfo = FixedOffset(330, "+0530"))

            }
                    },
                    {
                        u"USER_ID.INCOMPLETE_SIGNUP": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.USER_NAME": {
                            u"$not": Regex(u"^.*test.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.schoolId.NAME": {
                            u"$not": Regex(u"^.*blocked.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*TEST.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*1gen.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.ROLE_ID.ROLE_NAME": {
                            u"$not": Regex(u"^.*PRESENT.*$", "i")
                        }
                    }
                ]
            }
        }, 
        {
            "$group": {
                "_id": 
                    u"$USER_ID.schoolId._id",

                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {

            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"objectid": u"$_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    df_2020_r4=pd.DataFrame(list(cursor))


    # In[573]:


    df_2020_r4_1=df_2020_r4[~df_2020_r4['objectid'].isin(dfcloud['objectid'])] #removed cloud from r4
    df_2020_r4_2=df_2020_r4_1[~df_2020_r4_1['objectid'].isin(dfpassive_r2['objectid'])]
    df_2020_r4_3 =df_2020_r4_2[~df_2020_r4_2['objectid'].isin(dfactive_r3['objectid'])]          #dfactive_r3
    df_2020_r4_4=df_2020_r4_3[~df_2020_r4_3['objectid'].isin(dfactive_district_r3['objectid'])]
    df_2020_r4_5=df_2020_r4_4[df_2020_r4_4['objectid'].isin(dfwebapp['objectid'])]


    # In[579]:


    database = client["compass"]
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"$and": [
                    {
                        u"USER_ID.IS_BLOCKED": {
                            u"$ne": u"Y"
                        }
                    },
                    { 
            "USER_ID.CREATED_DATE" : { 
                "$gt" : datetime.strptime("2020-06-30 15:32:04.177000", "%Y-%m-%d %H:%M:%S.%f").replace(tzinfo = FixedOffset(330, "+0530"))
            }
        },

                    {
                        u"USER_ID.IS_DISABLED": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.INCOMPLETE_SIGNUP": {
                            u"$ne": u"Y"
                        }
                    },
                    {
                        u"USER_ID.USER_NAME": {
                            u"$not": Regex(u"^.*test.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.schoolId.NAME": {
                            u"$not": Regex(u"^.*blocked.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*TEST.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.EMAIL_ID": {
                            u"$not": Regex(u"^.*1gen.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.ROLE_ID.ROLE_NAME": {
                            u"$not": Regex(u"^.*PRESENT.*$", "i")
                        }
                    },
                    {
                        u"USER_ID.DEVICE_USED": Regex(u"^.*webapp.*$", "i")
                    }
                ]
            }
        }, 
        {
            "$group": {
                "_id": 
                    u"$USER_ID.schoolId._id",

                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {

            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"objectid": u"$_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    df_r0=pd.DataFrame(list(cursor))


    # In[586]:


    df_r0_1=df_r0[~df_r0['objectid'].isin(dfcloud['objectid'])] #removed cloud from r4
    df_r0_2=df_r0_1[~df_r0_1['objectid'].isin(dfpassive_r2['objectid'])]
    df_r0_3 =df_r0_2[~df_r0_2['objectid'].isin(dfactive_r3['objectid'])]          #dfactive_r3
    df_r0_4=df_r0_3[~df_r0_3['objectid'].isin(dfactive_district_r3['objectid'])]
    df_r0_5=df_r0_4[df_r0_4['objectid'].isin(dfwebapp['objectid'])]


    # In[591]:


    df_2020_r4_6=df_2020_r4_5[~df_2020_r4_5['objectid'].isin(df_r0_5['objectid'])]


    # In[615]:





    # In[628]:


    final_ro_count=len(df_r0_5)
    final_ro_count=final_ro_count
    new_cloud_r1_count=newcloud
    trial_cloud_r1_count=totaltrial
    final_r2_count=passive_r2_count
    final_r3_district_count=dfactive_district_r3_count
    final_r3_active_count=active_r3_count
    final_r4_count=len(df_2020_r4_6)
    final_r4_lifetime_count=lifetime
    final_green_appcount=greenapp
    final_iamp_count=iampresent


    # In[633]:


    totalweb=sum([final_r4_lifetime_count,final_ro_count,new_cloud_r1_count,trial_cloud_r1_count,final_r2_count,final_r3_district_count,final_r3_active_count])


    # In[634]:





    # In[636]:


    final_r4_count=webapp-totalweb


    # In[638]:


    webapp2=sum([final_r4_lifetime_count,final_ro_count,new_cloud_r1_count,trial_cloud_r1_count,final_r2_count,final_r3_district_count,final_r3_active_count,final_r4_count])


    # In[643]:


    total_school=sum([webapp2,final_green_appcount,final_iamp_count])
    
    

    # In[ ]:



    # print(total_school)


    database = client["compass"]

    collection1 = database["user_master"]

    df = DataFrame(list(collection1.aggregate([{"$match":
    {'$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",
                             '$options':'i'}}},
    {"IS_DISABLED":{"$ne":"Y"}},
    {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {"IS_BLOCKED":{"$ne":"Y"}}]}},
     {"$group":{'_id':{},'distincts': {'$addToSet': "$_id"}}},
        {"$project":{'_id':0,'Total_user':{'$size':'$distincts'}}}])))

    Total_user=df['Total_user'][0]

    # print(Total_user)

    Total_classroom=Total_user+total_school
    # print(Total_classroom)
    Total_students=Total_classroom*26
    # print(Total_students)
    Total_mindful_minutes=Total_students*8
    # print(Total_mindful_minutes)


    df2 = DataFrame(list(collection1.aggregate([{"$match":
        {'$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",
                                 '$options':'i'}}},
        {"IS_DISABLED":{"$ne":"Y"}},
        {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        {"IS_BLOCKED":{"$ne":"Y"}}, 
    {"_id":{"$nin":database.audio_track_master.distinct("USER_ID._id")}}                       
                                 ]}},
    {"$group":{'_id':{},'distincts': {'$addToSet': "$_id"}}},
    {"$project":{'_id':0,'never_loggedin':{'$size':'$distincts'}}}])))

    Never_logged_in=df2['never_loggedin'][0]
    # print(Never_logged_in)

    collection2 = database["audio_track_master"]


    df3 = DataFrame(list(collection2.aggregate([
    {"$match":
     {
        '$and':[{'USER_ID.ROLE_ID.ROLE_ID' :{'$ne':3}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},

     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]

     }},
    {'$group':{'_id':{},'auc':{'$addToSet':'$USER_ID.schoolId._id'}}},
    {'$project':{'_id':0, 'active_schools':{'$size':'$auc'}}}

    ])))

    active_school=df3['active_schools'][0]
    # print(active_school)




    temp={"total_school":total_school,
        "total_webapp":webapp2,
          "ro_count":final_ro_count, 
          "new_cloud_r1":new_cloud_r1_count,
          "trial_cloud":trial_cloud_r1_count,
          "passive_r2":final_r2_count,
          "district_r3":final_r3_district_count,
          "active_r3":final_r3_active_count,
          "r4_count":final_r4_count,
          "r4_lifetime":final_r4_lifetime_count,
          "green_app":final_green_appcount,
          "family_app":final_iamp_count,
           "user_count":str(Total_user),
            "total_classrooms":str(Total_classroom),
          "total_students":str(Total_students),
          "mindful_minutes":str(Total_mindful_minutes),
          "active_school":str(active_school),
         "never_logged_in":str(Never_logged_in)}
   

    return json.dumps(temp)


#sarthak_edit
@app.route('/planschoolcount')
def planid_schoolcount():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.subscription_master
    df = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
            {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {'USER_ID.IS_ADMIN':'Y'},
               {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
         {'PLAN_ID.PLAN_ID':{'$ne':None}}
            ]}},
    {"$group":{'_id':'$PLAN_ID.PLAN_NAME', 'distinct':{'$addToSet':'$USER_ID.schoolId._id'}}},
     {"$project":{'_id':1, 'schoolcount':{'$size':'$distinct'}}},
    ])))
    df.dropna()
    df.rename(columns = { '_id': 'progname'}, inplace = True)
    schoolcount=df['schoolcount'].tolist()
    progname=df['progname'].tolist()
#     pg=df['pg'].tolist()
#     print(df)
    for i in range(len(progname)):
            progname[i] = progname[i]
    data={'schoolcount':schoolcount,'progname':progname}
    return json.dumps(data)


@app.route('/progschoolcount')
def program_schoolcount():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    collection1 = db.user_master
    df = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    #              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    #         {'USER_ID.IS_ADMIN':'Y'},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
      {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}}
            ]}},
    {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME', 'distinct':{'$addToSet':'$USER_ID.schoolId._id'}}},
     {"$project":{'_id':1, 'schoolcount':{'$size':'$distinct'}}},
    ])))
    # df
    df1 = DataFrame(list(collection1.aggregate([
        {"$match":
         {'$and': [
             #              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId._id':{"$nin":db.audio_track_master.distinct("USER_ID.schoolId._id")}},
#         {'USER_ID.IS_ADMIN':'Y'},
          {"IS_BLOCKED":{"$ne":"Y"}},
           {'schoolId._id':{'$ne':None}},
             {'schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
             {'EMAIL_ID':{'$ne':''}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //       {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}}
                ]}},
        {"$group":{'_id':'$CAP_PROGRAM', 'distinct':{'$addToSet':'$schoolId._id'}}},
         {"$project":{'_id':1, 'schoolcount':{'$size':'$distinct'}}},
        ])))
    # df4= pd.merge(df3, df,how='left', on='_id')
    # df5= pd.merge(df3, df1,how='left', on='_id')
    frames=[df,df1]
    df2= pd.concat(frames)
    df2.dropna()
    df2.rename(columns = { '_id': 'progname'}, inplace = True)
    df3= df2.reset_index(drop = True)
    df3 = df3.replace(np.nan, 'unknown', regex=True)

    # print(df3)
    df_elem = df3[(df3.progname == "Exploring Originality Elementary")]
    df_elem2 = df3[(df3.progname == "ELEMENTARY")]
    elem = df_elem['schoolcount'].sum()+df_elem2['schoolcount'].sum()
    df_mid = df3[(df3.progname == "Exploring Potential Middle")]
    df_mid2 = df3[(df3.progname == "MIDDLE")]
    mid = df_mid['schoolcount'].sum()+df_mid2['schoolcount'].sum()
    df_high = df3[(df3.progname == "Exploring Relevance High")]
    df_high2 = df3[(df3.progname == "HIGH")]
    high = df_high['schoolcount'].sum()+df_high2['schoolcount'].sum()
    df_prek = df3[(df3.progname == "Exploring Me Pre-k-Kindergarten")]
    df_prek2 = df3[(df3.progname == "PREK")]
    prek = df_prek['schoolcount'].sum()+df_prek2['schoolcount'].sum()
    df_all = df3[(df3.progname == "Sound Practices")]
    df_all2 = df3[(df3.progname == "ALL")]
    all_prog = df_all['schoolcount'].sum()+df_all2['schoolcount'].sum()
    none_prog = df3['schoolcount'].sum() - (elem+mid+high+all_prog+prek)
    schoolcount=[elem,mid,high,prek,all_prog,none_prog]
    progname=['Exploring Originality Elementary','Exploring Potential Middle','Exploring Relevance High','Exploring Me Pre-k-Kindergarten','Sound Practices','Others']
    # # # # #     print(df)
    data={'schoolcount':schoolcount,'progname':progname}
    # print(data)
    return json.dumps(data,cls=NumpyEncoder)


@app.route('/progschoolcountexclusively')
def programe_schcount_exclusively():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 

    collection2=db.school_master

    df1=DataFrame(list(collection2.aggregate([{'$match':{'$and':[{'CAP_PROGRAM':{'$exists':True}},
                                                                 {'BLOCKED_BY_CAP':{'$exists':False}},
                                                                 {'NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                                                 {'CAP_PROGRAM':{'$ne':'NULL'}}

    ]}},
    {'$group':{'_id':'$CAP_PROGRAM','school':{'$addToSet':'$_id'}}},
    {'$project':{'_id':1,'schoolid':{'$size':'$school'}}},
    {'$sort':{'_id':1}}

    ])))



#     df1
    capprog=df1['_id'].tolist()
    schoolcount=df1['schoolid'].tolist()

    data={'programe':capprog,'schoolcount':schoolcount}
    return json.dumps(data)




@app.route('/schoolsummaryprog/<pg>')
def schsummaryprogram_table(pg):
    
    
    reader = geolite2.reader()
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    
    collection2= db.audio_track_master
    collection1= db.user_master
    
    df = DataFrame(list(collection2.aggregate([
    {"$match":
     {'$and': [
    #              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    #         {'USER_ID.IS_ADMIN':'Y'},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
      {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}}
            ]}},
    {"$group":{'_id':{'prog':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME','school':'$USER_ID.schoolId._id'}}},
     {'$project':{'_id':0,'school':'$_id.school','prog':'$_id.prog'}}
    ])))
    # df
    df1 = DataFrame(list(collection1.aggregate([
        {"$match":
         {'$and': [
             #              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId._id':{"$nin":db.audio_track_master.distinct("USER_ID.schoolId._id")}},
#         {'USER_ID.IS_ADMIN':'Y'},
          {"IS_BLOCKED":{"$ne":"Y"}},
           {'schoolId._id':{'$ne':None}},
             {'schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
             {'EMAIL_ID':{'$ne':''}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //       {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}}
                ]}},
       {"$group":{'_id':{'prog':'$CAP_PROGRAM','school':'$schoolId._id'}}},
         {"$project":{'_id':0, 'prog':'$_id.prog','school':'$_id.school'}},
        ])))
    # df4= pd.merge(df3, df,how='left', on='_id')
    # df5= pd.merge(df3, df1,how='left', on='_id')
    frames=[df,df1]
    df2= pd.concat(frames)
    df2.dropna()
    df2.rename(columns = { 'prog': 'progname'}, inplace = True)
    df3= df2.reset_index(drop = True)
    df3 = df3.replace(np.nan, 'Others', regex=True)
    df3 = df3[df3.school != 'Others']

    df_elem = df3[(df3.progname == "Exploring Originality Elementary")]
    df_elem2 = df3[(df3.progname == "ELEMENTARY")]

    elem = pd.concat([df_elem,df_elem2])
    elem=elem.replace(to_replace='ELEMENTARY', value='Exploring Originality Elementary', inplace=False)
    # print(elem)
    df_mid = df3[(df3.progname == "Exploring Potential Middle")]
    df_mid2 = df3[(df3.progname == "MIDDLE")]
    mid = pd.concat([df_mid,df_mid2])
    mid=mid.replace(to_replace='MIDDLE', value='Exploring Potential Middle', inplace=False)
    # print(mid)

    df_high = df3[(df3.progname == "Exploring Relevance High")]
    df_high2 = df3[(df3.progname == "HIGH")]
    high = pd.concat([df_high,df_high2])
    high=high.replace(to_replace='HIGH', value='Exploring Relevance High', inplace=False)
    # print(high)

    df_prek = df3[(df3.progname == "Exploring Me Pre-k-Kindergarten")]
    df_prek2 = df3[(df3.progname == "PREK")]
    prek = pd.concat([df_prek,df_prek2])
    prek=prek.replace(to_replace='PREK', value='Exploring Me Pre-k-Kindergarten', inplace=False)
    # print(prek)

    df_all = df3[(df3.progname == "Sound Practices")]
    df_all2 = df3[(df3.progname == "ALL")]
    all_prog = pd.concat([df_all,df_all2])
    all_prog=all_prog.replace(to_replace='ALL', value='Sound Practices', inplace=False)
    # print(all_prog)
    df_none = df3[(df3.progname == "Others")]

    # print(df_none)
    final_df=pd.concat([elem,mid,high,prek,all_prog,df_none])
#     print(final_df)


 
   

    collection1= db.user_master
    query1=[
    {"$match":
     {'$and': [
#              {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
           {"IS_DISABLED":{"$ne":"Y"}},
     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#         {'USER_ID.IS_ADMIN':'Y'},
          {"IS_BLOCKED":{"$ne":"Y"}},
     {'schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
         {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
     {'EMAIL_ID':{'$ne':''}},
                   {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
  
     ]}},

        {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'NAME':{'$first':'$schoolId.NAME'},'IS_ADMIN':{'$first':'IS_ADMIN'},
       'user_name':{'$first':'$USER_NAME'},'EMAIL_ID':{'$first':'$EMAIL_ID'},
        'country':{'$first':'$schoolId.COUNTRY'},'city':{'$first':'$schoolId.CITY'},'state':{'$first':'$schoolId.STATE'},'ip_address':{'$first':'$IP_ADDRESS'}
               }},
              {'$project':{'_id':1,'school_id':'$ID','name':'$NAME',
                          'admin':'$IS_ADMIN','ip_address':'$ip_address',

                  'USER_NAME':'$user_name','EMAIL':'$EMAIL_ID',
                  'state':'$state','city':'$city','country':'$country'}},]
    
    collection1= db.user_master
    query4=[
    {"$match":
     {'$and': [
#      {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
           {"IS_DISABLED":{"$ne":"Y"}},
     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#         {'USER_ID.IS_ADMIN':'Y'},
          {"IS_BLOCKED":{"$ne":"Y"}},
     {'schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
         {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
     {'EMAIL_ID':{'$ne':''}},
                   {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
  
     ]}},

        {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},
       'uc':{'$addToSet':'$_id'}
             }},
              {'$project':{'_id':1,'school_id':'$ID','user_count':{'$size':'$uc'}
                         }},]

    
    collection2= db.audio_track_master
    query5=[
    {"$match":
    {"$and":[ 
       {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#         {'USER_ID.IS_ADMIN':'Y'},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
     {'USER_ID.EMAIL_ID':{'$ne':''}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
  
    ]}},

    {'$group':{'_id':'$USER_ID.schoolId._id','pc':{'$sum':1},'date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }}},
               'pg':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}}},
    {'$project':{'_id':1,'Practice_Count':'$pc','Last_Practice_Date':'$date','program_name':'$pg'}}]




    

    
    
    collection3= db.subscription_master
    query3=[ {"$match":
    {"$and":[
       {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#         {'USER_ID.IS_ADMIN':'Y'},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
     {'USER_ID.EMAIL_ID':{'$ne':''}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
  
        ]}},

    {'$group':{'_id':'$USER_ID.schoolId._id','date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_EXPIRE_DATE" }}},
              'pn':{'$first' :'$PLAN_ID.PLAN_ID'},'DS_SM_COMMENTS':{'$max':'$DS_SM_COMMENTS'}}},
    {'$project':{'_id':1,'SUBSCRIPTION_EXPIRE_DATE':'$date','DS_SM_COMMENTS':'$DS_SM_COMMENTS','plan_id':'$pn'}}]


    list1=list(collection1.aggregate(query1))
    df_1=DataFrame(list1)
    list5=list(collection2.aggregate(query5))
    df_5=DataFrame(list5)
    list4=list(collection1.aggregate(query4))
    df_4=DataFrame(list4)

    list3=list(collection3.aggregate(query3))
    df_3=DataFrame(list3)
    
    
    df_1.rename(columns = { '_id': 'school'}, inplace = True)
    df_3.rename(columns = { '_id': 'school'}, inplace = True)
    df_4.rename(columns = { '_id': 'school'}, inplace = True)
    df_5.rename(columns = { '_id': 'school'}, inplace = True)
    # df_1['school_name'].fillna("NO SCHOOL FOUND", inplace=True)
    # df_3['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    # df_1['COUNTRY'].fillna("NO COUNTRY FOUND", inplace=True)
    # df_1['STATE'].fillna("NO STATE FOUND", inplace=True)
#     df_1['city'].fillna("NO CITY FOUND", inplace=True)
    # df_1['ADDRESS'].fillna("NO ADDRESS FOUND", inplace=True)
    
    
    df4= pd.merge(final_df, df_1,how='left', on='school')
    df1= pd.merge(df4, df_4,how='left', on='school')
    df2= pd.merge(df1, df_5,how='left', on='school')
    df= pd.merge(df2, df_3,how='left', on='school')
    
   
    df['name'].fillna("NO INFO", inplace=True)
    df['country'].fillna("NO INFO", inplace=True)
    df['user_count'].fillna("NO INFO", inplace=True)
    df['USER_NAME'].fillna("NO INFO", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
    df['Last_Practice_Date']=pd.to_datetime(df['Last_Practice_Date'])
    df['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    df['EMAIL'].fillna("EMAIL_ID NOT AVAILABLE", inplace=True)
    df['EMAIL'].replace("",'EMAIL_ID NOT AVAILABLE', inplace=True)
    df['name'].replace("",'NO INFO', inplace=True)
    df['city'].replace("",'NO INFO', inplace=True)
    df['state'].replace("",'NO INFO', inplace=True)
    df['country'].replace("",'NO INFO', inplace=True)
    df['USER_NAME'].replace("",'USER NAME NOT AVAILABLE', inplace=True)
    df['city'].fillna("INFO AVAILABLE", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['state'].fillna("NO STATE INFO AVAILABLE", inplace=True)
    df['state'].replace("NULL","NO INFO", inplace=True)

    
   
    df['SUBSCRIPTION_EXPIRE_DATE']=pd.to_datetime(df['SUBSCRIPTION_EXPIRE_DATE'])
    df['SUBSCRIPTION_EXPIRE_DATE'].fillna("NO INFO", inplace=True)
    
    df= df.groupby(df['progname'])
    df= df.get_group(''+pg+'')
    
    
#     # print(df)
    def country1(i):
        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con

    
    
    schname=df['name'].tolist()
    ip=df['ip_address'].tolist()
    user_count=df['user_count'].tolist()
    city=df['city'].tolist()
    ADMIN_NAME=df['USER_NAME'].tolist()
    ADMIN_EMAIL=df.EMAIL.tolist()
    state=df['state'].tolist()
    country=df['country'].tolist()
    SUBSCRIPTION_EXPIRE_DATE=df['SUBSCRIPTION_EXPIRE_DATE'].tolist()
    last_prac_date=df['Last_Practice_Date'].tolist()

    practice_count=df['Practice_Count'].tolist()
#     IS_ADMIN=df['IS_ADMIN'].tolist()

    for i in range(len(ip)):
        
        if city[i] is None:
            try:
                city[i]=city1(ip[i])
            except:
                pass

        if country[i] is None:
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if state[i] is None:

            try:
                state[i]=state1(ip[i])
            except:
                pass
        if country[i] is None:
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] is None:
            country[i]=''
        if state[i] is None:
            state[i]=''

        if  last_prac_date[i]!="NO PRACTICE":

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:

            last_prac_date[i]="NO PRACTICE"



        if SUBSCRIPTION_EXPIRE_DATE[i]!="NO INFO":
            SUBSCRIPTION_EXPIRE_DATE[i]=SUBSCRIPTION_EXPIRE_DATE[i].strftime('%d %b %Y')
        else:
            SUBSCRIPTION_EXPIRE_DATE[i]="NO INFO"

    data=[]    
    for i,k,l,m,o,p,q,s,z,y in zip(schname,ADMIN_NAME,ADMIN_EMAIL,user_count,
                               city,state,country,SUBSCRIPTION_EXPIRE_DATE,
                             last_prac_date,practice_count):

        data.append([i,k,l,m,o,p,q,s,z,y])
        
        
        
    return json.dumps({"data":data},cls=NumpyEncoder)


@app.route('/pracprogramsummary')
def pracprogcount():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    df = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
     #              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#          {'USER_ID.IS_ADMIN':'Y'},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}}
            ]}},

              {'$group':{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME','pc':{'$sum':1}}},
              {'$project':{'_id':1,'parcount':'$pc'}}])))
    
    df.dropna()
    df.rename(columns = { '_id': 'programname'}, inplace = True)
    parcount=df['parcount'].tolist()
    programname=df['programname'].tolist()
#     print(df)
    for i in range(len(programname)):
            programname[i] = programname[i]
    data={'programname':programname,'parcount':parcount}
    return json.dumps(data)


# --------------------------------heatmap-----------------------



@app.route('/heatmapweekly')
def heat_calender_pc():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},

        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'}}},
                      {'$project':{'_id':1,'schools':'$ID'}},

                      ])))

    ids=list(df['_id'])

    df1=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
#      {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.schoolId._id':{'$in':ids}},
     {'MODIFIED_DATE':{'$gte':datetime.datetime(2021,1,1)}},]}},



     {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'},'day':{'$dayOfWeek':'$MODIFIED_DATE'}},'ID':{'$sum':1},'dn':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'},'distrcit':{'$first':'$USER_ID.DISTRICT_ID._id'}}},
                      {'$project':{'DM':'$_id.day','_id':0,'month':'$_id.month','pc':'$ID'}},
    #        {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'}},'ID':{'$sum':'pc'},'dn':{'$addToSet':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
    # //                    {'$count':'count'}
       {'$sort' :  {'DM':1,'month'  :1}}
                  ])))

#     print(df1)
    
    dislist=list(set(df1["DM"]))
#   
    df1=df1[["DM","month","pc"]]
    # print(df2)
    overall=pd.DataFrame(columns=["DM","month","pc"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df1[df1["DM"]==k]
        df45.reset_index()
    #     print(df45)

        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]
#         print(df45)

  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        df2 = pd.concat(result)
#     print(df2)
       
    #     finaldf=finaldf.sort_values(by=['name'])


    SUN= df2[(df2.DM == 1)].reset_index(drop = True)
    SUN = SUN['pc'].tolist()
    MON= df2[(df2.DM == 2)].reset_index(drop = True)
    MON = MON['pc'].tolist()
    TUE= df2[(df2.DM == 3)].reset_index(drop = True)
    TUE = TUE['pc'].tolist()
    WED= df2[(df2.DM == 4)].reset_index(drop = True)
    WED = WED['pc'].tolist()
    THU= df2[(df2.DM == 5)].reset_index(drop = True)
    THU = THU['pc'].tolist()
    FRI= df2[(df2.DM == 6)].reset_index(drop = True)
    FRI = FRI['pc'].tolist()
    SAT= df2[(df2.DM == 7)].reset_index(drop = True)
    SAT = SAT['pc'].tolist()


    
    data = {
               'SUNDAY':SUN,'MONDAY':MON,
               'TUESDAY':TUE,'WEDNESDAY':WED,
               'THURSDAY':THU,'FRIDAY':FRI,
               'SATURDAY':SAT}
# #     print(data)


    dataframe=pd.DataFrame.from_dict(data,orient='index')
#     print(dataframe)
    
    DF=list(dataframe.sum(axis=0))

    DF = pd.Series(DF, index = dataframe.columns)
    DF = dataframe.append(DF, ignore_index=True)
    # df=dataframe.append(DF,orient='index')
    DF.columns =['JAN', 'FEB', 'MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'] 
    DF.index=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL']
    DF=DF.T
    for label, row in DF.iterrows():
        DF.loc[label,'SUN'] = row['SUNDAY']/row['TOTAL'] * 100
        DF.loc[label,'MON'] = row['MONDAY']/row['TOTAL'] * 100
        DF.loc[label,'TUE'] = row['TUESDAY']/row['TOTAL'] * 100
        DF.loc[label,'WED'] = row['WEDNESDAY']/row['TOTAL'] * 100
        DF.loc[label,'THU'] = row['THURSDAY']/row['TOTAL'] * 100
        DF.loc[label,'FRI'] = row['FRIDAY']/row['TOTAL'] * 100
        DF.loc[label,'SAT'] = row['SATURDAY']/row['TOTAL'] * 100

    DF = DF.drop(['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL'], axis=1)
    DF=DF.T
    DF=DF.round()
    DF=DF.fillna(0)
    
    
    day=DF.values.tolist()

    key=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY']
    
    

    data={'meanTemp':{key[0]:day[0],key[1]:day[1],key[2]:day[2],key[3]:day[3],key[4]:day[4],key[5]:day[5],key[6]:day[6]}}
    return json.dumps(data)

@app.route('/heatmapweeklyfamily')
def family_heat_calender_pc():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},

        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'}}},
                      {'$project':{'_id':1,'schools':'$ID'}},

                      ])))

    ids=list(df['_id'])

    df1=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
     {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.schoolId._id':{'$in':ids}},
     {'MODIFIED_DATE':{'$gte':datetime.datetime(2021,1,1)}},]}},



     {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'},'day':{'$dayOfWeek':'$MODIFIED_DATE'}},'ID':{'$sum':1},'dn':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'},'distrcit':{'$first':'$USER_ID.DISTRICT_ID._id'}}},
                      {'$project':{'DM':'$_id.day','_id':0,'month':'$_id.month','pc':'$ID',}},
    #        {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'}},'ID':{'$sum':'pc'},'dn':{'$addToSet':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
    # //                    {'$count':'count'}
       {'$sort' :  {'DM':1,'month'  :1}}
                  ])))
#     print(df1)
    
    dislist=list(set(df1["DM"]))
#   
    df1=df1[["DM","month","pc"]]
    # print(df2)
    overall=pd.DataFrame(columns=["DM","month","pc"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df1[df1["DM"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]
                
#         print(df45)

  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        df2 = pd.concat(result)
#     print(df2)
       
    #     finaldf=finaldf.sort_values(by=['name'])






    SUN= df2[(df2.DM == 1)].reset_index(drop = True)
    SUN = SUN['pc'].tolist()
    MON= df2[(df2.DM == 2)].reset_index(drop = True)
    MON = MON['pc'].tolist()
    TUE= df2[(df2.DM == 3)].reset_index(drop = True)
    TUE = TUE['pc'].tolist()
    WED= df2[(df2.DM == 4)].reset_index(drop = True)
    WED = WED['pc'].tolist()
    THU= df2[(df2.DM == 5)].reset_index(drop = True)
    THU = THU['pc'].tolist()
    FRI= df2[(df2.DM == 6)].reset_index(drop = True)
    FRI = FRI['pc'].tolist()
    SAT= df2[(df2.DM == 7)].reset_index(drop = True)
    SAT = SAT['pc'].tolist()


    
    data = {
               'SUNDAY':SUN,'MONDAY':MON,
               'TUESDAY':TUE,'WEDNESDAY':WED,
               'THURSDAY':THU,'FRIDAY':FRI,
               'SATURDAY':SAT}
# #     print(data)


    dataframe=pd.DataFrame.from_dict(data,orient='index')
#     print(dataframe)
    
    DF=list(dataframe.sum(axis=0))
    
    DF = pd.Series(DF, index = dataframe.columns)
    DF = dataframe.append(DF, ignore_index=True)
    # df=dataframe.append(DF,orient='index')
    DF.columns =['JAN', 'FEB', 'MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'] 
    DF.index=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL']
    DF=DF.T
    for label, row in DF.iterrows():
        DF.loc[label,'SUN'] = row['SUNDAY']/row['TOTAL'] * 100
        DF.loc[label,'MON'] = row['MONDAY']/row['TOTAL'] * 100
        DF.loc[label,'TUE'] = row['TUESDAY']/row['TOTAL'] * 100
        DF.loc[label,'WED'] = row['WEDNESDAY']/row['TOTAL'] * 100
        DF.loc[label,'THU'] = row['THURSDAY']/row['TOTAL'] * 100
        DF.loc[label,'FRI'] = row['FRIDAY']/row['TOTAL'] * 100
        DF.loc[label,'SAT'] = row['SATURDAY']/row['TOTAL'] * 100
        DF.loc[label,'TOTAL'] = row['TOTAL']/row['TOTAL'] * 100

    DF = DF.drop(['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL'], axis=1)
    DF=DF.T
    DF=DF.round()
    DF=DF.fillna(0)
#     print(DF)
    
    
    day=DF.values.tolist()

    key=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY']
    
    

    data={'meanTemp':{key[0]:day[0],key[1]:day[1],key[2]:day[2],key[3]:day[3],key[4]:day[4],key[5]:day[5],key[6]:day[6]}}
    return json.dumps(data)






@app.route('/heatmapweeklyteachers')
def teachers_heat_calender_pc():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},

        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'}}},
                      {'$project':{'_id':1,'schools':'$ID'}},

                      ])))

    ids=list(df['_id'])

    df1=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
     {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.schoolId._id':{'$in':ids}},
     {'MODIFIED_DATE':{'$gte':datetime.datetime(2021,1,1)}},]}},



     {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'},'day':{'$dayOfWeek':'$MODIFIED_DATE'}},'ID':{'$sum':1},'dn':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'},'distrcit':{'$first':'$USER_ID.DISTRICT_ID._id'}}},
                      {'$project':{'DM':'$_id.day','_id':0,'month':'$_id.month','pc':'$ID'}},
    #        {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'}},'ID':{'$sum':'pc'},'dn':{'$addToSet':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
    # //                    {'$count':'count'}
       {'$sort' :  {'DM':1,'month'  :1}}
                  ])))

#     print(df1)
    
    dislist=list(set(df1["DM"]))
#   
    df1=df1[["DM","month","pc"]]
    # print(df2)
    overall=pd.DataFrame(columns=["DM","month","pc"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df1[df1["DM"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]
                
#         print(df45)

  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        df2 = pd.concat(result)
#     print(df2)
       
    #     finaldf=finaldf.sort_values(by=['name'])






    SUN= df2[(df2.DM == 1)].reset_index(drop = True)
    SUN = SUN['pc'].tolist()
    MON= df2[(df2.DM == 2)].reset_index(drop = True)
    MON = MON['pc'].tolist()
    TUE= df2[(df2.DM == 3)].reset_index(drop = True)
    TUE = TUE['pc'].tolist()
    WED= df2[(df2.DM == 4)].reset_index(drop = True)
    WED = WED['pc'].tolist()
    THU= df2[(df2.DM == 5)].reset_index(drop = True)
    THU = THU['pc'].tolist()
    FRI= df2[(df2.DM == 6)].reset_index(drop = True)
    FRI = FRI['pc'].tolist()
    SAT= df2[(df2.DM == 7)].reset_index(drop = True)
    SAT = SAT['pc'].tolist()


    
    data = {
               'SUNDAY':SUN,'MONDAY':MON,
               'TUESDAY':TUE,'WEDNESDAY':WED,
               'THURSDAY':THU,'FRIDAY':FRI,
               'SATURDAY':SAT}
# #     print(data)


    dataframe=pd.DataFrame.from_dict(data,orient='index')
#     print(dataframe)
    
    DF=list(dataframe.sum(axis=0))

    DF = pd.Series(DF, index = dataframe.columns)
    DF = dataframe.append(DF, ignore_index=True)
    # df=dataframe.append(DF,orient='index')
    DF.columns =['JAN', 'FEB', 'MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC'] 
    DF.index=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL']
    DF=DF.T
    for label, row in DF.iterrows():
        DF.loc[label,'SUN'] = row['SUNDAY']/row['TOTAL'] * 100
        DF.loc[label,'MON'] = row['MONDAY']/row['TOTAL'] * 100
        DF.loc[label,'TUE'] = row['TUESDAY']/row['TOTAL'] * 100
        DF.loc[label,'WED'] = row['WEDNESDAY']/row['TOTAL'] * 100
        DF.loc[label,'THU'] = row['THURSDAY']/row['TOTAL'] * 100
        DF.loc[label,'FRI'] = row['FRIDAY']/row['TOTAL'] * 100
        DF.loc[label,'SAT'] = row['SATURDAY']/row['TOTAL'] * 100

    DF = DF.drop(['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL'], axis=1)
    DF=DF.T
    DF=DF.round()
    DF=DF.fillna(0)
    
    
    day=DF.values.tolist()

    key=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY']
    
    

    data={'meanTemp':{key[0]:day[0],key[1]:day[1],key[2]:day[2],key[3]:day[3],key[4]:day[4],key[5]:day[5],key[6]:day[6]}}
    return json.dumps(data)








@app.route('/heatmapweeklycsy')
def heat_csy_pc():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},

        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'}}},
                      {'$project':{'_id':1,'schools':'$ID'}},

                      ])))

    ids=list(df['_id'])

    df1=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
#      {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.schoolId._id':{'$in':ids}},
     {'MODIFIED_DATE':{'$gte':csy_first_date()}},]}},



     {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'},'day':{'$dayOfWeek':'$MODIFIED_DATE'}},'ID':{'$sum':1},'dn':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'},'distrcit':{'$first':'$USER_ID.DISTRICT_ID._id'}}},
                      {'$project':{'DM':'$_id.day','_id':0,'month':'$_id.month','pc':'$ID'}},
    #        {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'}},'ID':{'$sum':'pc'},'dn':{'$addToSet':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
    # //                    {'$count':'count'}
       {'$sort' :  {'DM':1,'month'  :1}}
                  ])))

#     print(df1)
    
    dislist=list(set(df1["DM"]))
    df1=df1[["DM","month","pc"]]
    result=[]
    for k in dislist:
        df45=df1[df1["DM"]==k]
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]
    #     print(df45,"check")
        sorted_df =df45.sort_values(by=['month'], ascending=True)
        sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        df2 = pd.concat(result)
#     print(df2)
#     df2.to_csv('monthcount1.csv')
       
    #     finaldf=finaldf.sort_values(by=['name'])


    SUN= df2[(df2.DM == 1)].reset_index(drop = True)
    SUN = SUN['pc'].tolist()
    MON= df2[(df2.DM == 2)].reset_index(drop = True)
    MON = MON['pc'].tolist()
    TUE= df2[(df2.DM == 3)].reset_index(drop = True)
    TUE = TUE['pc'].tolist()
    WED= df2[(df2.DM == 4)].reset_index(drop = True)
    WED = WED['pc'].tolist()
    THU= df2[(df2.DM == 5)].reset_index(drop = True)
    THU = THU['pc'].tolist()
    FRI= df2[(df2.DM == 6)].reset_index(drop = True)
    FRI = FRI['pc'].tolist()
    SAT= df2[(df2.DM == 7)].reset_index(drop = True)
    SAT = SAT['pc'].tolist()


    
    data = {
               'SUNDAY':SUN,'MONDAY':MON,
               'TUESDAY':TUE,'WEDNESDAY':WED,
               'THURSDAY':THU,'FRIDAY':FRI,
               'SATURDAY':SAT}
# #     print(data)


    data=pd.DataFrame.from_dict(data,orient='index')
    
#     print(data)
    
    dataframe = data[[7,8,9,10,11,0,1,2,3,4,5,6]]
#     print(dataframe)
    
    DF=list(dataframe.sum(axis=0))

    DF = pd.Series(DF, index = dataframe.columns)
    DF = dataframe.append(DF, ignore_index=True)
    # df=dataframe.append(DF,orient='index')
    DF.columns =['AUG','SEP','OCT','NOV','DEC','JAN', 'FEB', 'MAR','APR','MAY','JUN','JUL'] 
    DF.index=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL']
    DF=DF.T
    for label, row in DF.iterrows():
        DF.loc[label,'SUN'] = row['SUNDAY']/row['TOTAL'] * 100
        DF.loc[label,'MON'] = row['MONDAY']/row['TOTAL'] * 100
        DF.loc[label,'TUE'] = row['TUESDAY']/row['TOTAL'] * 100
        DF.loc[label,'WED'] = row['WEDNESDAY']/row['TOTAL'] * 100
        DF.loc[label,'THU'] = row['THURSDAY']/row['TOTAL'] * 100
        DF.loc[label,'FRI'] = row['FRIDAY']/row['TOTAL'] * 100
        DF.loc[label,'SAT'] = row['SATURDAY']/row['TOTAL'] * 100

    DF = DF.drop(['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL'], axis=1)
    DF=DF.T
    DF=DF.round()
    DF=DF.fillna(0)
#     print(DF)
    
    
    day=DF.values.tolist()

    key=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY']
    
    

    data={'meanTemp':{key[0]:day[0],key[1]:day[1],key[2]:day[2],key[3]:day[3],key[4]:day[4],key[5]:day[5],key[6]:day[6]}}
    return json.dumps(data)


@app.route('/familyheatmapweeklycsy')
def heat_csy_pc_family():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},

        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'}}},
                      {'$project':{'_id':1,'schools':'$ID'}},

                      ])))

    ids=list(df['_id'])

    df1=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
     {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.schoolId._id':{'$in':ids}},
     {'MODIFIED_DATE':{'$gte':csy_first_date()}},]}},



     {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'},'day':{'$dayOfWeek':'$MODIFIED_DATE'}},'ID':{'$sum':1},'dn':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'},'distrcit':{'$first':'$USER_ID.DISTRICT_ID._id'}}},
                      {'$project':{'DM':'$_id.day','_id':0,'month':'$_id.month','pc':'$ID'}},
    #        {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'}},'ID':{'$sum':'pc'},'dn':{'$addToSet':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
    # //                    {'$count':'count'}
       {'$sort' :  {'DM':1,'month'  :1}}
                  ])))

#     print(df1)
    
    dislist=list(set(df1["DM"]))
    df1=df1[["DM","month","pc"]]
    result=[]
    for k in dislist:
        df45=df1[df1["DM"]==k]
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]
    #     print(df45,"check")
        sorted_df =df45.sort_values(by=['month'], ascending=True)
        sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        df2 = pd.concat(result)
#     print(df2)
#     df2.to_csv('monthcount1.csv')
       
    #     finaldf=finaldf.sort_values(by=['name'])


    SUN= df2[(df2.DM == 1)].reset_index(drop = True)
    SUN = SUN['pc'].tolist()
    MON= df2[(df2.DM == 2)].reset_index(drop = True)
    MON = MON['pc'].tolist()
    TUE= df2[(df2.DM == 3)].reset_index(drop = True)
    TUE = TUE['pc'].tolist()
    WED= df2[(df2.DM == 4)].reset_index(drop = True)
    WED = WED['pc'].tolist()
    THU= df2[(df2.DM == 5)].reset_index(drop = True)
    THU = THU['pc'].tolist()
    FRI= df2[(df2.DM == 6)].reset_index(drop = True)
    FRI = FRI['pc'].tolist()
    SAT= df2[(df2.DM == 7)].reset_index(drop = True)
    SAT = SAT['pc'].tolist()


    
    data = {
               'SUNDAY':SUN,'MONDAY':MON,
               'TUESDAY':TUE,'WEDNESDAY':WED,
               'THURSDAY':THU,'FRIDAY':FRI,
               'SATURDAY':SAT}
# #     print(data)


    data=pd.DataFrame.from_dict(data,orient='index')
    
#     print(data)
    
    dataframe = data[[7,8,9,10,11,0,1,2,3,4,5,6]]
#     print(dataframe)
    
    DF=list(dataframe.sum(axis=0))

    DF = pd.Series(DF, index = dataframe.columns)
    DF = dataframe.append(DF, ignore_index=True)
    # df=dataframe.append(DF,orient='index')
    DF.columns =['AUG','SEP','OCT','NOV','DEC','JAN', 'FEB', 'MAR','APR','MAY','JUN','JUL'] 
    DF.index=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL']
    DF=DF.T
    for label, row in DF.iterrows():
        DF.loc[label,'SUN'] = row['SUNDAY']/row['TOTAL'] * 100
        DF.loc[label,'MON'] = row['MONDAY']/row['TOTAL'] * 100
        DF.loc[label,'TUE'] = row['TUESDAY']/row['TOTAL'] * 100
        DF.loc[label,'WED'] = row['WEDNESDAY']/row['TOTAL'] * 100
        DF.loc[label,'THU'] = row['THURSDAY']/row['TOTAL'] * 100
        DF.loc[label,'FRI'] = row['FRIDAY']/row['TOTAL'] * 100
        DF.loc[label,'SAT'] = row['SATURDAY']/row['TOTAL'] * 100

    DF = DF.drop(['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL'], axis=1)
    DF=DF.T
    DF=DF.round()
    DF=DF.fillna(0)
#     print(DF)
    
    
    day=DF.values.tolist()

    key=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY']
    
    

    data={'meanTemp':{key[0]:day[0],key[1]:day[1],key[2]:day[2],key[3]:day[3],key[4]:day[4],key[5]:day[5],key[6]:day[6]}}
    return json.dumps(data)
 
@app.route('/teachersheatmapweeklycsy')
def heat_csy_pc_teacher():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},

        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'}}},
                      {'$project':{'_id':1,'schools':'$ID'}},

                      ])))

    ids=list(df['_id'])

    df1=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
     {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.schoolId._id':{'$in':ids}},
     {'MODIFIED_DATE':{'$gte':csy_first_date()}},]}},



     {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'},'day':{'$dayOfWeek':'$MODIFIED_DATE'}},'ID':{'$sum':1},'dn':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'},'distrcit':{'$first':'$USER_ID.DISTRICT_ID._id'}}},
                      {'$project':{'DM':'$_id.day','_id':0,'month':'$_id.month','pc':'$ID'}},
    #        {'$group':{'_id':{'month':{'$month':'$MODIFIED_DATE'}},'ID':{'$sum':'pc'},'dn':{'$addToSet':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
    # //                    {'$count':'count'}
       {'$sort' :  {'DM':1,'month'  :1}}
                  ])))

#     print(df1)
    
    dislist=list(set(df1["DM"]))
    df1=df1[["DM","month","pc"]]
    result=[]
    for k in dislist:
        df45=df1[df1["DM"]==k]
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]
    #     print(df45,"check")
        sorted_df =df45.sort_values(by=['month'], ascending=True)
        sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        df2 = pd.concat(result)
#     print(df2)
#     df2.to_csv('monthcount1.csv')
       
    #     finaldf=finaldf.sort_values(by=['name'])


    SUN= df2[(df2.DM == 1)].reset_index(drop = True)
    SUN = SUN['pc'].tolist()
    MON= df2[(df2.DM == 2)].reset_index(drop = True)
    MON = MON['pc'].tolist()
    TUE= df2[(df2.DM == 3)].reset_index(drop = True)
    TUE = TUE['pc'].tolist()
    WED= df2[(df2.DM == 4)].reset_index(drop = True)
    WED = WED['pc'].tolist()
    THU= df2[(df2.DM == 5)].reset_index(drop = True)
    THU = THU['pc'].tolist()
    FRI= df2[(df2.DM == 6)].reset_index(drop = True)
    FRI = FRI['pc'].tolist()
    SAT= df2[(df2.DM == 7)].reset_index(drop = True)
    SAT = SAT['pc'].tolist()


    
    data = {
               'SUNDAY':SUN,'MONDAY':MON,
               'TUESDAY':TUE,'WEDNESDAY':WED,
               'THURSDAY':THU,'FRIDAY':FRI,
               'SATURDAY':SAT}
# #     print(data)


    data=pd.DataFrame.from_dict(data,orient='index')
    
#     print(data)
    
    dataframe = data[[7,8,9,10,11,0,1,2,3,4,5,6]]
#     print(dataframe)
    
    DF=list(dataframe.sum(axis=0))

    DF = pd.Series(DF, index = dataframe.columns)
    DF = dataframe.append(DF, ignore_index=True)
    # df=dataframe.append(DF,orient='index')
    DF.columns =['AUG','SEP','OCT','NOV','DEC','JAN', 'FEB', 'MAR','APR','MAY','JUN','JUL'] 
    DF.index=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL']
    DF=DF.T
    for label, row in DF.iterrows():
        DF.loc[label,'SUN'] = row['SUNDAY']/row['TOTAL'] * 100
        DF.loc[label,'MON'] = row['MONDAY']/row['TOTAL'] * 100
        DF.loc[label,'TUE'] = row['TUESDAY']/row['TOTAL'] * 100
        DF.loc[label,'WED'] = row['WEDNESDAY']/row['TOTAL'] * 100
        DF.loc[label,'THU'] = row['THURSDAY']/row['TOTAL'] * 100
        DF.loc[label,'FRI'] = row['FRIDAY']/row['TOTAL'] * 100
        DF.loc[label,'SAT'] = row['SATURDAY']/row['TOTAL'] * 100

    DF = DF.drop(['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL'], axis=1)
    DF=DF.T
    DF=DF.round()
    DF=DF.fillna(0)
#     print(DF)
    
    
    day=DF.values.tolist()

    key=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY']
    
    

    data={'meanTemp':{key[0]:day[0],key[1]:day[1],key[2]:day[2],key[3]:day[3],key[4]:day[4],key[5]:day[5],key[6]:day[6]}}
    return json.dumps(data)

    
    

@app.route('/districtheatmap/<districtid>/<startdate>/<enddate>')
def heat_district(districtid,startdate,enddate):
    
    import collections
    username = urllib.parse.quote_plus('admin')
    
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
#                  {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                  {'$sort':{'name':1}}
                      ])))

    ids=list(df['_id'])
    
    
#     df3=DataFrame(list(collection.aggregate([
# {"$match":
#     {'$and': [

         
#         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
# {'USER_ID.schoolId._id':{'$in':ids}},


# #  {'MODIFIED_DATE':{'$gte':csy_first_date()}},
#     {'MODIFIED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}}
#     ]}},


#         {'$group':{'_id':'$USER_ID.schoolId._id','uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
#               {'$project':{'_id':1,'active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
#     { '$sort' : { 'active_user_count' : -1} },
# #     {'$limit':30}
#     ])))
#     top=list(df3['_id'])
#     print(df3)
#     df3.to_csv('file1.csv')
    df22=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            
#              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
    # {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
  
#      {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    # df2
    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =active_user_count
    data=collections.OrderedDict(sorted(data.items()))
    data={'meanTemp':data}

    
    return json.dumps(data)

# --------
@app.route('/familydistrictheatmap/<districtid>/<startdate>/<enddate>')
def heat_district_family_active(districtid,startdate,enddate):
    
    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
#                  {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                        {'$sort':{'name':1}}
                      ])))

    ids=list(df['_id'])
    
    
#     df3=DataFrame(list(collection.aggregate([
# {"$match":
#     {'$and': [

         
#         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
# {'USER_ID.schoolId._id':{'$in':ids}},


# #  {'MODIFIED_DATE':{'$gte':csy_first_date()}},
#     {'MODIFIED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}}]}},


#         {'$group':{'_id':'$USER_ID.schoolId._id','uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
#               {'$project':{'_id':1,'active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
#     { '$sort' : { 'active_user_count' : -1} },
# #     {'$limit':30}
#     ])))
#     top=list(df3['_id'])
#     print(df3)
#     df3.to_csv('file1.csv')
    df22=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            
             {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
    # {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
  
#      {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    # df2
    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =active_user_count
    data=collections.OrderedDict(sorted(data.items()))
    df['_id']=df['_id'].astype(str)
    schoolid=  df['_id'].tolist()
    schoolname=  df['name'].tolist()
    data={'meanTemp':data,'schoolid':dict(zip(schoolname,schoolid))}
    return json.dumps(data)
#---
@app.route('/teachersdistrictheatmap/<districtid>/<startdate>/<enddate>')
def heat_district_teachers_active(districtid,startdate,enddate):
    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
#                  {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                    {'$sort':{'name':1}}
                      ])))

    ids=list(df['_id'])
    
    
#     df3=DataFrame(list(collection.aggregate([
# {"$match":
#     {'$and': [

         
#         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
# {'USER_ID.schoolId._id':{'$in':ids}},


# #  {'MODIFIED_DATE':{'$gte':csy_first_date()}},
#     {'MODIFIED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}}]}},


#         {'$group':{'_id':'$USER_ID.schoolId._id','uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
#               {'$project':{'_id':1,'active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
#     { '$sort' : { 'active_user_count' : -1} },
# #     {'$limit':30}
#     ])))
#     top=list(df3['_id'])
#     print(df3)
#     df3.to_csv('file1.csv')
    df22=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            
             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
    # {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
  
#      {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    # df2
    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =active_user_count
    data=collections.OrderedDict(sorted(data.items()))
    df['_id']=df['_id'].astype(str)
    schoolid=  df['_id'].tolist()
    schoolname=  df['name'].tolist()
    data={'meanTemp':data,'schoolid':dict(zip(schoolname,schoolid))}
    return json.dumps(data)


@app.route('/districtheatmappracteacher/<districtid>/<startdate>/<enddate>')
def heat_district_teachers_prac(districtid,startdate,enddate):
    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
#                  {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                         {'$sort':{'name':1}}

                      ])))

    ids=list(df['_id'])
    
    
#     df3=DataFrame(list(collection.aggregate([
# {"$match":
#     {'$and': [

         
#         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
# {'USER_ID.schoolId._id':{'$in':ids}},


# #  {'MODIFIED_DATE':{'$gte':csy_first_date()}},
#     {'MODIFIED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}}]}},


#         {'$group':{'_id':'$USER_ID.schoolId._id','uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
#               {'$project':{'_id':1,'active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
#     { '$sort' : { 'active_user_count' : -1} },
# #     {'$limit':30}
#     ])))
#     top=list(df3['_id'])
# #     print(df3)
# #     df3.to_csv('file1.csv')
    df22=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            
             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
    # {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
  
#      {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    # df2
    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =practice_count
    data=collections.OrderedDict(sorted(data.items()))
    df['_id']=df['_id'].astype(str)
    schoolid=  df['_id'].tolist()
    schoolname=  df['name'].tolist()
    data={'meanTemp':data,'schoolid':dict(zip(schoolname,schoolid))}
    return json.dumps(data)

@app.route('/districtheatmappracfamily/<districtid>/<startdate>/<enddate>')
def heat_district_family_prac(districtid,startdate,enddate):
    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
#                  {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
               {'$sort':{'name':1}}

                      ])))

    ids=list(df['_id'])
    
    
#     df3=DataFrame(list(collection.aggregate([
# {"$match":
#     {'$and': [

         
#         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
# {'USER_ID.schoolId._id':{'$in':ids}},


# #  {'MODIFIED_DATE':{'$gte':csy_first_date()}},
#     {'MODIFIED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}}]}},


#         {'$group':{'_id':'$USER_ID.schoolId._id','uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
#               {'$project':{'_id':1,'active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
#     { '$sort' : { 'active_user_count' : -1} },
# #     {'$limit':30}
#     ])))
#     top=list(df3['_id'])
#     print(df3)
#     df3.to_csv('file1.csv')
    df22=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            
             {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
    # {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
  
#      {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    # df2
    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =practice_count
    data=collections.OrderedDict(sorted(data.items()))
    df['_id']=df['_id'].astype(str)
    schoolid=  df['_id'].tolist()
    schoolname=  df['name'].tolist()
    data={'meanTemp':data,'schoolid':dict(zip(schoolname,schoolid))}
    return json.dumps(data)

@app.route('/districtheatmappractice/<districtid>/<startdate>/<enddate>')
def heatmap_prac_district(districtid,startdate,enddate):   
    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                             {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
        # //               {'IS_ADMIN':'Y'},
    #                      {'DISTRICT_ID._id':{'$ne':None}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
#                  {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},

#                   {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                      {'$sort':{'name':1}}

                      ])))

    ids=list(df['_id'])
    
    
#     df3=DataFrame(list(collection.aggregate([
# {"$match":
#     {'$and': [

         
#         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
# {'USER_ID.schoolId._id':{'$in':ids}},


# #  {'MODIFIED_DATE':{'$gte':csy_first_date()}},
#     {'MODIFIED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}}
#     ]}},


#         {'$group':{'_id':'$USER_ID.schoolId._id','uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
#               {'$project':{'_id':1,'active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
#     { '$sort' : { 'active_user_count' : -1} },
# #     {'$limit':30}
#     ])))
#     top=list(df3['_id'])
# #     print(df3)
# #     df3.to_csv('file1.csv')
    df22=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            
#              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
    # {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
  
#      {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =practice_count
    data=collections.OrderedDict(sorted(data.items()))
    df['_id']=df['_id'].astype(str)
    schoolid=  df['_id'].tolist()
    schoolname=  df['name'].tolist()
    data={'meanTemp':data,'schoolid':dict(zip(schoolname,schoolid))}
    return json.dumps(data)




@app.route('/weeklysummaryprog')
def weekprogpracsummary():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)
    qr1=[{"$match":
     {'$and': [
    #              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    #         {'USER_ID.IS_ADMIN':'Y'},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
         {'MODIFIED_DATE':{'$gte':start , '$lt':yester
    }},
            ]}},
              {'$group':{'_id':{'pn':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME','day':{'$dayOfWeek':'$MODIFIED_DATE'}}, 'LAST_WEEK_PRACTICE_parents':{'$sum':1},}},
     {'$project':{'pg':'$_id.pn','day':'$_id.day','_id':0, 'LAST_WEEK_PRACTICE_parents':'$LAST_WEEK_PRACTICE_parents'}},
    ]
    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
    df_atm
    LAST_WEEK_PRACTICE_parents=df_atm[['day','pg','LAST_WEEK_PRACTICE_parents']]
    qr2=[{"$match":
     {'$and': [
    #              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    #         {'USER_ID.IS_ADMIN':'Y'},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
        {'MODIFIED_DATE':{'$gte':start_15day
                    , '$lt': start}}
            ]}},
              {'$group':{'_id':{'pn':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME','day':{'$dayOfWeek':'$MODIFIED_DATE'}}, 'LAST_TO_LAST_WEEK_PRACTICE_parents':{'$sum':1},}},
     {'$project':{'pg':'$_id.pn','day':'$_id.day','_id':0, 'LAST_TO_LAST_WEEK_PRACTICE_parents':'$LAST_TO_LAST_WEEK_PRACTICE_parents'}},
    ]
    list2= list(collection1.aggregate(qr2))
    df_at2m= DataFrame(list2)
    LAST_TO_LAST_WEEK_PRACTICE_parents=df_at2m[['day','pg','LAST_TO_LAST_WEEK_PRACTICE_parents']]
    join_final= pd.merge(LAST_WEEK_PRACTICE_parents, LAST_TO_LAST_WEEK_PRACTICE_parents, on=['day','pg'], how='left') 
    final = join_final.sort_values(by = ['day']).reset_index(drop = True)
    final=final.fillna(0)
    week = ['Sunday', 'Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']
    elem = final[(final.pg == "Exploring Originality Elementary")].reset_index(drop = True)
    elem_l = elem['LAST_WEEK_PRACTICE_parents'].tolist()
    elem_l2l = elem['LAST_TO_LAST_WEEK_PRACTICE_parents'].tolist()
    mid = final[(final.pg == "Exploring Potential Middle")].reset_index(drop = True)
    mid_l = mid['LAST_WEEK_PRACTICE_parents'].tolist()
    mid_l2l = mid['LAST_TO_LAST_WEEK_PRACTICE_parents'].tolist()
    high = final[(final.pg == "Exploring Relevance High")].reset_index(drop = True)
    high_l = high['LAST_WEEK_PRACTICE_parents'].tolist()
    high_l2l = high['LAST_TO_LAST_WEEK_PRACTICE_parents'].tolist()
    prek = final[(final.pg == "Exploring Me Pre-k-Kindergarten")].reset_index(drop = True)
    prek_l = prek['LAST_WEEK_PRACTICE_parents'].tolist()
    prek_l2l = prek['LAST_TO_LAST_WEEK_PRACTICE_parents'].tolist()
    sound = final[(final.pg == "Sound Practices")].reset_index(drop = True)
    sound_l = sound['LAST_WEEK_PRACTICE_parents'].tolist()
    sound_l2l = sound['LAST_TO_LAST_WEEK_PRACTICE_parents'].tolist()
    data = {'Week':week,
           'Elem_1':elem_l2l,'Elem_2':elem_l,
           'Mid_1':mid_l2l,'Mid_2':mid_l,
           'High_1':high_l2l,'High_2t':high_l,
           'Prek_1':prek_l2l,'Prek_2':prek_l,
           'Sound_1':sound_l2l,'Sound_2':sound_l
           }
    return json.dumps(data)


@app.route('/schoolwiseusercounttop20/<districtid>/<startdate>/<enddate>')
def schwiseucc(districtid,startdate,enddate):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.user_master
    district=disdic[districtid]
    
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
#     enddate = dateutil.parser.parse(enddate)
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
#              {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                   
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
#              {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'user_count':{'$size':'$ID'},'name':'$NAME','district':'$district'}},
                   { '$sort' : { 'user_count' : -1}},
              {'$limit':20}
                  ])))
    if df1.empty:
        df1=pd.DataFrame({'_id':[],'user_count':[]})
    else:
        df1
    school=df1['_id'].tolist()
        
    df0 = DataFrame(list(db.audio_track_master.aggregate([
    {"$match":
    {'$and': [
    #       {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #             {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
    #             {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
       {'USER_ID.schoolId._id':{'$in':school}},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Broward', '$options':'i'}})}},
    #                {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#              {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'$USER_ID.schoolId._id','pc':{'$addToSet':'$USER_ID._id'},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
          {'$project':{'_id':1,'active':{'$size':'$pc'}}},
    { '$sort' : { 'active' : -1} },
         {'$limit':20}
          ])))
    if df0.empty:
        df0=pd.DataFrame({'_id':[],'active':[]})
    
    df2 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                          {'UTM_MEDIUM':{'$not':{'$regex':'clever','$options':'i'}}},
                    {'UTM_MEDIUM':{'$not':{'$regex':'schoology','$options':'i'}}},
#             {"_id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id",)}}},
#             {"_id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
#                       {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,'FULL_EXPERIENCE':'Y',"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                    {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'teachers':{'$size':'$ID'}}},
                   { '$sort' : { 'teachers' : -1}},
#               {'$limit':20}
                  ])))
    if df2.empty:
        df2=pd.DataFrame({'_id':[],'teachers':[]})
    
    df3 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
#               {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
                 {'EMAIL_ID':{'$ne':''}},
#                    
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'parents':{'$size':'$ID'}}},
                   { '$sort' : { 'parents' : -1}},
#               {'$limit':20}
                  ])))
    if df3.empty:
        df3=pd.DataFrame({'_id':[],'parents':[]})
    
    
    df4 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
#              {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"_id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#             {"_id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
              {'UTM_MEDIUM':{'$regex':'clever','$options':'i'}},
                    {'UTM_MEDIUM':{'$not':{'$regex':'schoology','$options':'i'}}},
                {"IS_DISABLED":{"$ne":"Y"}},
             
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
             
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
#                      
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'clever':{'$size':'$ID'}}},
                   { '$sort' : { 'clever' : -1}},
#               {'$limit':20}
                  ])))
    if df4.empty:
        df4=pd.DataFrame({'_id':[],'clever':[]})
    
    
    df5 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
#              {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'UTM_MEDIUM':{'$not':{'$regex':'clever','$options':'i'}}},
                    {'UTM_MEDIUM':{'$regex':'schoology','$options':'i'}},
#             {"_id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
#             {"_id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
#               {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
#                       {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,'FULL_EXPERIENCE':'Y',"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                   
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'scoology':{'$size':'$ID'}}},
                   { '$sort' : { 'scoology' : -1}},
#               {'$limit':20}
                  ])))
    if df5.empty:
        df5=pd.DataFrame({'_id':[],'scoology':[]})
    
    
    df6= pd.merge(df1,df0,on='_id',how='left')
    df9= pd.merge(df6,df2,on='_id',how='left')
    df7=pd.merge(df9,df3,on='_id',how='left')
    df8=pd.merge(df7,df4,on='_id',how='left')
    df=pd.merge(df8,df5,on='_id',how='left')
    
    df=df.fillna(0)
    df

 

    if df.empty == True:
        
        schname=[]
        teacher=[]
        parent=[]
        clever=[]
        scoology=[]
        active=[]
      
    else:
        schname=df['name'].tolist()
        teacher=df['teachers'].tolist()
        parent=df['parents'].tolist()
        clever=df['clever'].tolist()
        scoology=df['scoology'].tolist()
        active=df['active'].tolist()
   
    data={'schname':schname,'Teachers':teacher,'Parents':parent,'Clever':clever,'Scoology':scoology,'active':active}
    
    return json.dumps(data)


# schwiseucc('5f2609807a1c0000950bb46d','2021-08-01','2021-10-19')


@app.route('/schoolwisepracticecounttop20/<districtid>/<startdate>/<enddate>')
def schwisepc(districtid,startdate,enddate):
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.user_master
    district=disdic[districtid]
    
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
#     enddate = dateutil.parser.parse(enddate)
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
#              {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                   
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
#              {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'user_count':{'$size':'$ID'},'name':'$NAME','district':'$district'}},
                   { '$sort' : { 'user_count' : -1}},
              {'$limit':20}
                  ])))
    if df1.empty:
        df1=pd.DataFrame({'_id':[],'user_count':[]})
    
    df2 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"_id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"_id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
#                       {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,'FULL_EXPERIENCE':'Y',"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                    {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'teachers':{'$size':'$ID'}}},
                   { '$sort' : { 'teachers' : -1}},
#               {'$limit':20}
                  ])))
    if df2.empty:
        df2=pd.DataFrame({'_id':[],'teachers':[]})
    
    df3 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
#               {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
                 {'EMAIL_ID':{'$ne':''}},
#                    
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'parents':{'$size':'$ID'}}},
                   { '$sort' : { 'parents' : -1}},
#               {'$limit':20}
                  ])))
    if df3.empty:
        df3=pd.DataFrame({'_id':[],'parents':[]})
    
    
    df4 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"_id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"_id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
             
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
#                      
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'clever':{'$size':'$ID'}}},
                   { '$sort' : { 'clever' : -1}},
#               {'$limit':20}
                  ])))
    if df4.empty:
        df4=pd.DataFrame({'_id':[],'clever':[]})
    
    
    df5 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"_id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
            {"_id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
#               {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
#                       {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,'FULL_EXPERIENCE':'Y',"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                   
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'scoology':{'$size':'$ID'}}},
                   { '$sort' : { 'scoology' : -1}},
#               {'$limit':20}
                  ])))
    if df5.empty:
        df5=pd.DataFrame({'_id':[],'scoology':[]})
    
    
    df6= pd.merge(df1,df2,on='_id',how='left')
    df7=pd.merge(df6,df3,on='_id',how='left')
    df8=pd.merge(df7,df4,on='_id',how='left')
    df=pd.merge(df8,df5,on='_id',how='left')
    
    df=df.fillna(0)
    df

 

    if df.empty == True:
        
        schname=[]
        teacher=[]
        parent=[]
        clever=[]
        scoology=[]
      
    else:
        schname=df['name'].tolist()
        teacher=df['teachers'].tolist()
        parent=df['parents'].tolist()
        clever=df['clever'].tolist()
        scoology=df['scoology'].tolist()
   
    data={'schname':schname,'Teachers':teacher,'Parents':parent,'Clever':clever,'Scoology':scoology}
    
    return json.dumps(data)



@app.route('/monthwisepracticepartner_')
def partner__monthwisepc():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
#     district=disdic[districtid]
    df = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
    #           {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"PARTNER_CATEGORY":{'$regex':'Skillman', '$options':'i'}})}},
#                {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
         {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'practice_count':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))


    df.rename(columns = { '_id': 'Month'}, inplace = True)

    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 


# Create the pandas DataFrame 
    df1 = pd.DataFrame(data, columns = ['Monthname', 'Month']) 

    DF=pd.merge(df1,df, on='Month',how='left')
    DF=DF.fillna(0)

#         d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname

#         try:
#             df['Month'] = df['Month'].map(d)
#         except:
#             pass

#         if df.empty == True:
#             Month=['Aug','Sep','Oct','Nov','Dec','Jan','Feb','Mar','Apr','May','Jun','Jul',]

#             pc=[0,0,0,0,0,0,0,0,0,0,0,0]
#         else:
    Month=DF['Monthname'].tolist()

    pc=DF['practice_count'].tolist()


    data={'monthname':Month,'practice_count':pc}
    return json.dumps(data)


@app.route('/attendance_heatmappractices/')

def Attendance_heatmap_prac():

    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},

                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},

                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'}}},
                      {'$project':{'_id':1,'schools':'$ID'}},

                      ])))

    ids=list(df['_id'])
    
    
    df3=DataFrame(list(collection.aggregate([
{"$match":
    {'$and': [

         
        {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
{'USER_ID.schoolId._id':{'$in':ids}},


 {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,1,1)}},]}},


        {'$group':{'_id':'$USER_ID.schoolId._id','uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
              {'$project':{'_id':1,'active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
    { '$sort' : { 'active_user_count' : -1} },
    {'$limit':30}])))
    top=list(df3['_id'])
#     print(df3)
#     df3.to_csv('file1.csv')
    df2=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            
#              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':top}},
    # {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
  
     {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,1,1)}},]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'school':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    # df2

    df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        finaldf = pd.concat(result)
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =practice_count
    data=collections.OrderedDict(sorted(data.items()))
    data={'meanTemp':data}

    
    return json.dumps(data)    

@app.route('/attendance_schoolwisefamilypracticecount_/')
def attendance_schppcfamily():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass  
    collection = db.audio_track_master
    collection1 = db.user_master
#     district=disdic[districtid]
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {'USER_ID.schoolId._id':{'$ne':None}},
                      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#               {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},

    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'practice_count':'$pc'}},
            { '$sort' : { 'practice_count' : -1}}
    # //               {'$count':'count'}
                  ])))
    df2=DataFrame(list(collection1.aggregate([{"$match":
     {'$and': [
           {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                  {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},

             {'EMAIL_ID':{'$ne':''}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'name':{'$first':'$schoolId.NAME'},'user_name':{'$first':'$USER_NAME'}
                  }},


        {'$project':{'_id':1,'name':1}},])))

    df=pd.merge(df1,df2, how='left', on='_id')
    
    if df.empty == True:
        
        schname=[]
        pc=[]
      
    else:
        schname=df['name'].tolist()
        pc=df['practice_count'].tolist()
    data={'schname':schname[0:20],'Familypracticecount':pc[0:20]}
    
    return json.dumps(data)

@app.route('/attendance_schoolwisefamilycount_/')
def attendance__schpuc():
   
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection= db.user_master
#     district=disdic[districtid]
    df = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                      {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
                 {'EMAIL_ID':{'$ne':''}},
#                    {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'user_count':{'$size':'$ID'},'name':'$NAME','district':'$district'}},
                   { '$sort' : { 'user_count' : -1}}
    # //               {'$count':'count'}
                  ])))

    # df['SCH_CREATED_DATE']=pd.to_datetime(df['SCH_CREATED_DATE'])

#     df=df.nlargest(20,'user_count')
#     df= df.groupby(df['district'])
#     df= df.get_group(''+district+'')


    if df.empty == True:
        
        schname=[]
        uc=[]
      
    else:
        schname=df['name'].tolist()
        uc=df['user_count'].tolist()
    
    

    data={'schname':schname[0:20],'Familycount':uc[0:20]}
    
    return json.dumps(data)


@app.route('/Attendance_schoolwisepracticecounttop20_/')
def Attendancechwisepc():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection1 = db.user_master
#     district=disdic[districtid]
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {'USER_ID.schoolId._id':{'$ne':None}},
                      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#               {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},

    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'practice_count':'$pc'}},
            { '$sort' : { 'practice_count' : -1}}
    # //               {'$count':'count'}
                  ])))
    df2=DataFrame(list(collection1.aggregate([{"$match":
     {'$and': [
           {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                  {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},

             {'EMAIL_ID':{'$ne':''}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'name':{'$first':'$schoolId.NAME'},'user_name':{'$first':'$USER_NAME'}
                  }},


        {'$project':{'_id':1,'name':1}},])))

    df=pd.merge(df1,df2, how='left', on='_id')
#     print(df)
    if df.empty == True:
        
        schname=[]
        pc=[]
      
    else:
        schname=df['name'].tolist()
        pc=df['practice_count'].tolist()
    data={'schname':schname[0:20],'Familypracticecount':pc[0:20]}
    
    return json.dumps(data)

@app.route('/attendance_top20userspractisinginfo_/')
def attendance__topusers_practice():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
#     district=disdic[districtid]


    collection1 = db.user_master
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
    #           {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
             {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},

             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':'$USER_ID._id','pc':{'$sum':1}}},
              {'$project':{'_id':1,'practice_count':'$pc'}},
    { '$sort' : { 'practice_count' : -1} }



    # //               {'$count':'count'}
              ])))
    df1

    df2=DataFrame(list(collection1.aggregate([{"$match":
     {'$and': [
    #         {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                  {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},

             {'EMAIL_ID':{'$ne':''}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$_id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'user_name':{'$first':'$USER_NAME'}
                  }},


        {'$project':{'_id':1,'user_name':1,'school_name':1}},])))

    df=pd.merge(df1,df2, how='left', on='_id')
    df
    if df.empty == True:

        schname=[]
        pc=[]

    else:
        df["users"] = df["user_name"] +','+' ' + df["school_name"]
        schname=df['users'].tolist()
        pc=df['practice_count'].tolist()



    #     data=[]    
    #     for i,k in zip(schname,uc):

    #         data.append([i,k])

    #     for i in range(len(schname)):
    #             schname[i] = schname[i]
    data={'schname':schname[0:20],'practicecount':pc[0:20]}

    return json.dumps(data)

@app.route('/Attendance_schoolwiseusercounttop20_/')
def attendance__schwiseuc():
   
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass  
    collection = db.user_master
#     district=disdic[districtid]
    df = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                      {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
#                    {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'user_count':{'$size':'$ID'},'name':'$NAME','district':'$district'}},
                   { '$sort' : { 'user_count' : -1}}
    # //               {'$count':'count'}
                  ])))

    # df['SCH_CREATED_DATE']=pd.to_datetime(df['SCH_CREATED_DATE'])

#     df=df.nlargest(20,'user_count')
#     df= df.groupby(df['district'])
#     df= df.get_group(''+district+'')

    if df.empty == True:
        
        schname=[]
        pc=[]
      
    else:
        schname=df['name'].tolist()
        uc=df['user_count'].tolist()
   
    data={'schname':schname[0:20],'usercount':uc[0:20]}
    
    return json.dumps(data)

@app.route('/monthwisepracticeattendance_')
def attendance__monthwisepc():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
#     district=disdic[districtid]
    df = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
    #           {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
#                {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
         {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'practice_count':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))


    df.rename(columns = { '_id': 'Month'}, inplace = True)

    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 


# Create the pandas DataFrame 
    df1 = pd.DataFrame(data, columns = ['Monthname', 'Month']) 

    DF=pd.merge(df1,df, on='Month',how='left')
    DF=DF.fillna(0)

#         d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname

#         try:
#             df['Month'] = df['Month'].map(d)
#         except:
#             pass

#         if df.empty == True:
#             Month=['Aug','Sep','Oct','Nov','Dec','Jan','Feb','Mar','Apr','May','Jun','Jul',]

#             pc=[0,0,0,0,0,0,0,0,0,0,0,0]
#         else:
    Month=DF['Monthname'].tolist()

    pc=DF['practice_count'].tolist()


    data={'monthname':Month,'practice_count':pc}
    return json.dumps(data)



@app.route('/attendancepartnercardsinfo_/')
def attend_count_cards():
    from datetime import datetime
    from datetime import timedelta
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection1 = db.user_master
    collection2=db.audio_track_master
    collection3=db.login_logs
#     district=disdic[districtid]
#     print(district)
    df1 = DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                  {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
#                  {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
             {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
    #              {'DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','ID':{'$addToSet':'$schoolId._id'},'dn':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'school_count':{'$size':'$ID'},'district':'$dn'}}
                  ])))
    df2 = DataFrame(list(collection1.aggregate([ {"$match":
         {'$and': [
              {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2a")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                  {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
#                  {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','ID':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':1,'teacher_count':{'$size':'$ID'}}}
                  ])))
    df5 = DataFrame(list(collection1.aggregate([ {"$match":
         {'$and': [
              {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                  {'IS_PORTAL':'Y'},
                  {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
                 {'EMAIL_ID':{'$ne':''}},
#                  {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','ID':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':1,'family_count':{'$size':'$ID'}}}
                  ])))
    today1= datetime.utcnow()
    tod1= today1+ timedelta(hours=4)
    start1= tod1-timedelta(days=30)
    df3=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
    # //          {'ROLE_ID._id' :{'$':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
                 {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions':'$pc','MINDFUL_MINUTES':'$MINDFUL_MINUTES'}}])))
   

    df4=DataFrame(list(collection3.aggregate([{"$match":
         {'$and': [
    #           {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                 {'LAST_LOGGED_IN':{'$gte':start1}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1}}},
                  {'$project':{'_id':1,'logins':'$pc'}}])))
    df6=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
                 {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions_t':'$pc'}}])))
   
    df7=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
             {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'Attendance', '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
                 {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions_p':'$pc'}}])))
   

    sc=[0]
    try:
        sc=df1['school_count']
    except:
        sc=[0]
        
    tc=[0]
    try:
        tc=df2['teacher_count']
    except:
        tc=[0]
    
    pct=[0]
    try:
        pct=df6['practice_sessions_t']
    except:
        pct=[0]
    pcp=[0]
    try:
        pcp=df7['practice_sessions_p']
    except:
        pcp=[0]
    mm=[0]
    try:
        mm=df3['MINDFUL_MINUTES']
    except:
        mm=[0]
    
    lc=[0]
    try:
        lc=df4['logins']
    except:
        lc=[0]
        
    fc=[0]
    try:
        fc=df5['family_count']
    except:
        fc=[0]
    
    
    
    
    dn=[0]
    try:
        dn=df1['district']
    except:
        dn=[0]
    
    
#     print(lc)
    
    data={"schoolcount":str(sc[0]),"teachercount":str(tc[0]),"familycount":str(fc[0]),"teacherpracticecount":str(pct[0]),"parentspracticecount":str(pcp[0]),"logincount":str(lc[0]),
          'MINDFUL_MINUTES':str(mm[0]),'district':'Attendance Works'}
    return json.dumps(data)







@app.route('/monthwisepracticedistrict/<districtid>/<startdate>/<enddate>')
def monthwisepc(districtid,startdate,enddate):
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
    pre_start= myDatetime1 - relativedelta(years=1)
    print(pre_start)
    pre_end=myDatetime2 - relativedelta(years=1)
    print(pre_end)
    df0= DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
#       {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#             {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
        
    # //             {'USER_ID.IS_PORTAL':'Y'},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#          {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": pre_start ,
                             "$lte":pre_end}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'practice_count_lsy':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    if df0.empty:
        df0=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'practice_count_lsy':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    
    df1= DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
#       {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#             {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
        
    # //             {'USER_ID.IS_PORTAL':'Y'},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#          {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'practice_count':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    if df1.empty:
        df1=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'practice_count':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    df2 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
      {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#          
        {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
#             {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#             {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
        
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#          {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'teachers':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    if df2.empty:
        df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'teachers':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    df3 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
      {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#             {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#          {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'parents':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    if df3.empty:
        df3=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    df4 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
#       {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$in":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
#             {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#             {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#          {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'clever':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    if df4.empty:
        df4=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'clever':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    df5 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
#       {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$in":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
            {"USER_ID._id":{"$in":db.schoology_master.distinct("USER_ID._id")}},
        
            {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#                {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#          {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'scoology':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    
    
    if df5.empty:
        df5=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'scoology':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    df6= pd.merge(df1,df2,on='_id',how='left')
    df66= pd.merge(df6,df0,on='_id',how='left')
    df7= pd.merge(df66,df3,on='_id',how='left')
    df8= pd.merge(df7,df4,on='_id',how='left')
    df= pd.merge(df8,df5,on='_id',how='left')

    df.rename(columns = { '_id': 'Month'}, inplace = True)

    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 


# Create the pandas DataFrame 
    df9 = pd.DataFrame(data, columns = ['Monthname', 'Month']) 

    DF=pd.merge(df9,df, on='Month',how='left')
    DF=DF.fillna(0)

#         d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname

#         try:
#             df['Month'] = df['Month'].map(d)
#         except:
#             pass

    if df.empty == True:
        Month=['Aug','Sep','Oct','Nov','Dec','Jan','Feb','Mar','Apr','May','Jun','Jul',]

        T=[0,0,0,0,0,0,0,0,0,0,0,0]
    else:
        Month=DF['Monthname'].tolist()
        
        T=DF['teachers'].tolist()
        P=DF['parents'].tolist()
        C=DF['clever'].tolist()
        S=DF['scoology'].tolist()
        pc=DF['practice_count'].tolist()
        lsy=DF['practice_count_lsy'].tolist()


    data={'monthname':Month,'Teachers':T,'Parents':P,'Clever':C,'Scoology':S,'lsy':lsy}
    return json.dumps(data)
# monthwisepc('5f2609807a1c0000950bb46d','2021-08-01','2021-10-19')



@app.route('/90daysuserpractising/<districtid>/<startdate>/<enddate>')
def user_practice_90days(districtid,startdate,enddate):
    
    from datetime import datetime
    from datetime import timedelta
    
    today1= datetime.utcnow()
    tod1= today1+ timedelta(hours=4)
    start1= tod1-timedelta(days=90)
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    district=disdic[districtid]
    
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
#     {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
#             {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#              {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#              {'MODIFIED_DATE':{'$gte':start1}},
         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
# //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'user_count':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df1.empty:
        df1=pd.DataFrame({'_id':[],'user_count':[]})
    
    df2 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
#             {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#             {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#              {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#              {'MODIFIED_DATE':{'$gte':start1}},
         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
# //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'teachers':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df2.empty:
        df2=pd.DataFrame({'_id':[],'teachers':[]})
    
    df3 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
#             {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#              {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#              {'MODIFIED_DATE':{'$gte':start1}},
         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
# //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'parents':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df3.empty:
        df3=pd.DataFrame({'_id':[],'parents':[]})
    
    df4 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
#     {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$in":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
#             {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#             {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#              {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#              {'MODIFIED_DATE':{'$gte':start1}},
         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
# //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'clever':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df4.empty:
        df4=pd.DataFrame({'_id':[],'clever':[]})
    
    
    df5 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
#     {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$in":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
#             {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
#             {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#              {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#              {'MODIFIED_DATE':{'$gte':start1}},
         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
# //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'scoology':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df5.empty:
        df5=pd.DataFrame({'_id':[],'scoology':[]})
        
        
        
    df6= pd.merge(df1,df2,on='_id',how='left')
    df7= pd.merge(df6,df3,on='_id',how='left')
    df8= pd.merge(df7,df4,on='_id',how='left')
    DF= pd.merge(df8,df5,on='_id',how='left')
    DF=DF.fillna(0)
    # df['SCH_CREATED_DATE']=pd.to_datetime(df['SCH_CREATED_DATE'])
    DF.rename(columns = { '_id': 'date'}, inplace = True)
    
    
    if DF.empty == True:
        date=[]
        teachers=[]
    else:
        date=DF['date'].tolist()

        T=DF['teachers'].tolist()
        P=DF['parents'].tolist()
        C=DF['clever'].tolist()
        S=DF['scoology'].tolist()
        uc=DF['user_count'].tolist()


    data={'Date':date,'Teachers':T,'Parents':P,'Clever':C,'Scoology':S}
    return json.dumps(data)







@app.route('/last90daysuserpractising/<districtid>')
def last_practice_90days_(districtid):
    
    from datetime import datetime
    from datetime import timedelta
    
    today1= datetime.utcnow()
    tod1= today1+ timedelta(hours=4)
    start1= tod1-timedelta(days=90)
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    district=disdic[districtid]
    
#     myDatetime1 = dateutil.parser.parse(startdate)
#     myDatetime2 = dateutil.parser.parse(enddate)
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
#     {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
#             {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#              {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#              {'MODIFIED_DATE':{'$gte':start1}},
         {'MODIFIED_DATE':{"$gte": start1}},
#                              "$lte":myDatetime2}},
# //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'user_count':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df1.empty:
        df1=pd.DataFrame({'_id':[],'user_count':[]})
    
    df2 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#              {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#              {'MODIFIED_DATE':{'$gte':start1}},
         {'MODIFIED_DATE':{"$gte": start1}},
# //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'teachers':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df2.empty:
        df2=pd.DataFrame({'_id':[],'teachers':[]})
    
    df3 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
#             {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#              {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#              {'MODIFIED_DATE':{'$gte':start1}},
         {'MODIFIED_DATE':{"$gte": start1}},
# //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'parents':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df3.empty:
        df3=pd.DataFrame({'_id':[],'parents':[]})
    
    df4 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#              {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#              {'MODIFIED_DATE':{'$gte':start1}},
         {'MODIFIED_DATE':{"$gte": start1}},
# //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'clever':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df4.empty:
        df4=pd.DataFrame({'_id':[],'clever':[]})
    
    
    df5 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
            {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#              {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
#              {'MODIFIED_DATE':{'$gte':start1}},
         {'MODIFIED_DATE':{"$gte":start1}},
# //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'scoology':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df5.empty:
        df5=pd.DataFrame({'_id':[],'scoology':[]})
        
        
        
    df6= pd.merge(df1,df2,on='_id',how='left')
    df7= pd.merge(df6,df3,on='_id',how='left')
    df8= pd.merge(df7,df4,on='_id',how='left')
    DF= pd.merge(df8,df5,on='_id',how='left')
    DF=DF.fillna(0)
    # df['SCH_CREATED_DATE']=pd.to_datetime(df['SCH_CREATED_DATE'])
    DF.rename(columns = { '_id': 'date'}, inplace = True)
    
    
    if DF.empty == True:
        date=[]
        teachers=[]
    else:
        date=DF['date'].tolist()

        T=DF['teachers'].tolist()
        P=DF['parents'].tolist()
        C=DF['clever'].tolist()
        S=DF['scoology'].tolist()
        uc=DF['user_count'].tolist()


    data={'Date':date,'Teachers':T,'Parents':P,'Clever':C,'Scoology':S}
    return json.dumps(data)


@app.route('/90daysuserloggedindetail/<districtid>')
def user_logins_90days(districtid):
    disdic={'5f2609807a1c0000950bb465':'Middleton-Cross Plains Area School District',
    '5f2609807a1c0000950bb475':'Agawam School district',
    '5f2609807a1c0000950bb481':'Alameda Unified School District',
    '5f2609807a1c0000950bb47a':'Alpine School District',
    '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
    '5f2609807a1c0000950bb463':'Austin Independent School District',
    '5f59e4836451a9089d7d4007':'Belleville School District',
    '5f2609807a1c0000950bb46d':'Broward County Public Schools',
    '5f2609807a1c0000950bb46c':'Chico Unified School District',
    '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
    '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
    '5f2609807a1c0000950bb45c':'Comox Valley School District(sd71)',
    '5f2609807a1c0000950bb480':'Dell Texas',
    '5f7413ef9387fd71ce6387cb':'Douglas County School District',
    '5f895191609e08b76029f641':'Early learning Sarasota',
    '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
    '5f2609807a1c0000950bb461':'Englewood Public School District',
    '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
    '5f2609807a1c0000950bb47d':'Flint Public Schools',
    '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
    '5f2609807a1c0000950bb450':'Goleta District',
    '5f2609807a1c0000950bb474':'Greenburgh North Castle Union Free School District',
    '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
    '5f2609807a1c0000950bb476':'Hillsborough County',
    '5f2609807a1c0000950bb455':'Krum Independent School District',
    '5f2609807a1c0000950bb47e':'La Joya School District',
    '5f2609807a1c0000950bb467':'Lincolnshire Schools',
    '5f2609807a1c0000950bb45a':'LAUSD',
    '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
    '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
    '5fbcdf0ba84e48a64412a798':'Needham School District',
    '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
    '5f6994386451a9089d7d4009':'Ogden school district',
    '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
    '5fd704da04a848e368de5dc6':'Oakland Unified School District',
    '5f8fcd33609e08b76029f644':'Paradise Unified School District',
    '5f2609807a1c0000950bb466':'Pinellas County Schools',
    '5f2609807a1c0000950bb471':'Racine Unified Schools',
    '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
    '5f2609807a1c0000950bb478':'San Diego Unified School District',
    '5f2609807a1c0000950bb470':'San Leandro Unified School District',
    '5f2609807a1c0000950bb477':'Sarasota County',
    '5f2609807a1c0000950bb473':'Skillman Foundation',
    '5f2609807a1c0000950bb46a':'Springfield Public Schools',
    '5f2609807a1c0000950bb468':'Utah Board of Education',
    '5f698b826451a9089d7d4008':'Wayne Metro',
    '5f2609807a1c0000950bb45b':'Westfield Public School District',
    '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
    '5f2609807a1c0000950bb45d':'Youngstown',
    '5f2609807a1c0000950bb464':'Equity Education',
    '5f2609807a1c0000950bb469':'LSF-Head Start',
    '5f2609807a1c0000950bb46e':'District 25 New York Schools',
    '5f2609807a1c0000950bb46f':'Paradise Schools',
    '5f2609807a1c0000950bb479':'Panorama Education',
    '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
    '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
    '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
    '5fe2e25d4d0ca68d7baf889d':'BGCA',
    '5fe318b14d0ca68d7baf889e':'BLUE',
    '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
    '6017ab3043ca9c39151838d4':'Oswego School District',
    '60239a84e57dc27613699d57':'Austin Independent School District',
    '6023a6d79e8e623753fc305c':'Boulder Valley School District',
    '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
    '6023a7269e8e623753fc305e':'Fulton County School System',
    '6023a7499e8e623753fc305f':'Manatee County School District',
    '6023a76f9e8e623753fc3060':'San Jose Unified School District',
    '6023a7949e8e623753fc3061':'Wasatch County School District',
    '60473f8823e88e242074ebd2':'Champlain Valley School District',
    '60a7b03831afdba383052726':'United Way Of Santa Barbara',
    '123':'Skillman',
    '456':'UWBA',
    '789':'Attendance works'}
    from datetime import datetime
    from datetime import timedelta
    today1= datetime.utcnow()
    tod1= today1+ timedelta(hours=4)
    start1= tod1-timedelta(days=90)
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass 
    collection = db.login_logs
    district=disdic[districtid]
    df = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
#           {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,'FULL_EXPERIENCE':'Y',"CATEGORY":{'$regex':district, '$options':'i'}})}},
#              {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
             {'LAST_LOGGED_IN':{'$gte':start1}},
# //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_LOGGED_IN"}},'pc':{'$addToSet':'$USER_ID._id'},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'un':{'$first':'$USER_ID.USER_NAME'}}},
              {'$project':{'_id':1,'user_count':{'$size':'$pc'}}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    # df['SCH_CREATED_DATE']=pd.to_datetime(df['SCH_CREATED_DATE'])
    df.rename(columns = { '_id': 'date'}, inplace = True)
#     df=df.nlargest(20,'user_count')
#     df= df.groupby(df['district'])
#     df= df.get_group(''+district+'')



    if df.empty == True:
        
        date=[]
        uc=[]
      
    else:
        date=df['date'].tolist()
        uc=df['user_count'].tolist()
    
  
    
#     data=[]    
#     for i,k in zip(schname,uc):

#         data.append([i,k])
    
#     for i in range(len(schname)):
#             schname[i] = schname[i]
    data={'date':date,'daysuserlogins':uc}
    
    return json.dumps(data)


@app.route('/top20userspractisinginfo/<districtid>/<startdate>/<enddate>')
def topusers_practice(districtid,startdate,enddate):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)


    collection1 = db.user_master
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
    #           {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
             {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
                {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':'$USER_ID._id','pc':{'$sum':1}}},
              {'$project':{'_id':1,'practice_count':'$pc'}},
    { '$sort' : { 'practice_count' : -1} }



    # //               {'$count':'count'}
              ])))
    if df1.empty == True:

        schname=[]
        pc=[]
        
    else:

        df2=DataFrame(list(collection1.aggregate([{"$match":
         {'$and': [
        #         {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        #                  {'_id':{'$in':user}},
        # //               {'IS_ADMIN':'Y'},
    #          {'CREATED_DATE':{"$gte": myDatetime1 ,
    #                              "$lte":myDatetime2}},

                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$_id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'user_name':{'$first':'$USER_NAME'}
                      }},


            {'$project':{'_id':1,'user_name':1,'school_name':1}},]))).fillna('No info')

        df=pd.merge(df1,df2, how='left', on='_id')
        df
        if df.empty == True:

            schname=[]
            pc=[]

        else:
            df["users"] = df["user_name"] +','+' ' + df["school_name"]
            schname=df['users'].tolist()
            pc=df['practice_count'].tolist()



    #     data=[]    
    #     for i,k in zip(schname,uc):

    #         data.append([i,k])

    #     for i in range(len(schname)):
    #             schname[i] = schname[i]
    data={'schname':schname[0:20],'practicecount':pc[0:20]}

    return json.dumps(data)

@app.route('/districtfeedbackrating_csy/<districtid>/<startdate>/<enddate>')
def dis_schoolrating_csy__(districtid,startdate,enddate):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

    df1=DataFrame(list(db.user_master.aggregate([
        {"$match":
         {
            '$and':[
    # // #             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'EMAIL_ID':{'$ne':''}},
    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

    #                 {'schoolId._id':{'$in':school}},

                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]

         }},
        {'$project':{'_id':'$_id','school':'$schoolId._id' }}
        ])))

    user=df1['_id'].tolist() 


    df = DataFrame(list(collection.aggregate([
     {"$match":{'$and':[

           {'USER._id':{'$in':user}},

        {'RATING':{'$ne':0}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

     ]}},

    {'$group':{'_id':'$RATING' ,'count':{'$sum':1}}},
           {'$sort':{'_id':-1}}

    ])))

    df['_id']=df['_id'].replace({5:'five', 4:'four',3:'three',2:'two',1:'one'})

    dff=df.set_index("_id")["count"].to_dict()

    dff={str(k):int(v) for k,v in dff.items()}

    temp={"donut":dff}
   
    return json.dumps(temp)


@app.route('/districtsentimentdonut_csy/<districtid>/<startdate>/<enddate>')
def dis_sentiment_pie(districtid,startdate,enddate):
    clean_list=[]
    news_headlines_senti = []
    news_headlines_dict = {}
    pnews_headlines=0
    nnews_headlines=0
    nenews_headlines = 0
    # date1=startdate
    # date2=enddate
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    # myDatetimestrt = dateutil.parser.parse(date1)
    # myDatetimeend = dateutil.parser.parse(date2)
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

    df1=DataFrame(list(db.user_master.aggregate([
        {"$match":
         {
            '$and':[
#                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'EMAIL_ID':{'$ne':''}},
                {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}
            ]

         }},
        {'$project':{'_id':'$_id','school':'$schoolId._id' }}
        ])))

    userid=df1['_id'].tolist() 
    x=['NA','N/A','n.a','.\n',"a\\n","a\n","v\n","v\\n","0-",'na\n','na','Write a feedback (optional)','Na','k,n/l','[pppppppppppsz']
    user=[
    {"$match":{'$and':[ {'USER._id':{'$in':userid}},
                    {'COMMENT':{'$exists':1}},
                       {'COMMENT':{'$ne':''}},
                       {'COMMENT':{'$ne':None}},
                        {'COMMENT':{'$nin':x}},
                       
                       
                       
    #         {'RATING':{'$ne':0}},
         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}
                         ,
                        ]}},
    { "$project": { "USER_ID": "$USER._id", "USER_NAME": "$USER.USER_NAME","_id":0, "EMAIL": "$USER.EMAIL_ID", "RATING":1,
    "LAST_COMMENT_DATE": "$MODIFIED_DATE", "AUDIO_NAME": "$AUDIO_ID.AUDIO_NAME", "NARRATOR_NAME": "$AUDIO_ID.NARRATEDBY",
    "COMMENT":1, "PROGRAM_NAME": "$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME"}}
    ]
    update=list(collection.aggregate(user))
    df=pd.DataFrame(update).fillna("no info")
    text=df["COMMENT"].to_list()
    df=df[['COMMENT']]
    df = df.sample(frac=1.0).reset_index(drop=True)
    for i in df['COMMENT'].tolist():
        df = df[df.COMMENT.str.len()!=1] 
    
    import nltk
    nltk.download('vader_lexicon')

    from nltk.sentiment.vader import SentimentIntensityAnalyzer
    sia = SentimentIntensityAnalyzer()
    df['Positivity'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['pos'])
    df['Negativity'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['neg'])
    df['Neutrality'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['neu'])
    df['Compound'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['compound'])
    pd.pandas.set_option('display.max_rows',None)  
    neg=df[df['Compound']<0]
    pos=df[df['Compound']>0]
    neu=df[df['Compound']==0]
    neg_sentiment=round(100*(len(neg)/(len(neu)+len(neg)+len(pos))),2)
    pos_sentiment=round(100*(len(pos)/(len(neu)+len(neg)+len(pos))),2)
    neu_sentiment=round(100*(len(neu)/(len(neu)+len(neg)+len(pos))),2)
    word_chart={'donut':{'pos':pos_sentiment,'neg':neg_sentiment,'neu':neu_sentiment},'text':['pos','neg','neu']}

#     print(df)
    
#     word_chart={"donut":{"pos":round(pos, 2),"neg":round(neg, 2)}}
    return json.dumps(word_chart)

@app.route('/districtsentiment_table/<districtid>/<table_type>/<startdate>/<enddate>')
def dis_sentiment_pie_table(districtid,table_type,startdate,enddate):
    clean_list=[]
    news_headlines_senti = []
    news_headlines_dict = {}
    pnews_headlines=0
    nnews_headlines=0
    nenews_headlines = 0
    # date1=startdate
    # date2=enddate
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    # myDatetimestrt = dateutil.parser.parse(date1)
    # myDatetimeend = dateutil.parser.parse(date2)
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

    df1=DataFrame(list(db.user_master.aggregate([
        {"$match":
         {
            '$and':[
#                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'EMAIL_ID':{'$ne':''}},
                {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}
            ]

         }},
        {'$project':{'_id':'$_id','school':'$schoolId._id' }}
        ])))

    userid=df1['_id'].tolist() 
    x=['NA','N/A','n.a','.\n',"a\\n","a\n","v\n","v\\n","0-",'na\n','na','Write a feedback (optional)','Na','k,n/l','[pppppppppppsz']
    user=[
    {"$match":{'$and':[ {'USER._id':{'$in':userid}},
                    {'COMMENT':{'$exists':1}},
                       {'COMMENT':{'$ne':''}},
                       {'COMMENT':{'$ne':None}},
                        {'COMMENT':{'$nin':x}},
                       
                       
                       
    #         {'RATING':{'$ne':0}},
         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}
                         ,
                        ]}},
    { "$project": { "USER_ID": "$USER._id", "USER_NAME": "$USER.USER_NAME","_id":0, "EMAIL": "$USER.EMAIL_ID", "RATING":1,
    "LAST_COMMENT_DATE":{"$dateToString": { "format": "%Y-%m-%d", "date":"$MODIFIED_DATE"}}, "AUDIO_NAME": "$AUDIO_ID.AUDIO_NAME", "NARRATOR_NAME": "$AUDIO_ID.NARRATEDBY",
    "COMMENT":1, "PROGRAM_NAME": "$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME"}}
    ]
    update=list(collection.aggregate(user))
    df=pd.DataFrame(update).fillna("no info")
    text=df["COMMENT"].tolist()
#     df=df[['COMMENT']]
    df = df.sample(frac=1.0).reset_index(drop=True)
    df['RATING']=df['RATING'].replace({0:'NO RATING'})
    for i in df['COMMENT'].tolist():
        df = df[df.COMMENT.str.len()!=1] 
    
    import nltk
    nltk.download('vader_lexicon')

    from nltk.sentiment.vader import SentimentIntensityAnalyzer
    sia = SentimentIntensityAnalyzer()
    df['Positivity'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['pos'])
    df['Negativity'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['neg'])
    df['Neutrality'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['neu'])
    df['Compound'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['compound'])
    pd.pandas.set_option('display.max_rows',None)  
    neg=df[df['Compound']<0]
    pos=df[df['Compound']>0]
    neu=df[df['Compound']==0]
    neg_sentiment=round(100*(len(neg)/(len(neu)+len(neg)+len(pos))),2)
    pos_sentiment=round(100*(len(pos)/(len(neu)+len(neg)+len(pos))),2)
    neu_sentiment=round(100*(len(neu)/(len(neu)+len(neg)+len(pos))),2)
    a={'pos':pos,'neg':neg,'neu':neu}
    table_name=a[table_type]
    table=table_name[["USER_NAME","EMAIL","COMMENT","RATING","LAST_COMMENT_DATE"]]
    if "export" in request.args:
        try:
            csv = df.to_csv(index=False)
            return Response(
                csv,
                mimetype="text/csv",
                headers={"Content-disposition":
                        "attachment; filename=Comments.csv"})
        except:
            return jsonify("Unauthorized Access")    
    else:

        temp = {"table":table.to_numpy().tolist()}
        return json.dumps(temp, default=str)
#     return df
# dis_sentiment_pie_table('5f2609807a1c0000950bb45d','neg','2021-08-01','2021-12-17')








# @app.route('/districtsentimentdonut_csy/<districtid>/<startdate>/<enddate>')
# def dis_sentiment_pie(districtid,startdate,enddate):
#     clean_list=[]
#     news_headlines_senti = []
#     news_headlines_dict = {}
#     pnews_headlines=0
#     nnews_headlines=0
#     nenews_headlines = 0
#     # date1=startdate
#     # date2=enddate
#     today = date.today()
#     d1 = today.strftime("%Y-%m-%d")
#     # myDatetimestrt = dateutil.parser.parse(date1)
#     # myDatetimeend = dateutil.parser.parse(date2)
#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
#     db=client.compass
#     collection = db.audio_feedback
#     district=disdic[districtid]
#     myDatetime1 = dateutil.parser.parse(startdate)
#     myDatetime2 = dateutil.parser.parse(enddate)

#     df1=DataFrame(list(db.user_master.aggregate([
#         {"$match":
#          {
#             '$and':[
#     # // #             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#              {"IS_DISABLED":{"$ne":"Y"}},
#               {"IS_BLOCKED":{"$ne":"Y"}},
#              {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#                 {'EMAIL_ID':{'$ne':''}},
#                 {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

                
#                  {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#              { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#          { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                            {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                              {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]

#          }},
#         {'$project':{'_id':'$_id','school':'$schoolId._id' }}
#         ])))

#     userid=df1['_id'].tolist() 

#     user=[
#     {"$match":{'$and':[ {'USER._id':{'$in':userid}},
      
# #         {'RATING':{'$ne':0}},
#          {'MODIFIED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
#                         ]}},
#     { "$project": { "USER_ID": "$USER._id", "USER_NAME": "$USER.USER_NAME","_id":0, "EMAIL": "$USER.EMAIL_ID", "RATING":1,
#     "LAST_COMMENT_DATE": "$MODIFIED_DATE", "AUDIO_NAME": "$AUDIO_ID.AUDIO_NAME", "NARRATOR_NAME": "$AUDIO_ID.NARRATEDBY",
#     "COMMENT":1, "PROGRAM_NAME": "$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME"}}
#     ]
#     update=list(collection.aggregate(user))
#     df=pd.DataFrame(update).fillna("no info")
#     list_of_names=df["USER_ID"].to_list()
#     df

#     # def Average(lst):
#     #     return sum(lst) / len(lst)

#     # # Driver Code
#     # lst =df123["RATING"].to_list()
#     # average = Average(lst)
#     # average

#     #     print(df123["COMMENT"],"lola")
#     xx=df[df["COMMENT"]!="no info"]
#     xxc=xx[xx["COMMENT"]!=""]

#     comment_list=xxc["COMMENT"].to_list()
#     comment_list
#     newtexttoken=[]
#     for i in comment_list:
#         text_tokens = word_tokenize(i)
#         newtexttoken.append(text_tokens)
#     newlist=[]
#     for i in newtexttoken:
#         for z in i:
#             newlist.append(z.lower())
#     st_word=stopwords.words('english')
#     tokens_without_sw= [word for word in newlist if not word in st_word]
#     token5=[]
#     for sentence in tokens_without_sw:
#     #     print(sentence)
#         text3 = sentence.split('ing')
#     #     print(text3,"text3")
#         for i in text3:
#     #         print(i)
#             token5.append(i)
#     words = [w.replace('liked', 'like') for w in token5]
#     words2 = [w.replace('relaxed', 'relax') for w in words]
#     words3 = [w.replace('relaxing', 'relax') for w in words2]
#     words4 = [w.replace('excitinging', 'excited') for w in words3]
#     #     print(words4)
#     zxc=""
#     name=""
#     count=""
#     try:
#         xcvv=[x for x in words4 if len(x)>3]
#         fdist=FreqDist(xcvv)
#         df_fdist = pd.DataFrame.from_dict(fdist, orient='index')
#     #         print(df_fdist)
#         df_fdist.columns = ['Frequency']
#         df_fdist.index.name = 'Term'
#         xc=df_fdist.sort_values(by='Frequency', ascending=False, na_position='first')
#         #     tt=xc.drop(["i","it","we","made","us","the","feeling","some","students"])
#         cc=xc[0:10]
#         name=cc.index.to_list()
#         count=cc["Frequency"].to_list()
#         zxc=' '.join(word for word in xcvv)
#     except:
#         pass
#     for item in comment_list:
#         # trim
#         item = item.strip()
#         # Removing RT
#         item = item.replace('RT', '')
#         # Removing new line character
#         item = item.replace('\\n', '')
#         # Replace #word with word
#         news_headlines = re.sub(r'#([^\s]+)', r'\1', item)
#         # Convert @username to username
#         news_headlines = re.sub(r'@([^\s]+)', r'\1', item)
#         item = " ".join(re.findall("[a-zA-Z]+", item))
#         tmp_var = re.sub(r'^\S*\s', '', item)
#         clean_list.append(tmp_var)
#     for item in clean_list:
#             #print(item)
#             # create TextBlob object of passed news_headlines text
#             analysis = TextBlob(item)
#             # set sentiment
#             if analysis.sentiment.polarity > 0:
#                 # saving sentiment of news_headlines
#                 news_headlines_score = 'positive'
#                 pnews_headlines = pnews_headlines + 1
#                 news_headlines_dict[item] = news_headlines_score
#             elif analysis.sentiment.polarity == 0:
#                 # saving sentiment of news_headlines
#                 news_headlines_score = 'neutral'
#                 nenews_headlines = nenews_headlines + 1
#                 news_headlines_dict[item] = news_headlines_score
#             else:
#                 # saving sentiment of news_headlines
#                 news_headlines_score = 'negative'
#                 nnews_headlines = nnews_headlines + 1
#                 news_headlines_dict[item] = news_headlines_score
#     # print(clean_list)
#     newssentiment=[]
#     # for k, v in news_headlines_dict.items():
#     #     print(k,':',v)
#     for k, v in news_headlines_dict.items():

#         if v == "positive":
#             newssentiment.append({"sentiment":int(1),"text":k})
#         elif v == "negative":
#             newssentiment.append({"sentiment":int(-1),"text":k})
#         else:
#             newssentiment.append({"sentiment":int(0),"text":k})

#     #print(newssentiment)
#     newssentiment_dataframe=pd.DataFrame.from_dict(newssentiment)
#     # newssentiment_dataframe.to_csv("news_headlines_sentiment.csv", encoding='utf-8', index=False)
#     neg = 100 * (nnews_headlines) / ((nnews_headlines) + (pnews_headlines))
#     pos = 100 * (pnews_headlines) / ((nnews_headlines) + (pnews_headlines))

#     word_chart={"donut":{"pos":round(pos, 2),"neg":round(neg, 2)}}
    
#     return json.dumps(word_chart)
# # sentiment_pie('5f2609807a1c0000950bb46d','2021-08-01','2021-10-19')

@app.route('/90daystable/<districtid>/<startdate>')
def district_Date_table(districtid,startdate):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 

    
    collection2=db.school_master
    collection=db.user_master
    collection1=db.audio_track_master
    collection3=db.subscription_master
    district=disdic[districtid]
    print(district)
    startdate= dateutil.parser.parse(str(startdate))
    enddat= dateutil.parser.parse(str(startdate))
    enddate=datetime.datetime.combine(enddat,datetime.time.max)

#     from datetime import datetime


    

    df2=DataFrame(list(collection.aggregate([{"$match":
         {'$and': [
            {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                 {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},
              {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$_id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'school_id':{'$first':'$schoolId._id'},'user_name':{'$first':'$USER_NAME'},'EMAIL':{'$first':'$EMAIL_ID'},'date':{'$first':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
                      'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},


            {'$project':{'_id':1,'Created_date':'$date','country':1,'State':1,'user_name':1,'EMAIL':1,'school_name':1,'city':1,'school_id':'$school_id'}},])))


    
    
    df3=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
#               {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
             {'MODIFIED_DATE':{"$gte": startdate ,
                             '$lte':enddate}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'user_id':'$user','Practice_Count':'$pc','last_practice_date':1}}])))

    if df3.empty is True:
        return json.dumps('NO DATA')
    else:
        df3



        df4 = DataFrame(list(collection3.aggregate([
        {"$match":
             {'$and': [
                     {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        #             {'USER_ID._id':{'$in':user}},
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

                     {'USER_ID.EMAIL_ID':{'$ne':''}},
    #              {'USER_ID.CREATED_DATE':{"$gte": myDatetime1 ,
    #                              "$lte":myDatetime2}},
    #     #                  
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
                {'$group':{'_id':'$USER_ID._id','subsdate':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$SUBSCRIPTION_EXPIRE_DATE'}}}}},
                      {'$project':{'_id':1,'Subscription_expire_date':'$subsdate'}},
                       ])))

        df5=pd.merge(df2,df3, how='right', on='_id')
        df=pd.merge(df5,df4, how='left', on='_id')
        df


        df['country'].fillna("NO INFO", inplace=True)
        df['user_name'].fillna("NO INFO", inplace=True)
        df['EMAIL'].fillna("NO INFO", inplace=True)
        df['school_name'].fillna("NO INFO", inplace=True)
        df['school_id'].fillna("NO INFO", inplace=True)
        df.Practice_Count=df.Practice_Count.fillna(0)
        df.Practice_Count=df.Practice_Count.astype('int64')

        df['school_name'].replace("",'NO INFO', inplace=True)
        df['city'].replace("",'NO INFO', inplace=True)
        df['State'].replace("",'NO INFO', inplace=True)
        df['country'].replace("",'NO INFO', inplace=True)
        df['user_name'].replace("",'NO INFO', inplace=True)
        df['city'].fillna("NO INFO", inplace=True)
        df['city'].replace("NULL","NO INFO", inplace=True)
        df['State'].fillna("NO INFO", inplace=True)
        df['State'].replace("NULL","NO INFO", inplace=True)



        df['Created_date']=df['Created_date'].fillna(0)
        df['last_practice_date']=df['last_practice_date'].fillna('NO PRACTICE')
        df['Subscription_expire_date']=df['Subscription_expire_date'].fillna('No Info')
        if "export" in request.args:
            try:
                df1=df[['user_name','EMAIL','school_name','country','State','city',
                         'Created_date','Practice_Count','last_practice_date']]
                 
                csv = df.to_csv(index=False)
                return Response(
                    csv,
                    mimetype="text/csv",
                    headers={"Content-disposition":
                            "attachment; filename=Data.csv"})
            except:
                return jsonify("Unauthorized Access")    
        else:

            data=[]
            for i,j,k,l,m,n,o,p,r,s in zip(df['user_name'].tolist(),df['EMAIL'].tolist(),df['school_name'].tolist(),df['country'].tolist(),df['State'].tolist(),df['city'].tolist(),df['Created_date'].tolist(),df['Practice_Count'].tolist(),df['last_practice_date'].tolist(),df['school_id'].tolist()):
                data.append([i,j,k,l,m,n,o,p,r,s])
            temp={"data":data}
            return json.dumps(temp,default=str)

# district_Date_table('5f2609807a1c0000950bb45d','2021-11-11')




@app.route('/districtcardsinfo/<districtid>/<startdate>/<enddate>')
def district_count_cards(districtid,startdate,enddate):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection1 = db.user_master
    collection2=db.audio_track_master
    collection3=db.login_logs
    collection4=db.school_master
    
    district=disdic[districtid]
    
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)


    df1_1 = DataFrame(list(collection1.aggregate([
    {"$match":
    {'$and': [
    {"IS_DISABLED":{"$ne":"Y"}},
    {"IS_BLOCKED":{"$ne":"Y"}},
    {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'EMAIL_ID':{'$ne':''}},
    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'$_id','ID':{'$addToSet':'$schoolId._id'},'dn':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},

    ])))

    schoolid=df1_1['ID'].tolist()

    userid=df1_1['_id'].tolist()

    df1 = DataFrame(list(collection1.aggregate([
    {"$match":
    {'$and': [
    {"IS_DISABLED":{"$ne":"Y"}},
    {"IS_BLOCKED":{"$ne":"Y"}},
    {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},{'EMAIL_ID':{'$ne':''}},

    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'','ID':{'$addToSet':'$schoolId._id'},'dn':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
    {'$project':{'_id':1,'school_count':{'$size':'$ID'},'district':'$dn'}}
    ])))


    df10 = DataFrame(list(collection4.aggregate([ {"$match":{"CATEGORY":{'$regex':district, '$options':'i'}}},
                          {'$group':{'_id':'$STATE','STATE':{'$first':'$STATE'},'CATEGORY':{'$max':'$CATEGORY'},'PARTNER_CATEGORY':{'$max':'$PARTNER_CATEGORY'},'count':{'$sum':1}}},

                           {'$sort':{'count':-1}},
                           {'$limit':1}                      
                           ])))  


    df1['district']=df1['district'].fillna(df10['CATEGORY']) 



    df2 = DataFrame(list(collection1.aggregate([ {"$match":
         {'$and': [
              {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'EMAIL_ID':{'$ne':''}},
                {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','ID':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':1,'teacher_count':{'$size':'$ID'}}}
                  ])))
    df5 = DataFrame(list(collection1.aggregate([ {"$match":
         {'$and': [
              {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},

                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','ID':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':1,'family_count':{'$size':'$ID'}}}
                  ])))

    today1= datetime.datetime.utcnow()
    tod1= today1+ timedelta(hours=4)
    start1= tod1-timedelta(days=30)

    df3=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
          {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'USER_ID.EMAIL_ID':{'$ne':''}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

                 {'MODIFIED_DATE':{'$gte':csy_first_date()}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
                  {'$project':{'_id':1,'engd_teacher_csy':{'$size':'$pc'}}}])))
    df33=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
          {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
                 {'MODIFIED_DATE':{'$gte':LSY_Date(),'$lt':csy_first_date()}},
    #             
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
                  {'$project':{'_id':1,'engd_teacher_lsy':{'$size':'$pc'}}}])))


    df333=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
          {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    {'MODIFIED_DATE':{'$gte':csy_first_date()}},
                {"_id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"_id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
                  {'$project':{'_id':1,'engd_parent_csy':{'$size':'$pc'}}}])))


    df3333=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
          {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},{"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

                {'MODIFIED_DATE':{'$gte':LSY_Date(),'$lt':csy_first_date()}},             
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
                  {'$project':{'_id':1,'engd_parent_lsy':{'$size':'$pc'}}}])))



    df4=DataFrame(list(db.audio_feedback.aggregate([{"$match":
         {'$and': [
    #
                  {"USER._id":{"$in":userid}},
               { 'RATING':{'$ne':0}}, 
    #
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

         ]}},
            {'$group':{'_id':'','rating':{'$avg':'$RATING'}}},
                  {'$project':{'_id':1,'rating':'$rating'}}])))
    df6=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions_t':'$pc','MINDFUL_MINUTES_t':'$MINDFUL_MINUTES'}}])))

    df7=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
             {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
    #                  {'MODIFIED_DATE':{'$gte':csy_first_date()}},
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions_p':'$pc','MINDFUL_MINUTES_p':'$MINDFUL_MINUTES'}}])))


    df77=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
    #              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
    #                  {'MODIFIED_DATE':{'$gte':csy_first_date()}},
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions':'$pc','MINDFUL_MINUTES':'$MINDFUL_MINUTES'}}])))


    df0=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
    # //          {'ROLE_ID._id' :{'$':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
                 {'MODIFIED_DATE':{'$gte':csy_first_date()}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID.schoolId._id'}}},
                  {'$project':{'_id':1,'engdschool_csy':{'$size':'$pc'}}}])))


    df00=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
                {'MODIFIED_DATE':{'$gte':LSY_Date(),'$lt':csy_first_date()}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID.schoolId._id'}}},
                  {'$project':{'_id':1,'engdschool_lsy':{'$size':'$pc'}}}])))


    df123=DataFrame(list(collection2.aggregate([
    {"$match":
    {'$and': [
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{'$ne':''}},
    {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    {'MODIFIED_DATE':{'$gte':csy_first_date()}},
    {"USER_ID._id":{"$in":db.schoology_master.distinct("USER_ID._id")}},
    {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct("USER_ID._id")}}},
    {"USER_ID._id":{'$not':{"$in":db.canvas_master.distinct("USER_ID._id")}}},

    {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
    {'$project':{'_id':1,'engd_schoology':{'$size':'$pc'}}}])))


    df321=DataFrame(list(collection2.aggregate([
    {"$match":
    {'$and': [
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{'$ne':''}},
    {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    {'MODIFIED_DATE':{'$gte':csy_first_date()}},
        {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
    {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct("USER_ID._id")}}},
    {"USER_ID._id":{'$not':{"$in":db.canvas_master.distinct("USER_ID._id")}}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
    {'$project':{'_id':1,'engd_clever':{'$size':'$pc'}}}])))

    df456=DataFrame(list(collection2.aggregate([
    {"$match":
    {'$and': [
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{'$ne':''}},
    {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    {'MODIFIED_DATE':{'$gte':csy_first_date()}},
    {"USER_ID._id":{"$in":db.canvas_user_master.distinct("USER_ID._id")}},
    {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct("USER_ID._id")}}},
    {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct("USER_ID._id")}}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
    {'$project':{'_id':1,'engd_canvas':{'$size':'$pc'}}}])))




    df123_lsy=DataFrame(list(collection2.aggregate([
    {"$match":
    {'$and': [
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{'$ne':''}},
    {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    {'MODIFIED_DATE':{'$gte':LSY_Date(),'$lt':csy_first_date()}},
        {"USER_ID._id":{"$in":db.schoology_master.distinct("USER_ID._id")}},
    {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct("USER_ID._id")}}},
    {"USER_ID._id":{'$not':{"$in":db.cannvas_master.distinct("USER_ID._id")}}},

    {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
    {'$project':{'_id':1,'engd_schoology':{'$size':'$pc'}}}])))


    df321_lsy=DataFrame(list(collection2.aggregate([
    {"$match":
    {'$and': [
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{'$ne':''}},
    {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    {'MODIFIED_DATE':{'$gte':LSY_Date(),'$lt':csy_first_date()}},
    {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
    {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct("USER_ID._id")}}},
    {"USER_ID._id":{'$not':{"$in":db.canvas_master.distinct("USER_ID._id")}}},

    {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
    {'$project':{'_id':1,'engd_clever':{'$size':'$pc'}}}])))


    df456_lsy=DataFrame(list(collection2.aggregate([
    {"$match":
    {'$and': [
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{'$ne':''}},
    {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    {'MODIFIED_DATE':{'$gte':LSY_Date(),'$lt':csy_first_date()}},
    {"USER_ID._id":{"$in":db.canvas_user_master.distinct("USER_ID._id")}},
    {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct("USER_ID._id")}}},
    {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct("USER_ID._id")}}},

    {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
    {'$project':{'_id':1,'engd_canvas':{'$size':'$pc'}}}])))


    df6_schoology_practice=DataFrame(list(collection2.aggregate([
    {"$match":
    {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{'$ne':''}},
    {"USER_ID.schoolId._id":{"$in":db.school_master.distinct("_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

    {"USER_ID._id":{"$in":db.schoology_master.distinct("USER_ID._id")}},
    {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct("USER_ID._id")}}},
    {"USER_ID._id":{'$not':{"$in":db.canvas_master.distinct("USER_ID._id")}}},

    {'MODIFIED_DATE':{"$gte": myDatetime1 ,
    "$lte":myDatetime2}},

    {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
    {'$project':{'_id':1,'practice_sessions_t':'$pc','MINDFUL_MINUTES_t':'$MINDFUL_MINUTES'}}])))


    df6_clever_practice=DataFrame(list(collection2.aggregate([
    {"$match":
    {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{'$ne':''}},
    {"USER_ID.schoolId._id":{"$in":db.school_master.distinct("_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

    {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
    {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct("USER_ID._id")}}},
    {"USER_ID._id":{'$not':{"$in":db.canvas_master.distinct("USER_ID._id")}}},

    {'MODIFIED_DATE':{"$gte": myDatetime1 ,
    "$lte":myDatetime2}},

    {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
    {'$project':{'_id':1,'practice_sessions_t':'$pc','MINDFUL_MINUTES_t':'$MINDFUL_MINUTES'}}])))



    df6_canvas_practice=DataFrame(list(collection2.aggregate([
    {"$match":
    {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{'$ne':''}},
    {"USER_ID.schoolId._id":{"$in":db.school_master.distinct("_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

    {"USER_ID._id":{"$in":db.canvas_master.distinct("USER_ID._id")}},
    {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct("USER_ID._id")}}},
    {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct("USER_ID._id")}}},

    {'MODIFIED_DATE':{"$gte": myDatetime1 ,
    "$lte":myDatetime2}},

    {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
    {'$project':{'_id':1,'practice_sessions_t':'$pc','MINDFUL_MINUTES_t':'$MINDFUL_MINUTES'}}])))



    engd_parent_lsy=[0]
    try:
        engd_parent_lsy=df3333['engd_parent_lsy']
    except:
        engd_parent_lsy=[0]

    engd_parent_csy=[0]
    try:
        engd_parent_csy=df333['engd_parent_csy']
    except:
        engd_parent_csy=[0]

    engd_teacher_csy=[0]
    try:
        engd_teacher_csy=df3['engd_teacher_csy']
    except:
        engd_teacher_csy=[0]

    engd_teacher_lsy=[0]
    try:
        engd_teacher_lsy=df33['engd_teacher_lsy']
    except:
        engd_teacher_lsy=[0]

    engdschool_lsy=[0]
    try:
        engdschool_lsy=df00['engdschool_lsy']
    except:
        engdschool_lsy=[0]

    rating=[0]
    try:
        rating=df4['rating']
    except:
        rating=[0]

    engdschool_csy=[0]
    try:
        engdschool_csy=df0['engdschool_csy']
    except:
        engdschool_csy=[0]
    sc=[0]
    try:
        sc=df1['school_count']
    except:
        sc=[0]

    tc=[0]
    try:
        tc=df2['teacher_count']
    except:
        tc=[0]

    pct=[0]
    try:
        pct=df6['practice_sessions_t']
    except:
        pct=[0]
    pcp=[0]
    try:
        pcp=df7['practice_sessions_p']
    except:
        pcp=[0]

    mmt=[0]
    try:
        mmt=df6['MINDFUL_MINUTES_t']
    except:
        mmt=[0]
    mmp=[0]
    try:
        mmp=df7['MINDFUL_MINUTES_p']
    except:
        mmp=[0]     


    mm=[0]
    try:
        mm=df77['MINDFUL_MINUTES']
    except:
        mm=[0]
    pc=[0]
    try:
        pc=df77['practice_sessions']
    except:
        pc=[0]

    lc=[0]
    try:
        lc=df4['logins']
    except:
        lc=[0]

    fc=[0]
    try:
        fc=df5['family_count']
    except:
        fc=[0]

    dn=[0]
    try:
        dn=df1['district']
    except:
        dn=[0]


    ca=[0]
    try:
        ca=df10['CATEGORY']
    except:
        ca=[0]

    Pa=[0]
    try:
        Pa=df10['PARTNER_CATEGORY']
    except:
        Pa=[0] 
    state=[0]
    try:
        state=df10['STATE']
    except:
        state=[0]

    schoology_eng_csy=[0]
    try:
        schoology_eng_csy=df123['engd_schoology']
    except:
        schoology_eng_csy=[0]

    clever_eng_csy=[0]
    try:
        clever_eng_csy=df321['engd_clever']
    except:
        clever_eng_csy=[0]

    canvas_eng_csy=[0]
    try:
        canvas_eng_csy=df456['engd_canvas']
    except:
        canvas_eng_csy=[0]  



    schoology_eng_lsy=[0]
    try:
        schoology_eng_lsy=df123_lsy['engd_schoology']
    except:
        schoology_eng_lsy=[0]

    clever_eng_lsy=[0]
    try:
        clever_eng_lsy=df321_lsy['engd_clever']
    except:
        clever_eng_lsy=[0]

    canvas_eng_lsy=[0]
    try:
        canvas_eng_lsy=df456_lsy['engd_canvas']
    except:
        canvas_eng_lsy=[0]  


    schoology_practice=[0]
    try:
        schoology_practice=df6_schoology_practice['practice_sessions_t']
    except:
        schoology_practice=[0]

    clever_practice=[0]
    try:
        schoology_practice=df6_clever_practice['practice_sessions_t']
    except:
        schoology_practice=[0]   

    canvas_practice=[0]
    try:
        canvas_practice=df6_canvas_practice['practice_sessions_t']
    except:
        canvas_practice=[0]    



    mmt_schoology=[0]
    try:
        mmt_schoology=df6_schoology_practice['MINDFUL_MINUTES_t']
    except:
        mmt_schoology=[0]

    mmt_clever=[0]
    try:
        mmt_clever=df6_clever_practice['MINDFUL_MINUTES_t']
    except:
        mmt_clever=[0]  


    mmt_canvas=[0]
    try:
        mmt_canvas=df6_canvas_practice['MINDFUL_MINUTES_t']
    except:
        mmt_canvas=[0]  


    data={"schoolcount":str(sc[0]),"engd_teacher_lsy":str(engd_teacher_lsy[0]),"engd_teacher_csy":str(engd_teacher_csy[0]),
          "engd_parent_csy":str(engd_parent_csy[0]),"engd_parent_lsy":str(engd_parent_lsy[0]),
          "schoology_eng_csy":str(schoology_eng_csy[0]), "clever_eng_csy":str(clever_eng_csy[0]),
          "canvas_eng_csy":str(canvas_eng_csy[0]),
          "schoology_eng_lsy":str(schoology_eng_lsy[0]), "clever_eng_lsy":str(clever_eng_lsy[0]),
          "canvas_eng_lsy":str(canvas_eng_lsy[0]),
          "schoology_playback":str(schoology_practice[0]), "clever_practice":str(clever_practice[0]),
          "canvas_practice":str(canvas_practice[0]),
          "Schoology_mindful":str(round(int(mmt_schoology[0]))), "clever_mindful":str(round(int(mmt_clever[0]))),
          "canvas_mindful": str(round(int(mmt_canvas[0]))),

          "engaged_school_csy":str(engdschool_csy[0]),"engaged_school_lsy":str(engdschool_lsy[0]),"teachercount":str(tc[0]),"familycount":str(fc[0]),"teacherpracticecount":str(pct[0]),"parentspracticecount":str(pcp[0]),
          'MINDFUL_MINUTES':str(round(int(mm[0]))),'rating':str(round(rating[0],1)),'state':str(state[0]),'MINDFUL_MINUTES_Teacher':str(round(int(mmt[0]))),'MINDFUL_MINUTES_parent':str(round(int(mmp[0]))),'district':str(dn[0]),"practicecount":str(pc[0]),'category':str(ca[0]),'partnercategory':str(Pa[0])}

    return json.dumps(data)

      
      
@app.route('/districtusertableteacher/<districtid>/<startdate>/<enddate>')
def district_user_table_teacher(districtid,startdate,enddate):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 

    
    collection2=db.school_master
    collection=db.user_master
    collection1=db.audio_track_master
    collection3=db.subscription_master
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

    from datetime import datetime


    

    df2=DataFrame(list(collection.aggregate([{"$match":
         {'$and': [
            {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                 {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},
              {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$_id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'school_id':{'$first':'$schoolId._id'},'user_name':{'$first':'$USER_NAME'},'EMAIL':{'$first':'$EMAIL_ID'},'date':{'$first':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
                      'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},


            {'$project':{'_id':1,'Created_date':'$date','country':1,'State':1,'user_name':1,'EMAIL':1,'school_name':1,'city':1,'school_id':'$school_id'}},])))


    a=df2['_id'].tolist()
    b=[0]*len(a)
    c=['No Practice']*len(a)
    
    
    df3=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'user_id':'$user','Practice_Count':'$pc','last_practice_date':1}}])))

    if df3.empty is True:
        df3=pd.DataFrame(list(zip(a, b,c)),
               columns =['_id', 'Practice_Count','last_practice_date'])
    else:
        df3
    df_=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
             {'MODIFIED_DATE':{"$gte": csy_first_date() ,
                             }},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'Practice_Count_csy':'$pc'}}])))
    if df_.empty is True:
        df_=pd.DataFrame(list(zip(a, b)),
               columns =['_id', 'Practice_Count_csy'])
    else:
        df_

    df__=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
            {'MODIFIED_DATE':{"$gte": LSY_Date() ,
                               "$lte": csy_first_date()
                             }},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'Practice_Count_lsy':'$pc',}}])))
    if df__.empty is True:
        df__=pd.DataFrame(list(zip(a, b)),
               columns =['_id', 'Practice_Count_lsy'])
    else:
        df__




#     df4 = DataFrame(list(collection3.aggregate([
#     {"$match":
#          {'$and': [
#                  {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#                 {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#                   {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#                  {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     #             {'USER_ID._id':{'$in':user}},
#             {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

#                  {'USER_ID.EMAIL_ID':{'$ne':''}},
# #              {'USER_ID.CREATED_DATE':{"$gte": myDatetime1 ,
# #                              "$lte":myDatetime2}},
# #     #                  
#                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                              {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
#             {'$group':{'_id':'$USER_ID._id','subsdate':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$SUBSCRIPTION_EXPIRE_DATE'}}}}},
#                   {'$project':{'_id':1,'Subscription_expire_date':'$subsdate'}},
#                    ])))

    df5=pd.merge(df2,df3, how='left', on='_id')
    dff=pd.merge(df5,df_, how='left', on='_id')
    df=pd.merge(dff,df__, how='left', on='_id')
#     df=pd.merge(df5,df4, how='left', on='_id')
    df


    df['country'].fillna("NO INFO", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
    df.Practice_Count_lsy=df.Practice_Count_lsy.fillna(0)
    df.Practice_Count_csy=df.Practice_Count_csy.fillna(0)
#     df.Practice_Count=df.Practice_Count.astype('int64')
    df.Practice_Count_csy=df.Practice_Count_csy.astype('int64')
    df.Practice_Count_lsy=df.Practice_Count_lsy.astype('int64')

    df['school_name'].replace("",'NO INFO', inplace=True)
    df['city'].replace("",'NO INFO', inplace=True)
    df['State'].replace("",'NO INFO', inplace=True)
    df['country'].replace("",'NO INFO', inplace=True)
    df['user_name'].replace("",'NO INFO', inplace=True)
    df['EMAIL'].replace("",'NO INFO', inplace=True)
    df['city'].fillna("NO INFO", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['State'].fillna("NO INFO", inplace=True)
    df['State'].replace("NULL","NO INFO", inplace=True)



    df['Created_date']=df['Created_date'].fillna(0)
    df['last_practice_date']=df['last_practice_date'].fillna('NO PRACTICE')
    df['label'] = np.where(df['Practice_Count_csy']!= 0, 'ENGAGED IN CSY', 'ENGAGED IN LSY')
    df.loc[(df['Practice_Count_lsy']==0) & (df['Practice_Count_csy']== 0), 'label']='INACTIVE'
#     df['Subscription_expire_date']=df['Subscription_expire_date'].fillna('No Info')
    if "export" in request.args:
        try:
            df1=df[['user_name','EMAIL','school_name','country','State','city','Practice_Count',
                    'Practice_Count_csy','Practice_Count_lsy',
                    'Created_date','last_practice_date','label']]
            csv = df1.to_csv(index=False)
            return Response(
                csv,
                mimetype="text/csv",
                headers={"Content-disposition":
                        "attachment; filename=TeacherData.csv"})
        except:
            return jsonify("Unauthorized Access")  
    else:

        data=[]
        for i,j,k,l,m,n,o,p,r,q,s,x,z in zip(df['user_name'].tolist(),df['EMAIL'].tolist(),df['school_name'].tolist(),df['country'].tolist(),
                                             df['State'].tolist(),df['city'].tolist(),df['Practice_Count'].tolist(),df['Practice_Count_csy'].tolist(),
                                             df['Practice_Count_lsy'].tolist(),df['Created_date'].tolist(),df['last_practice_date'].tolist(),
                                             df['school_id'].tolist(),df['label'].tolist()):
            data.append([i,j,k,l,m,n,o,p,r,q,s,x,z])
        temp={"data":data}
    #     return df
        return json.dumps(temp,default=str)
# district_user_table_teacher('5f2609807a1c0000950bb45d','2021-08-01','2021-11-10')



@app.route('/districtusertableparent/<districtid>/<startdate>/<enddate>')
def district_user_table_parent(districtid,startdate,enddate):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 

    
    collection2=db.school_master
    collection=db.user_master
    collection1=db.audio_track_master
    collection3=db.subscription_master
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

    from datetime import datetime


    

    df2=DataFrame(list(collection.aggregate([{"$match":
         {'$and': [
            {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                 {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},
              {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$_id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'school_id':{'$first':'$schoolId._id'},'user_name':{'$first':'$USER_NAME'},'EMAIL':{'$first':'$EMAIL_ID'},'date':{'$first':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
                      'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},


            {'$project':{'_id':1,'Created_date':'$date','country':1,'State':1,'user_name':1,'EMAIL':1,'school_name':1,'city':1,'school_id':'$school_id'}},])))

    a=df2['_id'].tolist()
    b=[0]*len(a)
    c=['No Practice']*len(a)
    
    
    df3=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'user_id':'$user','Practice_Count':'$pc','last_practice_date':1}}])))
    if df3.empty is True:
        df3=pd.DataFrame(list(zip(a, b,c)),
               columns =['_id', 'Practice_Count','last_practice_date'])
    else:
        df3

    df_=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
             {'MODIFIED_DATE':{"$gte": csy_first_date() ,
                             }},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'Practice_Count_csy':'$pc'}}])))
    if df_.empty is True:
        df_=pd.DataFrame(list(zip(a, b)),
               columns =['_id', 'Practice_Count_csy'])
    else:
        df_

    df__=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
             {'MODIFIED_DATE':{"$gte": LSY_Date() ,
                               "$lte": csy_first_date()
                             }},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'Practice_Count_lsy':'$pc',}}])))

    if df__.empty is True:
        df__=pd.DataFrame(list(zip(a, b)),
               columns =['_id', 'Practice_Count_lsy'])
    else:
        df__



#     df4 = DataFrame(list(collection3.aggregate([
#     {"$match":
#          {'$and': [
#                  {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#                 {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#                   {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#                  {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     #             {'USER_ID._id':{'$in':user}},
#             {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

#                  {'USER_ID.EMAIL_ID':{'$ne':''}},
# #              {'USER_ID.CREATED_DATE':{"$gte": myDatetime1 ,
# #                              "$lte":myDatetime2}},
# #     #                  
#                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                              {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
#             {'$group':{'_id':'$USER_ID._id','subsdate':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$SUBSCRIPTION_EXPIRE_DATE'}}}}},
#                   {'$project':{'_id':1,'Subscription_expire_date':'$subsdate'}},
#                    ])))

    df5=pd.merge(df2,df3, how='left', on='_id')
    dff=pd.merge(df5,df_, how='left', on='_id')
    df=pd.merge(dff,df__, how='left', on='_id')
#     df=pd.merge(df5,df4, how='left', on='_id')
    df


    df['country'].fillna("NO INFO", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
    df.Practice_Count_lsy=df.Practice_Count_lsy.fillna(0)
    df.Practice_Count_csy=df.Practice_Count_csy.fillna(0)
#     df.Practice_Count=df.Practice_Count.astype('int64')
    df.Practice_Count_csy=df.Practice_Count_csy.astype('int64')
    df.Practice_Count_lsy=df.Practice_Count_lsy.astype('int64')

    df['school_name'].replace("",'NO INFO', inplace=True)
    df['city'].replace("",'NO INFO', inplace=True)
    df['State'].replace("",'NO INFO', inplace=True)
    df['country'].replace("",'NO INFO', inplace=True)
    df['user_name'].replace("",'NO INFO', inplace=True)
    df['EMAIL'].replace("",'NO INFO', inplace=True)
    df['city'].fillna("NO INFO", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['State'].fillna("NO INFO", inplace=True)
    df['State'].replace("NULL","NO INFO", inplace=True)



    df['Created_date']=df['Created_date'].fillna(0)
    df['last_practice_date']=df['last_practice_date'].fillna('NO PRACTICE')
    df['label'] = np.where(df['Practice_Count_csy']!= 0, 'ENGAGED IN CSY', 'ENGAGED IN LSY')
    df.loc[(df['Practice_Count_lsy']==0) & (df['Practice_Count_csy']== 0), 'label']='INACTIVE'
#     df['Subscription_expire_date']=df['Subscription_expire_date'].fillna('No Info')

    if "export" in request.args:
        try:
            df1=df[['user_name','EMAIL','school_name','country','State','city','Practice_Count',
                    'Practice_Count_csy','Practice_Count_lsy',
                    'Created_date','last_practice_date','label']]
            csv = df1.to_csv(index=False)
            return Response(
                csv,
                mimetype="text/csv",
                headers={"Content-disposition":
                        "attachment; filename=ParentData.csv"})
        except:
            return jsonify("Unauthorized Access")    
    else:
        data=[]
        for i,j,k,l,m,n,o,p,r,q,s,x,z in zip(df['user_name'].tolist(),df['EMAIL'].tolist(),df['school_name'].tolist(),df['country'].tolist(),
                                             df['State'].tolist(),df['city'].tolist(),df['Practice_Count'].tolist(),df['Practice_Count_csy'].tolist(),
                                             df['Practice_Count_lsy'].tolist(),df['Created_date'].tolist(),df['last_practice_date'].tolist(),
                                             df['school_id'].tolist(),df['label'].tolist()):
            data.append([i,j,k,l,m,n,o,p,r,q,s,x,z])
        temp={"data":data}
    #     return df
        return json.dumps(temp,default=str)

# district_user_table_teacher('5f2609807a1c0000950bb45d','2021-08-01','2021-11-10')

# district_user_table_teacher('5f2609807a1c0000950bb477','2015-04-01','2021-04-13')
    
    
    
    
@app.route('/districtschooltable/<districtid>/<startdate>/<enddate>')
def district_school_table(districtid,startdate,enddate):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    from flask import request
    collection2=db.school_master
    collection=db.user_master
    collection1=db.audio_track_master
    collection3=db.subscription_master
    district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
    

    df2=DataFrame(list(collection.aggregate([{"$match":
         {'$and': [
#         {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},


    # //               {'IS_ADMIN':'Y'},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},

                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'date':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
                      'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},



            {'$project':{'_id':1,'usercount':{'$size':'$ID'},'Created_date':'$date','country':1,'State':1,'school_name':1,'city':1}},



  
                                            ])))

    ids=df2['_id'].tolist()


    df3 = DataFrame(list(collection1.aggregate([
    {"$match":
         {'$and': [
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

    # //        
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    #                  
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','ID':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},'prog':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}}},
                  {'$project':{'_id':1,'Practice_Count':'$ID','program':1,'last_practice_date':'$last_practice_date'}},
                   ]))).fillna(0)
    if df3.empty==True:
        df3=pd.DataFrame({'_id':ids})
        df3['last_practice_date'] = pd.Series(['NO PRACTICE' for x in range(len(df3.index))])
        df3['Practice_Count'] = pd.Series([0 for x in range(len(df3.index))])
#         df3['Mindful_Minutes_overall'] = pd.Series([0 for x in range(len(df0.index))])
    column3 =['_id','last_practice_date']
    for i in column3:
        df3=df3.fillna('')
        if i not in df3.columns:
            df3[i] = 'No info' 
    df_ = DataFrame(list(collection1.aggregate([
    {"$match":
         {'$and': [
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

    # //        
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'MODIFIED_DATE':{"$gte": csy_first_date(),
                              }},
    #                  
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','ID':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},'prog':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}}},
                  {'$project':{'_id':1,'Practice_Count_csy':'$ID'}},
                   ]))).fillna(0)
    if df_.empty==True:
        df_=pd.DataFrame({'_id':ids})
#         df_['last_practice_date'] = pd.Series(['NO PRACTICE' for x in range(len(df_.index))])
        df_['Practice_Count_csy'] = pd.Series([0 for x in range(len(df_.index))])
#         df3['Mindful_Minutes_overall'] = pd.Series([0 for x in range(len(df0.index))])
#     column_ =['_id','Practice_Count_csy']
#     for i in column_:
#         df_=df_.fillna('')
#         if i not in df_.columns:
#             df_[i] = 'No info' 
    df__ = DataFrame(list(collection1.aggregate([
    {"$match":
         {'$and': [
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

    # //        
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'MODIFIED_DATE':{"$gte": LSY_Date() ,
                               "$lte": csy_first_date()
                             }},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','ID':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},'prog':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}}},
                  {'$project':{'_id':1,'Practice_Count_lsy':'$ID'}},
                   ])))
    if df__.empty==True:
        df__=pd.DataFrame({'_id':ids})
#         df_['last_practice_date'] = pd.Series(['NO PRACTICE' for x in range(len(df_.index))])
        df__['Practice_Count_lsy'] = pd.Series([0 for x in range(len(df__.index))])
#         df3['Mindful_Minutes_overall'] = pd.Series([0 for x in range(len(df0.index))])
#     column__ =['_id','Practice_Count_lsy']
#     for i in column_:
#         df__=df__.fillna('')
#         if i not in df__.columns:
#             df__[i] = 'No info' 
    df4 = DataFrame(list(collection3.aggregate([
    {"$match":
         {'$and': [
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
             {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
  
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#              {'USER_ID.CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
    #                  
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','subsdate':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$SUBSCRIPTION_EXPIRE_DATE'}}}}},
                  {'$project':{'_id':1,'program':1,'Subscription_expire_date':'$subsdate'}},
                   ])))
    

    df5=pd.merge(df2,df3, how='left', on='_id')
    dff=pd.merge(df5,df_, how='left', on='_id')
    dfff=pd.merge(dff,df__, how='left', on='_id')
    df=pd.merge(dfff,df4, how='left', on='_id')
#     df=pd.merge(df6,df4, how='left', on='_id')
    df.rename(columns = { '_id': 'schoolid_'}, inplace = True)
    
    
#     df[["schoolid_", "schoolid"]]=df[["schoolid_", "schoolid"]].astype(str) 

    # df4.fillna(0)
#     print(df)
    df['school_name'].fillna("NO INFO", inplace=True)
    df['country'].fillna("NO INFO", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count_lsy=df.Practice_Count_lsy.fillna(0)
    df.Practice_Count_csy=df.Practice_Count_csy.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
    df.Practice_Count_csy=df.Practice_Count_csy.astype('int64')
    df.Practice_Count_lsy=df.Practice_Count_lsy.astype('int64')
    df.usercount=df.usercount.fillna(0)
    df.usercount=df.usercount.astype('int64')   
    df['school_name'].replace("",'NO INFO', inplace=True)
    df['city'].replace("",'NO INFO', inplace=True)
    df['State'].replace("",'NO INFO', inplace=True)
    df['country'].replace("",'NO INFO', inplace=True)
    
    df['city'].fillna("NO INFO", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['State'].fillna("NO INFO", inplace=True)
    df['State'].replace("NULL","NO INFO", inplace=True)
   
    df['Created_date']=df['Created_date'].fillna(0)
    df['last_practice_date']=df['last_practice_date'].fillna('NO PRACTICE')
    df['Subscription_expire_date']=df['Subscription_expire_date'].fillna('No Info')
    df['label'] = np.where(df['Practice_Count_csy']!= 0, 'ENGAGED IN CSY', 'ENGAGED IN LSY')
    df.loc[(df['Practice_Count_lsy']==0) & (df['Practice_Count_csy']== 0), 'label']='INACTIVE'
    if "export" in request.args:
        try:
            df1=df[['school_name','country','State','city','Practice_Count',
                    'Practice_Count_csy','Practice_Count_lsy','usercount',
                    'Created_date','last_practice_date','Subscription_expire_date','label']]
            csv = df1.to_csv(index=False)
            return Response(
                csv,
                mimetype="text/csv",
                headers={"Content-disposition":
                        "attachment; filename=SchoolData.csv"})
        except:
            return jsonify("Unauthorized Access")   
    else:
        data=[]
        for i,j,k,l,m,n,o,p,r,s,q,x,z in zip(df['school_name'].tolist(),df['country'].tolist(),df['State'].tolist(),df['city'].tolist(),df['Practice_Count'].tolist(),df['Practice_Count_csy'].tolist(),df['Practice_Count_lsy'].tolist(),df['usercount'].tolist(),df['Created_date'].tolist(),df['last_practice_date'].tolist(),df['Subscription_expire_date'].tolist(),df['schoolid_'].tolist(),df['label'].tolist()):
            data.append([i,j,k,l,m,n,o,p,r,s,q,x,z])
        temp={"data":data}
    #     return df
        
        return json.dumps(temp,default=str)


    
# district_school_table('619268dd81f00a4319a65a52','2021-08-01','2021-11-10')




@app.route('/schoolsummaryplan/<pn>')
def schsummaryplan_table(pn):
    reader = geolite2.reader()
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection1= db.user_master
    query1=[
    {"$match":
     {'$and': [
             {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
          {'IS_ADMIN':'Y'},
         {'schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'NAME':{'$first':'$schoolId.NAME'},'IS_ADMIN':{'$first':'IS_ADMIN'},
       'user_name':{'$first':'$USER_NAME'},'EMAIL_ID':{'$first':'$EMAIL_ID'},
        'country':{'$first':'$schoolId.COUNTRY'},'city':{'$first':'$schoolId.CITY'},'state':{'$first':'$schoolId.STATE'},'ip_address':{'$first':'$IP_ADDRESS'},'phn':{'$first':
        '$CONTACT_NUMBER'}
             }},
              {'$project':{'_id':1,'school_id':'$ID','name':'$NAME',
                          'admin':'$IS_ADMIN','ip_address':'$ip_address','phonenubmer':'$phn',
                  'USER_NAME':'$user_name','EMAIL':'$EMAIL_ID',
                  'state':'$state','city':'$city','country':'$country'}},]
    
    
    
    collection1= db.user_master
    query4=[
    {"$match":
     {'$and': [
     {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
          {'IS_ADMIN':'Y'},
         {'schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},
       'uc':{'$addToSet':'$_id'}
             }},
              {'$project':{'_id':1,'school_id':'$ID','user_count':{'$size':'$uc'}
                         }},]
    
    
    
    collection2= db.audio_track_master
    query2=[
    {"$match":
    {"$and":[ 
     {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'$USER_ID.schoolId._id','pc':{'$sum':1},'date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }}},
               'pg':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}}},
    {'$project':{'_id':1,'Practice_Count':'$pc','Last_Practice_Date':'$date','program_name':'$pg'}}]
    
    collection3= db.subscription_master
    query3=[ {"$match":
    {"$and":[
     {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
          {'USER_ID.IS_ADMIN':'Y'},
        {'PLAN_ID.PLAN_ID':{'$ne':None}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
        ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id','date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_EXPIRE_DATE" }}},
              'pn':{'$first' :'$PLAN_ID.PLAN_NAME'},'DS_SM_COMMENTS':{'$max':'$DS_SM_COMMENTS'}}},
    {'$project':{'_id':1,'SUBSCRIPTION_EXPIRE_DATE':'$date','DS_SM_COMMENTS':'$DS_SM_COMMENTS','plan_name':'$pn'}}]
    list1=list(collection1.aggregate(query1))
    df_1=DataFrame(list1)
    list4=list(collection1.aggregate(query4))
    df_4=DataFrame(list4)
    list2=list(collection2.aggregate(query2))
    df_2=DataFrame(list2)
    list3=list(collection3.aggregate(query3))
    df_3=DataFrame(list3)
    # df_1['school_name'].fillna("NO SCHOOL FOUND", inplace=True)
    # df_3['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    # df_1['COUNTRY'].fillna("NO COUNTRY FOUND", inplace=True)
    # df_1['STATE'].fillna("NO STATE FOUND", inplace=True)
#     df_1['city'].fillna("NO CITY FOUND", inplace=True)
    # df_1['ADDRESS'].fillna("NO ADDRESS FOUND", inplace=True)
    df1= pd.merge(df_1, df_4,how='left', on='_id')
    df2= pd.merge(df1, df_2,how='left', on='_id')
    df= pd.merge(df2, df_3,how='left', on='_id')
#     df['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    df['name'].fillna("NO NAME", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
    df['Last_Practice_Date']=pd.to_datetime(df['Last_Practice_Date'])
    df['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    df['EMAIL'].fillna("EMAIL_ID NOT AVAILABLE", inplace=True)
    df['EMAIL'].replace("",'EMAIL_ID NOT AVAILABLE', inplace=True)
    df['USER_NAME'].replace("",'USER NAME NOT AVAILABLE', inplace=True)
    df['city'].fillna("INFO AVAILABLE", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['state'].fillna("NO STATE INFO AVAILABLE", inplace=True)
    df['state'].replace("NULL","NO INFO", inplace=True)
    df['SUBSCRIPTION_EXPIRE_DATE']=pd.to_datetime(df['SUBSCRIPTION_EXPIRE_DATE'])
    df= df.groupby(df['plan_name'])
    df= df.get_group(''+pn+'')
#     # print(df)
    def country1(i):
        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    pn=df['plan_name'].tolist()
    schname=df['name'].tolist()
    ip=df['ip_address'].tolist()
    user_count=df['user_count'].tolist()
    city=df['city'].tolist()
    ADMIN_NAME=df['USER_NAME'].tolist()
    ADMIN_EMAIL=df.EMAIL.tolist()
    state=df['state'].tolist()
    country=df['country'].tolist()
    SUBSCRIPTION_EXPIRE_DATE=df['SUBSCRIPTION_EXPIRE_DATE'].tolist()
    last_prac_date=df['Last_Practice_Date'].tolist()
    practice_count=df['Practice_Count'].tolist()
#     IS_ADMIN=df['IS_ADMIN'].tolist()
    for i in range(len(ip)):
        if city[i] is None:
            try:
                city[i]=city1(ip[i])
            except:
                pass
        if country[i] is None:
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if state[i] is None:
            try:
                state[i]=state1(ip[i])
            except:
                pass
        if country[i] is None:
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] is None:
            country[i]=''
        if state[i] is None:
            state[i]=''
        if  last_prac_date[i] != "NO PRACTICE":
            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:
            last_prac_date[i]="NO PRACTICE"
        if SUBSCRIPTION_EXPIRE_DATE[i] is not None:
            SUBSCRIPTION_EXPIRE_DATE[i]=SUBSCRIPTION_EXPIRE_DATE[i].strftime('%d %b %Y')
    data=[]    
    for i,k,l,o,p,q,s,z,y in zip(schname,ADMIN_NAME,ADMIN_EMAIL,
                               city,state,country,SUBSCRIPTION_EXPIRE_DATE,
                             last_prac_date,practice_count):
        data.append([i,k,l,o,p,q,s,z,y])
    return json.dumps({"data":data})

#sarthak_sadhna_end
#sarthak_chhavika

# test
@app.route('/last_day_pr')
def pract_cards_24hr():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master
    # datetime.datetime.now() - datetime.timedelta(days=7)
    # ar d = new Date();
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today+ timedelta(hours=4)
    start= tod-timedelta(days=1)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': yester, '$lte':tod
    }},
    ]}},

    {'$group':{'_id':'null', 

    'parents_playback_24hr': {'$sum':{'$cond':[{'$eq':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_24hr': {'$sum':{'$cond':[{'$ne':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_24hr': {'$sum':1}            
    }}]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    df_atm1[['parents_playback_24hr', 'teachers_playback_24hr','total_playback_24hr']]




    qr2=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start_15day
                , '$lte': startend
    }},
    ]}},

    {'$group':{'_id':'null', 

    'parents_playback_48hrs': {'$sum':{'$cond':[{'$eq':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_48hrs': {'$sum':{'$cond':[{'$ne':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_48hrs': {'$sum':1}            
    }}]

    list2= list(collection1.aggregate(qr2))
    df_atm2= DataFrame(list2)
    df_atm2[['parents_playback_48hrs', 'teachers_playback_48hrs','total_playback_48hrs']]




    PARENTSCHANGE=[]
    PARENT_percentagechange=[]
    if df_atm2['parents_playback_48hrs'].iloc[0] > df_atm1['parents_playback_24hr'].iloc[0]:
        xx=df_atm2['parents_playback_48hrs'].iloc[0]-df_atm1['parents_playback_24hr'].iloc[0]
        yy= xx/df_atm2['parents_playback_48hrs'].iloc[0]
        zz= round(yy*100,2)
        PARENTSCHANGE.append('-1')
        PARENT_percentagechange.append(zz)

    elif df_atm2['parents_playback_48hrs'].iloc[0] == df_atm1['parents_playback_24hr'].iloc[0]:
        xx=df_atm2['parents_playback_48hrs'].iloc[0]-df_atm1['parents_playback_24hr'].iloc[0]
        yy= xx/df_atm2['parents_playback_48hrs'].iloc[0]
        zz= round(yy*100,2)
        PARENTSCHANGE.append('0')
        PARENT_percentagechange.append(zz)

    else:
        xx=df_atm1['parents_playback_24hr'].iloc[0]-df_atm2['parents_playback_48hrs'].iloc[0]
        yy= xx/df_atm1['parents_playback_24hr'].iloc[0]
        zz= round(yy*100,2)
        PARENTSCHANGE.append('1')
        PARENT_percentagechange.append(zz)



    TEACHERSCHANGE=[]
    TEACHER_percentagechange=[]
    if df_atm2['teachers_playback_48hrs'].iloc[0] > df_atm1['teachers_playback_24hr'].iloc[0]:
        xx=df_atm2['teachers_playback_48hrs'].iloc[0]-df_atm1['teachers_playback_24hr'].iloc[0]
        yy= xx/df_atm2['teachers_playback_48hrs'].iloc[0]
        zz= round(yy*100,2)
        TEACHERSCHANGE.append('-1')
        TEACHER_percentagechange.append(zz)

    elif df_atm2['teachers_playback_48hrs'].iloc[0] == df_atm1['teachers_playback_24hr'].iloc[0]:
        xx=df_atm2['teachers_playback_48hrs'].iloc[0]-df_atm1['teachers_playback_24hr'].iloc[0]
        yy= xx/df_atm2['teachers_playback_48hrs'].iloc[0]
        zz= round(yy*100,2)
        TEACHERSCHANGE.append('0')
        TEACHER_percentagechange.append(zz)


    else:
        xx=df_atm1['teachers_playback_24hr'].iloc[0]-df_atm2['teachers_playback_48hrs'].iloc[0]
        yy= xx/df_atm1['teachers_playback_24hr'].iloc[0]
        zz= round(yy*100,2)
        TEACHERSCHANGE.append('1')
        TEACHER_percentagechange.append(zz)


    TOTALCHANGE=[]
    TOTAL_percentagechange=[]
    if df_atm2['total_playback_48hrs'].iloc[0] > df_atm1['total_playback_24hr'].iloc[0]:
        xx=df_atm2['total_playback_48hrs'].iloc[0]-df_atm1['total_playback_24hr'].iloc[0]
        yy= xx/df_atm2['total_playback_48hrs'].iloc[0]
        zz= round(yy*100,2)
        TOTALCHANGE.append('-1')
        TOTAL_percentagechange.append(zz)


    elif df_atm2['total_playback_48hrs'].iloc[0] == df_atm1['total_playback_24hr'].iloc[0]:
        xx=df_atm2['total_playback_48hrs'].iloc[0]-df_atm1['total_playback_24hr'].iloc[0]
        yy= xx/df_atm2['total_playback_48hrs'].iloc[0]
        zz= round(yy*100,2)
        TOTALCHANGE.append('0')
        TOTAL_percentagechange.append(zz)


    else: 
        xx=df_atm1['total_playback_24hr'].iloc[0]-df_atm2['total_playback_48hrs'].iloc[0]
        yy= xx/df_atm1['total_playback_24hr'].iloc[0]
        zz= round(yy*100,2)
        TOTALCHANGE.append('1')
        TOTAL_percentagechange.append(zz)


    parents_playback_24hr=df_atm1['parents_playback_24hr'].tolist()
    teachers_playback_24hr=df_atm1['teachers_playback_24hr'].tolist()
    total_playback_24hr=df_atm1['total_playback_24hr'].tolist()
    parents_playback_48hrs =df_atm2['parents_playback_48hrs'].tolist()
    teachers_playback_48hrs= df_atm2['teachers_playback_48hrs'].tolist()
    total_playback_48hrs= df_atm2['total_playback_48hrs'].tolist()


    temp={'parents_playback_24hr':parents_playback_24hr, 'PARENTSCHANGE':PARENTSCHANGE, 'PARENT_percentagechange':PARENT_percentagechange,
          'teachers_playback_24hr':teachers_playback_24hr, 'TEACHERSCHANGE':TEACHERSCHANGE, 'TEACHER_percentagechange':TEACHER_percentagechange,
          'total_playback_24hr':total_playback_24hr, 'TOTALCHANGE':TOTALCHANGE, 'TOTAL_percentagechange':TOTAL_percentagechange,
          'parents_playback_48hrs':parents_playback_48hrs, 'teachers_playback_48hrs':teachers_playback_48hrs,
          'total_playback_48hrs':total_playback_48hrs
         }
    return json.dumps(temp)





#testttt
@app.route('/comentperfeedbacktabledaily')
def highstarfeedbacktabledaily():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1 = db.audio_track_master
    collection2=db.audio_feedback
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today
#     + timedelta(hours=4)
    start= tod-timedelta(days=1)
    yester= yesterday
#     +timedelta(hours=4)
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)
    
    qr1= [{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester,
                             '$lt':tod
                             }},
    ]}},
    {'$group':{'_id':'$USER_ID._id',
           'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
           'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
           'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
           'COUNTRY':{'$first':'$USER_ID.schoolId.COUNTRY'},
           'CITY':{'$first':'$USER_ID.schoolId.CITY'},
           'STATE':{'$first':'$USER_ID.schoolId.STATE'}
    }}, 
         ]
    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    qr2= [{"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':yester,
                             '$lt':tod
                             }},
                {'RATING':{'$nin':[None,''," "]}},
    {'COMMENT':{'$nin':[None,''," ", 'false']}},
    ]}},
           {'$match':{'$or':[{'RATING':{'$eq':5}},
    {'RATING':{'$eq':4}}, 
    {'RATING':{'$eq':0}}]}},

    {'$group':{'_id':'$USER._id', 'USER_NAME':{'$first':'$USER.USER_NAME'},
               'EMAIL':{'$first':'$USER.EMAIL_ID'},
               'SCHOOL':{'$first':'$USER.schoolId.NAME'},
               'CREATED_DATE':{'$first':'$CREATED_DATE'},
               'COMMENT':{'$first':'$COMMENT'}, 
         'RATING':{'$first':'$RATING'},
         'COMMENT':{'$first':'$COMMENT'}
        }} ,

        
          {'$project':{'_id':1, 'USER_NAME':1, 'EMAIL':1,'SCHOOL':1, 
                      'CREATED_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" }},
                       
        'COMMENT':1,         'ACTION_DATE':1,     'RATING':1,   
                       
                      }},
    {'$sort':{'RATING':-1}}    ]   
    list2= list(collection2.aggregate(qr2))
    audio1= DataFrame(list2)
    audio=pd.merge(audio1,df_atm1, on='_id', how='left')
    audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'PROGRAM_NAME','RATING','COMMENT','AUDIO_DAY','CREATED_DATE','COUNTRY', 'STATE'
            ,'CITY']]
    audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['RATING'].fillna('NO RATING GIVEN', inplace=True)
    audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
    audio2['AUDIO_DAY'].fillna('NO AUDIO DAY', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    

    Msg='No feedback has been captured on this date'
    if audio2.empty is False:
    #     # audio2['CREATED_DATE']=audio2['CREATED_DATE']
    #     # audio3=audio2[audio2['CREATED_DATE']>=date_object]
        audio2['RATING']=audio2['RATING'].replace(0,'NO RATING')
        return {"data":audio2.values.tolist()}
    else:               
        return {"data":Msg.values.tolist()}



@app.route('/lowstartabledaily')
def lowstarfeed():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1 = db.audio_track_master
    collection2=db.audio_feedback
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today
#     + timedelta(hours=4)
    start= tod-timedelta(days=1)
    yester= yesterday
#     +timedelta(hours=4)
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)

    
    qr1= [{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester,
                             '$lt':tod
                             }},
    ]}},
    {'$group':{'_id':'$USER_ID._id',
           'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
           'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
           'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
           'COUNTRY':{'$first':'$USER_ID.schoolId.COUNTRY'},
           'CITY':{'$first':'$USER_ID.schoolId.CITY'},
           'STATE':{'$first':'$USER_ID.schoolId.STATE'}
    }}, 
         ]
    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    qr2= [{"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':yester,
                             '$lt':tod
                             }},
                {'RATING':{'$nin':[None,''," "]}}
    
    ]}},
           {'$match':{'$or':[{'RATING':{'$eq':1}},
    {'RATING':{'$eq':2}}, 
    {'RATING':{'$eq':3}}]}},

    {'$group':{'_id':'$USER._id', 'USER_NAME':{'$first':'$USER.USER_NAME'},
               'EMAIL':{'$first':'$USER.EMAIL_ID'},
               'SCHOOL':{'$first':'$USER.schoolId.NAME'},
               'CREATED_DATE':{'$first':'$CREATED_DATE'},
               'COMMENT':{'$first':'$COMMENT'}, 'ACTION_DATE':{'$first':'$MODIFIED_DATE'},
         'RATING':{'$first':'$RATING'},
         'COMMENT':{'$first':'$COMMENT'}
        }} ,
    {'$sort':{'RATING':-1}}    ]   
    list2= list(collection2.aggregate(qr2))
    audio1= DataFrame(list2)
    audio=pd.merge(audio1,df_atm1, on='_id', how='left')
    audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'PROGRAM_NAME','RATING','COMMENT','AUDIO_DAY','CREATED_DATE','COUNTRY', 'STATE','ACTION_DATE'
            ,'CITY']]
    audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['RATING'].fillna('NO RATING GIVEN', inplace=True)
    audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
    audio2['AUDIO_DAY'].fillna('NO AUDIO DAY', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['CREATED_DATE'].dt.strftime('%Y-%m-%d')
    audio2['ACTION_DATE'].dt.strftime('%Y-%m-%d')

    Msg='No feedback has been captured on this date'
    if audio2.empty is False:
    #     # audio2['CREATED_DATE']=audio2['CREATED_DATE']
    #     # audio3=audio2[audio2['CREATED_DATE']>=date_object]
        audio2['RATING']=audio2['RATING'].replace(0,'NO RATING')
        return {"data":audio2.values.tolist()}
    else:               
        return {"data":Msg.values.tolist()}


#testttttttttttttt

@app.route('/programPRACTICE_dailycomparsion')
def progpracticedaily():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1 = db.audio_track_master
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today
#     + timedelta(hours=4)
    start= tod-timedelta(days=1)
    yester= yesterday
#     +timedelta(hours=4)
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)
    

    qr111=[
    {'$match':{'USER_ID.schoolId':{'$exists':1}}},
    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
             {'MODIFIED_DATE':{'$gte':yester,
                                 '$lt':tod
                                 }},
                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME', 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'teacherspracticecount':'$practicecount'}},
        ]    


    qr222=   [

    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
             {'MODIFIED_DATE':{'$gte':yester,
                                 '$lt':tod
                                 }},

                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME', 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'parentspracticecount':'$practicecount'}},
        ]   
    
    
    qr44=[
    {'$match':{'USER_ID.schoolId':{'$exists':1}}},
    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
             {'MODIFIED_DATE':{'$gte':start_15day,
                                 '$lt':startend
                                 }},
                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME', 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'teacherspracticecount':'$practicecount'}},
        ]    


    qr33=   [

    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
             {'MODIFIED_DATE':{'$gte':start_15day,
                                 '$lt':startend
                                 }},

                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME', 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'parentspracticecount':'$practicecount'}},
        ]     
    

    list1= list(collection1.aggregate(qr111))
    df_atm1= DataFrame(list1)
    list2= list(collection1.aggregate(qr222))
    df_atm2= DataFrame(list2)
    join= pd.merge(df_atm1,df_atm2, how='left', on='_id')
    
    list3= list(collection1.aggregate(qr33))
    df_atm3= DataFrame(list3)
    list4= list(collection1.aggregate(qr44))
    df_atm4= DataFrame(list4)
    join_lastweek24hrs= pd.merge(df_atm3,df_atm4, how='left', on='_id')
    
    join.rename(columns = { '_id': 'progname'}, inplace = True)
    join['parentspracticecount'].fillna(0, inplace=True)
    join['teacherspracticecount'].fillna(0, inplace=True)
    
    parentspractice=join['parentspracticecount'].tolist()
    teacherspractice=join['teacherspracticecount'].tolist()
    progname=join['progname'].tolist()
        
    join_lastweek24hrs.rename(columns = { '_id': 'progname'}, inplace = True)
    join_lastweek24hrs['parentspracticecount'].fillna(0, inplace=True)
    join_lastweek24hrs['teacherspracticecount'].fillna(0, inplace=True)
    
    parentspractice_lastweek24hrs=join_lastweek24hrs['parentspracticecount'].tolist()
    teacherspractice_lastweek24hrs=join_lastweek24hrs['teacherspracticecount'].tolist()
    progname_lastweek24hrs=join_lastweek24hrs['progname'].tolist()
    
#     print(df)
    for i in range(len(progname)):
            progname[i] = progname[i]
    data={'parentspractice':parentspractice,'teacherspractice':teacherspractice,
          'parentspractice_lastweek24hrs':parentspractice_lastweek24hrs,
          'teacherspractice_lastweek24hrs':teacherspractice_lastweek24hrs,
          'progname':progname}
    
    return json.dumps(data)



# @app.route('/SIGNUPS_dailycomparsion') #test3
# def SIGNUP_24hr():
#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
#     db=client.compass
#     collection1= db.user_master

#     #     tz = timezone('UTC')
#     #     date=datetime.datetime.now(tz) 
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     #     yesterday = pd.to_datetime(date) - timedelta(days=1)
#     tz = timezone('UTC')
#     date=datetime.datetime.now(tz) 
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     yesterday = pd.to_datetime(date) - timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     print(yesterday,"yessss")
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     print(today,"today")
#     tod= today
#     #     + timedelta(hours=4)
#     start= tod-timedelta(days=1)
#     yester= yesterday
#     #     +timedelta(hours=4)
#     start_15day=tod-timedelta(days=8)
#     startend= start_15day+timedelta(days=1)

#     qr1=[{"$match":{
#     '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'IS_BLOCKED':{"$ne":'Y'}}, 
#     {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'CREATED_DATE':{'$gt':yester , '$lte':tod}}
#     ]}},
#     {'$group':{'_id':'null', 
#     'parents_signup_last_week': {'$sum':{'$cond':[{'$eq':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
#     'teachers_signup_last_week': {'$sum':{'$cond':[{'$ne':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
#     'total_signup_last_week': {'$sum':1}            
#     }}]
#     list1= list(collection1.aggregate(qr1))
#     df_atm= DataFrame(list1)
#     df_atm1=df_atm[['parents_signup_last_week', 'teachers_signup_last_week','total_signup_last_week']]
#     qr2=[{"$match":{
#     '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'IS_BLOCKED':{"$ne":'Y'}}, 
#     {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'CREATED_DATE':{'$gte':start_15day
#                 , '$lt': startend}}
#     ]}},
#     {'$group':{'_id':'null', 
#     'parents_signup_last_to_lastweek': {'$sum':{'$cond':[{'$eq':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
#     'teachers_signup_last_to_lastweek': {'$sum':{'$cond':[{'$ne':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
#     'total_signup_last_to_lastweek': {'$sum':1}            
#     }}]
#     list2= list(collection1.aggregate(qr2))
#     df_atm= DataFrame(list2)

#     df_atm2=df_atm[['parents_signup_last_to_lastweek', 'teachers_signup_last_to_lastweek','total_signup_last_to_lastweek']]


#     parentschange=[]
#     parents_Percentage_Change=[]
#     if df_atm2['parents_signup_last_to_lastweek'].iloc[0] > df_atm1['parents_signup_last_week'].iloc[0]:
#         xx=df_atm2['parents_signup_last_to_lastweek'].iloc[0]-df_atm1['parents_signup_last_week'].iloc[0]
#         yy= xx/df_atm2['parents_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)
#         parentschange.append('-1')
#         parents_Percentage_Change.append(zz)

#     elif df_atm2['parents_signup_last_to_lastweek'].iloc[0] == df_atm1['parents_signup_last_week'].iloc[0]:
#         xx=df_atm2['parents_signup_last_to_lastweek'].iloc[0]-df_atm1['parents_signup_last_week'].iloc[0]
#         yy= xx/df_atm2['parents_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)
#         parentschange.append('0')
#         parents_Percentage_Change.append(zz)

#     else:
#         xx=df_atm1['parents_signup_last_week'].iloc[0]-df_atm2['parents_signup_last_to_lastweek'].iloc[0]
#         yy= xx/df_atm1['parents_signup_last_week'].iloc[0]
#         zz= round(yy*100,2)
#         parentschange.append('1')
#         parents_Percentage_Change.append(zz)


#     teacherschange=[]
#     Teacher_percentage_change=[]
#     if df_atm2['teachers_signup_last_to_lastweek'].iloc[0] > df_atm1['teachers_signup_last_week'].iloc[0]:
#         xx=df_atm2['teachers_signup_last_to_lastweek'].iloc[0]-df_atm1['teachers_signup_last_week'].iloc[0]
#         yy= xx/df_atm2['teachers_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)
#         teacherschange.append('-1')
#         Teacher_percentage_change.append(zz)

#     elif df_atm2['teachers_signup_last_to_lastweek'].iloc[0] == df_atm1['teachers_signup_last_week'].iloc[0]:
#         xx=df_atm2['teachers_signup_last_to_lastweek'].iloc[0]-df_atm1['teachers_signup_last_week'].iloc[0]
#         yy= xx/df_atm2['teachers_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)
#         teacherschange.append('0')
#         Teacher_percentage_change.append(zz)

#     else:
#         xx=df_atm1['teachers_signup_last_week'].iloc[0]-df_atm2['teachers_signup_last_to_lastweek'].iloc[0]
#         yy= xx/df_atm1['teachers_signup_last_week'].iloc[0]
#         zz= round(yy*100,2)
#         teacherschange.append('1')
#         Teacher_percentage_change.append(zz)


#     totalchange=[]
#     Total_percentage_change=[]
#     if df_atm2['total_signup_last_to_lastweek'].iloc[0] > df_atm1['total_signup_last_week'].iloc[0]:
#         xx=df_atm2['total_signup_last_to_lastweek'].iloc[0]-df_atm1['total_signup_last_week'].iloc[0]
#         yy= xx/df_atm2['total_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)
#         totalchange.append('-1')
#         Total_percentage_change.append(zz)
#     elif df_atm2['total_signup_last_to_lastweek'].iloc[0] == df_atm1['total_signup_last_week'].iloc[0]:
#         xx=df_atm2['total_signup_last_to_lastweek'].iloc[0]-df_atm1['total_signup_last_week'].iloc[0]
#         yy= xx/df_atm2['total_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)
#         totalchange.append('0')
#         Total_percentage_change.append(zz)
#     else:
#         xx=df_atm1['total_signup_last_week'].iloc[0]-df_atm2['total_signup_last_to_lastweek'].iloc[0]
#         yy= xx/df_atm1['teachers_signup_last_week'].iloc[0]
#         zz= round(yy*100,2)
#         totalchange.append('1')
#         Total_percentage_change.append(zz)


#     data=pd.DataFrame({'parents_signup_yesterday':df_atm1['parents_signup_last_week'].tolist(),
#                        'teachers_signup_yesterday':df_atm1['teachers_signup_last_week'].tolist(),
#     'total_signup_yesterday':df_atm1['total_signup_last_week'].tolist(),
#                        'parentschanged':parentschange, 'parents_Percentage_Change':parents_Percentage_Change,
#                        'teacherschanged':teacherschange, 'Teacher_percentage_change':Teacher_percentage_change,
#           'totalchanged':totalchange, 'Total_percentage_change':Total_percentage_change,
#                'parents_signup_lastweek':df_atm2['parents_signup_last_to_lastweek'].tolist(),
#                      'teachers_signup_lastweek':  df_atm2['teachers_signup_last_to_lastweek'].tolist(),
#                 'total_signup_lastweek':       df_atm2['total_signup_last_to_lastweek'].tolist()

#                       })  
#     temp2={}

#     for j in range(len(data.columns)):
#         key= data.columns[j]
#         value=[str(data[data.columns[j]].iloc[0])]
#         temp2.update({key:value})
#     return json.dumps(temp2)





@app.route('/Business_days_streaks_classroom')
def practice_streak_business_days_school():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    from datetime import datetime
    now= datetime.now()- timedelta(hours=5.5)

    collection= db.audio_track_master

    qratm=[{"$match":
             {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                 {'USER_ID.CREATED_DATE':{'$gte':datetime(2020,3,17)}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{'$ne':''}},
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'$USER_ID._id',
                'EMAIL_ID':{"$first":'$USER_ID.EMAIL_ID'},
                'PRACTICE_DATE_max':{"$max":'$MODIFIED_DATE'},
                'PRACTICE_DATE_min':{"$min":'$MODIFIED_DATE'},
    #             'PRACTICE_DATE':{'$addToSet':'$MODIFIED_DATE'} 
    #           'PRACTICE_DATE_max':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},
    #           'PRACTICE_DATE_min':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},
               'PRACTICE_DATE':{'$addToSet':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}

        }},
    {"$project":{
            "_id":0,
            "USER_ID":"$_id",
            "EMAIL_ID":"$EMAIL_ID",
            "max":"$PRACTICE_DATE_max",
            "min":"$PRACTICE_DATE_min",
            "list_of_day_of_practice":"$PRACTICE_DATE"
    }}
      ]

    bifur= list(collection.aggregate(qratm))
    blah=DataFrame(bifur)

    df77=blah
    df77=df77.sort_values(['USER_ID'],ascending=True).reset_index()
    
    # df_1 = pd.json_normalize(blah['_id'])
    # df_final = pd.concat([blah,df_1], axis =  1)
    # # df_final['PRACTICE_DATE'] =df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    # df_final['date_now']= now.strftime("%Y-%m-%d")
    # df_final['PRACTICE_DATE'] = pd.to_datetime(df_final['PRACTICE_DATE'])
    # df_final['day_of_practice']= df_final['PRACTICE_DATE'].dt.strftime('%A')

    # df_final['PRACTICE_DATE'] =df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")



    # df_final_sort=df_final.sort_values(['USER_ID','PRACTICE_DATE'],ascending=True)

    # group1=df_final_sort[['USER_ID','PRACTICE_DATE', 'day_of_practice']]

    # df2=group1.drop_duplicates()
    # df4=df2.reset_index(drop=True)
    # df4['PRACTICE_DATE']=df4['PRACTICE_DATE'].astype('datetime64[ns]')


    # df5=df4.groupby(['USER_ID'])['PRACTICE_DATE'].agg(['max', 'min']).reset_index()

    # df4['PRACTICE_DATE']=df4['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")


    # df6=df4.groupby('USER_ID')['PRACTICE_DATE'].apply(list).reset_index(name='list_of_day_of_practice')

    # list_of_list2=df6.list_of_day_of_practice.tolist()


    # df77= pd.merge(df5,df6 ,on ='USER_ID', how='left')

    daterange=[]
    for i in range(len(df77)):
        z=pd.date_range(df77['min'][i].strftime("%Y-%m-%d"),df77['max'][i].strftime("%Y-%m-%d"),freq='d')
        daterange.append(z)



    datetime_range=[]
    for j in range(len(daterange)):
        yyy=[]
        for i in range(len(daterange[j])):
            xx=daterange[j][i].strftime("%Y-%m-%d")
            yyy.append(xx) 

        datetime_range.append(yyy)

    df77['list_of_date_range']=datetime_range  

    day_of_daterange=[]
    for m in range(len(daterange)):
        yyy=[]
        for i in range(len(daterange[m])):
            xx=daterange[m][i].strftime("%A")
            yyy.append(xx) 

        day_of_daterange.append(yyy)



    df77['day_of_daterange']=day_of_daterange   

    zz=[]
    for i in range(len(df77['list_of_date_range'])):
        xxxx=[]
        for j in range(len(df77['list_of_date_range'][i])):

            if df77['list_of_date_range'][i][j] in df77['list_of_day_of_practice'][i]:
                xxxx.append(1)
            else:
                xxxx.append(0)

        zz.append(xxxx)

    df77['xxx']=zz


    list_without_satsun=[]
    for x in range(len(df77['day_of_daterange'])):

        listtt=[i for i,d in enumerate(df77['day_of_daterange'][x]) if d=='Saturday' or d=='Sunday']

        somelist = [i for j, i in enumerate(df77['xxx'][x]) if j not in listtt]                   

        list_without_satsun.append(somelist)    

    df77['list_without_satsun']=list_without_satsun


    from itertools import groupby
    from collections import defaultdict


    liststst=[]

    for w in range(len(df77['list_without_satsun'])):

        out = [len([*group]) for i, group in groupby(list_without_satsun[w])]


        ccc=[v for i, v in enumerate(list_without_satsun[w]) if i == 0 or v != list_without_satsun[w][i-1]]
        end=[]
        for l,m in zip(ccc,out):
            end.append([l,m])

        tup=[tuple(i) for i in end ]

        d= defaultdict( list )
        for v, k in tup:
            d[v].append(k)

        final_list=[ {v:d[v]} for v in sorted(d) ]


        liststst.append(final_list)



    maximum=[]
    for i in liststst:
        ccc=[]
        for j in i:
            try:
                xx=max(j[1])
                ccc.append(xx)
            except:
                pass
        maximum.append(ccc)     



    df77['maximum']=maximum   

    df77['maximum'] = df77['maximum'].str.get(0)
    df77[['USER_ID','list_without_satsun','maximum']]

    df88=df77.groupby(['maximum'], as_index=False)['USER_ID'].count()

    df88=df88.reset_index(drop=True)

    df99=pd.DataFrame(df88)

    df99.rename(columns={'USER_ID':'Number_of_users_having_streak','maximum':'STREAK'},inplace=True)

    df_final=df99.sort_values('STREAK', ascending=False)

    df_final['cumulativesum']= df_final['Number_of_users_having_streak'].cumsum()


    df_final_streak=df_final.sort_values('STREAK')


    df_final_streak[['STREAK','cumulativesum']]

    temp={'Number_of_streaks_x':df_final_streak['STREAK'].values.tolist(),'Practices_y':df_final_streak['cumulativesum'].values.tolist()}

    return json.dumps(temp)





@app.route('/Business_days_streaks_Family')
def practice_streak_business_days_parents():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    from datetime import datetime
    now= datetime.now()- timedelta(hours=5.5)

    collection= db.audio_track_master

    qratm=[{"$match":
             {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                 {'USER_ID.CREATED_DATE':{'$gte':datetime(2020,3,17)}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{'$ne':''}},
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'$USER_ID._id',
                'EMAIL_ID':{"$first":'$USER_ID.EMAIL_ID'},
                'PRACTICE_DATE_max':{"$max":'$MODIFIED_DATE'},
                'PRACTICE_DATE_min':{"$min":'$MODIFIED_DATE'},
    #             'PRACTICE_DATE':{'$addToSet':'$MODIFIED_DATE'} 
    #           'PRACTICE_DATE_max':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},
    #           'PRACTICE_DATE_min':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},
               'PRACTICE_DATE':{'$addToSet':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}

        }},
    {"$project":{
            "_id":0,
            "USER_ID":"$_id",
            "EMAIL_ID":"$EMAIL_ID",
            "max":"$PRACTICE_DATE_max",
            "min":"$PRACTICE_DATE_min",
            "list_of_day_of_practice":"$PRACTICE_DATE"
    }}
      ]

    bifur= list(collection.aggregate(qratm))
    blah=DataFrame(bifur)

    df77=blah
    df77=df77.sort_values(['USER_ID'],ascending=True).reset_index()

    # df_1 = pd.json_normalize(blah['_id'])
    # df_final = pd.concat([blah,df_1], axis =  1)
    # # df_final['PRACTICE_DATE'] =df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    # df_final['date_now']= now.strftime("%Y-%m-%d")
    # df_final['PRACTICE_DATE'] = pd.to_datetime(df_final['PRACTICE_DATE'])
    # df_final['day_of_practice']= df_final['PRACTICE_DATE'].dt.strftime('%A')

    # df_final['PRACTICE_DATE'] =df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")



    # df_final_sort=df_final.sort_values(['USER_ID','PRACTICE_DATE'],ascending=True)

    # group1=df_final_sort[['USER_ID','PRACTICE_DATE', 'day_of_practice']]

    # df2=group1.drop_duplicates()
    # df4=df2.reset_index(drop=True)
    # df4['PRACTICE_DATE']=df4['PRACTICE_DATE'].astype('datetime64[ns]')


    # df5=df4.groupby(['USER_ID'])['PRACTICE_DATE'].agg(['max', 'min']).reset_index()

    # df4['PRACTICE_DATE']=df4['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")


    # df6=df4.groupby('USER_ID')['PRACTICE_DATE'].apply(list).reset_index(name='list_of_day_of_practice')

    # list_of_list2=df6.list_of_day_of_practice.tolist()


    # df77= pd.merge(df5,df6 ,on ='USER_ID', how='left')

    daterange=[]
    for i in range(len(df77)):
        z=pd.date_range(df77['min'][i].strftime("%Y-%m-%d"),df77['max'][i].strftime("%Y-%m-%d"),freq='d')
        daterange.append(z)



    datetime_range=[]
    for j in range(len(daterange)):
        yyy=[]
        for i in range(len(daterange[j])):
            xx=daterange[j][i].strftime("%Y-%m-%d")
            yyy.append(xx) 

        datetime_range.append(yyy)

    df77['list_of_date_range']=datetime_range  

    day_of_daterange=[]
    for m in range(len(daterange)):
        yyy=[]
        for i in range(len(daterange[m])):
            xx=daterange[m][i].strftime("%A")
            yyy.append(xx) 

        day_of_daterange.append(yyy)



    df77['day_of_daterange']=day_of_daterange   

    zz=[]
    for i in range(len(df77['list_of_date_range'])):
        xxxx=[]
        for j in range(len(df77['list_of_date_range'][i])):

            if df77['list_of_date_range'][i][j] in df77['list_of_day_of_practice'][i]:
                xxxx.append(1)
            else:
                xxxx.append(0)

        zz.append(xxxx)

    df77['xxx']=zz


    list_without_satsun=[]
    for x in range(len(df77['day_of_daterange'])):

        listtt=[i for i,d in enumerate(df77['day_of_daterange'][x]) if d=='Saturday' or d=='Sunday']

        somelist = [i for j, i in enumerate(df77['xxx'][x]) if j not in listtt]                   

        list_without_satsun.append(somelist)    

    df77['list_without_satsun']=list_without_satsun


    from itertools import groupby
    from collections import defaultdict


    liststst=[]

    for w in range(len(df77['list_without_satsun'])):

        out = [len([*group]) for i, group in groupby(list_without_satsun[w])]


        ccc=[v for i, v in enumerate(list_without_satsun[w]) if i == 0 or v != list_without_satsun[w][i-1]]
        end=[]
        for l,m in zip(ccc,out):
            end.append([l,m])

        tup=[tuple(i) for i in end ]

        d= defaultdict( list )
        for v, k in tup:
            d[v].append(k)

        final_list=[ {v:d[v]} for v in sorted(d) ]


        liststst.append(final_list)



    maximum=[]
    for i in liststst:
        ccc=[]
        for j in i:
            try:
                xx=max(j[1])
                ccc.append(xx)
            except:
                pass
        maximum.append(ccc)     



    df77['maximum']=maximum   

    df77['maximum'] = df77['maximum'].str.get(0)
    df77[['USER_ID','list_without_satsun','maximum']]

    df88=df77.groupby(['maximum'], as_index=False)['USER_ID'].count()

    df88=df88.reset_index(drop=True)

    df99=pd.DataFrame(df88)

    df99.rename(columns={'USER_ID':'Number_of_users_having_streak','maximum':'STREAK'},inplace=True)

    df_final=df99.sort_values('STREAK', ascending=False)

    df_final['cumulativesum']= df_final['Number_of_users_having_streak'].cumsum()


    df_final_streak=df_final.sort_values('STREAK')


    df_final_streak[['STREAK','cumulativesum']]

    temp={'Number_of_streaks':df_final_streak['STREAK'].values.tolist(),'Practices':df_final_streak['cumulativesum'].values.tolist()}

    return json.dumps(temp)

#>>>>>>>>>>>>>>>------------------ PRACTICE BIFURCATION API------------------------
@app.route('/Business_days_streaks_Family/<charttype>')
def practicestreak___businessdays___parents(charttype):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    from datetime import datetime
    now= datetime.now()- timedelta(hours=5.5)

    collection= db.audio_track_master
    
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]

        qratm=[{"$match":
                 {'$and': [
                     {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                     {'USER_ID.CREATED_DATE':{'$gte':datetime(2020,3,17)}},
                          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{'$ne':''}},
                         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
               practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
#         {'$group':{'_id':{'USER_ID':'$USER_ID',
#                           'EMAIL_ID':'$USER_EMAIL',
#             'PRACTICE_DATE':'$MODIFIED_DATE'},
#             }},
            {'$group':{'_id':'$USER_ID',
                'EMAIL_ID':{"$first":'$USER_EMAIL'},
                'PRACTICE_DATE_max':{"$max":'$MODIFIED_DATE'},
                'PRACTICE_DATE_min':{"$min":'$MODIFIED_DATE'},
    #             'PRACTICE_DATE':{'$addToSet':'$MODIFIED_DATE'} 
    #           'PRACTICE_DATE_max':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},
    #           'PRACTICE_DATE_min':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},
               'PRACTICE_DATE':{'$addToSet':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}

        }},
        {"$project":{
                "_id":0,
                "USER_ID":"$_id",
                "EMAIL_ID":"$EMAIL_ID",
                "max":"$PRACTICE_DATE_max",
                "min":"$PRACTICE_DATE_min",
                "list_of_day_of_practice":"$PRACTICE_DATE"
        }}
          ]

        bifur= list(collection.aggregate(qratm))
        blah=DataFrame(bifur)

        df77=blah
        df77=df77.sort_values(['USER_ID'],ascending=True).reset_index()
    
#         df_1 = pd.json_normalize(blah['_id'])
#         df_final = pd.concat([blah,df_1], axis =  1)
#         # df_final['PRACTICE_DATE'] =df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
#         df_final['date_now']= now.strftime("%Y-%m-%d")
#         df_final['PRACTICE_DATE'] = pd.to_datetime(df_final['PRACTICE_DATE'])
#         df_final['day_of_practice']= df_final['PRACTICE_DATE'].dt.strftime('%A')

#         df_final['PRACTICE_DATE'] =df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")

# #         print(df_final)
#         if 'USER_ID' not in df_final.columns:
#             df_final['USER_ID'] = 0

#         df_final_sort=df_final.sort_values(['USER_ID','PRACTICE_DATE'],ascending=True)

#         group1=df_final_sort[['USER_ID','PRACTICE_DATE', 'day_of_practice']]

#         df2=group1.drop_duplicates()
#         df4=df2.reset_index(drop=True)
#         df4['PRACTICE_DATE']=df4['PRACTICE_DATE'].astype('datetime64[ns]')


#         df5=df4.groupby(['USER_ID'])['PRACTICE_DATE'].agg(['max', 'min']).reset_index()

#         df4['PRACTICE_DATE']=df4['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")


#         df6=df4.groupby('USER_ID')['PRACTICE_DATE'].apply(list).reset_index(name='list_of_day_of_practice')

#         list_of_list2=df6.list_of_day_of_practice.tolist()


#         df77= pd.merge(df5,df6 ,on ='USER_ID', how='left')

        daterange=[]
        for i in range(len(df77)):
            z=pd.date_range(df77['min'][i].strftime("%Y-%m-%d"),df77['max'][i].strftime("%Y-%m-%d"),freq='d')
            daterange.append(z)



        datetime_range=[]
        for j in range(len(daterange)):
            yyy=[]
            for i in range(len(daterange[j])):
                xx=daterange[j][i].strftime("%Y-%m-%d")
                yyy.append(xx) 

            datetime_range.append(yyy)

        df77['list_of_date_range']=datetime_range  

        day_of_daterange=[]
        for m in range(len(daterange)):
            yyy=[]
            for i in range(len(daterange[m])):
                xx=daterange[m][i].strftime("%A")
                yyy.append(xx) 

            day_of_daterange.append(yyy)



        df77['day_of_daterange']=day_of_daterange   

        zz=[]
        for i in range(len(df77['list_of_date_range'])):
            xxxx=[]
            for j in range(len(df77['list_of_date_range'][i])):

                if df77['list_of_date_range'][i][j] in df77['list_of_day_of_practice'][i]:
                    xxxx.append(1)
                else:
                    xxxx.append(0)

            zz.append(xxxx)

        df77['xxx']=zz


        list_without_satsun=[]
        for x in range(len(df77['day_of_daterange'])):

            listtt=[i for i,d in enumerate(df77['day_of_daterange'][x]) if d=='Saturday' or d=='Sunday']

            somelist = [i for j, i in enumerate(df77['xxx'][x]) if j not in listtt]                   

            list_without_satsun.append(somelist)    

        df77['list_without_satsun']=list_without_satsun


        from itertools import groupby
        from collections import defaultdict


        liststst=[]

        for w in range(len(df77['list_without_satsun'])):

            out = [len([*group]) for i, group in groupby(list_without_satsun[w])]


            ccc=[v for i, v in enumerate(list_without_satsun[w]) if i == 0 or v != list_without_satsun[w][i-1]]
            end=[]
            for l,m in zip(ccc,out):
                end.append([l,m])

            tup=[tuple(i) for i in end ]

            d= defaultdict( list )
            for v, k in tup:
                d[v].append(k)

            final_list=[ {v:d[v]} for v in sorted(d) ]


            liststst.append(final_list)



        maximum=[]
        for i in liststst:
            ccc=[]
            for j in i:
                try:
                    xx=max(j[1])
                    ccc.append(xx)
                except:
                    pass
            maximum.append(ccc)     



        df77['maximum']=maximum   

        df77['maximum'] = df77['maximum'].str.get(0)
        df77[['USER_ID','list_without_satsun','maximum']]

        df88=df77.groupby(['maximum'], as_index=False)['USER_ID'].count()

        df88=df88.reset_index(drop=True)

        df99=pd.DataFrame(df88)

        df99.rename(columns={'USER_ID':'Number_of_users_having_streak','maximum':'STREAK'},inplace=True)

        df_final=df99.sort_values('STREAK', ascending=False)

        df_final['cumulativesum']= df_final['Number_of_users_having_streak'].cumsum()


        df_final_streak=df_final.sort_values('STREAK')


        df_final_streak[['STREAK','cumulativesum']]

        temp={'Number_of_streaks':df_final_streak['STREAK'].values.tolist(),'Practices':df_final_streak['cumulativesum'].values.tolist()}

        return json.dumps(temp)
    
    else:
        qratm=[{"$match":
                 {'$and': [
                     {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                     {'USER_ID.CREATED_DATE':{'$gte':datetime(2020,3,17)}},
                          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{'$ne':''}},
                         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':'$USER_ID._id',
                'EMAIL_ID':{"$first":'$USER_ID.EMAIL_ID'},
                'PRACTICE_DATE_max':{"$max":'$MODIFIED_DATE'},
                'PRACTICE_DATE_min':{"$min":'$MODIFIED_DATE'},
    #             'PRACTICE_DATE':{'$addToSet':'$MODIFIED_DATE'} 
    #           'PRACTICE_DATE_max':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},
    #           'PRACTICE_DATE_min':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},
               'PRACTICE_DATE':{'$addToSet':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}

        }},
        {"$project":{
                "_id":0,
                "USER_ID":"$_id",
                "EMAIL_ID":"$EMAIL_ID",
                "max":"$PRACTICE_DATE_max",
                "min":"$PRACTICE_DATE_min",
                "list_of_day_of_practice":"$PRACTICE_DATE"
        }}
          ]

        bifur= list(collection.aggregate(qratm))
        blah=DataFrame(bifur)

        df77=blah
        df77=df77.sort_values(['USER_ID'],ascending=True).reset_index()

#         df_1 = pd.json_normalize(blah['_id'])
#         df_final = pd.concat([blah,df_1], axis =  1)
#         # df_final['PRACTICE_DATE'] =df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
#         df_final['date_now']= now.strftime("%Y-%m-%d")
#         df_final['PRACTICE_DATE'] = pd.to_datetime(df_final['PRACTICE_DATE'])
#         df_final['day_of_practice']= df_final['PRACTICE_DATE'].dt.strftime('%A')

#         df_final['PRACTICE_DATE'] =df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")



#         df_final_sort=df_final.sort_values(['USER_ID','PRACTICE_DATE'],ascending=True)

#         group1=df_final_sort[['USER_ID','PRACTICE_DATE', 'day_of_practice']]

#         df2=group1.drop_duplicates()
#         df4=df2.reset_index(drop=True)
#         df4['PRACTICE_DATE']=df4['PRACTICE_DATE'].astype('datetime64[ns]')


#         df5=df4.groupby(['USER_ID'])['PRACTICE_DATE'].agg(['max', 'min']).reset_index()

#         df4['PRACTICE_DATE']=df4['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")


#         df6=df4.groupby('USER_ID')['PRACTICE_DATE'].apply(list).reset_index(name='list_of_day_of_practice')

#         list_of_list2=df6.list_of_day_of_practice.tolist()


#         df77= pd.merge(df5,df6 ,on ='USER_ID', how='left')

        daterange=[]
        for i in range(len(df77)):
            z=pd.date_range(df77['min'][i].strftime("%Y-%m-%d"),df77['max'][i].strftime("%Y-%m-%d"),freq='d')
            daterange.append(z)



        datetime_range=[]
        for j in range(len(daterange)):
            yyy=[]
            for i in range(len(daterange[j])):
                xx=daterange[j][i].strftime("%Y-%m-%d")
                yyy.append(xx) 

            datetime_range.append(yyy)

        df77['list_of_date_range']=datetime_range  

        day_of_daterange=[]
        for m in range(len(daterange)):
            yyy=[]
            for i in range(len(daterange[m])):
                xx=daterange[m][i].strftime("%A")
                yyy.append(xx) 

            day_of_daterange.append(yyy)



        df77['day_of_daterange']=day_of_daterange   

        zz=[]
        for i in range(len(df77['list_of_date_range'])):
            xxxx=[]
            for j in range(len(df77['list_of_date_range'][i])):

                if df77['list_of_date_range'][i][j] in df77['list_of_day_of_practice'][i]:
                    xxxx.append(1)
                else:
                    xxxx.append(0)

            zz.append(xxxx)

        df77['xxx']=zz


        list_without_satsun=[]
        for x in range(len(df77['day_of_daterange'])):

            listtt=[i for i,d in enumerate(df77['day_of_daterange'][x]) if d=='Saturday' or d=='Sunday']

            somelist = [i for j, i in enumerate(df77['xxx'][x]) if j not in listtt]                   

            list_without_satsun.append(somelist)    

        df77['list_without_satsun']=list_without_satsun


        from itertools import groupby
        from collections import defaultdict


        liststst=[]

        for w in range(len(df77['list_without_satsun'])):

            out = [len([*group]) for i, group in groupby(list_without_satsun[w])]


            ccc=[v for i, v in enumerate(list_without_satsun[w]) if i == 0 or v != list_without_satsun[w][i-1]]
            end=[]
            for l,m in zip(ccc,out):
                end.append([l,m])

            tup=[tuple(i) for i in end ]

            d= defaultdict( list )
            for v, k in tup:
                d[v].append(k)

            final_list=[ {v:d[v]} for v in sorted(d) ]


            liststst.append(final_list)



        maximum=[]
        for i in liststst:
            ccc=[]
            for j in i:
                try:
                    xx=max(j[1])
                    ccc.append(xx)
                except:
                    pass
            maximum.append(ccc)     



        df77['maximum']=maximum   

        df77['maximum'] = df77['maximum'].str.get(0)
        df77[['USER_ID','list_without_satsun','maximum']]

        df88=df77.groupby(['maximum'], as_index=False)['USER_ID'].count()

        df88=df88.reset_index(drop=True)

        df99=pd.DataFrame(df88)

        df99.rename(columns={'USER_ID':'Number_of_users_having_streak','maximum':'STREAK'},inplace=True)

        df_final=df99.sort_values('STREAK', ascending=False)

        df_final['cumulativesum']= df_final['Number_of_users_having_streak'].cumsum()


        df_final_streak=df_final.sort_values('STREAK')


        df_final_streak[['STREAK','cumulativesum']]

        temp={'Number_of_streaks':df_final_streak['STREAK'].values.tolist(),'Practices':df_final_streak['cumulativesum'].values.tolist()}

        return json.dumps(temp)







#testtttttttt
@app.route('/power_users_having_streaks')
def power_users():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    from datetime import datetime
    now= datetime.now()- timedelta(hours=5.5)
    # dateStr = "2020-03-17T00:00:00.000Z"
    # myDatetime = dateutil.parser.parse(dateStr)
    collection= db.audio_track_master
    qratm=[{"$match":
             {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                 {'MODIFIED_DATE':{'$gte':csy_first_date()}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{'$ne':''}},
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'USER_ID':'$USER_ID._id',
                      'EMAIL_ID':'$USER_ID.EMAIL_ID',
        'PRACTICE_DATE':'$MODIFIED_DATE'},
        }},
        ]
    bifur= list(collection.aggregate(qratm))
    blah=DataFrame(bifur)
    #     df1= blah['_id']
    df_1 = pd.json_normalize(blah['_id'])
    df_final = pd.concat([blah,df_1], axis =  1)
    df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final['date_now']= now.strftime("%Y-%m-%d")
    df_final['PRACTICE_DATE'] = pd.to_datetime(df_final['PRACTICE_DATE'])
    df_final['date_now'] = pd.to_datetime(df_final['date_now'])
    df_final['days'] = (df_final['date_now'] - df_final['PRACTICE_DATE']).dt.days
    df_final1=df_final[['USER_ID','PRACTICE_DATE','EMAIL_ID','days']]
    date_list=df_final1.PRACTICE_DATE.tolist()
    # streak_empty=[]
    days=[]
    for k in range(len(date_list)):
        z=(now-date_list[k]).days
        days.append(z)
    df_final1['days']=days
    df_final2=df_final1.sort_values('PRACTICE_DATE', ascending=True)
    df_final2['PRACTICE_DATE']=df_final2['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final3= df_final2.groupby(['USER_ID', 'PRACTICE_DATE']).agg({'days':['max']})
    df_final3.columns=['days_max']
    df_final3= df_final3.reset_index()
    df_final3.sort_values('PRACTICE_DATE', ascending=True)
    #     df_final3.isnull().sum()
    df1 = df_final3.groupby('USER_ID')['days_max'].apply(list).reset_index(name='grouping')
    list_of_list=df1.grouping.tolist()
    def streak_count_function(streak_list):
        streak_list.sort()
        streak_count=[]
        counter = 1
        for i in range(len(streak_list)):
            if i != (len(streak_list) - 1):
                diff = streak_list[i+1] - streak_list[i]
                if diff == 1:
                    counter += 1
                else:
                    streak_count.append(counter)
                    counter = 1
            else:
                streak_count.append(counter)
        return(max(streak_count)) 
    streak_empty=[]
    for i in range(len(list_of_list)):
        streak_empty.append(streak_count_function(list_of_list[i]))
    df1['streak_frequencyy']=streak_empty
    df22=df1.groupby(['streak_frequencyy'], as_index=False)['USER_ID'].count()
    df22 = df22.reset_index(drop=True)
    dataframe=pd.DataFrame(df22)
    dataframe.rename(columns={'USER_ID':'Number_of_classroom_users_having_streak','streak_frequencyy':'STREAK'},inplace=True)
    dfff=dataframe.sort_values('STREAK', ascending=False)
    # =====================
    collection= db.audio_track_master
    qratmm=[{"$match":
             {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                 {'USER_ID.CREATED_DATE':{'$gte':datetime(2020,3,17)}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{'$ne':''}},
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'USER_ID':'$USER_ID._id',
                      'EMAIL_ID':'$USER_ID.EMAIL_ID',
        'PRACTICE_DATE':'$MODIFIED_DATE'},
        }},
        ]
    present= list(collection.aggregate(qratmm))
    blahhh=DataFrame(present)
    #     df1= blah['_id']
    df_11 = pd.json_normalize(blahhh['_id'])
    df_final_11 = pd.concat([blahhh,df_11], axis =  1)
    df_final_11['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final_11['date_now']= now.strftime("%Y-%m-%d")
    df_final_11['PRACTICE_DATE'] = pd.to_datetime(df_final_11['PRACTICE_DATE'])
    df_final_11['date_now'] = pd.to_datetime(df_final_11['date_now'])
    df_final_11['days'] = (df_final_11['date_now'] - df_final_11['PRACTICE_DATE']).dt.days
    df_final_11_11=df_final_11[['USER_ID','PRACTICE_DATE','EMAIL_ID','days']]
    date_list_=df_final_11_11.PRACTICE_DATE.tolist()
    # streak_empty=[]
    daysss=[]
    for k in range(len(date_list_)):
        z=(now-date_list_[k]).days
        daysss.append(z)
    df_final_11['daysss']=daysss
    df_final22=df_final_11.sort_values('PRACTICE_DATE', ascending=True)
    df_final22['PRACTICE_DATE']=df_final22['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final33= df_final22.groupby(['USER_ID', 'PRACTICE_DATE']).agg({'days':['max']})
    df_final33.columns=['days_max']
    df_final33= df_final33.reset_index()
    df_final33.sort_values('PRACTICE_DATE', ascending=True)
    #     df_final3.isnull().sum()
    df1111 = df_final33.groupby('USER_ID')['days_max'].apply(list).reset_index(name='grouping')
    list_of_list_=df1111.grouping.tolist()
    def streak_count_function_present(streak_list_):
        streak_list_.sort()
        streak_count_=[]
        counter = 1
        for i in range(len(streak_list_)):
            if i != (len(streak_list_) - 1):
                diff = streak_list_[i+1] - streak_list_[i]
                if diff == 1:
                    counter += 1
                else:
                    streak_count_.append(counter)
                    counter = 1
            else:
                streak_count_.append(counter)
        return(max(streak_count_)) 
    streak_emptyy=[]
    for i in range(len(list_of_list_)):
        streak_emptyy.append(streak_count_function_present(list_of_list_[i]))
    df1111['streak_frequencyy']=streak_emptyy
    df2222=df1111.groupby(['streak_frequencyy'], as_index=False)['USER_ID'].count()
    df2222 = df2222.reset_index(drop=True)
    dataframe11=pd.DataFrame(df2222)
    dataframe11.rename(columns={'USER_ID':'Number_of_present_users_having_streak','streak_frequencyy':'STREAK'},inplace=True)
    dfff11=dataframe11.sort_values('STREAK', ascending=False)
    final=dfff11.merge(dfff, on='STREAK', how='outer')
    power_user_streaks=final.sort_values('STREAK').reset_index(drop=True)
    power_user_streaks['Number_of_present_users_having_streak']=power_user_streaks['Number_of_present_users_having_streak'].fillna(0)
    power_user_streaks['Number_of_classroom_users_having_streak']=power_user_streaks['Number_of_classroom_users_having_streak'].fillna(0)
    ACTIVETREND={'STREAK':power_user_streaks['STREAK'].values.tolist(),'line':power_user_streaks['Number_of_present_users_having_streak'].values.tolist(),'bar':power_user_streaks['Number_of_classroom_users_having_streak'].values.tolist()}
    ACTIVETREND=[ACTIVETREND]
    return json.dumps(ACTIVETREND)


@app.route('/STREAKS')
def present_streaks():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    from datetime import datetime
    now= datetime.now()- timedelta(hours=5.5)
    # dateStr = "2020-03-17T00:00:00.000Z"
    # myDatetime = dateutil.parser.parse(dateStr)
    collection= db.audio_track_master
    qratm=[{"$match":
             {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                 {'USER_ID.CREATED_DATE':{'$gte':datetime(2020,3,17)}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{'$ne':''}},
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'USER_ID':'$USER_ID._id',
                      'EMAIL_ID':'$USER_ID.EMAIL_ID',
        'PRACTICE_DATE':'$MODIFIED_DATE'},
        }},
        ]
    bifur= list(collection.aggregate(qratm))
    blah=DataFrame(bifur)
#     df1= blah['_id']
    df_1 = pd.json_normalize(blah['_id'])
    df_final = pd.concat([blah,df_1], axis =  1)
    df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final['date_now']= now.strftime("%Y-%m-%d")
    df_final['PRACTICE_DATE'] = pd.to_datetime(df_final['PRACTICE_DATE'])
    df_final['date_now'] = pd.to_datetime(df_final['date_now'])
    df_final['days'] = (df_final['date_now'] - df_final['PRACTICE_DATE']).dt.days
    df_final1=df_final[['USER_ID','PRACTICE_DATE','EMAIL_ID','days']]
    date_list=df_final1.PRACTICE_DATE.tolist()
    # streak_empty=[]
    days=[]
    for k in range(len(date_list)):
        z=(now-date_list[k]).days
        days.append(z)
    df_final1['days']=days
    df_final2=df_final1.sort_values('PRACTICE_DATE', ascending=True)
    df_final2['PRACTICE_DATE']=df_final2['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final3= df_final2.groupby(['USER_ID', 'PRACTICE_DATE']).agg({'days':['max']})
    df_final3.columns=['days_max']
    df_final3= df_final3.reset_index()
    df_final3.sort_values('PRACTICE_DATE', ascending=True)
#     df_final3.isnull().sum()
    df1 = df_final3.groupby('USER_ID')['days_max'].apply(list).reset_index(name='grouping')
    list_of_list=df1.grouping.tolist()
    def streak_count_function(streak_list):
        streak_list.sort()
        streak_count=[]
        counter = 1
        for i in range(len(streak_list)):
            if i != (len(streak_list) - 1):
                diff = streak_list[i+1] - streak_list[i]
                if diff == 1:
                    counter += 1
                else:
                    streak_count.append(counter)
                    counter = 1
            else:
                streak_count.append(counter)
        return(max(streak_count)) 
    streak_empty=[]
    for i in range(len(list_of_list)):
        streak_empty.append(streak_count_function(list_of_list[i]))
    df1['streak_frequencyy']=streak_empty
    df22=df1.groupby(['streak_frequencyy'], as_index=False)['USER_ID'].count()
    df22 = df22.reset_index(drop=True)
    dataframe=pd.DataFrame(df22)
    dataframe.rename(columns={'USER_ID':'Number_of_users_having_streak','streak_frequencyy':'STREAK'},inplace=True)
    dfff=dataframe.sort_values('STREAK', ascending=False)
    dfff['cumulativesum']= dfff['Number_of_users_having_streak'].cumsum()
    df_final_streak=dfff.sort_values('STREAK')
    df_final_streak=df_final_streak[['STREAK','cumulativesum']]
    temp={'streak':df_final_streak['STREAK'].values.tolist(), 'line_chart':df_final_streak['cumulativesum'].values.tolist()}
    return json.dumps(temp)


@app.route('/teachers_STREAKS')
def classroom_streaks():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    from datetime import datetime
    now= datetime.now()- timedelta(hours=5.5)
    # dateStr = "2020-03-17T00:00:00.000Z"
    # myDatetime = dateutil.parser.parse(dateStr)
    collection= db.audio_track_master
    qratm=[{"$match":
             {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                 {'MODIFIED_DATE':{'$gte':csy_first_date()}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{'$ne':''}},
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'USER_ID':'$USER_ID._id',
                      'EMAIL_ID':'$USER_ID.EMAIL_ID',
        'PRACTICE_DATE':'$MODIFIED_DATE'},
        }},
        ]
    bifur= list(collection.aggregate(qratm))
    blah=DataFrame(bifur)
#     df1= blah['_id']
    df_1 = pd.json_normalize(blah['_id'])
    df_final = pd.concat([blah,df_1], axis =  1)
    df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final['date_now']= now.strftime("%Y-%m-%d")
    df_final['PRACTICE_DATE'] = pd.to_datetime(df_final['PRACTICE_DATE'])
    df_final['date_now'] = pd.to_datetime(df_final['date_now'])
    df_final['days'] = (df_final['date_now'] - df_final['PRACTICE_DATE']).dt.days
    df_final1=df_final[['USER_ID','PRACTICE_DATE','EMAIL_ID','days']]
    date_list=df_final1.PRACTICE_DATE.tolist()
    # streak_empty=[]
    days=[]
    for k in range(len(date_list)):
        z=(now-date_list[k]).days
        days.append(z)
    df_final1['days']=days
    df_final2=df_final1.sort_values('PRACTICE_DATE', ascending=True)
    df_final2['PRACTICE_DATE']=df_final2['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final3= df_final2.groupby(['USER_ID', 'PRACTICE_DATE']).agg({'days':['max']})
    df_final3.columns=['days_max']
    df_final3= df_final3.reset_index()
    df_final3.sort_values('PRACTICE_DATE', ascending=True)
#     df_final3.isnull().sum()
    df1 = df_final3.groupby('USER_ID')['days_max'].apply(list).reset_index(name='grouping')
    list_of_list=df1.grouping.tolist()
    def streak_count_function(streak_list):
        streak_list.sort()
        streak_count=[]
        counter = 1
        for i in range(len(streak_list)):
            if i != (len(streak_list) - 1):
                diff = streak_list[i+1] - streak_list[i]
                if diff == 1:
                    counter += 1
                else:
                    streak_count.append(counter)
                    counter = 1
            else:
                streak_count.append(counter)
        return(max(streak_count)) 
    streak_empty=[]
    for i in range(len(list_of_list)):
        streak_empty.append(streak_count_function(list_of_list[i]))
    df1['streak_frequencyy']=streak_empty
    df22=df1.groupby(['streak_frequencyy'], as_index=False)['USER_ID'].count()
    df22 = df22.reset_index(drop=True)
    dataframe=pd.DataFrame(df22)
    dataframe.rename(columns={'USER_ID':'Number_of_users_having_streak','streak_frequencyy':'STREAK'},inplace=True)
    dfff=dataframe.sort_values('STREAK', ascending=False)
    dfff['cumulativesum']= dfff['Number_of_users_having_streak'].cumsum()
    classroom_streak=dfff.sort_values('STREAK')
    classroom_streak=classroom_streak[['STREAK','cumulativesum']]
    temp={'streak':classroom_streak['STREAK'].values.tolist(), 'line_chart':classroom_streak['cumulativesum'].values.tolist()}
    return json.dumps(temp)




@app.route('/daywisefeedcardss')
def feeddailycardsdayofweek():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today
#     + timedelta(hours=4)
    start= tod-timedelta(days=1)
    yester= yesterday
#     +timedelta(hours=4)
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)
    query1=[
    {"$match":{"$and":[
    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.IS_DISABLE':{"$ne":'Y'}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
        {'COMMENT':{'$nin':['',' ',None]}},
    {"MODIFIED_DATE":{"$gte": yester, '$lt': tod}}
    ]}},
    {'$match':{'$or':[{'RATING':{'$eq':5}},
    {'RATING':{'$eq':4}}, 
    {'RATING':{'$eq':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed=list(collection2.aggregate(query1))
    commentsonfeedback=pd.DataFrame(commentsonfeed)
    comments_per_feedback=commentsonfeedback[['rating']]


    query2=[
    {"$match":{"$and":[
    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.IS_DISABLE':{"$ne":'Y'}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
    {"MODIFIED_DATE":{"$gte": yester, '$lt': tod}}
    ]}},
    {'$match':{'$or':[{'RATING':{'$eq':1}},
    {'RATING':{'$eq':2}}, 
    {'RATING':{'$eq':3}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    low_star=list(collection2.aggregate(query2))
    low_starfeedback_df=pd.DataFrame(low_star)
    low_star_rating=low_starfeedback_df[['rating']]


    query3=[
    {"$match":{"$and":[
    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.IS_DISABLE':{"$ne":'Y'}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
    {"MODIFIED_DATE":{"$gte": yester, '$lt': tod}},
#         {'RATING':{'$ne':0}}
    ]}},
#     {'$match':{'$or':[{'RATING':{'$eq':1}},
#     {'RATING':{'$eq':2}}, 
#     {'RATING':{'$eq':3}}]}},

    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rating=list(collection2.aggregate(query3))
    avg_ratings=pd.DataFrame(avg_rating)
#     avg=avg_ratings[['avg']]

    avg_ratings_yester=pd.DataFrame({'avg_ratings_yester':round(avg_ratings[avg_ratings['RATING']!=0]['RATING'].mean(),1)}, index=[0])

    # last_week_compare

    query4=[
    {"$match":{"$and":[
    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.IS_DISABLE':{"$ne":'Y'}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
        {'COMMENT':{'$nin':['',' ',None]}},
    {"MODIFIED_DATE":{"$gte": start_15day, '$lt': startend}}
    ]}},
    {'$match':{'$or':[{'RATING':{'$eq':5}},
    {'RATING':{'$eq':4}}, 
    {'RATING':{'$eq':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed=list(collection2.aggregate(query4))
    commentsonfeedback1=pd.DataFrame(commentsonfeed)
    comments_per_feedback_lastweek=commentsonfeedback1[['rating']]


    query5=[
    {"$match":{"$and":[
    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.IS_DISABLE':{"$ne":'Y'}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
    {"MODIFIED_DATE":{"$gte": start_15day, '$lt': startend}}
    ]}},
    {'$match':{'$or':[{'RATING':{'$eq':1}},
    {'RATING':{'$eq':2}}, 
    {'RATING':{'$eq':3}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    feedback=list(collection2.aggregate(query5))
    feedback_df=pd.DataFrame(feedback)
    low_star_rating_lastweek=feedback_df[['rating']]



    query6=[
    {"$match":{"$and":[
    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.IS_DISABLE':{"$ne":'Y'}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
    {"MODIFIED_DATE":{"$gte": start_15day, '$lt': startend}},
        {'RATING':{'$ne':0}}
    ]}},
#     {'$match':{'$or':[{'RATING':{'$eq':1}},
#     {'RATING':{'$eq':2}}, 
#     {'RATING':{'$eq':3}}]}},

    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rating=list(collection2.aggregate(query6))
    avg_ratings=pd.DataFrame(avg_rating)
    avg_ratings_lastweek=avg_ratings[['RATING']]

    avg_ratings_lastweek=pd.DataFrame({'avg_ratings_lastweekk':round(avg_ratings_lastweek[avg_ratings_lastweek['RATING']!=0]['RATING'].mean(),1)}, index=[0])

    Comment_per_feedbackchange=[]
    if comments_per_feedback['rating'].iloc[0] > comments_per_feedback_lastweek['rating'].iloc[0]:
        Comment_per_feedbackchange.append('1')
    elif comments_per_feedback['rating'].iloc[0] == comments_per_feedback_lastweek['rating'].iloc[0]:
        Comment_per_feedbackchange.append('0')
    else:
        Comment_per_feedbackchange.append('-1')


    low_star_ratingchange=[]
    if low_star_rating['rating'].iloc[0] > low_star_rating_lastweek['rating'].iloc[0]:
        low_star_ratingchange.append('1')
    elif low_star_rating['rating'].iloc[0] == low_star_rating_lastweek['rating'].iloc[0]:
        low_star_ratingchange.append('0')
    else:
        low_star_ratingchange.append('-1')



    Average_Rating_change=[]
    if avg_ratings_yester['avg_ratings_yester'].iloc[0] > avg_ratings_lastweek['avg_ratings_lastweekk'].iloc[0]:
        Average_Rating_change.append('1')
    elif avg_ratings_yester['avg_ratings_yester'].iloc[0] == avg_ratings_lastweek['avg_ratings_lastweekk'].iloc[0]:
        Average_Rating_change.append('0')
    else:
        Average_Rating_change.append('-1')



    data_final=pd.DataFrame({'Low_star_rating_yesterday':low_star_rating['rating'].tolist(),
                             'Low_star_rating_lastweek':low_star_rating_lastweek['rating'].tolist(),
                             
    'Comment_per_feedback_yesterday':comments_per_feedback['rating'].tolist(),
    'Comment_per_feedback_lastweek':comments_per_feedback_lastweek['rating'].tolist(),
                                 
     'Average_Rating_yesterday':avg_ratings_yester['avg_ratings_yester'].tolist(),
     'avg_ratings_lastweek':avg_ratings_lastweek['avg_ratings_lastweekk'].tolist(),
                             
      'Comment_per_feedbackchange':Comment_per_feedbackchange,
      'low_star_ratingchange':low_star_ratingchange,
      'Average_Rating_change':Average_Rating_change
                                })    
    temp={}
    for j in range(len(data_final.columns)):
        key = data_final.columns[j]
        value = [str(data_final[data_final.columns[j]].iloc[0])]
        temp.update({key:value})
        #     print(temp)
    return json.dumps(temp)







#testttt
@app.route('/ratedaily')
def RATINGssy():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection=db.audio_feedback
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today
#     + timedelta(hours=4)
    start= tod-timedelta(days=1)
    yester= yesterday
#     +timedelta(hours=4)
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)
    index=[0]

    df1 = DataFrame(list(collection.aggregate([
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lt':tod}}    ,         
    {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
    'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
    'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},           
    
    }},
    {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3',
                'rating_2':'$rating_2', 'rating_1':'$rating_1'}},
    {'$sort':{'_id':1}}
    ])))
    df1.rename(columns = { '_id': 'week'}, inplace = True)
    
    if df1.empty:
        df1 = pd.DataFrame(index=index, columns=['week','rating_5','rating_4','rating_3','rating_2','rating_1'])
        df1 = df1.fillna(0)
    
    df1[['week','rating_5','rating_4','rating_3','rating_2','rating_1']]
    print(df1,"teachers_yes")
    df2 = DataFrame(list(collection.aggregate([
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester, '$lt':tod}}    ,         
    {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
    'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
    'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},              
    
    }},
    {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3',
                'rating_2':'$rating_2', 'rating_1':'$rating_1'}},
    {'$sort':{'_id':1}}
    ])))
    df2.rename(columns = {'_id': 'week'}, inplace = True)
    
    if df2.empty:
        df2 = pd.DataFrame(index=index, columns=['week','rating_5','rating_4','rating_3','rating_2','rating_1'])
        df2 = df2.fillna(0) 
    
    df2[['week','rating_5','rating_4','rating_3','rating_2','rating_1']]
    print(df2,"par_yes")
    df10 = DataFrame(list(collection.aggregate([
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lt':startend}}    ,         
    {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
    'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
    'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},              
    
    }},
    {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3',
                'rating_2':'$rating_2', 'rating_1':'$rating_1'}},
    {'$sort':{'_id':1}}
    ])))
    df10.rename(columns = { '_id': 'week'}, inplace = True)
    if df10.empty:
        df10 = pd.DataFrame(index=index, columns=['week','rating_5','rating_4','rating_3','rating_2','rating_1'])
        df10 = df10.fillna(0)
    
    df10[['week','rating_5','rating_4','rating_3','rating_2','rating_1']]
    print(df10,"teach_lastweek")
    df20 = DataFrame(list(collection.aggregate([
     {"$match":{'$and':[
         {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER.IS_DISABLED":{"$ne":"Y"}},
         { "USER.IS_BLOCKED":{"$ne":"Y"}},
        { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
           {'MODIFIED_DATE':{'$gte':start_15day, '$lt':startend}}    ,         
        {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
    'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
    'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},              
   
    }},
    {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3',
                'rating_2':'$rating_2', 'rating_1':'$rating_1'}},
    {'$sort':{'_id':1}}
        ])))
    df20.rename(columns = { '_id': 'week'}, inplace = True)
    if df20.empty:
        df20 = pd.DataFrame(index=index, columns=['week','rating_5','rating_4','rating_3','rating_2','rating_1'])
        df20 = df20.fillna(0)
    
    df20[['week','rating_5','rating_4','rating_3','rating_2','rating_1']]
    print(df20,"par_lastweek")
    teachers_yes=df1.values.tolist()
    par_yes=df2.values.tolist()
    teach_lastweek=df10.values.tolist()
    par_lastweek=df20.values.tolist()
    weekdata={"rating":["5 STAR","4 STAR","3 STAR", "2 STAR", "1 STAR"],"teachers_yes":teachers_yes[0][1:],"par_yes":par_yes[0][1:],"teach_lastweek":teach_lastweek[0][1:],"par_lastweek":par_lastweek[0][1:]}
    
    temp={'weekdata':weekdata}
    return json.dumps(temp)

# RATINGssy()


#testttttt

@app.route('/ratedailylowstar')
def RATINGslowstar():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection=db.audio_feedback
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today
#     + timedelta(hours=4)
    start= tod-timedelta(days=1)
    yester= yesterday
#     +timedelta(hours=4)
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)

    df1 = DataFrame(list(collection.aggregate([
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lt':tod}}    ,         
    {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    
    
    }},
    {'$project':{'_id':1, 'rating_1':'$rating_1','rating_2':'$rating_2'}},
    {'$sort':{'_id':1}}
    ])))
    df1.rename(columns = { '_id': 'week'}, inplace = True)
    df1[['week','rating_1','rating_2']]
    print(df1,"teachers_yes")
    df2 = DataFrame(list(collection.aggregate([
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester, '$lt':tod}}    ,         
    {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    
    
    }},
    {'$project':{'_id':1, 'rating_1':'$rating_1','rating_2':'$rating_2'}},
    {'$sort':{'_id':1}}
    ])))
    df2.rename(columns = {'_id': 'week'}, inplace = True)
    df2[['week','rating_1','rating_2']]
    print(df2,"par_yes")
    df10 = DataFrame(list(collection.aggregate([
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lt':startend}}    ,         
    {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    
    
    }},
    {'$project':{'_id':1, 'rating_1':'$rating_1','rating_2':'$rating_2'}},
    {'$sort':{'_id':1}}
    ])))
    df10.rename(columns = { '_id': 'week'}, inplace = True)
    df10[['week','rating_1','rating_2']]
    print(df10,"teach_lastweek")
    df20 = DataFrame(list(collection.aggregate([
     {"$match":{'$and':[
         {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER.IS_DISABLED":{"$ne":"Y"}},
         { "USER.IS_BLOCKED":{"$ne":"Y"}},
        { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
           {'MODIFIED_DATE':{'$gte':start_15day, '$lt':startend}}    ,         
        {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    
   
    }},
    {'$project':{'_id':1, 'rating_1':'$rating_1','rating_2':'$rating_2'}},
    {'$sort':{'_id':1}}
        ])))
    df20.rename(columns = { '_id': 'week'}, inplace = True)
    df20[['week','rating_1','rating_2']]
    print(df20,"par_lastweek")
    teachers_yes=df1.values.tolist()
    par_yes=df2.values.tolist()
    teach_lastweek=df10.values.tolist()
    par_lastweek=df20.values.tolist()
    weekdata={"rating":["1 STAR","2 STAR"],"teachers_yes":teachers_yes[0][1:],"par_yes":par_yes[0][1:],"teach_lastweek":teach_lastweek[0][1:],"par_lastweek":par_lastweek[0][1:]}
    
    temp={'weekdata':weekdata}
    return json.dumps(temp)


@app.route('/teacher_signup_table_daily')
def teacher_signup_table():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today
    start= tod-timedelta(days=1)
    yester= yesterday
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte':yester , '$lt':tod
#     }},
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
     'PRACTICE_DATE':{'$first':'$MODIFIED_DATE'}, 
     'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
    }}, 

    {'$sort':{'_id':1}}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},                    
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':yester
                , '$lt': tod}}
    ]}},
         {'$project':{'_id':'$_id','CREATED_DATE':'$CREATED_DATE', 'schoolNAME':'$schoolId.NAME',
                      'USER_NAME':'$USER_NAME','EMAIL':'$EMAIL_ID',
                     'COUNTRY':'$schoolId.COUNTRY', 'STATE':'$schoolId.STATE', 'CITY':'$schoolId.CITY'
                     }}
    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    df_final= pd.merge(df_um,df_atm,how='left', on='_id')
   
    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','PRACTICE_DATE','COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['PRACTICE_DATE']=audio2['PRACTICE_DATE'].dt.strftime('%d %b %Y')
#     audio2['PRACTICE_DATE']=pd.to_datetime(audio2['PRACTICE_DATE'], errors='coerce').dt.time
#     audio2['PRACTICE_DATE']=pd.to_datetime(audio2['PRACTICE_DATE'], format = '%d%b%Y')
    audio2['PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)


    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    
    temp={'data':audio2.values.tolist()}
    return json.dumps(temp)









@app.route('/parents_signup_table_daily')
def signupdataparent():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today
#     + timedelta(hours=4)
    start= tod-timedelta(days=1)
    yester= yesterday
#     +timedelta(hours=4)
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte':yester , '$lt':tod
#     }},
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
     'PRACTICE_DATE':{'$first':'$MODIFIED_DATE'}, 
     'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
    }}, 

    {'$sort':{'_id':1}}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                    
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':yester
                , '$lt': tod}}
    ]}},
         {'$project':{'_id':'$_id','CREATED_DATE':'$CREATED_DATE', 'schoolNAME':'$schoolId.NAME',
                      'USER_NAME':'$USER_NAME','EMAIL':'$EMAIL_ID',
                     'COUNTRY':'$schoolId.COUNTRY', 'STATE':'$schoolId.STATE', 'CITY':'$schoolId.CITY',
                
                     }}
         

    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    df_final= pd.merge(df_um,df_atm,how='left', on='_id')
   
    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','PRACTICE_DATE','COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['PRACTICE_DATE']=audio2['PRACTICE_DATE'].dt.strftime('%d %b %Y')
#     audio2['PRACTICE_DATE']=pd.to_datetime(audio2['PRACTICE_DATE'], errors='coerce').dt.time
#     audio2['PRACTICE_DATE']=pd.to_datetime(audio2['PRACTICE_DATE'], format = '%d%b%Y')
    audio2['PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)


    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

   
    temp={'data':audio2.values.tolist()}
    return json.dumps(temp)





# ===================uwba====
@app.route('/uwbaheatmappractices/')

def UWBA_heatmap_prac():

    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},

                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},

                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'}}},
                      {'$project':{'_id':1,'schools':'$ID'}},

                      ])))

    ids=list(df['_id'])
    
    
    df3=DataFrame(list(collection.aggregate([
{"$match":
    {'$and': [

         
        {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
{'USER_ID.schoolId._id':{'$in':ids}},


 {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,1,1)}},]}},


        {'$group':{'_id':'$USER_ID.schoolId._id','uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
              {'$project':{'_id':1,'active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
    { '$sort' : { 'active_user_count' : -1} },
    {'$limit':30}])))
    top=list(df3['_id'])
#     print(df3)
#     df3.to_csv('file1.csv')
    df2=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            
#              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':top}},
    # {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
  
     {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,1,1)}},]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'school':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'name':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    # df2

    df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        finaldf = pd.concat(result)
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =practice_count
    data=collections.OrderedDict(sorted(data.items()))
    data={'meanTemp':data}

    
    return json.dumps(data)    

@app.route('/uwba_schoolwisefamilypracticecount_/')
def UWBA_schppcfamily():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass  
    collection = db.audio_track_master
    collection1 = db.user_master
#     district=disdic[districtid]
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {'USER_ID.schoolId._id':{'$ne':None}},
                      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#               {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},

    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'practice_count':'$pc'}},
            { '$sort' : { 'practice_count' : -1}}
    # //               {'$count':'count'}
                  ])))
    df2=DataFrame(list(collection1.aggregate([{"$match":
     {'$and': [
           {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                  {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},

             {'EMAIL_ID':{'$ne':''}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'name':{'$first':'$schoolId.NAME'},'user_name':{'$first':'$USER_NAME'}
                  }},


        {'$project':{'_id':1,'name':1}},])))

    df=pd.merge(df1,df2, how='left', on='_id')
    
    if df.empty == True:
        
        schname=[]
        pc=[]
      
    else:
        schname=df['name'].tolist()
        pc=df['practice_count'].tolist()
    data={'schname':schname[0:20],'Familypracticecount':pc[0:20]}
    
    return json.dumps(data)

@app.route('/uwba_schoolwisefamilycount_/')
def uwba__schpuc():
   
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection= db.user_master
#     district=disdic[districtid]
    df = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                      {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
                 {'EMAIL_ID':{'$ne':''}},
#                    {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'user_count':{'$size':'$ID'},'name':'$NAME','district':'$district'}},
                   { '$sort' : { 'user_count' : -1}}
    # //               {'$count':'count'}
                  ])))

    # df['SCH_CREATED_DATE']=pd.to_datetime(df['SCH_CREATED_DATE'])

#     df=df.nlargest(20,'user_count')
#     df= df.groupby(df['district'])
#     df= df.get_group(''+district+'')


    if df.empty == True:
        
        schname=[]
        uc=[]
      
    else:
        schname=df['name'].tolist()
        uc=df['user_count'].tolist()
    
    

    data={'schname':schname[0:20],'Familycount':uc[0:20]}
    
    return json.dumps(data)


@app.route('/uwba_schoolwisepracticecounttop20_/')
def uwbachwisepc():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection1 = db.user_master
#     district=disdic[districtid]
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {'USER_ID.schoolId._id':{'$ne':None}},
                      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#               {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},

    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'practice_count':'$pc'}},
            { '$sort' : { 'practice_count' : -1}}
    # //               {'$count':'count'}
                  ])))
    df2=DataFrame(list(collection1.aggregate([{"$match":
     {'$and': [
           {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                  {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},

             {'EMAIL_ID':{'$ne':''}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$schoolId._id'},'name':{'$first':'$schoolId.NAME'},'user_name':{'$first':'$USER_NAME'}
                  }},


        {'$project':{'_id':1,'name':1}},])))

    df=pd.merge(df1,df2, how='left', on='_id')
#     print(df)
    if df.empty == True:
        
        schname=[]
        pc=[]
      
    else:
        schname=df['name'].tolist()
        pc=df['practice_count'].tolist()
    data={'schname':schname[0:20],'Familypracticecount':pc[0:20]}
    
    return json.dumps(data)

@app.route('/uwba_top20userspractisinginfo_/')
def uwba__topusers_practice():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
#     district=disdic[districtid]


    collection1 = db.user_master
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
    #           {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
             {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},

             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':'$USER_ID._id','pc':{'$sum':1}}},
              {'$project':{'_id':1,'practice_count':'$pc'}},
    { '$sort' : { 'practice_count' : -1} }



    # //               {'$count':'count'}
              ])))
    df1

    df2=DataFrame(list(collection1.aggregate([{"$match":
     {'$and': [
    #         {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                  {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},

             {'EMAIL_ID':{'$ne':''}},
             {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$_id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'user_name':{'$first':'$USER_NAME'}
                  }},


        {'$project':{'_id':1,'user_name':1,'school_name':1}},])))

    df=pd.merge(df1,df2, how='left', on='_id')
    df
    if df.empty == True:

        schname=[]
        pc=[]

    else:
        df["users"] = df["user_name"] +','+' ' + df["school_name"]
        schname=df['users'].tolist()
        pc=df['practice_count'].tolist()



    #     data=[]    
    #     for i,k in zip(schname,uc):

    #         data.append([i,k])

    #     for i in range(len(schname)):
    #             schname[i] = schname[i]
    data={'schname':schname[0:20],'practicecount':pc[0:20]}

    return json.dumps(data)

@app.route('/uwba_schoolwiseusercounttop20_/')
def uwba__schwiseuc():
   
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass  
    collection = db.user_master
#     district=disdic[districtid]
    df = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
#                 {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                      {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
#                    {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#                  {'DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'user_count':{'$size':'$ID'},'name':'$NAME','district':'$district'}},
                   { '$sort' : { 'user_count' : -1}}
    # //               {'$count':'count'}
                  ])))

    # df['SCH_CREATED_DATE']=pd.to_datetime(df['SCH_CREATED_DATE'])

#     df=df.nlargest(20,'user_count')
#     df= df.groupby(df['district'])
#     df= df.get_group(''+district+'')

    if df.empty == True:
        
        schname=[]
        pc=[]
      
    else:
        schname=df['name'].tolist()
        uc=df['user_count'].tolist()
   
    data={'schname':schname[0:20],'usercount':uc[0:20]}
    
    return json.dumps(data)

@app.route('/monthwisepracticeuwba')
def uwba__monthwisepc():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
#     district=disdic[districtid]
    df = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
    #           {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
    # //             {'USER_ID.IS_PORTAL':'Y'},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
#                {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
#              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
         {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'practice_count':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))


    df.rename(columns = { '_id': 'Month'}, inplace = True)

    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 


# Create the pandas DataFrame 
    df1 = pd.DataFrame(data, columns = ['Monthname', 'Month']) 

    DF=pd.merge(df1,df, on='Month',how='left')
    DF=DF.fillna(0)

#         d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname

#         try:
#             df['Month'] = df['Month'].map(d)
#         except:
#             pass

#         if df.empty == True:
#             Month=['Aug','Sep','Oct','Nov','Dec','Jan','Feb','Mar','Apr','May','Jun','Jul',]

#             pc=[0,0,0,0,0,0,0,0,0,0,0,0]
#         else:
    Month=DF['Monthname'].tolist()

    pc=DF['practice_count'].tolist()


    data={'monthname':Month,'practice_count':pc}
    return json.dumps(data)



@app.route('/uwbapartnercardsinfo_/')
def uwba_count_cards():
    from datetime import datetime
    from datetime import timedelta
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection1 = db.user_master
    collection2=db.audio_track_master
    collection3=db.login_logs
#     district=disdic[districtid]
#     print(district)
    df1 = DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                  {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
#                  {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
             {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
    #              {'DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','ID':{'$addToSet':'$schoolId._id'},'dn':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'school_count':{'$size':'$ID'},'district':'$dn'}}
                  ])))
    df2 = DataFrame(list(collection1.aggregate([ {"$match":
         {'$and': [
              {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2a")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                  {'IS_PORTAL':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
#                  {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','ID':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':1,'teacher_count':{'$size':'$ID'}}}
                  ])))
    df5 = DataFrame(list(collection1.aggregate([ {"$match":
         {'$and': [
              {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                  {'IS_PORTAL':'Y'},
                  {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
                 {'EMAIL_ID':{'$ne':''}},
#                  {'DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','ID':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':1,'family_count':{'$size':'$ID'}}}
                  ])))
    today1= datetime.utcnow()
    tod1= today1+ timedelta(hours=4)
    start1= tod1-timedelta(days=30)
    df3=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
    # //          {'ROLE_ID._id' :{'$':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
                 {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions':'$pc','MINDFUL_MINUTES':'$MINDFUL_MINUTES'}}])))
   

    df4=DataFrame(list(collection3.aggregate([{"$match":
         {'$and': [
    #           {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {'USER_ID.schoolId._id':{'$ne':None}},
    # //               {'IS_ADMIN':'Y'},
                  {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Broward County Public Schools'},
                 {'LAST_LOGGED_IN':{'$gte':start1}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1}}},
                  {'$project':{'_id':1,'logins':'$pc'}}])))
    df6=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
                 {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions_t':'$pc'}}])))
   
    df7=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
             {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                               {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'UWBA', '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
                 {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions_p':'$pc'}}])))
   

    sc=[0]
    try:
        sc=df1['school_count']
    except:
        sc=[0]
        
    tc=[0]
    try:
        tc=df2['teacher_count']
    except:
        tc=[0]
    
    pct=[0]
    try:
        pct=df6['practice_sessions_t']
    except:
        pct=[0]
    pcp=[0]
    try:
        pcp=df7['practice_sessions_p']
    except:
        pcp=[0]
    mm=[0]
    try:
        mm=df3['MINDFUL_MINUTES']
    except:
        mm=[0]
    
    lc=[0]
    try:
        lc=df4['logins']
    except:
        lc=[0]
        
    fc=[0]
    try:
        fc=df5['family_count']
    except:
        fc=[0]
    
    
    
    
    dn=[0]
    try:
        dn=df1['district']
    except:
        dn=[0]
    
    
#     print(lc)
    
    data={"schoolcount":str(sc[0]),"teachercount":str(tc[0]),"familycount":str(fc[0]),"teacherpracticecount":str(pct[0]),"parentspracticecount":str(pcp[0]),"logincount":str(lc[0]),
          'MINDFUL_MINUTES':str(mm[0]),'district':'UWBA Works'}
    return json.dumps(data)





# ===============






#testt
@app.route('/dayofweekpractparandteach')
def practice_PARandTeacherchart():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today
#     + timedelta(hours=4)
    start= tod-timedelta(days=1)
    yester= yesterday
#     +timedelta(hours=4)
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    #     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester , '$lt':tod
    }},
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_WEEK_PRACTICE_parents':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
    df_atm
    df_atm.rename(columns = { '_id': 'DAY_OF_WEEK'}, inplace = True)
    LAST_WEEK_PRACTICE_parents=df_atm[['DAY_OF_WEEK','LAST_WEEK_PRACTICE_parents']]
    print(LAST_WEEK_PRACTICE_parents)

    qr2=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    #         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start_15day
                    , '$lt': startend}}
        ]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_TO_LAST_WEEK_PRACTICE_parents':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list2= list(collection1.aggregate(qr2))
    df_at2m= DataFrame(list2)
    df_at2m.rename(columns = { '_id': 'DAY_OF_WEEK'}, inplace = True)

    LAST_TO_LAST_WEEK_PRACTICE_parents=df_at2m[['DAY_OF_WEEK','LAST_TO_LAST_WEEK_PRACTICE_parents']]
    print(LAST_TO_LAST_WEEK_PRACTICE_parents)

    # join_final= pd.merge(LAST_WEEK_PRACTICE_parents, LAST_TO_LAST_WEEK_PRACTICE_parents, on='_id', how='left')    
    # =========================================
    qr3=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester , '$lt':tod
    }},
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_WEEK_PRACTICE_TEACHERS':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list3= list(collection1.aggregate(qr3))
    df_atm3= DataFrame(list3)
    df_atm3.rename(columns = { '_id': 'DAY_OF_WEEK'}, inplace = True)

    LAST_WEEK_PRACTICE_TEACHERS=df_atm3[['DAY_OF_WEEK','LAST_WEEK_PRACTICE_TEACHERS']]
    print(LAST_WEEK_PRACTICE_TEACHERS)



    qr4=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start_15day
                    , '$lt': startend}}
        ]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_TO_LAST_WEEK_PRACTICE_teachers':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list4= list(collection1.aggregate(qr4))
    df_atm4= DataFrame(list4)
    df_atm4.rename(columns = { '_id': 'DAY_OF_WEEK'}, inplace = True)
    LAST_TO_LAST_WEEK_PRACTICE_teachers=df_atm4[['DAY_OF_WEEK','LAST_TO_LAST_WEEK_PRACTICE_teachers']]
    print(LAST_TO_LAST_WEEK_PRACTICE_teachers)

    LAST_WEEK_PRACTICE_parents= df_atm.values.tolist()
    LAST_TO_LAST_WEEK_PRACTICE_parents=df_at2m.values.tolist()
    LAST_WEEK_PRACTICE_TEACHERS=df_atm3.values.tolist()
    LAST_TO_LAST_WEEK_PRACTICE_teachers=df_atm4.values.tolist()

    weekdata={"week":["MONDAY","TUESDAY","WEDNESDAY","THURSDAY","FRIDAY", "SATURDAY", "SUNDAY"],
              "LAST_WEEK_PRACTICE_parents":LAST_WEEK_PRACTICE_parents[0][1:],
              "LAST_TO_LAST_WEEK_PRACTICE_parents":LAST_TO_LAST_WEEK_PRACTICE_parents[0][1:],
              "LAST_WEEK_PRACTICE_TEACHERS":LAST_WEEK_PRACTICE_TEACHERS[0][1:],
              "LAST_TO_LAST_WEEK_PRACTICE_teachers":LAST_TO_LAST_WEEK_PRACTICE_teachers[0][1:]}

    temp={'weekdata':weekdata}
    return json.dumps(temp)





# WEEKLY COMPARSION CHART


# WEEKLY PRACTICE CARDS FOR PARENTS, TEACHERS AND TOTAL #test1
@app.route('/playback_cards_week')
def practice_cards_weeklyPandT():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    # todaydate=today.strftime("%Y-%m-%d")
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)

    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    
    print(today,"today")
    tod= today+ timedelta(hours=4)
# yester-timedelta(days=8)
    start= tod-timedelta(days=8)+timedelta(days=1)
    yester= yesterday+timedelta(hours=4)+timedelta(days=1)
    start_15day=tod-timedelta(days=15)+timedelta(days=1)

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gt':start , '$lte':yester}}
    ]}},
    {'$group':{'_id':'null', 
    'parents_playback_last_week': {'$sum':{'$cond':[{'$eq':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_last_week': {'$sum':{'$cond':[{'$ne':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_last_week': {'$sum':1}                  
    }}]
    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
    df_atm1=df_atm[['parents_playback_last_week', 'teachers_playback_last_week','total_playback_last_week']]
    qr2=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start_15day
                , '$lt': start}}
    ]}},
    {'$group':{'_id':'null', 
    'parents_playback_last_to_lastweek': {'$sum':{'$cond':[{'$eq':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_last_to_lastweek': {'$sum':{'$cond':[{'$ne':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_last_to_lastweek': {'$sum':1}            
    }}]
    list2= list(collection1.aggregate(qr2))
    df_atm= DataFrame(list2)
    df_atm2=df_atm[['parents_playback_last_to_lastweek', 'teachers_playback_last_to_lastweek','total_playback_last_to_lastweek']]
    
    
    parentschange=[]
    parents_percentage_change=[]
    if df_atm2['parents_playback_last_to_lastweek'].iloc[0] > df_atm1['parents_playback_last_week'].iloc[0]:
        xx=df_atm2['parents_playback_last_to_lastweek'].iloc[0]-df_atm1['parents_playback_last_week'].iloc[0]
        yy= xx/df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('-1')
        parents_percentage_change.append(zz)

    elif df_atm2['parents_playback_last_to_lastweek'].iloc[0] == df_atm1['parents_playback_last_week'].iloc[0]:
        xx=df_atm2['parents_playback_last_to_lastweek'].iloc[0]-df_atm1['parents_playback_last_week'].iloc[0]
        yy= xx/df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('0')
        parents_percentage_change.append(zz)
        
    else:
        xx=df_atm1['parents_playback_last_week'].iloc[0]-df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm1['parents_playback_last_week'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('1')
        parents_percentage_change.append(zz)

    
    
    teacherschange=[]
    teachers_percentage_change=[]
    if df_atm2['teachers_playback_last_to_lastweek'].iloc[0] > df_atm1['teachers_playback_last_week'].iloc[0]:
        xx=df_atm2['teachers_playback_last_to_lastweek'].iloc[0]-df_atm1['teachers_playback_last_week'].iloc[0]
        yy= xx/df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('-1')
        teachers_percentage_change.append(zz)

    elif df_atm2['teachers_playback_last_to_lastweek'].iloc[0] == df_atm1['teachers_playback_last_week'].iloc[0]:
        xx=df_atm2['teachers_playback_last_to_lastweek'].iloc[0]-df_atm1['teachers_playback_last_week'].iloc[0]
        yy= xx/df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('0')
        teachers_percentage_change.append(zz)

    else:
        xx=df_atm1['teachers_playback_last_week'].iloc[0]-df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm1['teachers_playback_last_week'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('1')
        teachers_percentage_change.append(zz)

    
    
    totalchange=[]
    total_percentage_change=[]
    if df_atm2['total_playback_last_to_lastweek'].iloc[0] > df_atm1['total_playback_last_week'].iloc[0]:
        xx=df_atm2['total_playback_last_to_lastweek'].iloc[0]-df_atm1['total_playback_last_week'].iloc[0]
        yy= xx/df_atm2['total_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('-1')
        total_percentage_change.append(zz)
        
    elif df_atm2['total_playback_last_to_lastweek'].iloc[0] == df_atm1['total_playback_last_week'].iloc[0]:
        xx=df_atm2['total_playback_last_to_lastweek'].iloc[0]-df_atm1['total_playback_last_week'].iloc[0]
        yy= xx/df_atm2['total_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('0')
        total_percentage_change.append(zz)

    else:
        xx=df_atm1['total_playback_last_week'].iloc[0]-df_atm2['total_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm1['total_playback_last_week'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('1')
        total_percentage_change.append(zz)
        
        
    data=pd.DataFrame({'parents_playback_last_week':df_atm1['parents_playback_last_week'].tolist(),
                       'teachers_playback_last_week':df_atm1['teachers_playback_last_week'].tolist(),
    'total_playback_last_week':df_atm1['total_playback_last_week'].tolist(),
                       'parentschange':parentschange,'parents_percentage_change':parents_percentage_change,
                       'teacherschange':teacherschange, 'teachers_percentage_change':teachers_percentage_change,
          'totalchange':totalchange, 'total_percentage_change':total_percentage_change})  
    
    
    temp2={}
    for j in range(len(data.columns)):
        key= data.columns[j]
        value=[str(data[data.columns[j]].iloc[0])]
        temp2.update({key:value})
        
        
    return json.dumps(temp2)





@app.route('/newsignupsss') #test4
def newweekcomparison():
    username= urllib.parse.quote_plus('admin')
    password= urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.user_master
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)
    qr1=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    #     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start , '$lt':yester
    }},
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$CREATED_DATE'}, 
    'LAST_WEEK_PRACTICE_parents':{'$sum':1}
    }}, {'$sort':{'_id':1}}
    ]
    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
    df_atm
    LAST_WEEK_PRACTICE_parents=df_atm[['_id','LAST_WEEK_PRACTICE_parents']]
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    #         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start_15day
                , '$lt': start}}
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$CREATED_DATE'}, 
    'LAST_TO_LAST_WEEK_PRACTICE_parents':{'$sum':1}
    }}, {'$sort':{'_id':1}}
    ]
    list2= list(collection1.aggregate(qr2))
    df_at2m= DataFrame(list2)
    LAST_TO_LAST_WEEK_PRACTICE_parents=df_at2m[['_id','LAST_TO_LAST_WEEK_PRACTICE_parents']]
    join_final= pd.merge(LAST_WEEK_PRACTICE_parents, LAST_TO_LAST_WEEK_PRACTICE_parents, on='_id', how='left')    
    # =========================================
    qr3=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start , '$lt':yester
    }},
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$CREATED_DATE'}, 
    'LAST_WEEK_PRACTICE_TEACHERS':{'$sum':1}
    }}, {'$sort':{'_id':1}}
    ]
    list3= list(collection1.aggregate(qr3))
    df_atm3= DataFrame(list3)
    df_atm3
    LAST_WEEK_PRACTICE_TEACHERS=df_atm3[['_id','LAST_WEEK_PRACTICE_TEACHERS']]
    qr4=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'IS_BLOCKED':{"$ne":'Y'}}, 
            {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start_15day
                , '$lt': start}}
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$CREATED_DATE'}, 
    'LAST_TO_LAST_WEEK_PRACTICE_teachers':{'$sum':1}
    }}, {'$sort':{'_id':1}}
    ]
    list4= list(collection1.aggregate(qr4))
    df_atm4= DataFrame(list4)
    LAST_TO_LAST_WEEK_PRACTICE_teachers=df_atm4[['_id','LAST_TO_LAST_WEEK_PRACTICE_teachers']]
    join_final= pd.merge(LAST_WEEK_PRACTICE_TEACHERS, LAST_TO_LAST_WEEK_PRACTICE_teachers, on='_id', how='left')    
    weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],
    "count_last_week_parents":[str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][0]),str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][1]),
    str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][2]),str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][3]),
    str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][4]),str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][5]),str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][6])],
    'count_last_to_lastweek_parents':[str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][0]),str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][1]),
    str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][2]),str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][3]),
    str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][4]),str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][5]),str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][6])],
    'count_last_week_teachers': [str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][0]),str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][1]),
    str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][2]),str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][3]),
    str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][4]),str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][5]),str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][6])],
    'count_last_to_last_week_teachers':[str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][0]),str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][1]),
    str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][2]),str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][3]),
    str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][4]),str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][5]),str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][6])],
    }
    temp={'weekdata':weekdata}
    return json.dumps(temp)


@app.route('/SIGNUPS_WEEK') #test3
def SIGNUP_cards_WEEK():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.user_master
    yesterday= datetime.datetime.now(tz=datetime.timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)+timedelta(days=1)
    yester= yesterday+timedelta(hours=4)+timedelta(days=1)
    start_15day=tod-timedelta(days=15)+timedelta(days=1)
    startend= start_15day+timedelta(days=1)
    qr1=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gt':start , '$lte':yester}}

    ]}},
    {'$group':{'_id':'null', 
    'parents_playback_last_week': {'$sum':{'$cond':[{'$eq':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_last_week': {'$sum':{'$cond':[{'$ne':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_last_week': {'$sum':1}            
    }}]
    
    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
    df_atm1=df_atm[['parents_playback_last_week', 'teachers_playback_last_week','total_playback_last_week']]
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start_15day
            , '$lt': start}}
    ]}},
    {'$group':{'_id':'null', 
    'parents_playback_last_to_lastweek': {'$sum':{'$cond':[{'$eq':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_last_to_lastweek': {'$sum':{'$cond':[{'$ne':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_last_to_lastweek': {'$sum':1}            
    }}]
    list2= list(collection1.aggregate(qr2))
    df_atm= DataFrame(list2)
    df_atm2=df_atm[['parents_playback_last_to_lastweek', 'teachers_playback_last_to_lastweek','total_playback_last_to_lastweek']]
    
    parentschange=[]
    parents_percentage_change=[]
    if df_atm2['parents_playback_last_to_lastweek'].iloc[0] > df_atm1['parents_playback_last_week'].iloc[0]:
        xx=df_atm2['parents_playback_last_to_lastweek'].iloc[0]-df_atm1['parents_playback_last_week'].iloc[0]
        yy= xx/df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('-1')
        parents_percentage_change.append(zz)
        
    elif df_atm2['parents_playback_last_to_lastweek'].iloc[0] == df_atm1['parents_playback_last_week'].iloc[0]:
        xx=df_atm2['parents_playback_last_to_lastweek'].iloc[0]-df_atm1['parents_playback_last_week'].iloc[0]
        yy= xx/df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('0')
        parents_percentage_change.append(zz)

    else:
        xx=df_atm1['parents_playback_last_week'].iloc[0]-df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm1['parents_playback_last_week'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('1')
        parents_percentage_change.append(zz)
        
        
    teacherschange=[]
    teachers_percentage_change=[]
    if df_atm2['teachers_playback_last_to_lastweek'].iloc[0] > df_atm1['teachers_playback_last_week'].iloc[0]:
        xx=df_atm2['teachers_playback_last_to_lastweek'].iloc[0]-df_atm1['teachers_playback_last_week'].iloc[0]
        yy= xx/df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('-1')
        teachers_percentage_change.append(zz)
        
    elif df_atm2['teachers_playback_last_to_lastweek'].iloc[0] == df_atm1['teachers_playback_last_week'].iloc[0]:
        xx=df_atm2['teachers_playback_last_to_lastweek'].iloc[0]-df_atm1['teachers_playback_last_week'].iloc[0]
        yy= xx/df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('0')
        teachers_percentage_change.append(zz)
    
    else:
        xx=df_atm1['teachers_playback_last_week'].iloc[0]-df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm1['teachers_playback_last_week'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('1')
        teachers_percentage_change.append(zz)
        
        
    totalchange=[]
    total_percentage_change=[]
    
    if df_atm2['total_playback_last_to_lastweek'].iloc[0] > df_atm1['total_playback_last_week'].iloc[0]:
        xx=df_atm2['total_playback_last_to_lastweek'].iloc[0]-df_atm1['total_playback_last_week'].iloc[0]
        yy= xx/df_atm2['total_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('-1')
        total_percentage_change.append(zz)
        
    elif df_atm2['total_playback_last_to_lastweek'].iloc[0] == df_atm1['total_playback_last_week'].iloc[0]:
        xx=df_atm2['total_playback_last_to_lastweek'].iloc[0]-df_atm1['total_playback_last_week'].iloc[0]
        yy= xx/df_atm2['total_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('0')
        total_percentage_change.append(zz)
        
    else:
        xx=df_atm1['total_playback_last_week'].iloc[0]-df_atm2['total_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm1['total_playback_last_week'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('1')
        total_percentage_change.append(zz)

    data=pd.DataFrame({'parents_signup_last_week':df_atm1['parents_playback_last_week'].tolist(),
                       'teachers_signup_last_week':df_atm1['teachers_playback_last_week'].tolist(),
    'total_signup_last_week':df_atm1['total_playback_last_week'].tolist(),
                       'parentschanged':parentschange, 'parents_percentage_change':parents_percentage_change,
                       'teacherschanged':teacherschange, 'teachers_percentage_change':teachers_percentage_change,
          'totalchanged':totalchange, 'total_percentage_change':total_percentage_change})  
    temp2={}
    for j in range(len(data.columns)):
        key= data.columns[j]
        value=[str(data[data.columns[j]].iloc[0])]
        temp2.update({key:value})
    return json.dumps(temp2)




@app.route('/Weekly_power_users_having_streaks')
def power_users_weekly__():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)+timedelta(days=1)
    yester= yesterday+timedelta(hours=4)+timedelta(days=1)
    start_15day=tod-timedelta(days=15)+timedelta(days=1)

    now= datetime.datetime.now()- timedelta(hours=5.5)

    collection= db.audio_track_master
    qratm=[{"$match":
             {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                 {'MODIFIED_DATE':{'$gte':start, '$lt':yester}},

                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{'$ne':''}},
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'USER_ID':'$USER_ID._id',
                      'EMAIL_ID':'$USER_ID.EMAIL_ID',
        'PRACTICE_DATE':'$MODIFIED_DATE'},
        }},
        ]
    bifur= list(collection.aggregate(qratm))
    blah=DataFrame(bifur)
    #     df1= blah['_id']
    df_1 = pd.json_normalize(blah['_id'])
    df_final = pd.concat([blah,df_1], axis =  1)
    df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final['date_now']= yester.strftime("%Y-%m-%d")
    df_final['PRACTICE_DATE'] = pd.to_datetime(df_final['PRACTICE_DATE'])
    df_final['date_now'] = pd.to_datetime(df_final['date_now'])
    df_final['days'] = (df_final['date_now'] - df_final['PRACTICE_DATE']).dt.days
    df_final1=df_final[['USER_ID','PRACTICE_DATE','EMAIL_ID','days']]
    date_list=df_final1.PRACTICE_DATE.tolist()
    # streak_empty=[]
    days=[]
    for k in range(len(date_list)):
        z=(now-date_list[k]).days
        days.append(z)
    df_final1['days']=days
    df_final2=df_final1.sort_values('PRACTICE_DATE', ascending=True)
    df_final2['PRACTICE_DATE']=df_final2['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final3= df_final2.groupby(['USER_ID', 'PRACTICE_DATE']).agg({'days':['max']})
    df_final3.columns=['days_max']
    df_final3= df_final3.reset_index()
    df_final3.sort_values('PRACTICE_DATE', ascending=True)
    #     df_final3.isnull().sum()
    df1 = df_final3.groupby('USER_ID')['days_max'].apply(list).reset_index(name='grouping')
    list_of_list=df1.grouping.tolist()
    def streak_count_function(streak_list):
        streak_list.sort()
        streak_count=[]
        counter = 1
        for i in range(len(streak_list)):
            if i != (len(streak_list) - 1):
                diff = streak_list[i+1] - streak_list[i]
                if diff == 1:
                    counter += 1
                else:
                    streak_count.append(counter)
                    counter = 1
            else:
                streak_count.append(counter)
        return(max(streak_count)) 
    streak_empty=[]
    for i in range(len(list_of_list)):
        streak_empty.append(streak_count_function(list_of_list[i]))
    df1['streak_frequencyy']=streak_empty
    df22=df1.groupby(['streak_frequencyy'], as_index=False)['USER_ID'].count()
    df22 = df22.reset_index(drop=True)
    dataframe=pd.DataFrame(df22)
    dataframe.rename(columns={'USER_ID':'Number_of_classroom_users_having_streak','streak_frequencyy':'STREAK'},inplace=True)
    dfff=dataframe.sort_values('STREAK', ascending=False)
    # =====================
    collection= db.audio_track_master
    qratmm=[{"$match":
             {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                 {'MODIFIED_DATE':{'$gte':start, '$lt':yester}},

                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{'$ne':''}},
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'USER_ID':'$USER_ID._id',
                      'EMAIL_ID':'$USER_ID.EMAIL_ID',
        'PRACTICE_DATE':'$MODIFIED_DATE'},
        }},
        ]
    present= list(collection.aggregate(qratmm))
    blahhh=DataFrame(present)
    #     df1= blah['_id']
    df_11 = pd.json_normalize(blahhh['_id'])
    df_final_11 = pd.concat([blahhh,df_11], axis =  1)
    df_final_11['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final_11['date_now']= now.strftime("%Y-%m-%d")
    df_final_11['PRACTICE_DATE'] = pd.to_datetime(df_final_11['PRACTICE_DATE'])
    df_final_11['date_now'] = pd.to_datetime(df_final_11['date_now'])
    df_final_11['days'] = (df_final_11['date_now'] - df_final_11['PRACTICE_DATE']).dt.days
    df_final_11_11=df_final_11[['USER_ID','PRACTICE_DATE','EMAIL_ID','days']]
    date_list_=df_final_11_11.PRACTICE_DATE.tolist()
    # streak_empty=[]
    daysss=[]
    for k in range(len(date_list_)):
        z=(now-date_list_[k]).days
        daysss.append(z)
    df_final_11['daysss']=daysss
    df_final22=df_final_11.sort_values('PRACTICE_DATE', ascending=True)
    df_final22['PRACTICE_DATE']=df_final22['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final33= df_final22.groupby(['USER_ID', 'PRACTICE_DATE']).agg({'days':['max']})
    df_final33.columns=['days_max']
    df_final33= df_final33.reset_index()
    df_final33.sort_values('PRACTICE_DATE', ascending=True)
    #     df_final3.isnull().sum()
    df1111 = df_final33.groupby('USER_ID')['days_max'].apply(list).reset_index(name='grouping')
    list_of_list_=df1111.grouping.tolist()
    def streak_count_function_present(streak_list_):
        streak_list_.sort()
        streak_count_=[]
        counter = 1
        for i in range(len(streak_list_)):
            if i != (len(streak_list_) - 1):
                diff = streak_list_[i+1] - streak_list_[i]
                if diff == 1:
                    counter += 1
                else:
                    streak_count_.append(counter)
                    counter = 1
            else:
                streak_count_.append(counter)
        return(max(streak_count_)) 
    streak_emptyy=[]
    for i in range(len(list_of_list_)):
        streak_emptyy.append(streak_count_function_present(list_of_list_[i]))
    df1111['streak_frequencyy']=streak_emptyy
    df2222=df1111.groupby(['streak_frequencyy'], as_index=False)['USER_ID'].count()
    df2222 = df2222.reset_index(drop=True)
    dataframe11=pd.DataFrame(df2222)
    dataframe11.rename(columns={'USER_ID':'Number_of_present_users_having_streak','streak_frequencyy':'STREAK'},inplace=True)
    dfff11=dataframe11.sort_values('STREAK', ascending=False)
    final=dfff11.merge(dfff, on='STREAK', how='outer')
    power_user_streaks=final.sort_values('STREAK').reset_index(drop=True)
    power_user_streaks['Number_of_present_users_having_streak']=power_user_streaks['Number_of_present_users_having_streak'].fillna(0)
    power_user_streaks['Number_of_classroom_users_having_streak']=power_user_streaks['Number_of_classroom_users_having_streak'].fillna(0)
    ACTIVETREND={'STREAK':power_user_streaks['STREAK'].values.tolist(),'line':power_user_streaks['Number_of_present_users_having_streak'].values.tolist(),'bar':power_user_streaks['Number_of_classroom_users_having_streak'].values.tolist()}
    ACTIVETREND=[ACTIVETREND]
    return json.dumps(ACTIVETREND)



# @app.route('/AVG_audio_completion_weekly_less_50')
# def avg_audio_completed_less_():

#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
#     db=client.compass
#     collection1= db.audio_track_master
#     # datetime.datetime.now() - datetime.timedelta(days=7)
#     # ar d = new Date();
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     tod= today+ timedelta(hours=4)
#     # yester-timedelta(days=8)
#     start= tod-timedelta(days=8)+timedelta(days=1)
#     yester= yesterday+timedelta(hours=4)+timedelta(days=1)
#     start_15day=tod-timedelta(days=15)+timedelta(days=1)

#     qr1=[{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte': start, '$lt':yester
#     }},
#     ]}},


#     {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
#                  'AUDIO_ID':'$PROGRAM_AUDIO_ID.AUDIO_ID', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
#               'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

#     }}]

#     list1= list(collection1.aggregate(qr1))
#     userprac_trend= DataFrame(list1)

#     userprac_trend.start.fillna(0, inplace=True)

#     userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

#     userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

#     #     userprac_trend_1=userprac_trend[userprac_trend.completed_precentage>=75]
#     # d=userprac_trend.groupby('AUDIO_ID')['completed_precentage'].mean().reset_index()

#     userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

#     # dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)



# #     userprac_trend=userprac_trend[userprac_trend.completed_precentage < 101]
#     userprac_trend[userprac_trend.completed_precentage <= 0]=0
#     # d['completed_precentage']=round(d['completed_precentage'],0)

#     dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

#     dd['cumulativesum_line']= dd['Audio_Count'].cumsum()

#     # dd[dd.completed_precentage< 0]=0


#     percentage_of_audio_completed= dd.completed_precentage.tolist(),
#     number_of_audios_compelted=dd.Audio_Count.tolist()
#     cumulative_audio_completion=dd.cumulativesum_line.tolist()

#     temp={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
#          'cumulative_audio_completion':cumulative_audio_completion}

#     data={'temp':temp}

#     return json.dumps(data)



# @app.route('/AVG_audio_completion_weekly_more_50')
# def avg_audio_completed_more_():

#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
#     db=client.compass
#     collection1= db.audio_track_master
#     # datetime.datetime.now() - datetime.timedelta(days=7)
#     # ar d = new Date();
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     tod= today+ timedelta(hours=4)
#     # yester-timedelta(days=8)
#     start= tod-timedelta(days=8)+timedelta(days=1)
#     yester= yesterday+timedelta(hours=4)+timedelta(days=1)
#     start_15day=tod-timedelta(days=15)+timedelta(days=1)

#     qr1=[{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte': start, '$lt':yester
#     }},
#     ]}},


#     {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
#                  'AUDIO_ID':'$PROGRAM_AUDIO_ID.AUDIO_ID', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
#               'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

#     }}]

#     list1= list(collection1.aggregate(qr1))
#     userprac_trend= DataFrame(list1)

#     userprac_trend.start.fillna(0, inplace=True)

#     userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

#     userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

#     #     userprac_trend_1=userprac_trend[userprac_trend.completed_precentage>=75]
#     # d=userprac_trend.groupby('AUDIO_ID')['completed_precentage'].mean().reset_index()

#     userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

#     # dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)



#     userprac_trend=userprac_trend[userprac_trend.completed_precentage >50]
# #     userprac_trend[userprac_trend.completed_precentage < 0]=0
#     # d['completed_precentage']=round(d['completed_precentage'],0)

#     dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

#     dd['cumulativesum_line']= dd['Audio_Count'].cumsum()

#     # dd[dd.completed_precentage< 0]=0


#     percentage_of_audio_completed= dd.completed_precentage.tolist(),
#     number_of_audios_compelted=dd.Audio_Count.tolist()
#     cumulative_audio_completion=dd.cumulativesum_line.tolist()

#     temp={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
#          'cumulative_audio_completion':cumulative_audio_completion}

#     data={'temp':temp}

#     return json.dumps(data)








@app.route('/comparison1') #test2
def weekly_compare_chart():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)+timedelta(days=1)
    yester= yesterday+timedelta(hours=4)+timedelta(days=1)
    start_15day=tod-timedelta(days=15)+timedelta(days=1)
    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
#     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start , '$lt':yester
    }},
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_WEEK_PRACTICE_parents':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
    df_atm
    LAST_WEEK_PRACTICE_parents=df_atm[['_id','LAST_WEEK_PRACTICE_parents']]
    qr2=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start_15day
                    , '$lt': start}}
        ]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_TO_LAST_WEEK_PRACTICE_parents':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list2= list(collection1.aggregate(qr2))
    df_at2m= DataFrame(list2)
    LAST_TO_LAST_WEEK_PRACTICE_parents=df_at2m[['_id','LAST_TO_LAST_WEEK_PRACTICE_parents']]
    join_final= pd.merge(LAST_WEEK_PRACTICE_parents, LAST_TO_LAST_WEEK_PRACTICE_parents, on='_id', how='left')    
# =========================================
    qr3=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start , '$lt':yester
    }},
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_WEEK_PRACTICE_TEACHERS':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list3= list(collection1.aggregate(qr3))
    df_atm3= DataFrame(list3)
    df_atm3
    LAST_WEEK_PRACTICE_TEACHERS=df_atm3[['_id','LAST_WEEK_PRACTICE_TEACHERS']]
    qr4=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start_15day
                    , '$lt': start}}
        ]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_TO_LAST_WEEK_PRACTICE_teachers':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list4= list(collection1.aggregate(qr4))
    df_atm4= DataFrame(list4)
    LAST_TO_LAST_WEEK_PRACTICE_teachers=df_atm4[['_id','LAST_TO_LAST_WEEK_PRACTICE_teachers']]
    join_final= pd.merge(LAST_WEEK_PRACTICE_TEACHERS, LAST_TO_LAST_WEEK_PRACTICE_teachers, on='_id', how='left')    
    weekdata={"day":['Sunday', 'Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'],
     "count_last_week_parents":[int(str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][0])),int(str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][1])),
       int(str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][2])),int(str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][3])),
    int(str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][4])),int(str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][5])),int(str(LAST_WEEK_PRACTICE_parents['LAST_WEEK_PRACTICE_parents'][6]))],
    'count_last_to_lastweek_parents':[int(str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][0])),int(str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][1])),
    int(str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][2])),int(str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][3])),
    int(str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][4])),int(str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][5])),int(str(LAST_TO_LAST_WEEK_PRACTICE_parents['LAST_TO_LAST_WEEK_PRACTICE_parents'][6]))],
    'count_last_week_teachers': [int(str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][0])),int(str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][1])),
    int(str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][2])),int(str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][3])),
    int(str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][4])),int(str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][5])),int(str(LAST_WEEK_PRACTICE_TEACHERS['LAST_WEEK_PRACTICE_TEACHERS'][6]))],
    'count_last_to_last_week_teachers':[int(str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][0])),int(str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][1])),
    int(str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][2])),int(str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][3])),
    int(str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][4])),int(str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][5])),int(str(LAST_TO_LAST_WEEK_PRACTICE_teachers['LAST_TO_LAST_WEEK_PRACTICE_teachers'][6]))],
    }
    weekdata
    temp={'weekdata':weekdata}
    return json.dumps(temp)



#sarthak_chhavika_end

@app.route('/pschoolsearchchart/<name>')
def school_FAMsearch_mongo1(name):
    name1=name.replace("%20"," ")
    print(name1,"hola")
    from bson.regex import Regex
    from pymongo import MongoClient
    from flask import Flask,json

    import urllib 
    import pandas as pd
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = MongoClient(mongo_uri)
    # client = MongoClient("mongodb://host:port/")
    database = client["compass"]
    collection = database["user_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com
    query = {}
    query["schoolId.NAME"] = name1
    #     query["EMAIL_ID"] = Regex(u".*amorgan@methacton\\.org.*", "i")
    query["USER_NAME"] = {
        u"$not": Regex(u".*TEST.*", "i")
    }
    query["ROLE_ID.ROLE_NAME"] = u"PRESENT"
#     query["IS_BLOCKED"] = {
#         u"$ne": u"Y"
#     }

    query["IS_DISABLED"] = {
        u"$ne": u"Y"
    }

    query["INCOMPLETE_SIGNUP"] = {
        u"$ne": u"Y"
    }

    

    projection = {}
    projection["USER_ID.USER_ID"] = 1.0
    projection["EMAIL_ID"] = 1.0
    projection["CREATED_DATE"] = 1.0

    projection["USER_NAME"] = 1.0
    
    projection["schoolId.ADDRESS"] = 1.0
    projection["schoolId.CITY"] = 1.0
    projection["schoolId.STATE"] = 1.0
    projection["schoolId.COUNTRY"] = 1.0
    projection["schoolId.NAME"] = 1.0

    cursor = collection.find(query, projection = projection)
    dfum=(list(cursor))
#     print(dfum,"usermaster")
    dfum=pd.json_normalize(dfum, max_level=1)
    email=list(dfum['EMAIL_ID'])
#     print(email)
    totaluser=len(email)
    collection = database["audio_track_master"]

#     Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(MODIFIED_DATE)": {
                    u"$max": u"$MODIFIED_DATE"
                },
                u"COUNT(USER_ID\u1390_id)": {
                    u"$sum": 1
                }
            }
        }, 
        {
            u"$project": {
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"MAX(MODIFIED_DATE)": u"$MAX(MODIFIED_DATE)",
                u"COUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfatd=list(cursor)
    dfatd=pd.json_normalize(dfatd, max_level=1)
#     print(dfatd)
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {
            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfsbm=list(cursor)
    dfsbm=pd.json_normalize(dfsbm, max_level=1)
    print(dfatd,"atd pracice data")
    
    try:
        dffinal=pd.merge(dfum,dfatd,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
    except:
        dfum['MAX(MODIFIED_DATE)']='NO PRACTICE'
        dfum['COUNT(USER_ID᎐_id)']=0
        dffinal=dfum
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
        
        
    email=list(dfum['EMAIL_ID'])
    totaluser=len(email)
    dffinalnew['MAX(MODIFIED_DATE)'].fillna("NO PRACTICE", inplace=True)
    dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)'].fillna(" ", inplace=True)
    dffinalnew['COUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
#     pracsum=sum(list(dffinalnew['COUNT(USER_ID᎐_id)']))
    dffinalnew.fillna(value=pd.np.nan, inplace=True)

    MAX=[]
    for i in dffinalnew['MAX(MODIFIED_DATE)']:
        if  i != 'NO PRACTICE' :
            MAX.append(i.strftime("%d %b %Y "))
        else:
            MAX.append("NO PRACTICE")
    SUBSCRIPTION_EXPIRE_DATE=[]
    for i in dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)']:
        if  i != ' ' :
            SUBSCRIPTION_EXPIRE_DATE.append(i.strftime("%d %b %Y "))
        else:
            SUBSCRIPTION_EXPIRE_DATE.append(" ")        
    CREATED_DATE=[]
    for i in dffinalnew['CREATED_DATE']:
        if  i != ' ' :
            CREATED_DATE.append(i.strftime("%d %b %Y "))
        else:
            CREATED_DATE.append(" ")
    data=[]

    for T,k,l,m,o,p in zip(dffinalnew['USER_NAME'].tolist(),dffinalnew['EMAIL_ID'].tolist(),CREATED_DATE,MAX,SUBSCRIPTION_EXPIRE_DATE,dffinalnew['COUNT(USER_ID᎐_id)'].tolist()):
        #print(p,q,r)
        data.append([T,k,l,m,o,p])
    temp={"data":data}
#     ,"school_practice_count":str(card_detail['school_practice_count1'][0])
#     temp={"data":data}
    return json.dumps(temp)


@app.route('/pschoolsearchchart/<school>/<daate>')
def schooluserrdata(school,daate):  
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection3= db.audio_track_master
    query3=[

    {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
     {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},{'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
{'USER_ID.CREATED_DATE':{'$gt':datetime.datetime(2020,3,17)}},{'USER_ID.EMAIL_ID':{'$not':{'$regex':'null', '$options':'i'}}},
        {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
        {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},

    ]}},
    {'$group':{'_id':'$USER_ID.EMAIL_ID',
               'USER_ID':{'$first':'$USER_ID._id'},  
        'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}},
    'Last_Practice_Date':{'$max':'$MODIFIED_DATE'}, 'School_ID':{'$first':'$USER_ID.schoolId._id'},
               'School_NAME':{'$first':'$USER_ID.schoolId.NAME'},
               'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
               'PROGRAM_ID':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID._id'},
               'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
               
               
               
    }}, 
    {'$project':{'_id':1,'USER_NAME':1, 'PROGRAM_ID':1, 'PROGRAM_NAME':1,'School_NAME':1,
        'MINDFUL_MINUTES':1, 'Last_Practice_Date':{"$dateToString": { "format": "%Y-%m-%d", "date": "$Last_Practice_Date" }}
    }}
    ]
    
    atm_ss= list(collection3.aggregate(query3))
    df_atmss= DataFrame(atm_ss)
    
    df_atmss1=df_atmss[['School_NAME','USER_NAME','MINDFUL_MINUTES','PROGRAM_NAME','Last_Practice_Date', '_id']]
    final_group= df_atmss1.groupby(by=['School_NAME', 'Last_Practice_Date'])

    data= final_group.get_group((''+school+'',''+daate+'') )
   
    data1= pd.DataFrame(data)
    temp={'data':data1.values.tolist()}
    return json.dumps(temp)







@app.route('/schoology_cards')
def schoology_cardd():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.audio_track_master

    #dateStr = "2020-03-17T00:00:00.000Z"
    #myDatetime = dateutil.parser.parse(dateStr)

    df = DataFrame(list(collection.aggregate([
    {'$match':{'schoolId._id':{'$exists':1}}},
        {"$match":
                 {"$and":[{'EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}}, 
                          {'EMAIL_ID':{"$ne":""}}, 
        {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_NAME':{"$not":{"$regex":'test','$options':'i'}}}, 
        {'IS_DISABLED':{"$ne":'Y'}},{'IS_BLOCKED':{"$ne":'Y'}},  {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
         {'EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
     {'_id':{'$in':db.schoology_master.distinct('USER_ID._id')}},
     {'DISTRICT_ID.DISTRICT_NAME':{"$not":{"$regex":'test','$options':'i'}}},
         {'ROLE_TYPE':{"$regex":'schoology', '$options':'i'}}
     ]}},

        {"$group":{"_id": "null",
                   'sc':{"$addToSet":'$schoolId._id'}, 
                   'tu':{"$addToSet":'$_id'}}},
        {"$project":{"_id":0, 'School_Count':{"$size":'$sc'}, 
                     'Total_User':{"$size":'$tu'}}}])))
#     del df['_id']



    df1 = DataFrame(list(collection2.aggregate([
    {'$match':{'USER_ID.schoolId._id':{'$exists':1}}},
        {"$match":
                 {"$and":[{'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}}, 
                          {'USER_ID.EMAIL_ID':{"$ne":""}}, 
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}},  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
         {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
     {'USER_ID._id':{'$in':db.schoology_master.distinct('USER_ID._id')}},
         {'USER_ID.ROLE_TYPE':{"$regex":'schoology', '$options':'i'}}
     ]}},
        {"$group":{"_id": "null",
                   'ac':{"$addToSet":'$USER_ID._id'}, 
                   'cs':{"$sum":{"$cond":[{"$eq":['$IS_DONE', 'Y']}, 1,0]}}}},
        {"$project":{"_id":0,
                     'Active_User':{"$size":'$ac'},
                     'Completed_Sessions':'$cs'}}])))


    df2 = DataFrame(list(collection2.aggregate(
       [{'$match':{'USER_ID.schoolId._id':{'$exists':1}}},
        {"$match":
                 {"$and":[{'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}}, 
                          {'USER_ID.EMAIL_ID':{"$ne":""}}, 
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}},  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
         {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
     {'USER_ID._id':{'$in':db.schoology_master.distinct('USER_ID._id')}},
         {'USER_ID.ROLE_TYPE':{"$regex":'schoology', '$options':'i'}}
     ]}},

        {"$group":{"_id":0,'Practice_Sessions':{"$sum":1}, 
                 'Total_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},3]}}}}])))

    del df2["_id"]
    df_final = pd.concat([df,df1,df2], axis = 1)



    data=[]
    for i,j in zip(df_final.columns.tolist(),df_final.iloc[0].tolist()):
        data.append([i,j])
        temp={"data":data}
    return(json.dumps(temp))




@app.route('/practicehistorychart')
def practice_historynew():
    mongo_uri = "mongodb://admin:" + urllib.parse.quote('I#L@teST^m0NGO_2o20!') + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.audio_track_master_all
    collection2 = db.audio_track_master
    ########## FOR DF ###########################
    dateStr = "2018-08-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    datestr1 = "2019-07-31T23:59:59.000Z"
    myDatetime1 = dateutil.parser.parse(datestr1)
    ########### FOR DF1 ############################
    dateStr2 = "2019-08-01T00:00:00.000Z"
    myDatetime2 = dateutil.parser.parse(dateStr2)
    ########################## FOR DF2 ###############
    dateStr3 = "2020-03-17T00:00:00.000Z"
    myDatetime3 = dateutil.parser.parse(dateStr3)
    ##################################
    ##################################
    dateStr4 = "2020-07-31T23:59:59.000Z"
    myDatetime4 = dateutil.parser.parse(dateStr4)
    ###################### USER PRACTICE 2018-2019###################################
    df = DataFrame(list(collection.aggregate([{"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'MODIFIED_DATE':{"$gte":myDatetime,"$lte" : myDatetime1}},
                    {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'}, 
                        'Users_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    ######################  USER PRACTICE 2019-2020(LSY) ############################################
    df1 = DataFrame(list(collection2.aggregate([{
            '$match':{'USER_ID.IS_DISABLED':{'$ne':'Y'},
                    'USER_ID.IS_BLOCKED':{"$ne":'Y'},
                    'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}, 
                    'USER_ID.EMAIL_ID':{'$ne':""},
                    "MODIFIED_DATE":{"$gte": myDatetime2,"$lte" : myDatetime4},
                    'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}},
            {"$match":
            {"$and" :[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Users_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    df_user = pd.concat([df,df1],ignore_index = True)
    ##################### PARENTS ##########################################
    df2 = DataFrame(list(collection2.aggregate([{
            '$match':{'USER_ID.IS_DISABLED':{'$ne':'Y'},
                    'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}, 
                    'USER_ID.EMAIL_ID':{'$ne':""},
                    "MODIFIED_DATE":{"$gte": myDatetime3,"$lte" : myDatetime4},
                    'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}},
            {"$match":
            {"$and" :[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    ###################### TOTAL LSY ##############################
    df3 = DataFrame(list(collection.aggregate([{"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'MODIFIED_DATE':{"$gte":myDatetime,"$lte": myDatetime1}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'}, 
                        'Total_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Total_Practice_LSY':'$Total_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    #user_CSY
    df1['Practice_date'] = pd.to_datetime(df1['Practice_date'])
    df5=df1.sort_values(by='Practice_date')
    #df5['Practice_date']=df5['Practice_date'].astype(np.int64)/int(1e6)
    #uscy=df5.values.tolist()
    df7=pd.date_range(start='2019-08-01', end='2020-07-31')
    df9 = pd.DataFrame(df7,columns = ["Practice_date"])
    df9['value'] = 0
    uscy1= df5.merge(df9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    uscy1['Practice_date']=uscy1['Practice_date'].astype(np.int64)/int(1e6)
    uscy=uscy1[["Practice_date","Users_Practice_CSY"]].values.tolist()
    #Parent_CSY
    df2['Practice_date'] = pd.to_datetime(df2['Practice_date'])
    df6=df2.sort_values(by='Practice_date')
    dfp=pd.date_range(start='2019-08-01', end='2020-07-31')
    dfp9 = pd.DataFrame(dfp,columns = ["Practice_date"])
    dfp9['value'] = 0
    pscy1= df6.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    pscy1['Practice_date']=pscy1['Practice_date'].astype(np.int64)/int(1e6)
    pscy=pscy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()
    #practice_Lsy
    df3['Practice_date'] = pd.to_datetime(df3['Practice_date'])
    df4=df3.sort_values(by='Practice_date')
    dfl=pd.date_range(start='2018-08-01', end='2019-07-31')
    dfl9 = pd.DataFrame(dfl,columns = ["Practice_date"])
    dfl9['value'] = 0
    plcy1= df4.merge(dfl9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    plcy1['Practice_date']=plcy1['Practice_date'].astype(np.int64)/int(1e6)
    plcy=plcy1[["Practice_date","Total_Practice_LSY"]].values.tolist()
    temp={'data':{'csy':uscy,'pcsy':pscy,'lsy':plcy}}
    return json.dumps(temp)


# @app.route('/AVG_audio_completion_daily_less_than50')
# def avg_audio_completed_():

#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
#     db=client.compass
#     collection1= db.audio_track_master
#     # datetime.datetime.now() - datetime.timedelta(days=7)
#     # ar d = new Date();
#     tz = timezone('UTC')
#     date=datetime.datetime.now(tz) 
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     yesterday = pd.to_datetime(date) - timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     print(yesterday,"yessss")
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     print(today,"today")
#     tod= today+ timedelta(hours=4)
#     start= tod-timedelta(days=1)
#     yester= yesterday+timedelta(hours=4)
#     start_15day=tod-timedelta(days=8)
#     startend= start_15day+timedelta(days=1)

#     qr1=[{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte': yester, '$lt':tod
#     }},
#     ]}},


#     {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
#                  'AUDIO_ID':'$PROGRAM_AUDIO_ID.AUDIO_ID', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
#               'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

#     }}]

#     list1= list(collection1.aggregate(qr1))
#     userprac_trend= DataFrame(list1)

#     userprac_trend.start.fillna(0, inplace=True)

#     userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

#     userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

#     #     userprac_trend_1=userprac_trend[userprac_trend.completed_precentage>=75]
#     # d=userprac_trend.groupby('AUDIO_ID')['completed_precentage'].mean().reset_index()

#     userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

#     # dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)



#     userprac_trend=userprac_trend[userprac_trend.completed_precentage <=50]
#     userprac_trend[userprac_trend.completed_precentage < 0]=0
#     # d['completed_precentage']=round(d['completed_precentage'],0)

#     dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

#     dd['cumulativesum_line']= dd['Audio_Count'].cumsum()

#     # dd[dd.completed_precentage< 0]=0


#     percentage_of_audio_completed= dd.completed_precentage.tolist(),
#     number_of_audios_compelted=dd.Audio_Count.tolist()
#     cumulative_audio_completion=dd.cumulativesum_line.tolist()

#     temp={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
#          'cumulative_audio_completion':cumulative_audio_completion}

#     data={'temp':temp}

#     #     for i,j,k in zip(dd.completed_precentage.tolist(),dd.Audio_Count.tolist(), dd.cumulativesum_line.tolist()):
#     #         data.append([i,j,k])
#     #     temp={'data':data}
#     return json.dumps(data)


# @app.route('/AVG_audio_completion_daily_less_50')
# def avg_audio_completed_less_than__50():

#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
#     db=client.compass
#     collection1= db.audio_track_master
#     # datetime.datetime.now() - datetime.timedelta(days=7)
#     # ar d = new Date();
#     tz = timezone('UTC')
#     date=datetime.datetime.now(tz) 
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     yesterday = pd.to_datetime(date) - timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     print(yesterday,"yessss")
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     print(today,"today")
#     tod= today+ timedelta(hours=4)
#     start= tod-timedelta(days=1)
#     yester= yesterday+timedelta(hours=4)
#     start_15day=tod-timedelta(days=8)
#     startend= start_15day+timedelta(days=1)

#     qr1=[{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte': yester, '$lt':tod
#     }},
#     ]}},


#     {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
#                  'AUDIO_ID':'$PROGRAM_AUDIO_ID.AUDIO_ID', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
#               'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

#     }}]

#     list1= list(collection1.aggregate(qr1))
#     userprac_trend= DataFrame(list1)

#     userprac_trend.start.fillna(0, inplace=True)

#     userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

#     userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

#     #     userprac_trend_1=userprac_trend[userprac_trend.completed_precentage>=75]
#     # d=userprac_trend.groupby('AUDIO_ID')['completed_precentage'].mean().reset_index()

#     userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

#     # dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)



#     userprac_trend=userprac_trend[userprac_trend.completed_precentage <=50]
#     userprac_trend[userprac_trend.completed_precentage < 0]=0
#     # d['completed_precentage']=round(d['completed_precentage'],0)

#     dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

#     dd['cumulativesum_line']= dd['Audio_Count'].cumsum()

#     # dd[dd.completed_precentage< 0]=0


#     percentage_of_audio_completed= dd.completed_precentage.tolist(),
#     number_of_audios_compelted=dd.Audio_Count.tolist()
#     cumulative_audio_completion=dd.cumulativesum_line.tolist()

#     temp={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
#          'cumulative_audio_completion':cumulative_audio_completion}

#     data={'temp':temp}

#     #     for i,j,k in zip(dd.completed_precentage.tolist(),dd.Audio_Count.tolist(), dd.cumulativesum_line.tolist()):
#     #         data.append([i,j,k])
#     #     temp={'data':data}
#     return json.dumps(data)









@app.route('/FAMILY_practice_table_DAILY')
def PARENTS_practice_table_DAY__(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master
    # datetime.datetime.now() - datetime.timedelta(days=7)
    # ar d = new Date();
  
    mydatetime= dateutil.parser.parse(datestr)-timedelta(hours=24)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
#     print(start_15day)
#     print(startend)



    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': yester, '$lt':tod
    }},
    ]}},


    {'$project':{'_id':'$USER_ID._id',
               'USER_NAME':'$USER_ID.USER_NAME',
                 'EMAIL_ID':'$USER_ID.EMAIL_ID',
    #                'PRACTICE_COUNT':{'$sum':1},
                   'LAST_PRACTICE_DATE':'$MODIFIED_DATE',
               'SCHOOL_NAME':'$USER_ID.schoolId.NAME',
               'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY',
               'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
               'COUNTRY':'$USER_ID.schoolId.COUNTRY',
               'CITY':'$USER_ID.schoolId.CITY',
               'STATE':'$USER_ID.schoolId.STATE',
                 'PHONE':'$USER_ID.CONTACT_NUMBER',
                 'IP':'$USER_ID.IP_ADDRESS','AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                 'AUDIO_LENGTH':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH',
    #        'Mindful_Minutes':{"$round":[{"$divide":
    #                     [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
    #                 'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
    #                     ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]},

         'CURSOR_START':"$cursorStart", 'CURSOR_END':'$CURSOR_END'
                }}
             ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    if df_atm1.empty:
        return json.dumps({'data':'NO DATA AVAILABLE'})
    else:
        
        if 'CURSOR_START' not in list(df_atm1.columns):
            df_atm1['CURSOR_START']=0
        else:
            df_atm1=df_atm1

        df_atm1['CURSOR_START'].fillna(0, inplace=True)
        df_atm1['USER_NAME'].fillna('NO INFO FOUND', inplace=True)
        df_atm1['EMAIL_ID'].fillna('NO INFO FOUND', inplace=True)
        df_atm1['CITY'].fillna('NO INFO FOUND', inplace=True)
        df_atm1['STATE'].fillna('NO INFO FOUND', inplace=True)
        df_atm1['COUNTRY'].fillna('NO INFO FOUND', inplace=True)
        df_atm1['PHONE'].fillna('NO INFO FOUND', inplace=True)

        df_atm1['subtract']=df_atm1['CURSOR_END']-df_atm1['CURSOR_START']
        df_atm1['divide']=df_atm1['subtract']/60

        decimals = 2    

        df_atm1['Mindful_minutess']=df_atm1['divide'].round(decimals)


        df_atm1['playback']= df_atm1['subtract']/df_atm1['AUDIO_LENGTH']
        df_atm1['playback_time_percent']= df_atm1['playback'].round(0)
    #     df_atm1['playback_time_PERCENTAGE']=df_atm1['playback_time_round']*100


        df_atm1['LAST_PRACTICE_DATE']=df_atm1['LAST_PRACTICE_DATE'].dt.strftime("%m/%d/%Y")
        df_atm1=df_atm1.fillna('')
        

        table=df_atm1[['SCHOOL_NAME','USER_NAME','EMAIL_ID','LAST_PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY',
#                        'PHONE',
#                        'AUDIO_LENGTH',
                       'Mindful_minutess',
                       'playback_time_percent',
#                        'CITY','STATE','COUNTRY'
                      ]]

        temp={'data':table.values.tolist()}
        return json.dumps(temp)

@app.route('/classroom_practice_table_DAILY')
def school_practice_table_DAILY():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master
    # datetime.datetime.now() - datetime.timedelta(days=7)
    # ar d = new Date();
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today+ timedelta(hours=4)
    start= tod-timedelta(days=1)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': yester, '$lt':tod
    }},
    ]}},


    {'$project':{'_id':'$USER_ID._id',
               'USER_NAME':'$USER_ID.USER_NAME',
                 'EMAIL_ID':'$USER_ID.EMAIL_ID',
    #                'PRACTICE_COUNT':{'$sum':1},
                   'LAST_PRACTICE_DATE':'$MODIFIED_DATE',
               'SCHOOL_NAME':'$USER_ID.schoolId.NAME',
               'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY',
               'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
               'COUNTRY':'$USER_ID.schoolId.COUNTRY',
               'CITY':'$USER_ID.schoolId.CITY',
               'STATE':'$USER_ID.schoolId.STATE',
                 'PHONE':'$USER_ID.CONTACT_NUMBER',
                 'IP':'$USER_ID.IP_ADDRESS','AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                 'AUDIO_LENGTH':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH',
    #        'Mindful_Minutes':{"$round":[{"$divide":
    #                     [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
    #                 'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
    #                     ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]},

         'CURSOR_START':"$cursorStart", 'CURSOR_END':'$CURSOR_END'
                }}
             ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    # df_atm1[['parents_playback_24hr', 'teachers_playback_24hr','total_playback_24hr']]


    df_atm1['CURSOR_START'].fillna(0, inplace=True)
    df_atm1['CITY'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['STATE'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['COUNTRY'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['PHONE'].fillna('NO INFO FOUND', inplace=True)

    df_atm1['subtract']=df_atm1['CURSOR_END']-df_atm1['CURSOR_START']
    df_atm1['divide']=df_atm1['subtract']/60

    decimals = 2    

    df_atm1['Mindful_minutess']=df_atm1['divide'].round(decimals)


    df_atm1['playback']= df_atm1['subtract']/df_atm1['AUDIO_LENGTH']
    df_atm1['playback_time_percent']= df_atm1['playback'].round(0)
#     df_atm1['playback_time_PERCENTAGE']=df_atm1['playback_time_round']*100


    df_atm1['LAST_PRACTICE_DATE']=df_atm1['LAST_PRACTICE_DATE'].dt.strftime("%m/%d/%Y, %H:%M:%S")

    table=df_atm1[['USER_NAME','EMAIL_ID','LAST_PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY','PHONE','AUDIO_LENGTH','Mindful_minutess','playback_time_percent','CITY','STATE','COUNTRY']]

    temp={'data':table.values.tolist()}
    return json.dumps(temp)
# practice_table()


@app.route('/classroom_practice_WEEKLY')
def School_practice_table_weekly():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master
    # datetime.datetime.now() - datetime.timedelta(days=7)
    # ar d = new Date();
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    # tod= today+ timedelta(hours=4)
    # start= tod-timedelta(days=1)
    # yester= yesterday+timedelta(hours=4)
    # start_15day=tod-timedelta(days=8)
    start= tod-timedelta(days=8)+timedelta(days=1)
    yester= yesterday+timedelta(hours=4)+timedelta(days=1)
    start_15day=tod-timedelta(days=15)+timedelta(days=1)
    startend= start_15day+timedelta(days=1)

    qr1=[
        {"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': start, '$lt':yester
    }},
    ]}},



    {'$project':{'_id':'$USER_ID._id',
               'USER_NAME':'$USER_ID.USER_NAME',
                 'EMAIL_ID':'$USER_ID.EMAIL_ID',
    #                'PRACTICE_COUNT':{'$sum':1},
                   'LAST_PRACTICE_DATE':'$MODIFIED_DATE',
               'SCHOOL_NAME':'$USER_ID.schoolId.NAME',
               'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY',
               'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
               'COUNTRY':'$USER_ID.schoolId.COUNTRY',
               'CITY':'$USER_ID.schoolId.CITY',
               'STATE':'$USER_ID.schoolId.STATE',
                 'PHONE':'$USER_ID.CONTACT_NUMBER',
                 'IP':'$USER_ID.IP_ADDRESS','AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                 'AUDIO_LENGTH':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH',
    #        'Mindful_Minutes':{"$round":[{"$divide":
    #                     [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
    #                 'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
    #                     ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]},

         'CURSOR_START':"$cursorStart", 'CURSOR_END':'$CURSOR_END'
                }}
             ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    # df_atm1[['parents_playback_24hr', 'teachers_playback_24hr','total_playback_24hr']]


    df_atm1['CURSOR_START'].fillna(0, inplace=True)
    df_atm1['CITY'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['STATE'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['COUNTRY'].fillna('NO INFO FOUND', inplace=True)

    df_atm1['subtract']=df_atm1['CURSOR_END']-df_atm1['CURSOR_START']
    df_atm1['divide']=df_atm1['subtract']/60

    decimals = 2    

    df_atm1['Mindful_minutess']=df_atm1['divide'].round(decimals)


    df_atm1['playback']= df_atm1['subtract']/df_atm1['AUDIO_LENGTH']
    df_atm1['playback_time_percent']= df_atm1['playback'].round(0)
    # df_atm1['playback_time_PERCENTAGE']=df_atm1['playback_time_round']*100


    df_atm1['LAST_PRACTICE_DATE']=df_atm1['LAST_PRACTICE_DATE'].dt.strftime("%m/%d/%Y, %H:%M:%S")

    table=df_atm1[['USER_NAME','EMAIL_ID','LAST_PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY','AUDIO_LENGTH','Mindful_minutess','playback_time_percent','CITY','STATE','COUNTRY']]

    temp={'data':table.values.tolist()}
    return json.dumps(temp)




@app.route('/PARENTS_practice_WEEKLY')
def family_practice_table_weekly():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master
    # datetime.datetime.now() - datetime.timedelta(days=7)
    # ar d = new Date();
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    # tod= today+ timedelta(hours=4)
    # start= tod-timedelta(days=1)
    # yester= yesterday+timedelta(hours=4)
    # start_15day=tod-timedelta(days=8)
    start= tod-timedelta(days=8)+timedelta(days=1)
    yester= yesterday+timedelta(hours=4)+timedelta(days=1)
    start_15day=tod-timedelta(days=15)+timedelta(days=1)
    startend= start_15day+timedelta(days=1)

    qr1=[
        {"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': start, '$lt':yester
    }},
    ]}},



    {'$project':{'_id':'$USER_ID._id',
               'USER_NAME':'$USER_ID.USER_NAME',
                 'EMAIL_ID':'$USER_ID.EMAIL_ID',
    #                'PRACTICE_COUNT':{'$sum':1},
                   'LAST_PRACTICE_DATE':'$MODIFIED_DATE',
               'SCHOOL_NAME':'$USER_ID.schoolId.NAME',
               'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY',
               'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
               'COUNTRY':'$USER_ID.schoolId.COUNTRY',
               'CITY':'$USER_ID.schoolId.CITY',
               'STATE':'$USER_ID.schoolId.STATE',
                 'PHONE':'$USER_ID.CONTACT_NUMBER',
                 'IP':'$USER_ID.IP_ADDRESS','AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                 'AUDIO_LENGTH':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH',
    #        'Mindful_Minutes':{"$round":[{"$divide":
    #                     [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
    #                 'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
    #                     ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]},

         'CURSOR_START':"$cursorStart", 'CURSOR_END':'$CURSOR_END'
                }}
             ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    # df_atm1[['parents_playback_24hr', 'teachers_playback_24hr','total_playback_24hr']]


    df_atm1['CURSOR_START'].fillna(0, inplace=True)
    df_atm1['CITY'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['STATE'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['COUNTRY'].fillna('NO INFO FOUND', inplace=True)

    df_atm1['subtract']=df_atm1['CURSOR_END']-df_atm1['CURSOR_START']
    df_atm1['divide']=df_atm1['subtract']/60

    decimals = 2    

    df_atm1['Mindful_minutess']=df_atm1['divide'].round(decimals)


    df_atm1['playback']= df_atm1['subtract']/df_atm1['AUDIO_LENGTH']
    df_atm1['playback_time_percent']= df_atm1['playback'].round(0)
    # df_atm1['playback_time_PERCENTAGE']=df_atm1['playback_time_round']*100


    df_atm1['LAST_PRACTICE_DATE']=df_atm1['LAST_PRACTICE_DATE'].dt.strftime("%m/%d/%Y, %H:%M:%S")

    table=df_atm1[['USER_NAME','EMAIL_ID','LAST_PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY','AUDIO_LENGTH','Mindful_minutess','playback_time_percent','CITY','STATE','COUNTRY']]

    temp={'data':table.values.tolist()}
    return json.dumps(temp)




# family_practice_table_weekly()




@app.route('/daywisefeedcards')

def feeddailycardssss():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.combine(datetime.utcnow() -timedelta(days=1),time.min)
    today= datetime.combine(datetime.utcnow(),time.min)
    tod= today+ timedelta(hours=4)
    print(tod)
    start= tod-timedelta(days=3)
    yester= yesterday+timedelta(hours=4)
    print(yester)
    start_15day=tod-timedelta(days=8)
    start_15dayplus1=start_15day+timedelta(days=1)

    



    query=[
            {"$match":{"$and":[
#                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{'$nin':['',' ',None]}},
                    {"MODIFIED_DATE":{"$gte": yester}}
                    ]}},
               {"$project":{"_id":0, "USER_ID":'$USER_ID.USER_ID','MODIFIED_DATE':1}}]
    query2=[
         {"$match":{"$and":[
#              {'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER.IS_DISABLE':{"$ne":'Y'}},
                    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
                    {'RATING':{'$ne':0}},
                    {"MODIFIED_DATE":{"$gte": yester}}
                    ]}},
                {"$project":{'RATING':1,'COMMENT':1,'USER_ID':'$USER.USER','USER_NAME':'$USER.USER_NAME','EMAIL':'$USER.EMAIL_ID'}}]
    practice=list(collection.aggregate(query))
    practice_df=pd.DataFrame(practice)
    feedback=list(collection2.aggregate(query2))
    feedback_df=pd.DataFrame(feedback)
#     print(feedback_df)
    print(len(practice_df))
    card_df=pd.DataFrame({
        'Total_Playbacks':len(practice_df),
        
    'Feedback_Percentage':round((len(feedback_df[feedback_df['RATING']!=0])/len(practice_df))*100,2),                      
                     'Comment_per_feedback':round(len(feedback_df[(feedback_df['COMMENT'].notnull()) & (feedback_df['COMMENT']!='') ])/
                     len(feedback_df[feedback_df['RATING']!=0])*100,2),
                      'Average_Rating':feedback_df[feedback_df['RATING']!=0]['RATING'].mean()},
                          index=[0])
    query3=[{"$match":{"$and":[
#         {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{'$nin':['',' ',None]}},
                    {"MODIFIED_DATE":{"$gte": start_15day, '$lt': start_15dayplus1}}
                    ]}},
    {"$project":{"_id":0, "USER_ID":'$USER_ID.USER_ID','MODIFIED_DATE':1}}]
    # =================================    
    query4=[{"$match":{"$and":[
#         {'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER.IS_DISABLE':{"$ne":'Y'}},
                    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
                    {'RATING':{'$ne':0}},
                    {"MODIFIED_DATE":{"$gte": start_15day, '$lt': start_15dayplus1}}
                    ]}},
    {"$project":{'RATING':1,'COMMENT':1,'USER_ID':'$USER.USER','USER_NAME':'$USER.USER_NAME','EMAIL':'$USER.EMAIL_ID'}}]
    practice_=list(collection.aggregate(query3))
    practice_yesterday_df=pd.DataFrame(practice_)
    feedback_=list(collection2.aggregate(query4))
    feedback_yesterday_df=pd.DataFrame(feedback_)
    card_yesterday_df=pd.DataFrame({'Feedback_Percentage_yester':(len(feedback_yesterday_df[feedback_yesterday_df['RATING']!=0])/len(practice_yesterday_df))*100,
                     'Comment_per_feedback_yester':round(len(feedback_yesterday_df[(feedback_yesterday_df['COMMENT'].notnull()) & (feedback_yesterday_df['COMMENT']!='') ])/
                     len(feedback_yesterday_df[feedback_yesterday_df['RATING']!=0])*100,2),
                      'Total_Playbacks':len(practice_yesterday_df),'Average_Rating_yester':round(feedback_yesterday_df[feedback_yesterday_df['RATING']!=0]['RATING'].mean(),2)},
                          index=[0])
    Feedback_Percentagechange=[]
    if card_df['Feedback_Percentage'].iloc[0] > card_yesterday_df['Feedback_Percentage_yester'].iloc[0]:
        Feedback_Percentagechange.append('1')
    elif card_df['Feedback_Percentage'].iloc[0] == card_yesterday_df['Feedback_Percentage_yester'].iloc[0]:
        Feedback_Percentagechange.append('0')
    else:
        Feedback_Percentagechange.append('-1')
    Comment_per_feedbackchange=[]
    if card_df['Comment_per_feedback'].iloc[0] > card_yesterday_df['Comment_per_feedback_yester'].iloc[0]:
        Comment_per_feedbackchange.append('1')
    elif card_df['Comment_per_feedback'].iloc[0] == card_yesterday_df['Comment_per_feedback_yester'].iloc[0]:
        Comment_per_feedbackchange.append('0')
    else:
        Comment_per_feedbackchange.append('-1')
    Average_Rating_change=[]
    if card_df['Average_Rating'].iloc[0] > card_yesterday_df['Average_Rating_yester'].iloc[0]:
        Average_Rating_change.append('1')
    elif card_df['Average_Rating'].iloc[0] == card_yesterday_df['Average_Rating_yester'].iloc[0]:
        Average_Rating_change.append('0')
    else:
        Average_Rating_change.append('-1')
    data_final=pd.DataFrame({'Feedback_Percentage':card_df['Feedback_Percentage'].tolist(), 
                            'Comment_per_feedback':card_df['Comment_per_feedback'].tolist(),
                             'Average_Rating':card_df['Average_Rating'].tolist()
                            })    
    temp={}
    for j in range(len(data_final.columns)):
        key = data_final.columns[j]
        value = [str(data_final[data_final.columns[j]].iloc[0])]
        temp.update({key:value})
    #     print(temp)
    return json.dumps(temp)
    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.combine(datetime.utcnow() -timedelta(days=1),time.min)
    today= datetime.combine(datetime.utcnow(),time.min)
    tod= today+ timedelta(hours=4)
    print(tod)
    start= tod-timedelta(days=2)
    yester= yesterday+timedelta(hours=4)
    print(yester)
    start_15day=tod-timedelta(days=8)
    start_15dayplus1=start_15day+timedelta(days=1)
    query=[
            {"$match":{"$and":[
#                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{'$nin':['',' ',None]}},
                    {"MODIFIED_DATE":{"$gte": yester, '$lt': tod}}
                    ]}},
               {"$project":{"_id":0, "USER_ID":'$USER_ID.USER_ID','MODIFIED_DATE':1}}]
    query2=[
         {"$match":{"$and":[
#              {'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER.IS_DISABLE':{"$ne":'Y'}},
                    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
                    {'RATING':{'$ne':0}},
                    {"MODIFIED_DATE":{"$gte": yester, '$lt': tod}}
                    ]}},
                {"$project":{'RATING':1,'COMMENT':1,'USER_ID':'$USER.USER','USER_NAME':'$USER.USER_NAME','EMAIL':'$USER.EMAIL_ID'}}]
    practice=list(collection.aggregate(query))
    practice_df=pd.DataFrame(practice)
    feedback=list(collection2.aggregate(query2))
    feedback_df=pd.DataFrame(feedback)
    print(feedback_df)
    print(len(practice_df))
    card_df=pd.DataFrame({
        'Total_Playbacks':len(practice_df),
        
    'Feedback_Percentage':round((len(feedback_df[feedback_df['RATING']!=0])/len(practice_df))*100,2),                      
                     'Comment_per_feedback':round(len(feedback_df[(feedback_df['COMMENT'].notnull()) & (feedback_df['COMMENT']!='') ])/
                     len(feedback_df[feedback_df['RATING']!=0])*100,2),
                      'Average_Rating':feedback_df[feedback_df['RATING']!=0]['RATING'].mean()},
                          index=[0])
    query3=[{"$match":{"$and":[
#         {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{'$nin':['',' ',None]}},
                    {"MODIFIED_DATE":{"$gte": start_15day, '$lt': start_15dayplus1}}
                    ]}},
    {"$project":{"_id":0, "USER_ID":'$USER_ID.USER_ID','MODIFIED_DATE':1}}]
    # =================================    
    query4=[{"$match":{"$and":[
#         {'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                    {'USER.IS_DISABLE':{"$ne":'Y'}},
                    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
                    {'RATING':{'$ne':0}},
                    {"MODIFIED_DATE":{"$gte": start_15day, '$lt': start_15dayplus1}}
                    ]}},
    {"$project":{'RATING':1,'COMMENT':1,'USER_ID':'$USER.USER','USER_NAME':'$USER.USER_NAME','EMAIL':'$USER.EMAIL_ID'}}]
    practice_=list(collection.aggregate(query3))
    practice_yesterday_df=pd.DataFrame(practice_)
    feedback_=list(collection2.aggregate(query4))
    feedback_yesterday_df=pd.DataFrame(feedback_)
    card_yesterday_df=pd.DataFrame({'Feedback_Percentage_yester':(len(feedback_yesterday_df[feedback_yesterday_df['RATING']!=0])/len(practice_yesterday_df))*100,
                     'Comment_per_feedback_yester':round(len(feedback_yesterday_df[(feedback_yesterday_df['COMMENT'].notnull()) & (feedback_yesterday_df['COMMENT']!='') ])/
                     len(feedback_yesterday_df[feedback_yesterday_df['RATING']!=0])*100,2),
                      'Total_Playbacks':len(practice_yesterday_df),'Average_Rating_yester':round(feedback_yesterday_df[feedback_yesterday_df['RATING']!=0]['RATING'].mean(),2)},
                          index=[0])
    Feedback_Percentagechange=[]
    if card_df['Feedback_Percentage'].iloc[0] > card_yesterday_df['Feedback_Percentage_yester'].iloc[0]:
        Feedback_Percentagechange.append('1')
    elif card_df['Feedback_Percentage'].iloc[0] == card_yesterday_df['Feedback_Percentage_yester'].iloc[0]:
        Feedback_Percentagechange.append('0')
    else:
        Feedback_Percentagechange.append('-1')
    Comment_per_feedbackchange=[]
    if card_df['Comment_per_feedback'].iloc[0] > card_yesterday_df['Comment_per_feedback_yester'].iloc[0]:
        Comment_per_feedbackchange.append('1')
    elif card_df['Comment_per_feedback'].iloc[0] == card_yesterday_df['Comment_per_feedback_yester'].iloc[0]:
        Comment_per_feedbackchange.append('0')
    else:
        Comment_per_feedbackchange.append('-1')
    Average_Rating_change=[]
    if card_df['Average_Rating'].iloc[0] > card_yesterday_df['Average_Rating_yester'].iloc[0]:
        Average_Rating_change.append('1')
    elif card_df['Average_Rating'].iloc[0] == card_yesterday_df['Average_Rating_yester'].iloc[0]:
        Average_Rating_change.append('0')
    else:
        Average_Rating_change.append('-1')
    data_final=pd.DataFrame({'Feedback_Percentage':card_df['Feedback_Percentage'].tolist(), 
                            'Comment_per_feedback':card_df['Comment_per_feedback'].tolist(),
                             'Average_Rating':card_df['Average_Rating'].tolist()
                            })    
    temp={}
    for j in range(len(data_final.columns)):
        key = data_final.columns[j]
        value = [str(data_final[data_final.columns[j]].iloc[0])]
        temp.update({key:value})
    #     print(temp)
    return json.dumps(temp)


# @app.route('/AVG_audio_completion_Weekly')
# def avg_audio_completed_weekly():

#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
#     db=client.compass
#     collection1= db.audio_track_master
#     # datetime.datetime.now() - datetime.timedelta(days=7)
#     # ar d = new Date();
#     tz = timezone('UTC')
#     date=datetime.datetime.now(tz) 
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     yesterday = pd.to_datetime(date) - timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     print(yesterday,"yessss")
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     print(today,"today")
#     tod= today+ timedelta(hours=4)
#     start= tod-timedelta(days=1)
#     yester= yesterday+timedelta(hours=4)
#     start_15day=tod-timedelta(days=8)
#     startend= start_15day+timedelta(days=1)

#     qr1=[{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte': start_15day, '$lt':start
#     }},
#     ]}},


#     {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
#                  'AUDIO_ID':'$PROGRAM_AUDIO_ID.AUDIO_ID', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
#               'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

#     }}]

#     list1= list(collection1.aggregate(qr1))
#     userprac_trend= DataFrame(list1)

#     userprac_trend.start.fillna(0, inplace=True)

#     userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']
#     userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)
#     #     userprac_trend_1=userprac_trend[userprac_trend.completed_precentage>=75]
#     # d=userprac_trend.groupby('AUDIO_ID')['completed_precentage'].mean().reset_index()

#     userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)
#     # dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

#     userprac_trend[userprac_trend.completed_precentage < 0]=0
    
    
#     # d['completed_precentage']=round(d['completed_precentage'],0)
#     dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)
#     dd['cumulativesum_line']= dd['Audio_Count'].cumsum()
#     # dd[dd.completed_precentage< 0]=0

#     percentage_of_audio_completed= dd.completed_precentage.tolist(),
#     number_of_audios_compelted=dd.Audio_Count.tolist()
#     cumulative_audio_completion=dd.cumulativesum_line.tolist()
    
#     temp={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
#          'cumulative_audio_completion':cumulative_audio_completion}

#     data={'temp':temp}
    
# #     for i,j,k in zip(dd.completed_precentage.tolist(),dd.Audio_Count.tolist(), dd.cumulativesum_line.tolist()):
# #         data.append([i,j,k])
# #     temp={'data':data}
# #     return json.dumps(data)

#     return json.dumps(temp)  

@app.route('/highhratingweeklyP&T')
def highRATING_weekSSS():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection= db.audio_feedback
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)
    df1 = DataFrame(list(collection.aggregate([
         {"$match":{'$and':[
             {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER.IS_DISABLED":{"$ne":"Y"}},
             { "USER.IS_BLOCKED":{"$ne":"Y"}},
            { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
               {'MODIFIED_DATE':{'$gte':start, '$lt':yester}}    ,         
            {'RATING':{'$ne':0}}]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
        'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
        'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
        'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
        'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
        'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}}
        }},
        {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3', 'rating_2':'$rating_2','rating_1':'$rating_1' }},
        {'$sort':{'_id':1}}
        ])))
    df1.rename(columns = { '_id': 'week'}, inplace = True)
    df1[['week','rating_5','rating_4','rating_3','rating_2','rating_1']]
    df2 = DataFrame(list(collection.aggregate([
         {"$match":{'$and':[
             {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER.IS_DISABLED":{"$ne":"Y"}},
             { "USER.IS_BLOCKED":{"$ne":"Y"}},
            { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
               {'MODIFIED_DATE':{'$gte':start, '$lt':yester}}    ,         
            {'RATING':{'$ne':0}}]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
        'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
        'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
        'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
        'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
        'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}}
        }},
        {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3', 'rating_2':'$rating_2','rating_1':'$rating_1' }},
        {'$sort':{'_id':1}}
        ])))
    df2.rename(columns = { '_id': 'week'}, inplace = True)
    df2[['week','rating_5','rating_4','rating_3','rating_2','rating_1']]
    df10 = DataFrame(list(collection.aggregate([
     {"$match":{'$and':[
         {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER.IS_DISABLED":{"$ne":"Y"}},
         { "USER.IS_BLOCKED":{"$ne":"Y"}},
        { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
           {'MODIFIED_DATE':{'$gte':start_15day, '$lt':start}}    ,         
    {'RATING':{'$ne':0}}]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
        'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
        'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
        'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
        'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
        'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}}
        }},
        {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3', 'rating_2':'$rating_2','rating_1':'$rating_1' }},
        {'$sort':{'_id':1}}
        ])))
    df10.rename(columns = { '_id': 'week'}, inplace = True)
    df10[['week','rating_5','rating_4','rating_3','rating_2','rating_1']]
    df20 = DataFrame(list(collection.aggregate([
         {"$match":{'$and':[
             {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER.IS_DISABLED":{"$ne":"Y"}},
             { "USER.IS_BLOCKED":{"$ne":"Y"}},
            { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
               {'MODIFIED_DATE':{'$gte':start_15day, '$lt':start}}    ,         
            {'RATING':{'$ne':0}}]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
        'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
        'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
        'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
        'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
        'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}}
        }},
        {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3', 'rating_2':'$rating_2','rating_1':'$rating_1' }},
        {'$sort':{'_id':1}}
        ])))
    df20.rename(columns = { '_id': 'week'}, inplace = True)
    df20[['week','rating_5','rating_4','rating_3']]
    weekdata={'day':['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'],
     "TEACHERrating_5LASTWEEK":[int(str(df1['rating_5'][0])),int(str(df1['rating_5'][1])),
           int(str(df1['rating_5'][2])),int(str(df1['rating_5'][3])),
        int(str(df1['rating_5'][4])),int(str(df1['rating_5'][5])),int(str(df1['rating_5'][6]))],
    "TEACHERrating_4LASTWEEK":[int(str(df1['rating_4'][0])),int(str(df1['rating_4'][1])),
           int(str(df1['rating_4'][2])),int(str(df1['rating_4'][3])),
        int(str(df1['rating_4'][4])),int(str(df1['rating_4'][5])),int(str(df1['rating_4'][6]))],
    "TEACHERrating_3LASTWEEK":[int(str(df1['rating_3'][0])),int(str(df1['rating_3'][1])),
           int(str(df1['rating_3'][2])),int(str(df1['rating_3'][3])),
        int(str(df1['rating_3'][4])),int(str(df1['rating_3'][5])),int(str(df1['rating_3'][6]))],
#     "TEACHERrating_2LASTWEEK":[int(str(df1['rating_2'][0])),int(str(df1['rating_2'][1])),
#            int(str(df1['rating_2'][2])),int(str(df1['rating_2'][3])),
#         int(str(df1['rating_2'][4])),int(str(df1['rating_2'][5])),int(str(df1['rating_2'][6]))],
#     "TEACHERrating_1LASTWEEK":[int(str(df1['rating_1'][0])),int(str(df1['rating_1'][1])),
#            int(str(df1['rating_1'][2])),int(str(df1['rating_1'][3])),
#         int(str(df1['rating_1'][4])),int(str(df1['rating_1'][5])),int(str(df1['rating_1'][6]))],          
    "PARENTrating_5LASTWEEK":[int(str(df2['rating_5'][0])),int(str(df2['rating_5'][1])),
           int(str(df2['rating_5'][2])),int(str(df2['rating_5'][3])),
        int(str(df2['rating_5'][4])),int(str(df2['rating_5'][5])),int(str(df2['rating_5'][6]))],
    "PARENTrating_4LASTWEEK":[int(str(df2['rating_4'][0])),int(str(df2['rating_4'][1])),
           int(str(df2['rating_4'][2])),int(str(df2['rating_4'][3])),
        int(str(df2['rating_4'][4])),int(str(df2['rating_4'][5])),int(str(df2['rating_4'][6]))],
    "PARENTrating_3LASTWEEK":[int(str(df2['rating_3'][0])),int(str(df2['rating_3'][1])),
           int(str(df2['rating_3'][2])),int(str(df2['rating_3'][3])),
        int(str(df2['rating_3'][4])),int(str(df2['rating_3'][5])),int(str(df2['rating_3'][6]))],
#     "PARENTrating_2LASTWEEK":[int(str(df2['rating_2'][0])),int(str(df2['rating_2'][1])),
#            int(str(df2['rating_2'][2])),int(str(df2['rating_2'][3])),
#         int(str(df2['rating_2'][4])),int(str(df2['rating_2'][5])),int(str(df2['rating_2'][6]))],
#     "PARENTrating_1LASTWEEK":[int(str(df2['rating_1'][0])),int(str(df2['rating_1'][1])),
#            int(str(df2['rating_1'][2])),int(str(df2['rating_1'][3])),
#         int(str(df2['rating_1'][4])),int(str(df2['rating_1'][5])),int(str(df2['rating_1'][6]))],                    
     "PARENTrating_5LAST_TO_LAST_WEEK":[int(str(df20['rating_5'][0])),int(str(df20['rating_5'][1])),
           int(str(df20['rating_5'][2])),int(str(df20['rating_5'][3])),
        int(str(df20['rating_5'][4])),int(str(df20['rating_5'][5])),int(str(df20['rating_5'][6]))],
    "PARENTrating_4LAST_TO_LAST_WEEK":[int(str(df20['rating_4'][0])),int(str(df20['rating_4'][1])),
           int(str(df20['rating_4'][2])),int(str(df20['rating_4'][3])),
        int(str(df20['rating_4'][4])),int(str(df20['rating_4'][5])),int(str(df20['rating_4'][6]))],
    "PARENTrating_3LAST_TO_LAST_WEEK":[int(str(df20['rating_3'][0])),int(str(df20['rating_3'][1])),
           int(str(df20['rating_3'][2])),int(str(df20['rating_3'][3])),
        int(str(df20['rating_3'][4])),int(str(df20['rating_3'][5])),int(str(df20['rating_3'][6]))],
#     "PARENTrating_2LAST_TO_LAST_WEEK":[int(str(df20['rating_2'][0])),int(str(df20['rating_2'][1])),
#            int(str(df20['rating_2'][2])),int(str(df20['rating_2'][3])),
#         int(str(df20['rating_2'][4])),int(str(df20['rating_2'][5])),int(str(df20['rating_2'][6]))],
#     "PARENTrating_1LAST_TO_LAST_WEEK":[int(str(df20['rating_1'][0])),int(str(df20['rating_1'][1])),
#            int(str(df20['rating_1'][2])),int(str(df20['rating_1'][3])),
#         int(str(df20['rating_1'][4])),int(str(df20['rating_1'][5])),int(str(df20['rating_1'][6]))],           
       "TEACHERrating_5LAST_TO_LAST_WEEK":[int(str(df10['rating_5'][0])),int(str(df10['rating_5'][1])),
           int(str(df10['rating_5'][2])),int(str(df10['rating_5'][3])),
        int(str(df10['rating_5'][4])),int(str(df1['rating_5'][5])),int(str(df10['rating_5'][6]))],
    "TEACHERrating_4LAST_TO_LAST_WEEK":[int(str(df10['rating_4'][0])),int(str(df10['rating_4'][1])),
           int(str(df10['rating_4'][2])),int(str(df10['rating_4'][3])),
        int(str(df10['rating_4'][4])),int(str(df10['rating_4'][5])),int(str(df10['rating_4'][6]))],
    "TEACHERrating_3LAST_TO_LAST_WEEK":[int(str(df10['rating_3'][0])),int(str(df10['rating_3'][1])),
           int(str(df10['rating_3'][2])),int(str(df10['rating_3'][3])),
        int(str(df10['rating_3'][4])),int(str(df10['rating_3'][5])),int(str(df10['rating_3'][6]))],
#     "TEACHERrating_2LAST_TO_LAST_WEEK":[int(str(df10['rating_2'][0])),int(str(df10['rating_2'][1])),
#            int(str(df10['rating_2'][2])),int(str(df10['rating_2'][3])),
#         int(str(df10['rating_2'][4])),int(str(df10['rating_2'][5])),int(str(df10['rating_2'][6]))],
#     "TEACHERrating_1LAST_TO_LAST_WEEK":[int(str(df10['rating_1'][0])),int(str(df10['rating_1'][1])),
#            int(str(df10['rating_1'][2])),int(str(df10['rating_1'][3])),
#         int(str(df10['rating_1'][4])),int(str(df10['rating_1'][5])),int(str(df10['rating_1'][6]))],        
              }
    temp={'weekdata':weekdata}
    return json.dumps(temp)

#testtttt

@app.route('/lowwwratingweeklyP&T')
def lowRATING_weekSSS():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection= db.audio_feedback
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)
    df1 = DataFrame(list(collection.aggregate([
         {"$match":{'$and':[
             {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER.IS_DISABLED":{"$ne":"Y"}},
             { "USER.IS_BLOCKED":{"$ne":"Y"}},
            { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
               {'MODIFIED_DATE':{'$gte':start, '$lt':yester}}    ,         
            {'RATING':{'$ne':0}}]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
#         'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
#         'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
#         'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
        'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
        'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}}
        }},
        {'$project':{'_id':1, 'rating_2':'$rating_2','rating_1':'$rating_1'}},
        {'$sort':{'_id':1}}
        ])))
    df1.rename(columns = { '_id': 'week'}, inplace = True)
    df1[['week','rating_1','rating_2']]
    df2 = DataFrame(list(collection.aggregate([
         {"$match":{'$and':[
             {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER.IS_DISABLED":{"$ne":"Y"}},
             { "USER.IS_BLOCKED":{"$ne":"Y"}},
            { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
               {'MODIFIED_DATE':{'$gte':start, '$lt':yester}}    ,         
            {'RATING':{'$ne':0}}]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
#         'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
#         'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
#         'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
        'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
        'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}}
        }},
        {'$project':{'_id':1, 'rating_1':'$rating_1','rating_2':'$rating_2'}},
        {'$sort':{'_id':1}}
        ])))
    df2.rename(columns = { '_id': 'week'}, inplace = True)
    df2[['week','rating_1','rating_2']]
    df10 = DataFrame(list(collection.aggregate([
     {"$match":{'$and':[
         {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER.IS_DISABLED":{"$ne":"Y"}},
         { "USER.IS_BLOCKED":{"$ne":"Y"}},
        { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
           {'MODIFIED_DATE':{'$gte':start_15day, '$lt':start}}    ,         
    {'RATING':{'$ne':0}}]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
#         'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
#         'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
#         'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
        'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
        'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}}
        }},
        {'$project':{'_id':1, 'rating_1':'$rating_1','rating_2':'$rating_2'}},
        {'$sort':{'_id':1}}
        ])))
    df10.rename(columns = { '_id': 'week'}, inplace = True)
    df10[['week','rating_1','rating_2']]
    df20 = DataFrame(list(collection.aggregate([
         {"$match":{'$and':[
             {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER.IS_DISABLED":{"$ne":"Y"}},
             { "USER.IS_BLOCKED":{"$ne":"Y"}},
            { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
               {'MODIFIED_DATE':{'$gte':start_15day, '$lt':start}}    ,         
            {'RATING':{'$ne':0}}]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
#         'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
#         'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
#         'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
        'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
        'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}}
        }},
        {'$project':{'_id':1, 'rating_1':'$rating_1','rating_2':'$rating_2'}},
        {'$sort':{'_id':1}}
        ])))
    df20.rename(columns = { '_id': 'week'}, inplace = True)
    df20[['week','rating_1','rating_2']]
    weekdata={'day':['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'],
#      "TEACHERrating_5LASTWEEK":[int(str(df1['rating_5'][0])),int(str(df1['rating_5'][1])),
#            int(str(df1['rating_5'][2])),int(str(df1['rating_5'][3])),
#         int(str(df1['rating_5'][4])),int(str(df1['rating_5'][5])),int(str(df1['rating_5'][6]))],
#     "TEACHERrating_4LASTWEEK":[int(str(df1['rating_4'][0])),int(str(df1['rating_4'][1])),
#            int(str(df1['rating_4'][2])),int(str(df1['rating_4'][3])),
#         int(str(df1['rating_4'][4])),int(str(df1['rating_4'][5])),int(str(df1['rating_4'][6]))],
#     "TEACHERrating_3LASTWEEK":[int(str(df1['rating_3'][0])),int(str(df1['rating_3'][1])),
#            int(str(df1['rating_3'][2])),int(str(df1['rating_3'][3])),
#         int(str(df1['rating_3'][4])),int(str(df1['rating_3'][5])),int(str(df1['rating_3'][6]))],
    "TEACHERrating_2LASTWEEK":[int(str(df1['rating_2'][0])),int(str(df1['rating_2'][1])),
           int(str(df1['rating_2'][2])),int(str(df1['rating_2'][3])),
        int(str(df1['rating_2'][4])),int(str(df1['rating_2'][5])),int(str(df1['rating_2'][6]))],
    "TEACHERrating_1LASTWEEK":[int(str(df1['rating_1'][0])),int(str(df1['rating_1'][1])),
           int(str(df1['rating_1'][2])),int(str(df1['rating_1'][3])),
        int(str(df1['rating_1'][4])),int(str(df1['rating_1'][5])),int(str(df1['rating_1'][6]))],          
#     "PARENTrating_5LASTWEEK":[int(str(df2['rating_5'][0])),int(str(df2['rating_5'][1])),
#            int(str(df2['rating_5'][2])),int(str(df2['rating_5'][3])),
#         int(str(df2['rating_5'][4])),int(str(df2['rating_5'][5])),int(str(df2['rating_5'][6]))],
#     "PARENTrating_4LASTWEEK":[int(str(df2['rating_4'][0])),int(str(df2['rating_4'][1])),
#            int(str(df2['rating_4'][2])),int(str(df2['rating_4'][3])),
#         int(str(df2['rating_4'][4])),int(str(df2['rating_4'][5])),int(str(df2['rating_4'][6]))],
#     "PARENTrating_3LASTWEEK":[int(str(df2['rating_3'][0])),int(str(df2['rating_3'][1])),
#            int(str(df2['rating_3'][2])),int(str(df2['rating_3'][3])),
#         int(str(df2['rating_3'][4])),int(str(df2['rating_3'][5])),int(str(df2['rating_3'][6]))],
    "PARENTrating_2LASTWEEK":[int(str(df2['rating_2'][0])),int(str(df2['rating_2'][1])),
           int(str(df2['rating_2'][2])),int(str(df2['rating_2'][3])),
        int(str(df2['rating_2'][4])),int(str(df2['rating_2'][5])),int(str(df2['rating_2'][6]))],
    "PARENTrating_1LASTWEEK":[int(str(df2['rating_1'][0])),int(str(df2['rating_1'][1])),
           int(str(df2['rating_1'][2])),int(str(df2['rating_1'][3])),
        int(str(df2['rating_1'][4])),int(str(df2['rating_1'][5])),int(str(df2['rating_1'][6]))],                    
#      "PARENTrating_5LAST_TO_LAST_WEEK":[int(str(df20['rating_5'][0])),int(str(df20['rating_5'][1])),
#            int(str(df20['rating_5'][2])),int(str(df20['rating_5'][3])),
#         int(str(df20['rating_5'][4])),int(str(df20['rating_5'][5])),int(str(df20['rating_5'][6]))],
#     "PARENTrating_4LAST_TO_LAST_WEEK":[int(str(df20['rating_4'][0])),int(str(df20['rating_4'][1])),
#            int(str(df20['rating_4'][2])),int(str(df20['rating_4'][3])),
#         int(str(df20['rating_4'][4])),int(str(df20['rating_4'][5])),int(str(df20['rating_4'][6]))],
#     "PARENTrating_3LAST_TO_LAST_WEEK":[int(str(df20['rating_3'][0])),int(str(df20['rating_3'][1])),
#            int(str(df20['rating_3'][2])),int(str(df20['rating_3'][3])),
#         int(str(df20['rating_3'][4])),int(str(df20['rating_3'][5])),int(str(df20['rating_3'][6]))],
    "PARENTrating_2LAST_TO_LAST_WEEK":[int(str(df20['rating_2'][0])),int(str(df20['rating_2'][1])),
           int(str(df20['rating_2'][2])),int(str(df20['rating_2'][3])),
        int(str(df20['rating_2'][4])),int(str(df20['rating_2'][5])),int(str(df20['rating_2'][6]))],
    "PARENTrating_1LAST_TO_LAST_WEEK":[int(str(df20['rating_1'][0])),int(str(df20['rating_1'][1])),
           int(str(df20['rating_1'][2])),int(str(df20['rating_1'][3])),
        int(str(df20['rating_1'][4])),int(str(df20['rating_1'][5])),int(str(df20['rating_1'][6]))],           
#        "TEACHERrating_5LAST_TO_LAST_WEEK":[int(str(df10['rating_5'][0])),int(str(df10['rating_5'][1])),
#            int(str(df10['rating_5'][2])),int(str(df10['rating_5'][3])),
#         int(str(df10['rating_5'][4])),int(str(df1['rating_5'][5])),int(str(df10['rating_5'][6]))],
#     "TEACHERrating_4LAST_TO_LAST_WEEK":[int(str(df10['rating_4'][0])),int(str(df10['rating_4'][1])),
#            int(str(df10['rating_4'][2])),int(str(df10['rating_4'][3])),
#         int(str(df10['rating_4'][4])),int(str(df10['rating_4'][5])),int(str(df10['rating_4'][6]))],
#     "TEACHERrating_3LAST_TO_LAST_WEEK":[int(str(df10['rating_3'][0])),int(str(df10['rating_3'][1])),
#            int(str(df10['rating_3'][2])),int(str(df10['rating_3'][3])),
#         int(str(df10['rating_3'][4])),int(str(df10['rating_3'][5])),int(str(df10['rating_3'][6]))],
    "TEACHERrating_2LAST_TO_LAST_WEEK":[int(str(df10['rating_2'][0])),int(str(df10['rating_2'][1])),
           int(str(df10['rating_2'][2])),int(str(df10['rating_2'][3])),
        int(str(df10['rating_2'][4])),int(str(df10['rating_2'][5])),int(str(df10['rating_2'][6]))],
    "TEACHERrating_1LAST_TO_LAST_WEEK":[int(str(df10['rating_1'][0])),int(str(df10['rating_1'][1])),
           int(str(df10['rating_1'][2])),int(str(df10['rating_1'][3])),
        int(str(df10['rating_1'][4])),int(str(df10['rating_1'][5])),int(str(df10['rating_1'][6]))],        
              }
    temp={'weekdata':weekdata}
    return json.dumps(temp)

@app.route('/practicehistorychartlatest')
def practice_historynewlatest():
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
            # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
        #     print("LSY", LSY_Date)
        #     print("CSY",csy_first_date())


    mongo_uri = "mongodb://admin:" + urllib.parse.quote('F5tMazRj47cYqm33e') + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.audio_track_master_all
    collection2 = db.audio_track_master
    ########## FOR DF ###########################
    dateStr = str(LSY_Date.date())
    myDatetime = dateutil.parser.parse(dateStr)
    datestr1 = str(csy_first_date())
    myDatetime1 = dateutil.parser.parse(datestr1)
    ########### FOR DF1 ############################
    dateStr2 = str(csy_first_date().date())
    myDatetime2 = dateutil.parser.parse(dateStr2)
    ########################## FOR DF2 ###############
    dateStr3 = "2020-03-17T00:00:00.000Z"
    myDatetime3 = dateutil.parser.parse(dateStr3)
    ##################################
    ##################################
    dateStr4 = str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1))
    myDatetime4 = dateutil.parser.parse(dateStr4)
    ######################  USER PRACTICE 2019-2020(LSY) ############################################
    df1 = DataFrame(list(collection2.aggregate([{
            '$match':{'USER_ID.IS_DISABLED':{'$ne':'Y'},
                    'USER_ID.IS_BLOCKED':{"$ne":'Y'},
                    'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}, 
                    "USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                    "USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                    'USER_ID.EMAIL_ID':{'$ne':""},
                    "MODIFIED_DATE":{"$gte": myDatetime2
    #                                      ,"$lte" : myDatetime4
                                    },
                    'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}},
            {"$match":
            {"$and" :[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Users_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    ##################### PARENTS ##########################################
    df2 = DataFrame(list(collection2.aggregate([{
            '$match':{'USER_ID.IS_DISABLED':{'$ne':'Y'},
                    'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}, 
                    'USER_ID.EMAIL_ID':{'$ne':""},
                      "USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                       "USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                    "MODIFIED_DATE":{"$gte": myDatetime2
    #                                      ,"$lte" : myDatetime4
                                    },
                    'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}},
            {"$match":
            {"$and" :[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))




    ########schoology################################

    schoology = DataFrame(list(collection2.aggregate([{
            '$match':{'USER_ID.IS_DISABLED':{'$ne':'Y'},
                    'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}, 
                    'USER_ID.EMAIL_ID':{'$ne':""},
                      "USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                   "USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")},
                    "MODIFIED_DATE":{"$gte": myDatetime2
    #                                      ,"$lte" : myDatetime4
                                    },
    #                     'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}
                     }},
            {"$match":
            {"$and" :[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    #     print(schoology,"schoology")
    ########clever################################
    clever = DataFrame(list(collection2.aggregate([{
            '$match':{'USER_ID.IS_DISABLED':{'$ne':'Y'},
                    'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}, 
                    'USER_ID.EMAIL_ID':{'$ne':""},
                      "USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                   "USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")},
                    "MODIFIED_DATE":{"$gte": myDatetime2
    #                                      ,"$lte" : myDatetime4
                                    },
    #                     'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}
                     }},
            {"$match":
            {"$and" :[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))


    ###################### TOTAL LSY ##############################
    df3 = DataFrame(list(collection2.aggregate([{"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'MODIFIED_DATE':{"$gte":myDatetime,"$lt": myDatetime1}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'}, 
                        'Total_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Total_Practice_LSY':'$Total_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))




    #user_CSY
    df1['Practice_date'] = pd.to_datetime(df1['Practice_date'])


    df5=df1.sort_values(by='Practice_date')
    #df5['Practice_date']=df5['Practice_date'].astype(np.int64)/int(1e6)
    #uscy=df5.values.tolist()
    df7=pd.date_range(start=str(csy_first_date().date()), end=str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1)))
    df9 = pd.DataFrame(df7,columns = ["Practice_date"])
    df9['value'] = 0

    uscy1= df5.merge(df9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    uscy1['Practice_date']=uscy1['Practice_date'].astype(np.int64)/int(1e6)
    uscy=uscy1[["Practice_date","Users_Practice_CSY"]].values.tolist()

    #clever csy
    if 'Practice_date' in list(clever.columns):
        clever['Practice_date'] = pd.to_datetime(clever['Practice_date'])
        df6c=clever.sort_values(by='Practice_date')
    else:
        dates=pd.date_range(start=str(csy_first_date().date()), end=str(datetime.date.today()))
        clever=pd.DataFrame(dates,columns = ["Practice_date"])
        clever['Parents_Practice_CSY'] = 0
        df6c=clever.sort_values(by='Practice_date')



    #schoology csy

    if 'Practice_date' in list(schoology.columns):
        schoology['Practice_date'] = pd.to_datetime(schoology['Practice_date'])
        df6s=schoology.sort_values(by='Practice_date')
    else:
        dates=pd.date_range(start=str(csy_first_date().date()), end=str(datetime.date.today()))
        schoology=pd.DataFrame(dates,columns = ["Practice_date"])
        schoology['Parents_Practice_CSY'] = 0
        df6s=schoology.sort_values(by='Practice_date')




    #Parent_CSY
    df2['Practice_date'] = pd.to_datetime(df2['Practice_date'])
    df6=df2.sort_values(by='Practice_date')
    dfp=pd.date_range(start=str(csy_first_date().date()), end=str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1)))
    dfp9 = pd.DataFrame(dfp,columns = ["Practice_date"])
    dfp9['value'] = 0

    pscy1= df6.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    pscy1['Practice_date']=pscy1['Practice_date'].astype(np.int64)/int(1e6)
    pscy=pscy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()


    ####clever
    ccsy1= df6c.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')


    ccsy1['Practice_date']=ccsy1['Practice_date'].astype(np.int64)/int(1e6)
    ccsy=ccsy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()




    ####schoology
    scsy1= df6c.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    scsy1['Practice_date']=scsy1['Practice_date'].astype(np.int64)/int(1e6)
    scsy=scsy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()
    #practice_Lsy
    df3['Practice_date'] = pd.to_datetime(df3['Practice_date'])
    df4=df3.sort_values(by='Practice_date')
    dfl=pd.date_range(start=str(csy_first_date().date()-relativedelta(years=1)), end=str(csy_first_date().date()-relativedelta(days=1)))
    dfl9 = pd.DataFrame(dfl,columns = ["Practice_date"])
    dfl9['value'] = 0
    plcy1= df4.merge(dfl9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    plcy1['Practice_date']=plcy1['Practice_date'].astype(np.int64)/int(1e6)
    plcy=plcy1[["Practice_date","Total_Practice_LSY"]].values.tolist()
    temp={'data':{'csy':uscy,'pcsy':pscy,'lsy':plcy,'clever':ccsy,'schoology':scsy}}

    return json.dumps(temp)
    
#>>>>>>>>>>>>>>>>>>>>>...........PRACTICE BIFURCATION................>>>>>>>>>
@app.route('/practicehistorychartlatest/<charttype>')
def practice___history___new___latest(charttype):    
    import datetime
    from datetime import timedelta
    from dateutil.relativedelta import relativedelta
    def csy_first_date():
            date_today =datetime.date.today()
        #     print(date_today)
        #     date_today='2024-07-01'
        #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
            initial_date='2020-08-01'
            day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
            # Check if leap year in the calculation
            if ((day1.year+1) % 4) == 0:
                if ((day1.year+1) % 100) == 0:
                    if ((day1.year+1) % 400) == 0:
                        days_diff=1
                    else:
                        days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=0
            if ((date_today-day1).days<(365+days_diff)):
                day_1=day1
            else:
                day1=day1+timedelta(days=(365+days_diff))
                day_1=day1

            csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

            return csy_date
                # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
        #     print("LSY", LSY_Date)
        #     print("CSY",csy_first_date())
        



    mongo_uri = "mongodb://admin:" + urllib.parse.quote('F5tMazRj47cYqm33e') + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.audio_track_master_all
    collection2 = db.audio_track_master
    ########## FOR DF ###########################
    dateStr = str(LSY_Date.date())
    myDatetime = dateutil.parser.parse(dateStr)
    datestr1 = str(csy_first_date())
    myDatetime1 = dateutil.parser.parse(datestr1)
    ########### FOR DF1 ############################
    dateStr2 = str(csy_first_date().date())
    myDatetime2 = dateutil.parser.parse(dateStr2)
    ########################## FOR DF2 ###############
    dateStr3 = "2020-03-17T00:00:00.000Z"
    myDatetime3 = dateutil.parser.parse(dateStr3)
    ##################################
    ##################################
    dateStr4 = str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1))
    myDatetime4 = dateutil.parser.parse(dateStr4)

    charttype=str(charttype).title()

    if charttype=='Practice':


    #     threshold=int(threshold)/100


        threshold=.5


        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        ######################  USER PRACTICE 2019-2020(LSY) ############################################
        df1 = DataFrame(list(collection2.aggregate([
            {"$match":
            {"$and" :[
                {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{'$ne':""}},

                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                {"MODIFIED_DATE":{"$gte": myDatetime2
        #                                      ,"$lte" : myDatetime4
                                    }},
                {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},


                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
        practice_cond_dictonary_list[0],
                    practice_cond_dictonary_list[1],
                     threshcond[0],

            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Users_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))

        df2 = DataFrame(list(collection2.aggregate([{"$match":
            {"$and" :[
                {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{'$ne':""}},

                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                {"MODIFIED_DATE":{"$gte": myDatetime2
        #                                      ,"$lte" : myDatetime4
                                    }},
                {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},


                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}},                
            ]}},
                                                practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],

                {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                                    'month':{'$month':'$MODIFIED_DATE'}},
                            'date':{'$first':'$MODIFIED_DATE'}, 
                            'Parents_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                                'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))

        schoology = DataFrame(list(collection2.aggregate([
                    {"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                             { "USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                           {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                        {"USER_ID._id":{"$nin":db.canvas_user_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": myDatetime2
            #                                      ,"$lte" : myDatetime4
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},

        practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],

                    {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                                    'month':{'$month':'$MODIFIED_DATE'}},
                            'date':{'$first':'$MODIFIED_DATE'}, 
                            'Parents_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                                'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))
            #     print(schoology,"schoology")
                                      ########clever################################

        clever = DataFrame(list(collection2.aggregate([{"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                             { "USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.schoology_master.distinct( "USER_ID._id")}},
                        {"USER_ID._id":{"$nin":db.canvas_user_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": myDatetime2
            #                                      ,"$lte" : myDatetime4
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},
        practice_cond_dictonary_list[0],
                    practice_cond_dictonary_list[1],
                     threshcond[0],
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
        
        
        
        
        canvas = DataFrame(list(collection2.aggregate([{"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                        { "USER_ID._id":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}},
                           { "USER_ID._id":{"$nin":db.clever_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.schoology_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": myDatetime2
            #                                      ,"$lte" : myDatetime4
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},
        practice_cond_dictonary_list[0],
                    practice_cond_dictonary_list[1],
                     threshcond[0],
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
        
        
        

        df3 = DataFrame(list(collection2.aggregate([{"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'MODIFIED_DATE':{"$gte":myDatetime,"$lt": myDatetime1}}]}},
                        practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],
                    {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                                    'month':{'$month':'$MODIFIED_DATE'}},
                                'date':{'$first':'$MODIFIED_DATE'}, 
                                'Total_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                                'Total_Practice_LSY':'$Total_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))






        df_last_to_lsy = DataFrame(list(collection2.aggregate([{"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'MODIFIED_DATE':{"$gte":myDatetime-relativedelta(years=1),"$lt": myDatetime}}]}},
                        practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],
                    {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                                    'month':{'$month':'$MODIFIED_DATE'}},
                                'date':{'$first':'$MODIFIED_DATE'}, 
                                'Total_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                                'Total_Practice_LSY':'$Total_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))






        #user_CSY
        df1['Practice_date'] = pd.to_datetime(df1['Practice_date'])


        df5=df1.sort_values(by='Practice_date')
        #df5['Practice_date']=df5['Practice_date'].astype(np.int64)/int(1e6)
        #uscy=df5.values.tolist()
        df7=pd.date_range(start=str(csy_first_date().date()), end=str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1)))
        df9 = pd.DataFrame(df7,columns = ["Practice_date"])
        df9['value'] = 0

        uscy1= df5.merge(df9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
        uscy1['Practice_date']=uscy1['Practice_date'].astype(np.int64)/int(1e6)
        uscy=uscy1[["Practice_date","Users_Practice_CSY"]].values.tolist()

        #clever csy
        if 'Practice_date' in list(clever.columns):

            clever['Practice_date'] = pd.to_datetime(clever['Practice_date'])
            df6c=clever.sort_values(by='Practice_date')
        else:

            dates=pd.date_range(start=str(csy_first_date().date()), end=str(datetime.date.today()))
            clever=pd.DataFrame(dates,columns = ["Practice_date"])
            clever['Parents_Practice_CSY'] = 0
            df6c=clever.sort_values(by='Practice_date')
            
            
        #canvas csy
        if 'Practice_date' in list(canvas.columns):

            canvas['Practice_date'] = pd.to_datetime(canvas['Practice_date'])
            df6can=canvas.sort_values(by='Practice_date')
        else:

            dates=pd.date_range(start=str(csy_first_date().date()), end=str(datetime.date.today()))
            canvas=pd.DataFrame(dates,columns = ["Practice_date"])
            canvas['Parents_Practice_CSY'] = 0
            df6can=canvas.sort_values(by='Practice_date')



        #schoology csy

        if 'Practice_date' in list(schoology.columns):

            schoology['Practice_date'] = pd.to_datetime(schoology['Practice_date'])
            df6s=schoology.sort_values(by='Practice_date')
        else:

            dates=pd.date_range(start=str(csy_first_date().date()), end=str(datetime.date.today()))
            schoology=pd.DataFrame(dates,columns = ["Practice_date"])
            schoology['Parents_Practice_CSY'] = 0
            df6s=schoology.sort_values(by='Practice_date')




        #Parent_CSY
        df2['Practice_date'] = pd.to_datetime(df2['Practice_date'])
        df6=df2.sort_values(by='Practice_date')
        dfp=pd.date_range(start=str(csy_first_date().date()), end=str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1)))
        dfp9 = pd.DataFrame(dfp,columns = ["Practice_date"])
        dfp9['value'] = 0

        pscy1= df6.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
        pscy1['Practice_date']=pscy1['Practice_date'].astype(np.int64)/int(1e6)
        pscy=pscy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()


        ####clever
        ccsy1= df6c.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')


        ccsy1['Practice_date']=ccsy1['Practice_date'].astype(np.int64)/int(1e6)
        ccsy=ccsy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()
        
        ####canvas
        cancsy1= df6can.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')


        cancsy1['Practice_date']=cancsy1['Practice_date'].astype(np.int64)/int(1e6)
        cancsy=cancsy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()


        ####schoology
        scsy1= df6s.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
        scsy1['Practice_date']=scsy1['Practice_date'].astype(np.int64)/int(1e6)
        scsy=scsy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()
        #practice_Lsy
        df3['Practice_date'] = pd.to_datetime(df3['Practice_date'])
        df4=df3.sort_values(by='Practice_date')
        dfl=pd.date_range(start=str(csy_first_date().date()-relativedelta(years=1)), end=str(csy_first_date().date()-relativedelta(days=1)))
        dfl9 = pd.DataFrame(dfl,columns = ["Practice_date"])
        dfl9['value'] = 0
        plcy1= df4.merge(dfl9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
        plcy1['Practice_date']=plcy1['Practice_date'].astype(np.int64)/int(1e6)
        plcy=plcy1[["Practice_date","Total_Practice_LSY"]].values.tolist()

        #practice_Lsy_to_Lsy
        df_last_to_lsy['Practice_date'] = pd.to_datetime(df_last_to_lsy['Practice_date'])
        df44=df_last_to_lsy.sort_values(by='Practice_date')
        dfk=pd.date_range(start=str(myDatetime-relativedelta(years=1)), end=str(myDatetime-relativedelta(days=1)))
        dfk9 = pd.DataFrame(dfk,columns = ["Practice_date"])
        dfk9['value'] = 0
        plcy111= df44.merge(dfk9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
        plcy111['Practice_date']=plcy111['Practice_date'].astype(np.int64)/int(1e6)
        plcy_lsy=plcy111[["Practice_date","Total_Practice_LSY"]].values.tolist()


        temp={'data':{'csy':uscy,'pcsy':pscy,'lsy':plcy,'lsy_to_lsy':plcy_lsy,'clever':ccsy,'schoology':scsy, 'canvas': cancsy}}
        return json.dumps(temp)

    else:
                        ######################  USER PRACTICE 2019-2020(LSY) ############################################
        
        df1 = DataFrame(list(collection2.aggregate([
            {"$match":
            {"$and" :[
                {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{'$ne':""}},

                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                {"MODIFIED_DATE":{"$gte": myDatetime2
        #                                      ,"$lte" : myDatetime4
                                    }},
                {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},


                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
#         practice_cond_dictonary_list[0],
#                     practice_cond_dictonary_list[1],
#                      threshcond[0],

            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Users_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))

        df2 = DataFrame(list(collection2.aggregate([{"$match":
            {"$and" :[
                {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{'$ne':""}},

                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                {"MODIFIED_DATE":{"$gte": myDatetime2
        #                                      ,"$lte" : myDatetime4
                                    }},
                {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},


                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}},                
            ]}},
#                                                 practice_cond_dictonary_list[0],
#                             practice_cond_dictonary_list[1],
#                              threshcond[0],

                {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                                    'month':{'$month':'$MODIFIED_DATE'}},
                            'date':{'$first':'$MODIFIED_DATE'}, 
                            'Parents_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                                'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))

        schoology = DataFrame(list(collection2.aggregate([
                    {"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                             { "USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                           {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": myDatetime2
            #                                      ,"$lte" : myDatetime4
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},

#         practice_cond_dictonary_list[0],
#                             practice_cond_dictonary_list[1],
#                              threshcond[0],

                    {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                                    'month':{'$month':'$MODIFIED_DATE'}},
                            'date':{'$first':'$MODIFIED_DATE'}, 
                            'Parents_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                                'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))
            #     print(schoology,"schoology")
                                      ########clever################################

        clever = DataFrame(list(collection2.aggregate([{"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                             { "USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.schoology_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": myDatetime2
            #                                      ,"$lte" : myDatetime4
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},
#         practice_cond_dictonary_list[0],
#                     practice_cond_dictonary_list[1],
#                      threshcond[0],
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
        
        
        
        
        canvas = DataFrame(list(collection2.aggregate([{"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                        { "USER_ID._id":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}},
                           { "USER_ID._id":{"$nin":db.clever_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.schoology_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": myDatetime2
            #                                      ,"$lte" : myDatetime4
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},
#         practice_cond_dictonary_list[0],
#                     practice_cond_dictonary_list[1],
#                      threshcond[0],
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
        
        
        

        df3 = DataFrame(list(collection2.aggregate([{"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'MODIFIED_DATE':{"$gte":myDatetime,"$lt": myDatetime1}}]}},
#                         practice_cond_dictonary_list[0],
#                             practice_cond_dictonary_list[1],
#                              threshcond[0],
                    {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                                    'month':{'$month':'$MODIFIED_DATE'}},
                                'date':{'$first':'$MODIFIED_DATE'}, 
                                'Total_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                                'Total_Practice_LSY':'$Total_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))






        df_last_to_lsy = DataFrame(list(collection2.aggregate([{"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'MODIFIED_DATE':{"$gte":myDatetime-relativedelta(years=1),"$lt": myDatetime}}]}},
#                         practice_cond_dictonary_list[0],
#                             practice_cond_dictonary_list[1],
#                              threshcond[0],
                    {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                                    'month':{'$month':'$MODIFIED_DATE'}},
                                'date':{'$first':'$MODIFIED_DATE'}, 
                                'Total_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                                'Total_Practice_LSY':'$Total_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))






        #user_CSY
        df1['Practice_date'] = pd.to_datetime(df1['Practice_date'])


        df5=df1.sort_values(by='Practice_date')
        #df5['Practice_date']=df5['Practice_date'].astype(np.int64)/int(1e6)
        #uscy=df5.values.tolist()
        df7=pd.date_range(start=str(csy_first_date().date()), end=str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1)))
        df9 = pd.DataFrame(df7,columns = ["Practice_date"])
        df9['value'] = 0

        uscy1= df5.merge(df9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
        uscy1['Practice_date']=uscy1['Practice_date'].astype(np.int64)/int(1e6)
        uscy=uscy1[["Practice_date","Users_Practice_CSY"]].values.tolist()

        #clever csy
        if 'Practice_date' in list(clever.columns):

            clever['Practice_date'] = pd.to_datetime(clever['Practice_date'])
            df6c=clever.sort_values(by='Practice_date')
        else:

            dates=pd.date_range(start=str(csy_first_date().date()), end=str(datetime.date.today()))
            clever=pd.DataFrame(dates,columns = ["Practice_date"])
            clever['Parents_Practice_CSY'] = 0
            df6c=clever.sort_values(by='Practice_date')
            
            
        #canvas csy
        if 'Practice_date' in list(canvas.columns):

            canvas['Practice_date'] = pd.to_datetime(canvas['Practice_date'])
            df6can=canvas.sort_values(by='Practice_date')
        else:

            dates=pd.date_range(start=str(csy_first_date().date()), end=str(datetime.date.today()))
            canvas=pd.DataFrame(dates,columns = ["Practice_date"])
            canvas['Parents_Practice_CSY'] = 0
            df6can=canvas.sort_values(by='Practice_date')



        #schoology csy

        if 'Practice_date' in list(schoology.columns):

            schoology['Practice_date'] = pd.to_datetime(schoology['Practice_date'])
            df6s=schoology.sort_values(by='Practice_date')
        else:

            dates=pd.date_range(start=str(csy_first_date().date()), end=str(datetime.date.today()))
            schoology=pd.DataFrame(dates,columns = ["Practice_date"])
            schoology['Parents_Practice_CSY'] = 0
            df6s=schoology.sort_values(by='Practice_date')




        #Parent_CSY
        df2['Practice_date'] = pd.to_datetime(df2['Practice_date'])
        df6=df2.sort_values(by='Practice_date')
        dfp=pd.date_range(start=str(csy_first_date().date()), end=str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1)))
        dfp9 = pd.DataFrame(dfp,columns = ["Practice_date"])
        dfp9['value'] = 0

        pscy1= df6.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
        pscy1['Practice_date']=pscy1['Practice_date'].astype(np.int64)/int(1e6)
        pscy=pscy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()


        ####clever
        ccsy1= df6c.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')


        ccsy1['Practice_date']=ccsy1['Practice_date'].astype(np.int64)/int(1e6)
        ccsy=ccsy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()
        
        ####canvas
        cancsy1= df6can.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')


        cancsy1['Practice_date']=cancsy1['Practice_date'].astype(np.int64)/int(1e6)
        cancsy=cancsy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()


        ####schoology
        scsy1= df6s.merge(dfp9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
        scsy1['Practice_date']=scsy1['Practice_date'].astype(np.int64)/int(1e6)
        scsy=scsy1[["Practice_date","Parents_Practice_CSY"]].values.tolist()
        #practice_Lsy
        df3['Practice_date'] = pd.to_datetime(df3['Practice_date'])
        df4=df3.sort_values(by='Practice_date')
        dfl=pd.date_range(start=str(csy_first_date().date()-relativedelta(years=1)), end=str(csy_first_date().date()-relativedelta(days=1)))
        dfl9 = pd.DataFrame(dfl,columns = ["Practice_date"])
        dfl9['value'] = 0
        plcy1= df4.merge(dfl9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
        plcy1['Practice_date']=plcy1['Practice_date'].astype(np.int64)/int(1e6)
        plcy=plcy1[["Practice_date","Total_Practice_LSY"]].values.tolist()

        #practice_Lsy_to_Lsy
        df_last_to_lsy['Practice_date'] = pd.to_datetime(df_last_to_lsy['Practice_date'])
        df44=df_last_to_lsy.sort_values(by='Practice_date')
        dfk=pd.date_range(start=str(myDatetime-relativedelta(years=1)), end=str(myDatetime-relativedelta(days=1)))
        dfk9 = pd.DataFrame(dfk,columns = ["Practice_date"])
        dfk9['value'] = 0
        plcy111= df44.merge(dfk9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
        plcy111['Practice_date']=plcy111['Practice_date'].astype(np.int64)/int(1e6)
        plcy_lsy=plcy111[["Practice_date","Total_Practice_LSY"]].values.tolist()


        temp={'data':{'csy':uscy,'pcsy':pscy,'lsy':plcy,'lsy_to_lsy':plcy_lsy,'clever':ccsy,'schoology':scsy, 'canvas': cancsy}}
        return json.dumps(temp)


@app.route('/signuptableschoology/<date>')
def signup_user_detail(date):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.subscription_master
    query1= [
{'$match':{'USER_ID.schoolId._id':{'$exists':1}}},
    {"$match":
             {"$and":[{'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}}, 
                      {'USER_ID.EMAIL_ID':{"$ne":""}}, 
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'IS_BLOCKED':{"$ne":'Y'}},  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
     {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
 {'USER_ID._id':{'$in':db.schoology_master.distinct('USER_ID._id')}},

     {'USER_ID.ROLE_TYPE':{"$regex":'schoology', '$options':'i'}}
 ]}},
    
    {'$group':{'_id':'$USER_ID._id', 
    'max':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}
    }}
            ,
    {'$project':{'_id':1, "RENEWAL_DATE": '$max'
        }} , {'$sort':{'RENEWAL_DATE':1}}
    ]

    collection2= db.audio_track_master
    query2=[
{'$match':{'USER_ID.schoolId._id':{'$exists':1}}},
    {"$match":
             {"$and":[{'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}}, 
                      {'USER_ID.EMAIL_ID':{"$ne":""}}, 
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'IS_BLOCKED':{"$ne":'Y'}},  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
     {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
 {'USER_ID._id':{'$in':db.schoology_master.distinct('USER_ID._id')}},

     {'USER_ID.ROLE_TYPE':{"$regex":'schoology', '$options':'i'}}
 ]}},
    
    {'$group':{'_id':'$USER_ID._id', 
    'PRACTICE_SESSIONS':{'$sum':1}, 
    'COMPLETED_SESSIONS':{'$sum':{'$cond':[{'$eq':['$IS_DONE', 'Y']},1,0]}},
    'LAST_PRACTICE_DATE':{'$max':'$MODIFIED_DATE'},
    'MINDFUL_MINUTES':{'$sum':{'$round':[{'$cond':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},1,0]},2]}}
              }},      
    {'$project':{'_id':1,'LAST_PRACTICE_DATE':{'$dateToString':{"format":"%Y-%m-%d","date":'$LAST_PRACTICE_DATE'}},
                    'PRACTICE_SESSIONS':1, 'COMPLETED_SESSIONS':1, 'MINDFUL_MINUTES':1
                    }}]



    collection3= db.user_master
    query3= [
{'$match':{'schoolId._id':{'$exists':1}}},
    {"$match":
             {"$and":[{'EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}}, 
                      {'EMAIL_ID':{"$ne":""}}, 
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_NAME':{"$not":{"$regex":'test','$options':'i'}}}, 
    {'IS_DISABLED':{"$ne":'Y'}},{'IS_BLOCKED':{"$ne":'Y'}},  {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
     {'EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
 {'_id':{'$in':db.schoology_master.distinct('USER_ID._id')}},
 {'DISTRICT_ID.DISTRICT_NAME':{"$not":{"$regex":'test','$options':'i'}}},
     {'ROLE_TYPE':{"$regex":'schoology', '$options':'i'}}
 ]}},

      {'$group':{'_id':'$_id',
            'CREATED_DATE':{'$first':'$CREATED_DATE'}, 'USER_NAME':{'$first':'$USER_NAME'}, 
                   'EMAIL_ID':{'$first':'$EMAIL_ID'},
            'School_id':{'$first':'$schoolId._id'}, 'SCHOOL_NAME':{'$first':"$schoolId.NAME"}
        }},
            {'$project':{'_id':1,'CREATED_DATE':{'$dateToString':{"format":"%Y-%m-%d","date":'$CREATED_DATE'}},
                        'USER_NAME':1, 'EMAIL_ID':1, 'SCHOOL_NAME':1
                        }}]


    subs_list= list(collection1.aggregate(query1))
    df_subs= DataFrame(subs_list)
    atm_list=list(collection2.aggregate(query2))
    df_atm= DataFrame(atm_list)
    um_list= list(collection3.aggregate(query3))
    df_um= DataFrame(um_list)
    join= pd.merge(df_um, df_subs, how='left', on='_id').fillna(0)

    join_final= pd.merge(join, df_atm, how='left', on='_id').fillna(0)

    final_table= join_final[['CREATED_DATE','USER_NAME','EMAIL_ID','SCHOOL_NAME','PRACTICE_SESSIONS','COMPLETED_SESSIONS',
                             'RENEWAL_DATE', 'LAST_PRACTICE_DATE','MINDFUL_MINUTES' ]]

    final_group=final_table.groupby(final_table['CREATED_DATE'])
    data=final_group.get_group(""+date+"")
    data1 = pd.DataFrame(data)
    temp={'data':data1.values.tolist()}


    return json.dumps(temp) #year has been used keep it in mind

@app.route('/schoology/<date>')
def practice_User_info(date):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection1= db.subscription_master
    query1= [
    {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
                        {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},
    {'USER_ID.EMAIL_ID':{'$regex':'schoology', '$options':'i'}}
    ]}}, 
    {'$group':{'_id':'$USER_ID._id', 
    'RENEWAL_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}
    }}
            ,
    {'$project':{'_id':1, "RENEWAL_DATE":{'$dateToString':{"format":"%Y-%m-%d","date":'$RENEWAL_DATE'}}
        }} , {'$sort':{'RENEWAL_DATE':1}}
    ]
    
    
    
    collection2= db.audio_track_master
    query2=[
    {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},
    {'USER_ID.EMAIL_ID':{'$regex':'schoology', '$options':'i'}}
    ]}},
    {'$group':{'_id':{'USER_ID':'$USER_ID._id', 'PRACTICE_DATE':'$MODIFIED_DATE'},
    'PRACTICE_SESSIONS':{'$sum':1}, 
    'COMPLETED_SESSIONS':{'$sum':{'$cond':[{'$eq':['$IS_DONE', 'Y']},1,0]}},
#     'PRACTICE_DATE':{'$first':'$MODIFIED_DATE'},
    'MINDFUL_MINUTES':{'$sum':{'$round':[{'$cond':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},1,0]},2]}}
              }},      
    {'$project':{'_id':1,
#                  'PRACTICE_DATE':{'$dateToString':{"format":"%Y-%m-%d","date":'$PRACTICE_DATE'}},
                 
                    'PRACTICE_SESSIONS':1, 'COMPLETED_SESSIONS':1, 'MINDFUL_MINUTES':1
                    }}]

           
                   
    collection3= db.user_master
    query3= [
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'schoolId._id':{'$not':{'$regex':'null'}}},
    {'EMAIL_ID':{'$regex':'schoology', '$options':'i'}}
    ]}},
    {'$group':{'_id':'$_id',
        'CREATED_DATE':{'$first':'$CREATED_DATE'}, 'USER_NAME':{'$first':'$USER_NAME'}, 
               'EMAIL_ID':{'$first':'$EMAIL_ID'},
        'School_id':{'$first':'$schoolId._id'}, 'SCHOOL_NAME':{'$first':"$schoolId.NAME"}
    }},
        {'$project':{'_id':1,'CREATED_DATE':{'$dateToString':{"format":"%Y-%m-%d","date":'$CREATED_DATE'}},
                    'USER_NAME':1, 'EMAIL_ID':1, 'SCHOOL_NAME':1
                    }}]
        
        
        
    subs_list= list(collection1.aggregate(query1))
    df_subs= DataFrame(subs_list)
    
    um_list= list(collection3.aggregate(query3))
    df_um= DataFrame(um_list)
    
    atm_list=DataFrame(list(collection2.aggregate(query2)))
    df_atm= DataFrame(atm_list)

    df_atm= pd.json_normalize(df_atm['_id'])
    df_atm_final=pd.concat([df_atm,atm_list], axis=1)
    del df_atm_final['_id']

    join= pd.merge(df_um, df_subs, how='left', on='_id')
    join_final= pd.merge(join, df_atm_final, how='left', left_on='_id', right_on='USER_ID')
    join_final
    
    final_table= join_final[['CREATED_DATE','USER_NAME','EMAIL_ID','SCHOOL_NAME','PRACTICE_SESSIONS','COMPLETED_SESSIONS',
                        'RENEWAL_DATE', 'PRACTICE_DATE','MINDFUL_MINUTES'
                        ]]
    
    final_group=final_table.groupby(final_table['PRACTICE_DATE'].dt.strftime("%Y-%M-%d"))
    data=final_group.get_group(""+date+"")
    data1 = pd.DataFrame(data)
    temp={'data':data1.values.tolist()}
    return json.dumps(temp)
# # signuphistory('2021-02-04')
@app.route('/signuphistortyschoology')
def signup_histx():    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    df = DataFrame(list(collection.aggregate([

    {'$match':{'schoolId._id':{'$exists':1}}},
    {"$match":
             {"$and":[{'EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}}, 
                      {'EMAIL_ID':{"$ne":""}}, 
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_NAME':{"$not":{"$regex":'test','$options':'i'}}}, 
    {'IS_DISABLED':{"$ne":'Y'}},{'IS_BLOCKED':{"$ne":'Y'}},  {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
     {'EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'_id':{'$in':db.schoology_master.distinct('USER_ID._id')}},
    {'DISTRICT_ID.DISTRICT_NAME':{"$not":{"$regex":'test','$options':'i'}}},
     {'ROLE_TYPE':{"$regex":'schoology', '$options':'i'}}
    ]}},

    {"$group":{"_id":{'day':{"$dayOfMonth":'$CREATED_DATE'},
          'month':{"$month":'$CREATED_DATE'}, 
          'year':{"$year":'$CREATED_DATE'} },
    'date':{'$first':'$CREATED_DATE'},
    'user_count':{"$sum":1}}},
    {"$project":{"_id":0, 'Signup_date':
    {"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
    'user_count':'$user_count'}},
    ])))


    df['Signup_date']= pd.to_datetime(df['Signup_date'])
    df['Signup_date']=df['Signup_date'].astype(np.int64)/int(1e6)
    df2=df.sort_values(by=['Signup_date'], ascending=True)

    df2['Total'] = df2['user_count'].cumsum()
    signdata=[]
    for i,j in zip(df2['Signup_date'].tolist(),df2['user_count'].tolist()):
        signdata.append([i,j])
    signdatacum=[]
    for i,j in zip(df2['Signup_date'].tolist(),df2['Total'].tolist()):
        signdatacum.append([i,j])


    temp={'data':{'signupdata':signdata,'signdatacum':signdatacum}}
    # temp
    return(json.dumps(temp))



@app.route('/practicehistoryschoology')
def practice_histx():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master


    df = DataFrame(list(collection.aggregate([
        {'$match':{'USER_ID.schoolId._id':{'$exists':1}}},
    {"$match":
             {"$and":[{'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}}, 
                      {'USER_ID.EMAIL_ID':{"$ne":""}}, 
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}},  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
     {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
 {'USER_ID._id':{'$in':db.schoology_master.distinct('USER_ID._id')}},
#  {'DISTRICT_ID.DISTRICT_NAME':{"$not":{"$regex":'test','$options':'i'}}},
     {'USER_ID.ROLE_TYPE':{"$regex":'schoology', '$options':'i'}}
 ]}},

        {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'},
                          'month':{'$month':'$MODIFIED_DATE'}, 
                          'year':{'$year':'$MODIFIED_DATE'}},
                   'date':{'$first':'$MODIFIED_DATE'},
                  'pract_count':{'$sum':1} 
                  }},
        {'$project':{'_id':0, 'Practice_date':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}}, 
                     'practice_count':'$pract_count'}},
        {'$sort':{'Practice_date':-1}}])))

    df1= df.dropna(subset=['Practice_date'])
    df1['Practice_date']=pd.to_datetime(df1['Practice_date'])
    df1['Practice_date']=df1['Practice_date'].astype(np.int64)/int(1e6)
    df2=df1.sort_values(by=['Practice_date'], ascending=True)
    

    df2['Total'] = df2['practice_count'].cumsum()
    pracdata=[]
    for i,j in zip(df2['Practice_date'].tolist(),df2['practice_count'].tolist()):
        pracdata.append([i,j])
    pracdatacum=[]
    for i,j in zip(df2['Practice_date'].tolist(),df2['Total'].tolist()):
        pracdatacum.append([i,j])

    temp={'data':{'pracdata':pracdata,'pracdatacum':pracdatacum}}
    return(json.dumps(temp))

#>>>>>>>>>>>------------PRACTICE BIFURCATION API------------------->>>>>>>>>
@app.route('/practicehistoryschoology/<charttype>')
def practice__histx__(charttype):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master


    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        df = DataFrame(list(collection.aggregate([
            {'$match':{'USER_ID.schoolId._id':{'$exists':1}}},
        {"$match":
                 {"$and":[{'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}}, 
                          {'USER_ID.EMAIL_ID':{"$ne":""}}, 
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}},  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
         {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
     {'USER_ID._id':{'$in':db.schoology_master.distinct('USER_ID._id')}},
    #  {'DISTRICT_ID.DISTRICT_NAME':{"$not":{"$regex":'test','$options':'i'}}},
         {'USER_ID.ROLE_TYPE':{"$regex":'schoology', '$options':'i'}}
     ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],

            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'},
                              'month':{'$month':'$MODIFIED_DATE'}, 
                              'year':{'$year':'$MODIFIED_DATE'}},
                       'date':{'$first':'$MODIFIED_DATE'},
                      'pract_count':{'$sum':1} 
                      }},
            {'$project':{'_id':0, 'Practice_date':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}}, 
                         'practice_count':'$pract_count'}},
            {'$sort':{'Practice_date':-1}}])))

        df1= df.dropna(subset=['Practice_date'])
        df1['Practice_date']=pd.to_datetime(df1['Practice_date'])
        df1['Practice_date']=df1['Practice_date'].astype(np.int64)/int(1e6)
        df2=df1.sort_values(by=['Practice_date'], ascending=True)


        df2['Total'] = df2['practice_count'].cumsum()
        pracdata=[]
        for i,j in zip(df2['Practice_date'].tolist(),df2['practice_count'].tolist()):
            pracdata.append([i,j])
        pracdatacum=[]
        for i,j in zip(df2['Practice_date'].tolist(),df2['Total'].tolist()):
            pracdatacum.append([i,j])

        temp={'data':{'pracdata':pracdata,'pracdatacum':pracdatacum}}
        return(json.dumps(temp))
    
    else:
        df = DataFrame(list(collection.aggregate([
            {'$match':{'USER_ID.schoolId._id':{'$exists':1}}},
        {"$match":
                 {"$and":[{'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}}, 
                          {'USER_ID.EMAIL_ID':{"$ne":""}}, 
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}},  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
         {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
     {'USER_ID._id':{'$in':db.schoology_master.distinct('USER_ID._id')}},
    #  {'DISTRICT_ID.DISTRICT_NAME':{"$not":{"$regex":'test','$options':'i'}}},
         {'USER_ID.ROLE_TYPE':{"$regex":'schoology', '$options':'i'}}
     ]}},

            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'},
                              'month':{'$month':'$MODIFIED_DATE'}, 
                              'year':{'$year':'$MODIFIED_DATE'}},
                       'date':{'$first':'$MODIFIED_DATE'},
                      'pract_count':{'$sum':1} 
                      }},
            {'$project':{'_id':0, 'Practice_date':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}}, 
                         'practice_count':'$pract_count'}},
            {'$sort':{'Practice_date':-1}}])))

        df1= df.dropna(subset=['Practice_date'])
        df1['Practice_date']=pd.to_datetime(df1['Practice_date'])
        df1['Practice_date']=df1['Practice_date'].astype(np.int64)/int(1e6)
        df2=df1.sort_values(by=['Practice_date'], ascending=True)


        df2['Total'] = df2['practice_count'].cumsum()
        pracdata=[]
        for i,j in zip(df2['Practice_date'].tolist(),df2['practice_count'].tolist()):
            pracdata.append([i,j])
        pracdatacum=[]
        for i,j in zip(df2['Practice_date'].tolist(),df2['Total'].tolist()):
            pracdatacum.append([i,j])

        temp={'data':{'pracdata':pracdata,'pracdatacum':pracdatacum}}
        return(json.dumps(temp))






@app.route('/pmlu')
def PAY_ME_LATER_USER():
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dfdb = DataFrame(list(db.subscription_master.aggregate([
        {"$match":{"USER_ID.IS_BLOCKED" :{"$ne": "Y"},
            "USER_ID.IS_DISABLED" :{"$ne": "Y"},
            "USER_ID.INCOMPLETE_SIGNUP" : {"$ne": "Y"},
            "USER_ID.DEVICE_USED" : {'$regex' : 'Webapp', '$options' : 'i'},
            "MODE_OF_PAYMENT" :{'$regex' : 'later', '$options' : 'i'},
            "LAST_PAYMENT_AMOUNT" :{'$gt' :100},
            "$and":[
            {"USER_ID.EMAIL_ID" :{"$not": {'$regex' : 'test', '$options' : 'i'}}},
            {"USER_ID.EMAIL_ID" :{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
            {"USER_ID.USER_NAME" :{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {"USER_ID.USER_NAME" :{"$not": {'$regex' : '1gen', '$options' : 'i'}}}
            ]}},
        {"$project":{"_id":0,"EMAIL_ID":"$USER_ID.EMAIL_ID","NAME":"$USER_ID.USER_NAME",
            "SUBSCRIPTION_DATE": { "$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_DATE" } },
            "SUBSCRIPTION_EXPIRE_DATE" : { "$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_EXPIRE_DATE" } },
            "MODE_OF_PAYMENT" :1,"LAST_PAYMENT_AMOUNT":1}},
        ])))

    googleSheetId = '15kYZU_cXkkdeZtmk2EQccKSt8ksYWNoxm3-Lchh8Xbo'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    email=dff["EMAIL_ID"].tolist()
    df2 = dfdb[~dfdb['EMAIL_ID'].isin(email)]
    df=dff.append(df2) 

    df1=df[['SUBSCRIPTION_DATE','LAST_PAYMENT_AMOUNT']]
    df1['SUBSCRIPTION_DATE'] = pd.to_datetime(df1['SUBSCRIPTION_DATE'])
    df2 = df1.groupby(df1['SUBSCRIPTION_DATE'].dt.date).size().reset_index(name='Count')
    df2['SUBSCRIPTION_DATE'] = pd.to_datetime(df2['SUBSCRIPTION_DATE'])
    df2['SUBSCRIPTION_DATE'] = df2['SUBSCRIPTION_DATE'].astype(np.int64) / int(1e6)
    df2['Total_USER'] = df2['Count'].cumsum()
    df3=df2[['SUBSCRIPTION_DATE','Count']]
    USER=df3.values.tolist()
    df4=df2[['SUBSCRIPTION_DATE','Total_USER']]
    TUSER=df4.values.tolist()
    temp={'bar':USER,'line':TUSER}
    return(json.dumps(temp))


@app.route('/pmltable/<date>')
def PAY_ME_LATER_TABLE(date):
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dfdb = DataFrame(list(db.subscription_master.aggregate([
        {"$match":{"USER_ID.IS_BLOCKED" :{"$ne": "Y"},
            "USER_ID.IS_DISABLED" :{"$ne": "Y"},
            "USER_ID.INCOMPLETE_SIGNUP" : {"$ne": "Y"},
            "USER_ID.DEVICE_USED" : {'$regex' : 'Webapp', '$options' : 'i'},
            "MODE_OF_PAYMENT" :{'$regex' : 'later', '$options' : 'i'},
            "LAST_PAYMENT_AMOUNT" :{'$gt' :100},
            "$and":[
            {"USER_ID.EMAIL_ID" :{"$not": {'$regex' : 'test', '$options' : 'i'}}},
            {"USER_ID.EMAIL_ID" :{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
            {"USER_ID.USER_NAME" :{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {"USER_ID.USER_NAME" :{"$not": {'$regex' : '1gen', '$options' : 'i'}}}
            ]}},
        {"$project":{"_id":0,"EMAIL_ID":"$USER_ID.EMAIL_ID","NAME":"$USER_ID.USER_NAME",
            "SUBSCRIPTION_DATE": { "$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_DATE" } },
            "SUBSCRIPTION_EXPIRE_DATE" : { "$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_EXPIRE_DATE" } },
            "MODE_OF_PAYMENT" :1,"LAST_PAYMENT_AMOUNT":1}},
        ])))

    googleSheetId = '15kYZU_cXkkdeZtmk2EQccKSt8ksYWNoxm3-Lchh8Xbo'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    email=dff["EMAIL_ID"].tolist()
    df2 = dfdb[~dfdb['EMAIL_ID'].isin(email)]
    df=dff.append(df2)  
    df1=df[['NAME','EMAIL_ID','MODE_OF_PAYMENT','SUBSCRIPTION_EXPIRE_DATE','SUBSCRIPTION_DATE','LAST_PAYMENT_AMOUNT']]
    df1['SUBSCRIPTION_DATE'] = pd.to_datetime(df1['SUBSCRIPTION_DATE'])
    df2 = df1[df.SUBSCRIPTION_DATE.str.contains("" + date + "",case=False)] 
    data1=df2[['NAME','EMAIL_ID','MODE_OF_PAYMENT','SUBSCRIPTION_EXPIRE_DATE','LAST_PAYMENT_AMOUNT']].values.tolist()
    temp={"data":data1}
    return json.dumps(temp)

@app.route('/pmlcsy')
def PAY_ME_LATERCSY():
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dfdb = DataFrame(list(db.subscription_master.aggregate([
        {"$match":{"USER_ID.IS_BLOCKED" :{"$ne": "Y"},
            "USER_ID.IS_DISABLED" :{"$ne": "Y"},
            "USER_ID.INCOMPLETE_SIGNUP" : {"$ne": "Y"},
            "USER_ID.DEVICE_USED" : {'$regex' : 'Webapp', '$options' : 'i'},
            "MODE_OF_PAYMENT" :{'$regex' : 'later', '$options' : 'i'},
            "LAST_PAYMENT_AMOUNT" :{'$gt' :100},
            "$and":[
            {"USER_ID.EMAIL_ID" :{"$not": {'$regex' : 'test', '$options' : 'i'}}},
            {"USER_ID.EMAIL_ID" :{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
            {"USER_ID.USER_NAME" :{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {"USER_ID.USER_NAME" :{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                {'SUBSCRIPTION_DATE':{'$gte':LSY_Date(),'$lt':csy_first_date()}},

            ]}},
        {"$project":{"_id":0,"EMAIL_ID":"$USER_ID.EMAIL_ID","NAME":"$USER_ID.USER_NAME",
            "SUBSCRIPTION_DATE": { "$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_DATE" } },
            "SUBSCRIPTION_EXPIRE_DATE" : { "$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_EXPIRE_DATE" } },
            "MODE_OF_PAYMENT" :1,"LAST_PAYMENT_AMOUNT":1}},
        ])))

    googleSheetId = '15kYZU_cXkkdeZtmk2EQccKSt8ksYWNoxm3-Lchh8Xbo'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    email=dff["EMAIL_ID"].tolist()
    df2 = dfdb[~dfdb['EMAIL_ID'].isin(email)]
    df=dff.append(df2) 

    df1=df[['SUBSCRIPTION_DATE','LAST_PAYMENT_AMOUNT']]
    df1['SUBSCRIPTION_DATE'] = pd.to_datetime(df1['SUBSCRIPTION_DATE'])
    df2 = df1.groupby(df1['SUBSCRIPTION_DATE'].dt.date).sum().reset_index()
    df2['SUBSCRIPTION_DATE'] = pd.to_datetime(df2['SUBSCRIPTION_DATE'])
    df2['SUBSCRIPTION_DATE'] = df2['SUBSCRIPTION_DATE'].astype(np.int64) / int(1e6)
    df2['Total_Amount'] = df2['LAST_PAYMENT_AMOUNT'].cumsum()
    df3=df2[['SUBSCRIPTION_DATE','LAST_PAYMENT_AMOUNT']]
    Amount=df3.values.tolist()
    df4=df2[['SUBSCRIPTION_DATE','Total_Amount']]
    TAmount=df4.values.tolist()
    temp={'bar':Amount,'line':TAmount}
    return(json.dumps(temp))

@app.route('/pmlcard/')
def PAY_ME_LATER_card():
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dfdb = DataFrame(list(db.subscription_master.aggregate([
        {"$match":{"USER_ID.IS_BLOCKED" :{"$ne": "Y"},
            "USER_ID.IS_DISABLED" :{"$ne": "Y"},
            "USER_ID.INCOMPLETE_SIGNUP" : {"$ne": "Y"},
            "USER_ID.DEVICE_USED" : {'$regex' : 'Webapp', '$options' : 'i'},
            "MODE_OF_PAYMENT" :{'$regex' : 'later', '$options' : 'i'},
            "LAST_PAYMENT_AMOUNT" :{'$gt' :100},
            "$and":[
            {"USER_ID.EMAIL_ID" :{"$not": {'$regex' : 'test', '$options' : 'i'}}},
            {"USER_ID.EMAIL_ID" :{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
            {"USER_ID.USER_NAME" :{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {"USER_ID.USER_NAME" :{"$not": {'$regex' : '1gen', '$options' : 'i'}}}
            ]}},
        {"$project":{"_id":0,"EMAIL_ID":"$USER_ID.EMAIL_ID","NAME":"$USER_ID.USER_NAME",
            "SUBSCRIPTION_DATE": { "$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_DATE" } },
            "SUBSCRIPTION_EXPIRE_DATE" : { "$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_EXPIRE_DATE" } },
            "MODE_OF_PAYMENT" :1,"LAST_PAYMENT_AMOUNT":1}},
        ])))

    googleSheetId = '15kYZU_cXkkdeZtmk2EQccKSt8ksYWNoxm3-Lchh8Xbo'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    email=dff["EMAIL_ID"].tolist()
    df2 = dfdb[~dfdb['EMAIL_ID'].isin(email)]
    df=dff.append(df2) 
    df1=df[['NAME','EMAIL_ID','MODE_OF_PAYMENT','SUBSCRIPTION_EXPIRE_DATE','SUBSCRIPTION_DATE','LAST_PAYMENT_AMOUNT']]
    dfsum=df1['LAST_PAYMENT_AMOUNT'].sum().tolist()
    dfcount=df1['LAST_PAYMENT_AMOUNT'].count().tolist()
    temp={"amount":dfsum,"count":dfcount}
    return json.dumps(temp)


@app.route('/renewalcardnew')
def renewal_cardnew():
    
    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    

    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']
    
    
    
    lifetime=df[df['status']=='lifetime']
    lifetimeonb=lifetime[lifetime['USER_COUNT']==1]
    lifetime0prac=lifetime[lifetime['school_practice_count']==0]
    lifetime0prac=lifetime0prac[lifetime0prac['USER_COUNT']!=1]
    onblifetimecount=len(lifetimeonb)
    zeropraclifetimecount=len(lifetime0prac)
    lifetimecount=len(lifetime)
    lifetimepractising=lifetimecount-(onblifetimecount+zeropraclifetimecount)

    cloudonb=cloud[cloud['USER_COUNT']==1]
    cloud0prac=cloud[cloud['school_practice_count']==0]
    cloud0prac=cloud0prac[cloud0prac['USER_COUNT']!=1]
    onbcloudcount=len(cloudonb)
    zeropraccloudcount=len(cloud0prac)
    cloudcount=len(cloud)
    cloudpractising=cloudcount-(onbcloudcount+zeropraccloudcount)


    trialonb=trial[trial['USER_COUNT']==1]
    trial0prac=trial[trial['school_practice_count']==0]
    trial0prac=trial0prac[trial0prac['USER_COUNT']!=1]
    onbtrialcount=len(trialonb)
    trialtotal=len(trial)
    zeropractrialcount=len(trial0prac)
    trialpractising=trialtotal-(onbtrialcount+zeropractrialcount)


    
    upccsyonb=upcoming[upcoming['USER_COUNT']==1]
    upccsy0prac=upcoming[upcoming['school_practice_count']==0]
    upccsy0prac=upccsy0prac[upccsy0prac['USER_COUNT']!=1]
    onbupccsycount=len(upccsyonb)
    zeropracupccsycount=len(upccsy0prac)
    upccsycountcount=len(upcoming)
    upcomingpractising=upccsycountcount-(onbupccsycount+zeropracupccsycount)
    
    
    expcsyonb=csy[csy['USER_COUNT']==1]
    expcsy0prac=csy[csy['school_practice_count']==0]
    expcsy0prac=expcsy0prac[expcsy0prac['USER_COUNT']!=1]
    onbexpcsycount=len(expcsyonb)
    zeropracexpcsycount=len(expcsy0prac)
    expcsycount=len(csy)
    expcsypractising=expcsycount-(zeropracexpcsycount+onbexpcsycount)


    aftercsyonb=after[after['USER_COUNT']==1]
    aftercsy0prac=after[after['school_practice_count']==0]
    aftercsy0prac=aftercsy0prac[aftercsy0prac['USER_COUNT']!=1]
    onbaftercsycount=len(aftercsyonb)
    zeropracaftercsycount=len(aftercsy0prac)
    aftercount=len(after)
    afterpractising=aftercount-(zeropracaftercsycount+onbaftercsycount)
    
    temp={"totalschool":3888,"lifetime":{"onbording":onblifetimecount, "total":lifetimecount, "zeropractice":zeropraclifetimecount,"practising":lifetimepractising},"cloud":{"onbording":onbcloudcount, "total":cloudcount, "zeropractice":zeropraccloudcount,"practising":cloudpractising},"trial":{"total":trialtotal,"onbording":onbtrialcount,"zeropractice":zeropractrialcount,"practising":trialpractising},"aftercsy":{"total":aftercount,"onbording":onbaftercsycount,"zeropractice":zeropracaftercsycount,"practising":afterpractising},"expcsy":{"total":expcsycount,"onbording":onbexpcsycount,"zeropractice":zeropracexpcsycount,"practising":expcsypractising},"upccsy":{"total":upccsycountcount,"onbording":onbupccsycount,"zeropractice":zeropracupccsycount,"practising":upcomingpractising}}
    return json.dumps(temp)

# @app.route('/renewal20/<month>/But')
# def subscription_Graphnewtabletwenty(month):
#     db = mysql.connector.connect(host="54.184.165.106",    # your host, usually localhost
#                      user="IE-tech",         # your username
#                      passwd="IE-tech@2O2O",  # your password
#                      db="compassJul")
    
    
        
#     query="""select m.School_Name,m.Admin_Name,m.Admin_Email,
#     m.Renewal_Date as Renewal_Date,m.Last_Practice_Date,m.Last_login_Date,
#     m.School_Practice_Count,
#     m.User_Count from (select y.School_Name,y.Admin_Name,y.Admin_Email,
#     y.Renewal_Date as Renewal_Date,
#     date(max(atd.modified_date)) as Last_Practice_Date,
#     date(max(ll.LAST_LOGGED_IN)) as Last_login_Date,
#     count(atd.USER_ID) as School_Practice_Count,
#     count(distinct(um.USER_ID)) As User_Count,
#     count(distinct(atd.USER_ID))/count(distinct(um.USER_ID)) as Practicing_Percentage
#     from (select sm.id as School_Id,sm.name as School_Name,
#     um.USER_ID as Admin_Id,um.USER_NAME as Admin_Name,
#     um.EMAIL_ID as Admin_Email,date(max(sbm.SUBSCRIPTION_EXPIRE_DATE)) as Renewal_Date
#     from user_master as um 
#     inner join subscription_master as sbm on sbm.USER_ID=um.USER_ID
#     left join user_profile as up on up.USER_ID=um.USER_ID
#     left join school_master as sm on sm.id =up.SCHOOL_ID
#     where um.admin_col='ADMIN' 
#     group by um.USER_ID ) as y
#     left join user_profile as up on up.SCHOOL_ID=y.School_Id
#     left join school_master as sm on sm.id=up.SCHOOL_ID
#     left join user_master as um on um.USER_ID=up.USER_ID
#     left join audio_track_detail as atd on atd.USER_ID=um.USER_ID
#     left join login_logs as ll on ll.USER_ID=um.USER_ID
#     where um.user_name not like '%TEST%' and um.IS_DISABLED != 'Y' 
#     and um.IS_BLOCKED != 'Y' 
#     and um.INCOMPLETE_SIGNUP != 'Y' and um.EMAIL_ID not like '%test%'
#     and um.EMAIL_ID not like '%1gen%' and sm.name not like '%blocked%' and um.ROLE_ID!=3
#     group by y.School_Id) as m
#     where m.Practicing_Percentage>=.5 and 
#     monthname(m.Renewal_Date) like '%"""+month+"""%' and year(m.Renewal_Date)='2020' """
#     df=pd.read_sql(query,con=db)
#     df['Renewal_Date']=pd.to_datetime(df['Renewal_Date'])
#     df['Last_Practice_Date']=pd.to_datetime(df['Last_Practice_Date'], errors='coerce')
#     df['Last_login_Date']=pd.to_datetime(df['Last_login_Date'], errors='coerce')
#     df['Last_login_Date']=df['Last_login_Date'].dt.strftime('%d %b %Y')
#     df['Last_Practice_Date']=df['Last_Practice_Date'].dt.strftime('%d %b %Y')
#     df['Renewal_Date']=df['Renewal_Date'].dt.strftime('%d %b %Y')
    
#     return json.dumps({"data":df.values.tolist()})
   

# @app.route('/renewal19/<month>/But')
# def subscription_Graphnewtable(month):
#     db = mysql.connector.connect(host="54.184.165.106",    # your host, usually localhost
#                      user="IE-tech",         # your username
#                      passwd="IE-tech@2O2O",  # your password
#                      db="compassJul")
    
#     year='2019'
#     if month in ['JAN','FEB','MAR','APR']:
#         year='2020'
        
#     query="""select m.School_Name,m.Admin_Name,m.Admin_Email,
#     m.Renewal_Date as Renewal_Date,m.Last_Practice_Date,m.Last_login_Date,
#     m.School_Practice_Count,
#     m.User_Count from (select y.School_Name,y.Admin_Name,y.Admin_Email,
#     y.Renewal_Date as Renewal_Date,
#     date(max(atd.modified_date)) as Last_Practice_Date,
#     date(max(ll.LAST_LOGGED_IN)) as Last_login_Date,
#     count(atd.USER_ID) as School_Practice_Count,
#     count(distinct(um.USER_ID)) As User_Count,
#     count(distinct(atd.USER_ID))/count(distinct(um.USER_ID)) as Practicing_Percentage
#     from (select sm.id as School_Id,sm.name as School_Name,
#     um.USER_ID as Admin_Id,um.USER_NAME as Admin_Name,
#     um.EMAIL_ID as Admin_Email,date(max(sbm.SUBSCRIPTION_EXPIRE_DATE)) as Renewal_Date
#     from user_master as um 
#     inner join subscription_master as sbm on sbm.USER_ID=um.USER_ID
#     left join user_profile as up on up.USER_ID=um.USER_ID
#     left join school_master as sm on sm.id =up.SCHOOL_ID
#     where um.admin_col='ADMIN' 
#     group by um.USER_ID ) as y
#     left join user_profile as up on up.SCHOOL_ID=y.School_Id
#     left join school_master as sm on sm.id=up.SCHOOL_ID
#     left join user_master as um on um.USER_ID=up.USER_ID
#     left join audio_track_detail as atd on atd.USER_ID=um.USER_ID
#     left join login_logs as ll on ll.USER_ID=um.USER_ID
#     where um.user_name not like '%TEST%' and um.IS_DISABLED != 'Y' 
#     and um.IS_BLOCKED != 'Y' 
#     and um.INCOMPLETE_SIGNUP != 'Y' and um.EMAIL_ID not like '%test%'
#     and um.EMAIL_ID not like '%1gen%' and sm.name not like '%blocked%' and um.ROLE_ID!=3
#     group by y.School_Id) as m
#     where m.Practicing_Percentage>=.5 and 
#     monthname(m.Renewal_Date) like '%"""+month+"""%' and year(m.Renewal_Date)='"""+year+"""' """
#     df=pd.read_sql(query,con=db)
#     df['Renewal_Date']=pd.to_datetime(df['Renewal_Date'])
#     df['Last_Practice_Date']=pd.to_datetime(df['Last_Practice_Date'], errors='coerce')
#     df['Last_login_Date']=pd.to_datetime(df['Last_login_Date'], errors='coerce')
#     df['Last_login_Date']=df['Last_login_Date'].dt.strftime('%d %b %Y')
#     df['Last_Practice_Date']=df['Last_Practice_Date'].dt.strftime('%d %b %Y')
#     df['Renewal_Date']=df['Renewal_Date'].dt.strftime('%d %b %Y')
    
#     return json.dumps({"data":df.values.tolist()})
   

@app.route('/subscriptionexpirednewgraph')
def subscription_Graphnew():
  

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.subscription_master
    df = DataFrame(list(collection.aggregate([
        {"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.DEVICE_USED':{"$regex":'webApp','$options':'i'}}
              ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id',
        'EXPIRY_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}}},
        {'$match':{"EXPIRY_DATE":{"$gte": datetime.datetime(2020,7,1),
                                         "$lt":datetime.datetime(2020,9,1)}}},
        {'$project':{'_id':0,'_id':1,'EXPIRY_DATE':1}},
        {'$group':{'_id':{'$month':'$EXPIRY_DATE'},'sc':{'$sum':1}}},
        {'$project':{'_id':1,'school_count':'$sc'}}
        ])))
    df1= df.rename(columns = { '_id': 'Month'})
    #print(df1)

    df1['Month'] = pd.to_datetime(df1['Month'], format='%m').dt.month_name().str.slice(stop=3)
    # print(df1)
    month=df1.Month.tolist()
    school_count=df1.school_count.tolist()
    # active=df.Active_School.tolist()
    # school_50=df.School_Count_50.tolist()
    data=({'month':month,'total':school_count})

    return json.dumps(data)

@app.route('/upcomingnewgraph')
def upcomingnewwwwww():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    # query=[
    #     {"$match":{
    #          '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    #                    {'USER_ID.USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    #                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #           {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    #           {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #           {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    #           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}]}},
    #           {'$project':{'_id':0,
    #               'School_Object_Id':
    #               '$USER_ID.schoolId._id','USER_ObjectId':'$USER_ID._id',
    #               'Practice_Date':'$MODIFIED_DATE'
    #               }}]
    query=[
        {"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId._id':{'$ne':None}}
                  ]}},
              {'$project':{'_id':0,
                  'School_Object_Id':
                  '$USER_ID.schoolId._id','USER_ObjectId':'$USER_ID._id',
                  'Practice_Date':'$MODIFIED_DATE'}},
                  {'$group':{'_id':'$School_Object_Id','Overall':{'$sum':1}
                      }},
                  {'$sort':{'Overall':-1}}]
    collection2=db.subscription_master
    query2=[
    {"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}}
              ]}},
    {'$group':{"_id":'$USER_ID.schoolId._id',
        'auc':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}}},
        {'$match':{"auc":{"$gte":datetime.datetime(2020,7,1),
                                         "$lt":datetime.datetime(2020,12,31)}}},
        {'$project':{'_id':0,'School_Object_Id':'$_id','Renewal_Date':'$auc'}}
        ]
    sub_master_list=list(collection2.aggregate(query2))
    df_sub_master=pd.DataFrame(sub_master_list)
    atm=list(collection.aggregate(query))
    atm_df=pd.DataFrame(atm)
    df=pd.merge(df_sub_master, atm_df, how='left', left_on=['School_Object_Id'], right_on=['_id']).fillna(0)
    df1=df[["Renewal_Date","Overall"]]
    EXPIRING_SOON0=df1.groupby(df1['Renewal_Date'].dt.strftime('%b'))['Overall'].count().reset_index()
    df2=df1[df1["Overall"]>0]
    EXPIRING_BUT_ACTIVE0=df2.groupby(df2['Renewal_Date'].dt.strftime('%b'))['Overall'].count().reset_index()
    EXPIRING_SOON0['Renewal_Date'] = EXPIRING_SOON0['Renewal_Date']
    EXPIRING_BUT_ACTIVE0['Renewal_Date'] = EXPIRING_BUT_ACTIVE0['Renewal_Date']
    month= ['Jul','Aug','Sep','Oct','Nov','Dec','Jan','Feb','Mar','Apr','May','Jun']
    df3 = pd.DataFrame(month,columns =['Renewal_Date'])
    df3['Renewal_Date']=df3['Renewal_Date']
    EXPIRING_SOON = pd.merge(df3, EXPIRING_SOON0, on="Renewal_Date", how='left').fillna(0)
    EXPIRING_BUT_ACTIVE= pd.merge(df3, EXPIRING_BUT_ACTIVE0, on="Renewal_Date", how='left').fillna(0)
    temp={'school_count':EXPIRING_SOON.values.tolist(),'Active_School':EXPIRING_BUT_ACTIVE.values.tolist(),'month':EXPIRING_SOON["Renewal_Date"].values.tolist()}
    return json.dumps(temp) 


@app.route('/upcomingzeropractable')
def upcomingzeropracttable2():
    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    upccsyonb=upcoming[upcoming['USER_COUNT']==1]
    upccsy0prac=upcoming[upcoming['school_practice_count']==0]
    upccsy0prac=upccsy0prac[upccsy0prac['USER_COUNT']!=1]
    onbupccsycount=len(upccsyonb)
    zeropracupccsycount=len(upccsy0prac)
    upccsycountcount=len(upcoming)
    upccsy0prac=upccsy0prac.drop(['UID'], axis=1)
    upccsy0prac=upccsy0prac.drop(['active_count'], axis=1)
    upccsy0prac=upccsy0prac.drop(['status'], axis=1)
    # upccsy0prac=upccsy0prac.drop(['CREATED_DATE'], axis=1)

    return json.dumps({"data":upccsy0prac.values.tolist(),"tablename":"UPCOMING RENEWAL DORMANT SCHOOL DETAILS"})



@app.route('/upcomingonbtable')
def upcomingonboardtable2():
    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']
    
    upccsyonb=upcoming[upcoming['USER_COUNT']==1]
    upccsy0prac=upcoming[upcoming['school_practice_count']==0]
    upccsy0prac=upccsy0prac[upccsy0prac['USER_COUNT']!=1]
    onbupccsycount=len(upccsyonb)
    zeropracupccsycount=len(upccsy0prac)
    upccsycountcount=len(upcoming)
    upccsyonb=upccsyonb.drop(['UID'], axis=1)
    upccsyonb=upccsyonb.drop(['active_count'], axis=1)
    upccsyonb=upccsyonb.drop(['status'], axis=1)
    # upccsyonb=upccsyonb.drop(['CREATED_DATE'], axis=1)

    return json.dumps({"data":upccsyonb.values.tolist(),"tablename":"UPCOMING RENEWAL ONBOARDING SCHOOL DETAILS"})



@app.route('/upcomingtable')
def upcomingtable2():
    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']
    
    
    upcoming=upcoming.drop(['UID'], axis=1)
    upcoming=upcoming.drop(['active_count'], axis=1)
    upcoming=upcoming.drop(['status'], axis=1)
    # upcoming=upcoming.drop(['CREATED_DATE'], axis=1)

    return json.dumps({"data":upcoming.values.tolist(),"tablename":"UPCOMING RENEWAL SCHOOL DETAILS"})



@app.route('/lifetimezeropracticetable')
def lifetimezeropractice():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    lifetime=df[df['status']=='lifetime']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    lifetimeonb=lifetime[lifetime['USER_COUNT']==1]
    lifetime0prac=lifetime[lifetime['school_practice_count']==0]
    lifetime0prac=lifetime0prac[lifetime0prac['USER_COUNT']!=1]
    onblifetimecount=len(lifetimeonb)
    zeropraclifetimecount=len(lifetime0prac)
    lifetimecountcount=len(lifetime)
    lifetime0prac=lifetime0prac.drop(['UID'], axis=1)
    lifetime0prac=lifetime0prac.drop(['active_count'], axis=1)
    lifetime0prac=lifetime0prac.drop(['status'], axis=1)
    # lifetime0prac=lifetime0prac.drop(['CREATED_DATE'], axis=1)

    return json.dumps({"data":lifetime0prac.values.tolist(),"tablename":"LIFETIME DORMANT SCHOOL DETAILS"})

@app.route('/trialzeropracticetable')
def trialzeropractice():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    trialonb=trial[trial['USER_COUNT']==1]
    trial0prac=trial[trial['school_practice_count']==0]
    trial0prac=trial0prac[trial0prac['USER_COUNT']!=1]
    onbtrialcount=len(trialonb)
    zeropractrialcount=len(trial0prac)
    trialcountcount=len(trial)
    trial0prac=trial0prac.drop(['UID'], axis=1)
    trial0prac=trial0prac.drop(['active_count'], axis=1)
    trial0prac=trial0prac.drop(['status'], axis=1)
    # trial0prac=trial0prac.drop(['CREATED_DATE'], axis=1)

    return json.dumps({"data":trial0prac.values.tolist(),"tablename":"TRIAL DORMANT SCHOOL DETAILS"})




@app.route('/lifetimetableonbording')
def lifetimetableonbord():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    lifetime=df[df['status']=='lifetime']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    lifetimeonb=lifetime[lifetime['USER_COUNT']==1]
    lifetime0prac=lifetime[lifetime['school_practice_count']==0]
    lifetime0prac=lifetime0prac[lifetime0prac['USER_COUNT']!=1]
    onblifetimecount=len(lifetimeonb)
    zeropraclifetimecount=len(lifetime0prac)
    lifetimecountcount=len(lifetime)
    lifetimeonb=lifetimeonb.drop(['UID'], axis=1)
    lifetimeonb=lifetimeonb.drop(['active_count'], axis=1)
    lifetimeonb=lifetimeonb.drop(['status'], axis=1)
    # lifetimeonb=lifetimeonb.drop(['CREATED_DATE'], axis=1)

    
    return json.dumps({"data":lifetimeonb.values.tolist(),"tablename":"LIFETIME ONBOARDING SCHOOL DETAILS"})

@app.route('/trialtableonbording')
def trialtableonbord():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    trialonb=trial[trial['USER_COUNT']==1]
    trial0prac=trial[trial['school_practice_count']==0]
    trial0prac=trial0prac[trial0prac['USER_COUNT']!=1]
    onbtrialcount=len(trialonb)
    zeropractrialcount=len(trial0prac)
    trialcountcount=len(trial)
    trialonb=trialonb.drop(['UID'], axis=1)
    trialonb=trialonb.drop(['active_count'], axis=1)
    trialonb=trialonb.drop(['status'], axis=1)
    # trialonb=trialonb.drop(['CREATED_DATE'], axis=1)

    
    return json.dumps({"data":trialonb.values.tolist(),"tablename":"TRIAL ONBOARDING SCHOOL DETAILS"})



@app.route('/lifetimetable')
def lifetimetable2():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    lifetime=df[df['status']=='lifetime']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    lifetimeonb=lifetime[lifetime['USER_COUNT']==1]
    lifetime0prac=lifetime[lifetime['school_practice_count']==0]
    lifetime0prac=lifetime0prac[lifetime0prac['USER_COUNT']!=1]
    onblifetimecount=len(lifetimeonb)
    zeropraclifetimecount=len(lifetime0prac)
    lifetimecountcount=len(lifetime)
    lifetime0prac=lifetime0prac.drop(['UID'], axis=1)
    lifetime0prac=lifetime0prac.drop(['active_count'], axis=1)
    lifetime0prac=lifetime0prac.drop(['status'], axis=1)
    # lifetime0prac=lifetime0prac.drop(['CREATED_DATE'], axis=1)

    
    return json.dumps({"data":lifetime.values.tolist(),"tablename":"LIFETIME ONBOARDING SCHOOL DETAILS"})

@app.route('/trialtable')
def trialtable2():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    trialonb=trial[trial['USER_COUNT']==1]
    trial0prac=trial[trial['school_practice_count']==0]
    trial0prac=trial0prac[trial0prac['USER_COUNT']!=1]
    onbtrialcount=len(trialonb)
    zeropractrialcount=len(trial0prac)
    trialcountcount=len(trial)
    trial0prac=trial0prac.drop(['UID'], axis=1)
    trial0prac=trial0prac.drop(['active_count'], axis=1)
    trial0prac=trial0prac.drop(['status'], axis=1)
    # trial0prac=trial0prac.drop(['CREATED_DATE'], axis=1)

    
    return json.dumps({"data":trial.values.tolist(),"tablename":"TRIAL ONBOARDING SCHOOL DETAILS"})
    


@app.route('/aftercsytable')
def aftercsytabledata():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    trialonb=trial[trial['USER_COUNT']==1]
    trial0prac=trial[trial['school_practice_count']==0]
    trial0prac=trial0prac[trial0prac['USER_COUNT']!=1]
    onbtrialcount=len(trialonb)
    zeropractrialcount=len(trial0prac)
    trialcountcount=len(trial)
    after=after.drop(['UID'], axis=1)
    after=after.drop(['active_count'], axis=1)
    after=after.drop(['status'], axis=1)
    # after=after.drop(['CREATED_DATE'], axis=1)
    return json.dumps({"data":after.values.tolist(),"tablename":"RENEWAL AFTER CURRENT SCHOOL YEAR SCHOOL DETAILS"})

@app.route('/aftercsytableoonbording')
def aftercsytabledataonboarding():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    afteronb=after[after['USER_COUNT']==1]
    after0prac=after[after['school_practice_count']==0]
    after0prac=after0prac[after0prac['USER_COUNT']!=1]
    onbaftercount=len(afteronb)
    zeropracaftercount=len(after0prac)
    aftercountcount=len(after)
    afteronb=afteronb.drop(['UID'], axis=1)
    afteronb=afteronb.drop(['active_count'], axis=1)
    afteronb=afteronb.drop(['status'], axis=1)
    # afteronb=afteronb.drop(['CREATED_DATE'], axis=1)
    return json.dumps({"data":afteronb.values.tolist(),"tablename":"RENEWAL AFTER CURRENT SCHOOL YEAR ONBOARDING SCHOOL DETAILS"})

@app.route('/aftercsytableozeroprac')
def aftercsytabledatazeropract():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    afteronb=after[after['USER_COUNT']==1]
    after0prac=after[after['school_practice_count']==0]
    after0prac=after0prac[after0prac['USER_COUNT']!=1]
    onbaftercount=len(afteronb)
    zeropracaftercount=len(after0prac)
    aftercountcount=len(after)
    after0prac=after0prac.drop(['UID'], axis=1)
    after0prac=after0prac.drop(['active_count'], axis=1)
    after0prac=after0prac.drop(['status'], axis=1)
    # after0prac=after0prac.drop(['CREATED_DATE'], axis=1)
    return json.dumps({"data":after0prac.values.tolist(),"tablename":"RENEWAL AFTER CURRENT SCHOOL YEAR DORMANT SCHOOL DETAILS"})
    
@app.route('/expcsytableonboarding')
def expcsytabledataonboarding():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    csyonb=csy[csy['USER_COUNT']==1]
    csy0prac=csy[csy['school_practice_count']==0]
    csy0prac=csy0prac[csy0prac['USER_COUNT']!=1]
    onbcsycount=len(csyonb)
    zeropraccsycount=len(csy0prac)
    csycountcount=len(csy)
    csyonb=csyonb.drop(['UID'], axis=1)
    csyonb=csyonb.drop(['active_count'], axis=1)
    csyonb=csyonb.drop(['status'], axis=1)
    # csyonb=csyonb.drop(['CREATED_DATE'], axis=1)
    return json.dumps({"data":csyonb.values.tolist(),"tablename":"EXPIRED CURRENT SCHOOL YEAR SCHOOL DETAILS"})


@app.route('/expcsytabledatazeropractice')

def expcsytabledatazeropractice():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    csyonb=csy[csy['USER_COUNT']==1]
    csy0prac=csy[csy['school_practice_count']==0]
    csy0prac=csy0prac[csy0prac['USER_COUNT']!=1]
    onbcsycount=len(csyonb)
    zeropraccsycount=len(csy0prac)
    csycountcount=len(csy)
    csy0prac=csy0prac.drop(['UID'], axis=1)
    csy0prac=csy0prac.drop(['active_count'], axis=1)
    csy0prac=csy0prac.drop(['status'], axis=1)
    # csy0prac=csy0prac.drop(['CREATED_DATE'], axis=1)
    return json.dumps({"data":csy0prac.values.tolist(),"tablename":"EXPIRED CURRENT SCHOOL YEAR DORMANT SCHOOL DETAILS"})
    

@app.route('/expcsytable')
def expcsytabledata():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    csyonb=csy[csy['USER_COUNT']==1]
    csy0prac=csy[csy['school_practice_count']==0]
    csy0prac=csy0prac[csy0prac['USER_COUNT']!=1]
    onbcsycount=len(csyonb)
    zeropraccsycount=len(csy0prac)
    csycountcount=len(csy)
    csy=csy.drop(['UID'], axis=1)
    csy=csy.drop(['active_count'], axis=1)
    csy=csy.drop(['status'], axis=1)
    # csy=csy.drop(['CREATED_DATE'], axis=1)
    return json.dumps({"data":csy.values.tolist(),"tablename":"EXPIRED CURRENT SCHOOL YEAR SCHOOL DETAILS"})

@app.route('/cloudtable')
def cloudtabledata():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    cloudonb=cloud[cloud['USER_COUNT']==1]
    cloud0prac=cloud[cloud['school_practice_count']==0]
    cloud0prac=cloud0prac[cloud0prac['USER_COUNT']!=1]
    onbcloudcount=len(cloudonb)
    zeropraccloudcount=len(cloud0prac)
    cloudcountcount=len(cloud)
    cloud=cloud.drop(['UID'], axis=1)
    cloud=cloud.drop(['active_count'], axis=1)
    cloud=cloud.drop(['status'], axis=1)
    # cloud=cloud.drop(['CREATED_DATE'], axis=1)
    return json.dumps({"data":cloud.values.tolist(),"tablename":"EXPIRED IN LAST SCHOOL YEAR SCHOOL DETAILS"}) 


@app.route('/cloudpractice')
def cloudpractice():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    cloudonb=cloud[cloud['USER_COUNT']==1]
    cloud0prac=cloud[cloud['school_practice_count']==0]
    cloud0prac=cloud0prac[cloud0prac['USER_COUNT']!=1]
    onbcloudcount=len(cloudonb)
    zeropraccloudcount=len(cloud0prac)
    cloudcountcount=len(cloud)
    cloud0prac=cloud0prac.drop(['UID'], axis=1)
    cloud0prac=cloud0prac.drop(['active_count'], axis=1)
    cloud0prac=cloud0prac.drop(['status'], axis=1)
    # cloud0prac=cloud0prac.drop(['CREATED_DATE'], axis=1)
    return json.dumps({"data":cloud0prac.values.tolist(),"tablename":"EXPIRED IN LAST SCHOOL YEAR DORMANT SCHOOL DETAILS"}) 


@app.route('/cloudonboard')
def cloudonboard():

    googleSheetId = '1A-rPVUmJ1SnDSfJXviCZbbQc4d5or4uSPC6qOKRqNk4'
    worksheetName = 'subscription'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    
    cloud=df[df['status']=='cloud']
    trial=df[df['status']=='trial']
    csy=df[df['status']=='csy']
    upcoming=df[df['status']=='upcoming']
    after=df[df['status']=='after']

    
    cloudonb=cloud[cloud['USER_COUNT']==1]
    cloud0prac=cloud[cloud['school_practice_count']==0]
    cloud0prac=cloud0prac[cloud0prac['USER_COUNT']!=1]
    onbcloudcount=len(cloudonb)
    zeropraccloudcount=len(cloud0prac)
    cloudcountcount=len(cloud)
    cloudonb=cloudonb.drop(['UID'], axis=1)
    cloudonb=cloudonb.drop(['active_count'], axis=1)
    cloudonb=cloudonb.drop(['status'], axis=1)
    # cloudonb=cloudonb.drop(['CREATED_DATE'], axis=1)
    return json.dumps({"data":cloudonb.values.tolist(),"tablename":"EXPIRED IN LAST SCHOOL YEAR ONBOARDING SCHOOL DETAILS"}) 






@app.route('/familyjourney/<emailid>')
def family_journey(emailid):
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = MongoClient(mongo_uri)

    database = client["compass"]
    collection = database["user_master"]
    query = {}
    query["$and"] = [{
            u"EMAIL_ID": emailid
        },{u"USER_NAME": {
                u"$not": Regex(u".*TEST.*", "i")
            }},{
            u"EMAIL_ID": {
                u"$not": Regex(u".*TEST.*", "i")
            }}]
    projection = {}
    projection["schoolId.NAME"] = 1.0
    projection["schoolId._id"] = 1.0
    projection["schoolId.COUNTRY"] = 1.0
    projection["schoolId.CITY"] = 1.0
    projection["schoolId.STATE"] = 1.0
    cursor = collection.find(query, projection = projection)
    school_info=pd.DataFrame(list(cursor))
    school_name=school_info.schoolId[0]['NAME']
    school_country=school_info.schoolId[0]['COUNTRY']
    school_city=school_info.schoolId[0]['CITY']
    school_state=school_info.schoolId[0]['STATE']
    school_id=school_info.schoolId[0]['_id']
    query = {}
    query["schoolId._id"] = school_id
    query["USER_NAME"] = {
        u"$not": Regex(u".*TEST.*", "i")
    }

    query["EMAIL_ID"] = {
        u"$not": Regex(u".*TEST.*", "i")
    }

    query["IS_DISABLED"] = {
        u"$ne": u"Y"
    }

    query["IS_BLOCKED"] = {
        u"$ne": u"Y"
    }

    query["INCOMPLETE_SIGNUP"] = {
        u"$ne": u"Y"
    }
    query["ROLE_ID.ROLE_NAME"] = Regex(u".*PRESENT.*", "i")


    projection = {}
    projection["EMAIL_ID"] = 1.0

    cursor = collection.find(query, projection = projection)
    email_info=pd.DataFrame(list(cursor))
    email=list(email_info['EMAIL_ID'])
    total_user=len(email)
    collection = database["subscription_master"]
    query = {}
    query["USER_ID.EMAIL_ID"] =emailid
    projection = {}
    projection["SUBSCRIPTION_EXPIRE_DATE"] = 1.0
    cursor = collection.find(query, projection = projection)
    expiry=pd.DataFrame(list(cursor))
    total_practice=0
    total_mindfulnesminutes=0
    dfatd = pd.DataFrame()
    try:
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
        client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
        db=client.compass
        db=client.compass
        collection = db.audio_track_master.aggregate(
        [{'$match':{'USER_ID.EMAIL_ID':{'$in':email
            }}},
        {'$project':{"cursorStart" : 1.0, 
            "CURSOR_END" : 1.0,'EMAIL_ID':'$USER_ID.EMAIL_ID',"MODIFIED_DATE" : 1.0,}},

        ])
        dfatd=pd.DataFrame(list(collection))
        total_practice=len(dfatd)
        dfatd['mm']=round((dfatd['CURSOR_END']-dfatd['cursorStart'])/60)
        dfatd=dfatd.fillna(0)
        total_mindfulnesminutes=sum(list(dfatd['mm']))
        dfatd['year'] = pd.DatetimeIndex(dfatd['MODIFIED_DATE']).year
        dfatd['month'] = pd.DatetimeIndex(dfatd['MODIFIED_DATE']).month
    except:
        total_practice=0
        total_mindfulnesminutes=0
        dfatd = pd.DataFrame()
    dfatdchart1=dfatd[dfatd['year']>2019]
    dfatdchart=dfatdchart1[dfatdchart1['month']>3]
    dfatdchart.drop('_id',axis='columns', inplace=True)
    dfatdchart.drop('MODIFIED_DATE',axis='columns', inplace=True)
    dfatdchart.drop('mm',axis='columns', inplace=True)
    dfatdchart.drop('CURSOR_END',axis='columns', inplace=True)
    dfatdchart.drop('cursorStart',axis='columns', inplace=True)
    dfatdchartprac=dfatdchart
    dfuniqueprac= dfatdchartprac.groupby('month')['EMAIL_ID'].nunique()
    dfprac=dfatdchartprac.groupby('month')['EMAIL_ID'].count()
    dfuniqueprac11=pd.DataFrame(dfuniqueprac)
    dfprac1=pd.DataFrame(dfprac)
    dfuniqueprac11.reset_index(level=0, inplace=True)
    dfprac1.reset_index(level=0, inplace=True)
    import calendar
    dfuniqueprac11['month'] = dfuniqueprac11['month'].apply(lambda x: calendar.month_abbr[x])
    dfprac1['month'] = dfprac1['month'].apply(lambda x: calendar.month_abbr[x])
    month1=""
    unique1=""
    prac=""
    tooo=""
    if dfatd.empty == True:
            month1=["Jun","Jul","Aug","Sep","Oct","Nov"]
            unique1=[0,0,0,0,0,0,0,0,0,0]
            prac=[0,0,0,0,0,0,0,0,0,0]
    else:
        month1=dfuniqueprac11['month'].tolist()
        unique1=dfuniqueprac11['EMAIL_ID'].tolist()
        prac=dfprac1['EMAIL_ID'].tolist()
    month12=["Jun","Jul","Aug","Sep","Oct","Nov"]
    for i in month12:
        if i not in month1:
            month1.append(i)
            unique1.append(0)
            prac.append(0)
    hell=dict(zip(month1,unique1))
    print(hell)
    hell2=dict(zip(month1,prac))
    month1=["Jun","Jul","Aug","Sep","Oct","Nov"]
    unique1=[hell["Apr"],hell["May"],hell["Jun"],hell["Jul"],hell["Aug"],hell["Sep"]]
    prac=[hell2["Apr"],hell2["May"],hell2["Jun"],hell["Jul"],hell2["Aug"],hell2["Sep"]]
    star_rating_cout=""
    try:
        collection = database["audio_feedback"]
        query = {}
        query["USER.EMAIL_ID"] = {
            u"$in":email
        }
        query["RATING"] = 5
        cursor = collection.find(query)
        star_rating=pd.DataFrame(list(cursor))
        star_rating_cout=len(star_rating)
    except:
        star_rating_cout=0
    graph={'Star_5_Ratings_Recieved':[str(star_rating_cout)],'mindfulness_minutes':[str(total_mindfulnesminutes)],'school_name':[school_name],'state':[school_state],'city':[school_city],'country':[school_country],'user_count':[total_user],'school_practice_count':[total_practice],'month':month1,'unique_user':unique1,'practice_count':prac,'renewal_date':[expiry['SUBSCRIPTION_EXPIRE_DATE'][0].strftime("%d %b %Y ")]}
    data=[graph]
    return json.dumps(data)

        
    

@app.route('/smsfail')
def sms_table():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username,       password))
    db=client.compass
    collection1= db.user_master
    query1=[
    {"$match":
        {"$and":[
        {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
                            {'schoolId._id':{'$not':{'$regex':'null'}}},{'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'CREATED_DATE':{'$gt':datetime.datetime(2020,3,17)}},{'EMAIL_ID':{'$not':{'$regex':'null', '$options':'i'}}},
            {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, {'EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':'$_id',  'Parents_Name':{'$first':'$USER_NAME'}, 'Sign_Up_Date':{'$first':'$CREATED_DATE'},
        'school_name':{'$first':'$schoolId.NAME'}, 'Parents_Email':{'$first':'$EMAIL_ID'}, 'contact_number':{'$first':'$CONTACT_NUMBER'},
        'ADDRESS':{'$first':'$schoolId.ADDRESS'}, 'city':{'$first':'$schoolId.CITY'},'STATE':{'$first':'$schoolId.STATE'}, 
        'COUNTRY':{'$first':'$schoolId.COUNTRY'}, 'USER_TYPE':{'$first':'$USER_TYPE'}, 'IP_ADDRESS':{'$first':'$IP_ADDRESS'}
        }}         
            ]
    collection3= db.audio_track_master
    query3=[
    {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
         {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},{'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.CREATED_DATE':{'$gt':datetime.datetime(2020,3,17)}},{'USER_ID.EMAIL_ID':{'$not':{'$regex':'null', '$options':'i'}}},
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':'$USER_ID._id',  'Practice_Count':{'$sum':1},
            'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}},
        'Last_Practice_Date':{'$max':'$MODIFIED_DATE'}
        }}, 
        {'$project':{'_id':1,'Practice_Count':1,
            'MINDFUL_MINUTES':1, 'Last_Practice_Date':{"$dateToString": { "format": "%Y-%m-%d", "date": "$Last_Practice_Date" }}
        }}
        ]
    list1=list(collection1.aggregate(query1))
    df_1=DataFrame(list1)
    list3=list(collection3.aggregate(query3))
    df_3=DataFrame(list3)
    df_1['school_name'].fillna("NO SCHOOL FOUND", inplace=True)
    # df_3['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    df_1['COUNTRY'].fillna("NO COUNTRY FOUND", inplace=True)
    df_1['STATE'].fillna("NO STATE FOUND", inplace=True)
    df_1['city'].fillna("NO CITY FOUND", inplace=True)
    df_1['ADDRESS'].fillna("NO ADDRESS FOUND", inplace=True)
    join12= pd.merge(df_1, df_3,how='left', on='_id')
    # join12['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    join12['Practice_Count'].fillna("NO PRACTICE", inplace=True)
    join12['MINDFUL_MINUTES'].fillna("NO PRACTICE", inplace=True)
    join12=join12[['Parents_Name','Sign_Up_Date','school_name','Parents_Email','contact_number','ADDRESS','city','STATE','COUNTRY','USER_TYPE',
                   'IP_ADDRESS','Practice_Count','MINDFUL_MINUTES','Last_Practice_Date'
                             ]]
    join12['Sign_Up_Date'].dtype
    Parents_Name=join12['Parents_Name'].tolist(),
    # join12['Sign_Up_Date']=pd.to_datetime(join12['Sign_Up_Date'])
    signup=join12['Sign_Up_Date'].to_list()
    school_name=join12['school_name'].tolist(),
    Parents_Email=join12['Parents_Email'].tolist(),
    contact_number=join12['contact_number'].tolist(),
    ADDRESS=join12['ADDRESS'].tolist(),
    city=join12['city'].tolist(),
    STATE=join12['STATE'].tolist(),
    COUNTRY=join12['COUNTRY'].tolist(),
    USER_TYPE=join12['USER_TYPE'].tolist(),
    IP_ADDRESS=join12['IP_ADDRESS'].tolist(),
    Practice_Count=join12['Practice_Count'].tolist(),
    MINDFUL_MINUTES=join12['MINDFUL_MINUTES'].tolist(),
    join12['Last_Practice_Date']=pd.to_datetime(join12['Last_Practice_Date'],errors='ignore')
    pracdates=join12['Last_Practice_Date'].to_list()
    Sign_Up_Date=[]
    prac_date1=[]
    for i in range(len(signup)):
            Sign_Up_Date.append(signup[i].strftime("%d %b %Y")) 
    for i in range(len(pracdates)):
        try:

            prac_date1.append(pracdates[i].strftime("%d %b %Y"))

        except:
            prac_date1.append('NO PRACTICE')

    data={'Parents_Name':Parents_Name,'Sign_Up_Date':Sign_Up_Date,'School_Name':school_name,'Parents_Email':Parents_Email,
          'Contact_number':contact_number,'ADDRESS':ADDRESS,'city':city,'STATE':STATE,'COUNTRY':COUNTRY,'USER_TYPE':USER_TYPE,
          'IP_ADDRESS':IP_ADDRESS,'Practice_Count':Practice_Count,'Mindful_Minutes':MINDFUL_MINUTES,'Last_Practice_Date':prac_date1} 
   # print(data)
    return json.dumps(data)




@app.route('/ratingcardsdaily_card')
def dailyratings():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection2=db.audio_feedback
    tz = timezone('UTC')
    date=datetime.datetime.now(tz) 
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday = pd.to_datetime(date) - timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    print(yesterday,"yessss")
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    print(today,"today")
    tod= today
#     + timedelta(hours=4)
    start= tod-timedelta(days=1)
    yester= yesterday
#     +timedelta(hours=4)
    start_15day=tod-timedelta(days=8)
    startend= start_15day+timedelta(days=1)


#TEACHERS COMMENT PER FEEDBACK LAST WEEK
    query1=[
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lt':tod}}    ,         
    {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed=list(collection2.aggregate(query1))
    commentsonfeedback=pd.DataFrame(commentsonfeed)
    comments_per_feedback_teacher=commentsonfeedback[['rating']]
    
    
#PARENTS COMMENT PER FEEDBACK LAST WEEK
    querya=[
   {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lt':tod}}    ,         
    {'RATING':{'$ne':0}}]}},
        

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed2=list(collection2.aggregate(querya))
    commentsonfeedback2=pd.DataFrame(commentsonfeed2)
    comments_per_feedback_parents=commentsonfeedback2[['rating']]
    

    
#TEACHERS COMMENT PER FEEDBACK before LAST WEEK
    query4=[
   {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lt':startend}}    ,         
    {'RATING':{'$ne':0}}]}},
   
    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed11=list(collection2.aggregate(query4))
    commentsonfeedback11=pd.DataFrame(commentsonfeed11)
    comments_per_feedback_before_last_week_teachers=commentsonfeedback11[['rating']]
    

    
#  PARENTS COMMENT PER FEEDBACK before LAST WEEK
    queryB=[
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lt':startend}}    ,         
    {'RATING':{'$ne':0}}]}},


    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed200=list(collection2.aggregate(queryB))
    commentsonfeedback20=pd.DataFrame(commentsonfeed200)
    comments_per_feedback_before_last_week_parents=commentsonfeedback20[['rating']]
    

    
# AVERAGE FEEDBACK RATING LAST WEEK
    query6=[
    {"$match":{'$and':[
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lt':tod}}    ,         
    {'RATING':{'$ne':0}}]}},
    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rating=list(collection2.aggregate(query6))
    avg_ratings=pd.DataFrame(avg_rating)
    avg_ratings_lastweek=avg_ratings[['RATING']]

    avg_ratings_last_week=pd.DataFrame({'avg_ratings_lastweek':round(avg_ratings_lastweek[avg_ratings_lastweek['RATING']!=0]['RATING'].mean(),1)}, index=[0])

    
   
    query60=[
    {"$match":{'$and':[
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lt':startend}}    ,         
    {'RATING':{'$ne':0}}]}},
   
    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rate=list(collection2.aggregate(query60))
    avg_ratin=pd.DataFrame(avg_rate)
    avg_ratings_before_lastweek=avg_ratin[['RATING']]

    avg_ratings_beforee_last_week=pd.DataFrame({'avg_ratings_before_lastweek':round(avg_ratings_before_lastweek[avg_ratings_before_lastweek['RATING']!=0]['RATING'].mean(),1)}, index=[0])



    
    
    TEACHER_Comment_per_feedbackchange=[]
    teacher_PERCENTAGE_change=[]
    if comments_per_feedback_teacher['rating'].iloc[0] > comments_per_feedback_before_last_week_teachers['rating'].iloc[0]:
        xx=comments_per_feedback_teacher['rating'].iloc[0]-comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        yy= xx/comments_per_feedback_teacher['rating'].iloc[0]
        zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('-1')
        teacher_PERCENTAGE_change.append(zz)
        
    elif comments_per_feedback_teacher['rating'].iloc[0] == comments_per_feedback_before_last_week_teachers['rating'].iloc[0]:
        xx=comments_per_feedback_teacher['rating'].iloc[0]-comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        yy= xx/comments_per_feedback_teacher['rating'].iloc[0]
        zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('0')
        teacher_PERCENTAGE_change.append(zz)
        
    else:
        xx=comments_per_feedback_before_last_week_teachers['rating'].iloc[0]-comments_per_feedback_teacher['rating'].iloc[0]
        yy= xx/comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('1')
        teacher_PERCENTAGE_change.append(zz)
        


    PARENT_Comment_per_feedbackchange=[]
    parent_PERCENTAGE_change=[]
    if comments_per_feedback_parents['rating'].iloc[0] > comments_per_feedback_before_last_week_parents['rating'].iloc[0]:
        xx=comments_per_feedback_parents['rating'].iloc[0]-comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        yy= xx/comments_per_feedback_parents['rating'].iloc[0]
        zz= round(yy*100,2)
        PARENT_Comment_per_feedbackchange.append('-1')
        parent_PERCENTAGE_change.append(zz)
        
    elif comments_per_feedback_parents['rating'].iloc[0] == comments_per_feedback_before_last_week_parents['rating'].iloc[0]:
        xx=comments_per_feedback_parents['rating'].iloc[0]-comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        yy= xx/comments_per_feedback_parents['rating'].iloc[0]
        zz= round(yy*100,2)
        PARENT_Comment_per_feedbackchange.append('0')
        parent_PERCENTAGE_change.append(zz)
        
    else:
        xx=comments_per_feedback_before_last_week_parents['rating'].iloc[0]-comments_per_feedback_parents['rating'].iloc[0]
        yy= xx/comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        zz= round(yy*100,2)
        PARENT_Comment_per_feedbackchange.append('1')
        parent_PERCENTAGE_change.append(zz)
        


    Average_FEEDBACK_Rating_change=[]
    Average_feedback_PERCENTAGE=[]
    if avg_ratings_last_week['avg_ratings_lastweek'].iloc[0] > avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]:
        xx=avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]-avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        yy= xx/avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
        zz= round(yy*100,2)
        Average_FEEDBACK_Rating_change.append('-1')
        Average_feedback_PERCENTAGE.append(zz)
        
        
    elif avg_ratings_last_week['avg_ratings_lastweek'].iloc[0] == avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]:
        xx=avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]-avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        yy= xx/avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
        zz= round(yy*100,2)
        Average_FEEDBACK_Rating_change.append('0')
        Average_feedback_PERCENTAGE.append(zz)
        
    else:
        xx=avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]-avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
        yy= xx/avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        zz= round(yy*100,2)
        Average_FEEDBACK_Rating_change.append('1')
        Average_feedback_PERCENTAGE.append(zz)



    data_final=pd.DataFrame({'TEACHER_FEEDBACK_RATING_LAST_WEEK':comments_per_feedback_teacher['rating'].tolist(),
                             'TEACHER_FEEDBACK_RATING_BEFORE_LAST_WEEK':comments_per_feedback_before_last_week_teachers['rating'].tolist(),
                             
    'PARENT_FEEDBACK_RATING_LAST_WEEK':comments_per_feedback_parents['rating'].tolist(),
    'PARENT_FEEDBACK_RATING_BEFORE_LAST_WEEK':comments_per_feedback_before_last_week_parents['rating'].tolist(),
                                 
     'Average_Rating_lastweek':avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].tolist(),
     'Average_Rating_lastweek':avg_ratings_last_week['avg_ratings_lastweek'].tolist(),
                             
      'TEACHER_Comment_per_feedbackchange':TEACHER_Comment_per_feedbackchange,
       'teacher_PERCENTAGE_change':teacher_PERCENTAGE_change,                      
      'PARENT_Comment_per_feedbackchange':PARENT_Comment_per_feedbackchange,
       'parent_PERCENTAGE_change':parent_PERCENTAGE_change,                      
      'Average_FEEDBACK_Rating_change':Average_FEEDBACK_Rating_change,
       'Average_feedback_PERCENTAGE':Average_feedback_PERCENTAGE                      
                                })   
    
    temp={}
    for j in range(len(data_final.columns)):
        key = data_final.columns[j]
        value = [str(data_final[data_final.columns[j]].iloc[0])]
        temp.update({key:value})
        #     print(temp)
    return json.dumps(temp)


# @app.route('/AVG_audio_completion_daily_greater_than50')

# def avg_audio_completed_greater_than_50():

#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
#     db=client.compass
#     collection1= db.audio_track_master
#     # datetime.datetime.now() - datetime.timedelta(days=7)
#     # ar d = new Date();
#     tz = timezone('UTC')
#     date=datetime.datetime.now(tz) 
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     yesterday = pd.to_datetime(date) - timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     print(yesterday,"yessss")
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     print(today,"today")
#     tod= today+ timedelta(hours=4)
#     start= tod-timedelta(days=1)
#     yester= yesterday+timedelta(hours=4)
#     start_15day=tod-timedelta(days=8)
#     startend= start_15day+timedelta(days=1)

#     qr1=[{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte': yester, '$lt':tod
#     }},
#     ]}},


#     {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
#                  'AUDIO_ID':'$PROGRAM_AUDIO_ID.AUDIO_ID', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
#               'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

#     }}]

#     list1= list(collection1.aggregate(qr1))
#     userprac_trend= DataFrame(list1)

#     userprac_trend.start.fillna(0, inplace=True)

#     userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

#     userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

#     #     userprac_trend_1=userprac_trend[userprac_trend.completed_precentage>=75]
#     # d=userprac_trend.groupby('AUDIO_ID')['completed_precentage'].mean().reset_index()

#     userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

#     # dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)



#     userprac_trend=userprac_trend[userprac_trend.completed_precentage >50]
# #     userprac_trend[userprac_trend.completed_precentage < 0]=0
#     # d['completed_precentage']=round(d['completed_precentage'],0)

#     dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

#     dd['cumulativesum_line']= dd['Audio_Count'].cumsum()

#     # dd[dd.completed_precentage< 0]=0


#     percentage_of_audio_completed= dd.completed_precentage.tolist(),
#     number_of_audios_compelted=dd.Audio_Count.tolist()
#     cumulative_audio_completion=dd.cumulativesum_line.tolist()

#     temp={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
#          'cumulative_audio_completion':cumulative_audio_completion}

#     data={'temp':temp}

#     #     for i,j,k in zip(dd.completed_precentage.tolist(),dd.Audio_Count.tolist(), dd.cumulativesum_line.tolist()):
#     #         data.append([i,j,k])
#     #     temp={'data':data}
#     return json.dumps(data)



@app.route('/parents_playback_table_daily/<program>')
def playbackdailyforPARENTS(program):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)
    
    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester , '$lt':tod
    }},
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
     'LAST_PRACTICE_DATE':{'$max':'$MODIFIED_DATE'}, 
     'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
    }}, 

    {'$sort':{'_id':1}}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    ]}},
    {'$group':{'_id':'$_id', 
    'CREATED_DATE':{'$first':'$CREATED_DATE'}, 'schoolNAME':{'$first':'$schoolId.NAME'},
    'USER_NAME':{'$first':'$USER_NAME'}, 'EMAIL':{'$first':'$EMAIL_ID'},
     'COUNTRY':{'$first':'$schoolId.COUNTRY'}, 'STATE':{'$first':'$schoolId.STATE'}, 'CITY':{'$first':'$schoolId.CITY'},
      'uc_id':{'$addToSet':'$_id'}
               
    }}, 
         {'$project':{'_id':1,'CREATED_DATE':1, 'schoolNAME':1, 'USER_NAME':1,'EMAIL':1,
                     'COUNTRY':1, 'STATE':1, 'CITY':1, 'USER_COUNT':{'$size':'$uc_id'}
                     }}
         

    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    df_final= pd.merge(df_atm, df_um,how='left', on='_id')
   
    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','LAST_PRACTICE_DATE','USER_COUNT', 'COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
    audio2['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    audio2['USER_COUNT'].fillna(0, inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['LAST_PRACTICE_DATE']=audio2['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    audio20= audio2.groupby(audio2['PROGRAM_NAME'])

    audio3=audio20.get_group(''+program+'')
    audio30= pd.DataFrame(audio3)

    temp={'data':audio30.values.tolist()}


    # #     data=[]
    # #     for i,j,k,l,m,n,o,p,q,r,s,t,u in zip(audio4,audio2['SCHOOL_NAME'].tolist(),audio2['USER_NAME'].tolist(),audio2['EMAIL'].tolist(),audio2['PROGRAM_NAME'].tolist(),audio2['AUDIO_DAY'].tolist(),audio2['COMMENT'].tolist(),audio2['PRACTICE_COUNT'].tolist(),audio2['LAST_PRACTICE_DATE'].tolist(),audio2['CREATED_DATE'].tolist(),audio2['COUNTRY'].tolist(),audio2['STATE'].tolist(),audio2['CITY'].tolist()):                       
    # #         data.append([i,j,k,l,m,n,o,p,q,r,s,t,u])
    # #     temp={"data":data}
    return json.dumps(temp)



# playbackdatateachers('Sound Practices')






@app.route('/teachers_playback_table_daily/<program>')
def playbackdailyforTEACHERS(program):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)
    
    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester , '$lt':tod
    }},
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
     'LAST_PRACTICE_DATE':{'$max':'$MODIFIED_DATE'}, 
     'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
    }}, 

    {'$sort':{'_id':1}}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    ]}},
    {'$group':{'_id':'$_id', 
    'CREATED_DATE':{'$first':'$CREATED_DATE'}, 'schoolNAME':{'$first':'$schoolId.NAME'},
    'USER_NAME':{'$first':'$USER_NAME'}, 'EMAIL':{'$first':'$EMAIL_ID'},
     'COUNTRY':{'$first':'$schoolId.COUNTRY'}, 'STATE':{'$first':'$schoolId.STATE'}, 'CITY':{'$first':'$schoolId.CITY'},
      'uc_id':{'$addToSet':'$_id'}
               
    }}, 
         {'$project':{'_id':1,'CREATED_DATE':1, 'schoolNAME':1, 'USER_NAME':1,'EMAIL':1,
                     'COUNTRY':1, 'STATE':1, 'CITY':1, 'USER_COUNT':{'$size':'$uc_id'}
                     }}
         

    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    df_final= pd.merge(df_atm, df_um,how='left', on='_id')
   
    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','LAST_PRACTICE_DATE','USER_COUNT', 'COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
    audio2['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    audio2['USER_COUNT'].fillna(0, inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['LAST_PRACTICE_DATE']=audio2['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    audio20= audio2.groupby(audio2['PROGRAM_NAME'])

    audio3=audio20.get_group(''+program+'')
    audio30= pd.DataFrame(audio3)

    temp={'data':audio30.values.tolist()}


    # #     data=[]
    # #     for i,j,k,l,m,n,o,p,q,r,s,t,u in zip(audio4,audio2['SCHOOL_NAME'].tolist(),audio2['USER_NAME'].tolist(),audio2['EMAIL'].tolist(),audio2['PROGRAM_NAME'].tolist(),audio2['AUDIO_DAY'].tolist(),audio2['COMMENT'].tolist(),audio2['PRACTICE_COUNT'].tolist(),audio2['LAST_PRACTICE_DATE'].tolist(),audio2['CREATED_DATE'].tolist(),audio2['COUNTRY'].tolist(),audio2['STATE'].tolist(),audio2['CITY'].tolist()):                       
    # #         data.append([i,j,k,l,m,n,o,p,q,r,s,t,u])
    # #     temp={"data":data}
    return json.dumps(temp)



# playbackdatateachers('Sound Practices')







# TO BE UPDATED ON NOV 24
@app.route('/feedback_table_weekly_PARENTS')
def weekly_feedback_table():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1 =db.audio_track_master
    collection2 = db.audio_feedback
    
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)


    qr1= [{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
            {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
    ]}},
    {'$group':{'_id':'$USER_ID._id',
               'PRACTICE_COUNT':{'$sum':1},
           'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
           'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
           'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
               'Audio_name':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_NAME'},
               'Audio_length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'},
               'Language':{'$first':'$PROGRAM_AUDIO_ID.LANGUAGE'},

          'CITY':{'$first':'$USER_ID.schoolId.CITY'},
           'STATE':{'$first':'$USER_ID.schoolId.STATE'},
                'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}},
                    'PlayBack_Time_Percent':{'$sum':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}
                                            }}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)

    qr2= [{"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
               {'RATING':{'$ne':0}}]}},


    {'$project':{'_id':'$USER._id', 'USER_NAME':'$USER.USER_NAME',
               'EMAIL':'$USER.EMAIL_ID',
                 'DEVICE_USED':'$DEVICE_USED',
               'SCHOOL':'$USER.schoolId.NAME',
    #            'CREATED_DATE':'$CREATED_DATE',
               'COMMENT':'$COMMENT', 'ACTION_DATE':'$MODIFIED_DATE',
         'RATING':'$RATING',
         'COMMENT':'$COMMENT'
        }} ,
    {'$sort':{'RATING':-1}}    ]  


    list2= list(collection2.aggregate(qr2))
    audio1= DataFrame(list2)
    audio=pd.merge(audio1,df_atm1, on='_id', how='left')


    audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'PROGRAM_NAME','RATING','COMMENT','AUDIO_DAY','PRACTICE_COUNT',
    'Language',  'Audio_name', 'mindful_minutes', 'PlayBack_Time_Percent' ,'STATE','CITY']]       
    #               'LAST_PRACTICE_DATE'
    audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['RATING'].fillna('NO RATING GIVEN', inplace=True)
    audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
    audio2['AUDIO_DAY'].fillna('NO AUDIO DAY', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['Audio_name'].fillna('NO AUDIO FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['Language'].fillna('NO LANGUAGE FOUND', inplace=True)
    audio2['RATING']=str(audio2['RATING'].iloc[0])
    audio2['RATING']=audio2['RATING'].replace(0, 'No Rating')
    # audio2['LAST_PRACTICE_DATE']=audio2['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
    # audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    # #     audio20= audio2.groupby(audio2['RATING'])
    # #     audio3= audio20.get_group(''+ratinggg+'')
    # #     audio30= pd.DataFrame(audio3)
    # #     audio4=audio30.values.tolist()

    temp={'data':audio2.values.tolist()}


    return json.dumps(temp)



# weekly_feedback_table()

@app.route('/parents_signup_table_weekly')
def signupparentweek():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
 # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)


    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte':yester , '$lt':tod
#     }},
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
     'LAST_PRACTICE_DATE':{'$max':'$MODIFIED_DATE'}, 
     'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
    }}, 

    {'$sort':{'_id':1}}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                    
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start
                , '$lt': yester}}
    ]}},
         {'$project':{'_id':'$_id','CREATED_DATE':'$CREATED_DATE', 'schoolNAME':'$schoolId.NAME',
                      'USER_NAME':'$USER_NAME','EMAIL':'$EMAIL_ID',
                     'COUNTRY':'$schoolId.COUNTRY', 'STATE':'$schoolId.STATE', 'CITY':'$schoolId.CITY',
                
                     }}
         

    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    df_final= pd.merge(df_um,df_atm,how='left', on='_id')
   
    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','LAST_PRACTICE_DATE','COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
    audio2['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
#     audio2['LAST_PRACTICE_DATE']=audio2['LAST_PRACTICE_DATE'].strftime('%d %b %Y')
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    
    temp={'data':audio2.values.tolist()}
    return json.dumps(temp)



# playbackdata('Monday')
# signupdatateacher()

# signupparentweek()






@app.route('/teacher_signup_table_weekly')
def signupteacherweek():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
 # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)


    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte':yester , '$lt':tod
#     }},
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
     'LAST_PRACTICE_DATE':{'$max':'$MODIFIED_DATE'}, 
     'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
    }}, 

    {'$sort':{'_id':1}}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},                    
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start
                , '$lt': yester}}
    ]}},
         {'$project':{'_id':'$_id','CREATED_DATE':'$CREATED_DATE', 'schoolNAME':'$schoolId.NAME',
                      'USER_NAME':'$USER_NAME','EMAIL':'$EMAIL_ID',
                     'COUNTRY':'$schoolId.COUNTRY', 'STATE':'$schoolId.STATE', 'CITY':'$schoolId.CITY',
                
                     }}
         

    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    df_final= pd.merge(df_um,df_atm,how='left', on='_id')
   
    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','LAST_PRACTICE_DATE','COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
    audio2['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
#     audio2['LAST_PRACTICE_DATE']=audio2['LAST_PRACTICE_DATE'].strftime('%d %b %Y')
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    
    temp={'data':audio2.values.tolist()}
    return json.dumps(temp)



# playbackdata('Monday')
# signupdatateacher()

# signupteacherweek()





# weekly_feedback_tableTEACHERS()




# TO BE UPDATED ON NOV 24
@app.route('/dailyfeedratingtable_TEACHERS')
def dailyyy_feedback_table_TEACHERS():
    username=urllib.parse.quote_plus('admin')
    password=urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1 =db.audio_track_master
    collection2 = db.audio_feedback

    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)


    qr1= [{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
            {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester,
                             '$lt':tod
                             }},
    ]}},
    {'$group':{'_id':'$USER_ID._id',
               'PRACTICE_COUNT':{'$sum':1},
           'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
           'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
           'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
               'Audio_name':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_NAME'},
               'Audio_length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'},
               'Language':{'$first':'$PROGRAM_AUDIO_ID.LANGUAGE'},

          'CITY':{'$first':'$USER_ID.schoolId.CITY'},
           'STATE':{'$first':'$USER_ID.schoolId.STATE'},
                'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}},
                    'PlayBack_Time_Percent':{'$sum':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}
                                            }}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)

    qr2= [{"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':yester,
                             '$lt':tod
                             }},
               {'RATING':{'$ne':0}}]}},


    {'$project':{'_id':'$USER._id', 'USER_NAME':'$USER.USER_NAME',
               'EMAIL':'$USER.EMAIL_ID',
                 'DEVICE_USED':'$DEVICE_USED',
               'SCHOOL':'$USER.schoolId.NAME',
    #            'CREATED_DATE':'$CREATED_DATE',
               'COMMENT':'$COMMENT', 'ACTION_DATE':'$MODIFIED_DATE',
         'RATING':'$RATING',
         'COMMENT':'$COMMENT'
        }} ,
    {'$sort':{'RATING':-1}}    ]  


    list2= list(collection2.aggregate(qr2))
    audio1= DataFrame(list2)
    audio=pd.merge(audio1,df_atm1, on='_id', how='left')


    audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'PROGRAM_NAME','RATING','COMMENT','AUDIO_DAY','PRACTICE_COUNT',
    'Language',  'Audio_name', 'mindful_minutes', 'PlayBack_Time_Percent' ,'STATE','CITY']]       
    #               'LAST_PRACTICE_DATE'
    audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['RATING'].fillna('NO RATING GIVEN', inplace=True)
    audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
    audio2['AUDIO_DAY'].fillna('NO AUDIO DAY', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['Audio_name'].fillna('NO AUDIO FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['Language'].fillna('NO LANGUAGE FOUND', inplace=True)
    audio2['RATING']=str(audio2['RATING'].iloc[0])
    audio2['RATING']=audio2['RATING'].replace(0, 'No Rating')
    # audio2['LAST_PRACTICE_DATE']=audio2['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
    # audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    # #     audio20= audio2.groupby(audio2['RATING'])
    # #     audio3= audio20.get_group(''+ratinggg+'')
    # #     audio30= pd.DataFrame(audio3)
    # #     audio4=audio30.values.tolist()

    temp={'data':audio2.values.tolist()}


    return json.dumps(temp)


# dailyyy_feedback_table_TEACHERS()



# TO BE UPDATED ON NOV 24
@app.route('/dailyfeedratingtable_PARENTS')
def dailyyy_feedback_table_PARENTS():
    username=urllib.parse.quote_plus('admin')
    password=urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1 =db.audio_track_master
    collection2 = db.audio_feedback

    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)


    qr1= [{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
            {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester,
                             '$lt':tod
                             }},
    ]}},
    {'$group':{'_id':'$USER_ID._id',
               'PRACTICE_COUNT':{'$sum':1},
           'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
           'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
           'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
               'Audio_name':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_NAME'},
               'Audio_length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'},
               'Language':{'$first':'$PROGRAM_AUDIO_ID.LANGUAGE'},

          'CITY':{'$first':'$USER_ID.schoolId.CITY'},
           'STATE':{'$first':'$USER_ID.schoolId.STATE'},
                'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}},
                    'PlayBack_Time_Percent':{'$sum':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}
                                            }}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)

    qr2= [{"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':yester,
                             '$lt':tod
                             }},
               {'RATING':{'$ne':0}}]}},


    {'$project':{'_id':'$USER._id', 'USER_NAME':'$USER.USER_NAME',
               'EMAIL':'$USER.EMAIL_ID',
                 'DEVICE_USED':'$DEVICE_USED',
               'SCHOOL':'$USER.schoolId.NAME',
    #            'CREATED_DATE':'$CREATED_DATE',
               'COMMENT':'$COMMENT', 'ACTION_DATE':'$MODIFIED_DATE',
         'RATING':'$RATING',
         'COMMENT':'$COMMENT'
        }} ,
    {'$sort':{'RATING':-1}}    ]  


    list2= list(collection2.aggregate(qr2))
    audio1= DataFrame(list2)
    audio=pd.merge(audio1,df_atm1, on='_id', how='left')


    audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'PROGRAM_NAME','RATING','COMMENT','AUDIO_DAY','PRACTICE_COUNT',
    'Language',  'Audio_name', 'mindful_minutes', 'PlayBack_Time_Percent' ,'STATE','CITY']]       
    #               'LAST_PRACTICE_DATE'
    audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['RATING'].fillna('NO RATING GIVEN', inplace=True)
    audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
    audio2['AUDIO_DAY'].fillna('NO AUDIO DAY', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['Audio_name'].fillna('NO AUDIO FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['Language'].fillna('NO LANGUAGE FOUND', inplace=True)
    audio2['RATING']=str(audio2['RATING'].iloc[0])
    audio2['RATING']=audio2['RATING'].replace(0, 'No Rating')
    # audio2['LAST_PRACTICE_DATE']=audio2['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
    # audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    # #     audio20= audio2.groupby(audio2['RATING'])
    # #     audio3= audio20.get_group(''+ratinggg+'')
    # #     audio30= pd.DataFrame(audio3)
    # #     audio4=audio30.values.tolist()

    temp={'data':audio2.values.tolist()}


    return json.dumps(temp)
# dailyyy_feedback_table_PARENTS()

@app.route('/practicetrendnew')
def practice_trendnew():
    
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    df1 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[

     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}}, 
      {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},    
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": LSY_Date,
                                        "$lt":csy_first_date()}}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
       {'$project':{'_id':1,'TOTAL_LSY':'$pc'}}])))
    df1.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df1['Month'] = df1['Month'].map(d)
   
    df2 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[{'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
      {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
       {'$project':{'_id':1,'teacher_CSY':'$pc'}}])))
    if df2.empty == True:
        df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        df2
    df2.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df2['Month'] = df2['Month'].map(d)

    practice_left= pd.merge(df1, df2,on='Month', how='outer')
    practice_left=practice_left.fillna(0)    
    
    dfschoology = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[{'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
            {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
      {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
       {'$project':{'_id':1,'schoology_CSY':'$pc'}}])))
    
    if dfschoology.empty == True:
        dfschoology=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'schoology_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        dfschoology
    dfschoology.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    dfschoology['Month'] = dfschoology['Month'].map(d)
    dfschoology=dfschoology.fillna(0)
    
    
    dfclever = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[{'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}}, 
       {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
       {'$project':{'_id':1,'clever_CSY':'$pc'}}])))
    if dfclever.empty == True:
        dfclever=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'clever_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        dfclever
    dfclever.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    dfclever['Month'] = dfclever['Month'].map(d)
    dfclever=dfclever.fillna(0)
    
    df4 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[{'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
           {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
             {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
             
             
              {"USER_ID.CREATED_DATE":{"$gte": datetime.datetime(2020,3,17)}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
       {'$project':{'_id':1,'parents_CSY':'$pc'}}])))
    if df4.empty == True:
        df4=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        df4
    df4.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df4['Month'] = df4['Month'].map(d)
    # df2
    practice_LSY= pd.merge(df1, df2,on='Month', how='left')
    practice_CSY =pd.merge(practice_LSY, dfschoology, on='Month', how='left')
    practice_CSY =pd.merge(practice_CSY, dfclever, on='Month', how='left')
    practice_CSY =pd.merge(practice_CSY, df4, on='Month', how='left').fillna(0)
    
    mon=pd.DataFrame({'Month':[8,9,10,11,12,1,2,3,4,5,6,7]})
    d = dict(enumerate(calendar.month_abbr))
    mon['Month'] = mon['Month'].map(d)
    
    data=pd.merge(mon,practice_CSY,on='Month',how='left')
    Month=data['Month'].tolist()
    TOTAL_LSY=data['TOTAL_LSY'].tolist()
    teacher_CSY=data['teacher_CSY'].tolist()
    parents_CSY=data['parents_CSY'].tolist()
    schoology_CSY=data['schoology_CSY'].tolist()
    clever_CSY=data['clever_CSY'].tolist()
    temp=[{'Month':Month,'curve':TOTAL_LSY,'bar':teacher_CSY},{'bar2':parents_CSY},{'bars':schoology_CSY},{'barc': clever_CSY}]
    
    return json.dumps(temp)


#<<<<<----------------PRACTICE AND PLAYBACK BIFURCATION API------------------------->>>>>>>>>>>>>>>>>>>>>>>>>>>>

@app.route('/practicetrendnew/<charttype>')
def practice_trendnew_(charttype):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    from datetime import datetime
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        
        
        
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        df0 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": LSYTOLSY_Date(),
                                            "$lt":LSY_Date()}}]}},
            practice_cond_dictonary_list[0],
            practice_cond_dictonary_list[1],
             threshcond[0],      

           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'TOTAL_LSYTOLSY':'$pc'}}])))
        df0.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        print(df0)
        df0['Month'] = df0['Month'].map(d)


        df1 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": LSY_Date(),
                                            "$lt":csy_first_date()}}]}},
            practice_cond_dictonary_list[0],
            practice_cond_dictonary_list[1],
             threshcond[0],      

           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'TOTAL_LSY':'$pc'}}])))
        df1.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df1['Month'] = df1['Month'].map(d)

        df2 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[{'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
                {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'canvas', '$options':'i'}})}},
                {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'google', '$options':'i'}})}},

#                  {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#                  {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
            practice_cond_dictonary_list[0],
            practice_cond_dictonary_list[1],
             threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'teacher_CSY':'$pc'}}])))
        if df2.empty == True:
            df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            df2
        df2.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df2['Month'] = df2['Month'].map(d)

        practice_left= pd.merge(df1, df2,on='Month', how='outer')
        practice_left=practice_left.fillna(0)    

        dfschoology = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
                 {"USER_ID._id":{"$in":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
#                 {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
#                 {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                              { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
            practice_cond_dictonary_list[0],
            practice_cond_dictonary_list[1],
             threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'schoology_CSY':'$pc'}}])))

        if dfschoology.empty == True:
            dfschoology=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'schoology_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfschoology
        dfschoology.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfschoology['Month'] = dfschoology['Month'].map(d)
        dfschoology=dfschoology.fillna(0)


        dfclever = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#                 {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
             {"USER_ID._id":{"$in":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
               { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
            practice_cond_dictonary_list[0],
            practice_cond_dictonary_list[1],
             threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'clever_CSY':'$pc'}}])))
        if dfclever.empty == True:
            dfclever=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'clever_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfclever
        dfclever.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfclever['Month'] = dfclever['Month'].map(d)
        dfclever=dfclever.fillna(0)
        
        dfcanvas = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#                 {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
        {"USER_ID._id":{"$in":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'canvas', '$options':'i'}})}},
        {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
               { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
            practice_cond_dictonary_list[0],
            practice_cond_dictonary_list[1],
             threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'canvas_CSY':'$pc'}}])))
        if dfcanvas.empty == True:
            dfcanvas=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'canvas_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfcanvas
        dfcanvas.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfcanvas['Month'] = dfcanvas['Month'].map(d)
        dfcanvas=dfcanvas.fillna(0)

        df4 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[{'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'canvas', '$options':'i'}})}},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'google', '$options':'i'}})}},
#                  {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                              { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {"USER_ID.CREATED_DATE":{"$gte": datetime(2020,3,17)}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
            practice_cond_dictonary_list[0],
            practice_cond_dictonary_list[1],
             threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'parents_CSY':'$pc'}}])))
        if df4.empty == True:
            df4=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            df4
        df4.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df4['Month'] = df4['Month'].map(d)
        # df2
        practice_LSY_lsy= pd.merge(df1, df0,on='Month', how='left')
        practice_LSY= pd.merge(practice_LSY_lsy, df2,on='Month', how='left')
        practice_CSY =pd.merge(practice_LSY, dfschoology, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, dfclever, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, dfcanvas, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, df4, on='Month', how='left').fillna(0)

        mon=pd.DataFrame({'Month':[8,9,10,11,12,1,2,3,4,5,6,7]})
        d = dict(enumerate(calendar.month_abbr))
        mon['Month'] = mon['Month'].map(d)

        data=pd.merge(mon,practice_CSY,on='Month',how='left')
        Month=data['Month'].tolist()
        TOTAL_LSYTOLSY=data['TOTAL_LSYTOLSY'].tolist()
        TOTAL_LSY=data['TOTAL_LSY'].tolist()
        teacher_CSY=data['teacher_CSY'].tolist()
        parents_CSY=data['parents_CSY'].tolist()
        schoology_CSY=data['schoology_CSY'].tolist()
        clever_CSY=data['clever_CSY'].tolist()
        canvas_CSY=data['canvas_CSY'].tolist()
        temp=[{'Month':Month,'curve':TOTAL_LSY,'curve_LYTOLY':TOTAL_LSYTOLSY,'bar':teacher_CSY},{'bar2':parents_CSY},{'bars':schoology_CSY},{'barc': clever_CSY},{'barcan': canvas_CSY}]

        return json.dumps(temp)
    
    else:
        df0 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": LSYTOLSY_Date(),
                                            "$lt":LSY_Date()}}]}},
#             practice_cond_dictonary_list[0],
#             practice_cond_dictonary_list[1],
#             threshcond[0],      

           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'TOTAL_LSYTOLSY':'$pc'}}])))
        df0.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        print(df0)
        df0['Month'] = df0['Month'].map(d)


        df1 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": LSY_Date(),
                                            "$lt":csy_first_date()}}]}},
#             practice_cond_dictonary_list[0],
#             practice_cond_dictonary_list[1],
#              threshcond[0],      

           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'TOTAL_LSY':'$pc'}}])))
        df1.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df1['Month'] = df1['Month'].map(d)

        df2 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[{'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
                {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'canvas', '$options':'i'}})}},
                {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'google', '$options':'i'}})}},

#                  {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#                  {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
#             practice_cond_dictonary_list[0],
#             practice_cond_dictonary_list[1],
#              threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'teacher_CSY':'$pc'}}])))
        if df2.empty == True:
            df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            df2
        df2.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df2['Month'] = df2['Month'].map(d)

        practice_left= pd.merge(df1, df2,on='Month', how='outer')
        practice_left=practice_left.fillna(0)    

        dfschoology = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
                 {"USER_ID._id":{"$in":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
#                 {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
#                 {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                              { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
#             practice_cond_dictonary_list[0],
#             practice_cond_dictonary_list[1],
#              threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'schoology_CSY':'$pc'}}])))

        if dfschoology.empty == True:
            dfschoology=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'schoology_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfschoology
        dfschoology.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfschoology['Month'] = dfschoology['Month'].map(d)
        dfschoology=dfschoology.fillna(0)


        dfclever = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#                 {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
             {"USER_ID._id":{"$in":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
               { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
#             practice_cond_dictonary_list[0],
#             practice_cond_dictonary_list[1],
#              threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'clever_CSY':'$pc'}}])))
        if dfclever.empty == True:
            dfclever=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'clever_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfclever
        dfclever.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfclever['Month'] = dfclever['Month'].map(d)
        dfclever=dfclever.fillna(0)
        
        dfcanvas = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#                 {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
        {"USER_ID._id":{"$in":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'canvas', '$options':'i'}})}},
        {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
               { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
#             practice_cond_dictonary_list[0],
#             practice_cond_dictonary_list[1],
#              threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'canvas_CSY':'$pc'}}])))
        if dfcanvas.empty == True:
            dfcanvas=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'canvas_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfcanvas
        dfcanvas.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfcanvas['Month'] = dfcanvas['Month'].map(d)
        dfcanvas=dfcanvas.fillna(0)

        df4 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[{'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'clever', '$options':'i'}})}},
         {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'schoology', '$options':'i'}})}},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'canvas', '$options':'i'}})}},
                 {"USER_ID._id":{"$nin":db.user_master.distinct("_id",{"UTM_MEDIUM":{'$regex':'google', '$options':'i'}})}},
#                  {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                              { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {"USER_ID.CREATED_DATE":{"$gte": datetime(2020,3,17)}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
#             practice_cond_dictonary_list[0],
#             practice_cond_dictonary_list[1],
#              threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
           {'$project':{'_id':1,'parents_CSY':'$pc'}}])))
        if df4.empty == True:
            df4=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            df4
        df4.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df4['Month'] = df4['Month'].map(d)
        # df2
        practice_LSY_lsy= pd.merge(df1, df0,on='Month', how='left')
        practice_LSY= pd.merge(practice_LSY_lsy, df2,on='Month', how='left')
        practice_CSY =pd.merge(practice_LSY, dfschoology, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, dfclever, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, dfcanvas, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, df4, on='Month', how='left').fillna(0)

        mon=pd.DataFrame({'Month':[8,9,10,11,12,1,2,3,4,5,6,7]})
        d = dict(enumerate(calendar.month_abbr))
        mon['Month'] = mon['Month'].map(d)

        data=pd.merge(mon,practice_CSY,on='Month',how='left')
        Month=data['Month'].tolist()
        TOTAL_LSYTOLSY=data['TOTAL_LSYTOLSY'].tolist()
        TOTAL_LSY=data['TOTAL_LSY'].tolist()
        teacher_CSY=data['teacher_CSY'].tolist()
        parents_CSY=data['parents_CSY'].tolist()
        schoology_CSY=data['schoology_CSY'].tolist()
        clever_CSY=data['clever_CSY'].tolist()
        canvas_CSY=data['canvas_CSY'].tolist()
        temp=[{'Month':Month,'curve':TOTAL_LSY,'curve_LYTOLY':TOTAL_LSYTOLSY,'bar':teacher_CSY},{'bar2':parents_CSY},{'bars':schoology_CSY},{'barc': clever_CSY},{'barcan': canvas_CSY}]

        return json.dumps(temp)
       
#<<<<<<<<<<<<<<<<--------------API Ending here--------------------------->>>>>>>>>>>>>>>>>>
#<<<<<<<<<<<<<<<<--------------API Ending here--------------------------->>>>>>>>>>>>>>>>>>






# @app.route('/activetrendnew')
# def active_trendnew():
    
#     def csy_first_date():
#         date_today =datetime.date.today()
#     #     print(date_today)
#     #     date_today='2024-07-01'
#     #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
#         initial_date='2020-08-01'
#         day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
#         # Check if leap year in the calculation
#         if ((day1.year+1) % 4) == 0:
#             if ((day1.year+1) % 100) == 0:
#                 if ((day1.year+1) % 400) == 0:
#                     days_diff=1
#                 else:
#                     days_diff=1
#             else:
#                 days_diff=1
#         else:
#             days_diff=0
#         if ((date_today-day1).days<(365+days_diff)):
#             day_1=day1
#         else:
#             day1=day1+timedelta(days=(365+days_diff))
#             day_1=day1

#         csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

#         return csy_date
#         # LSY logic:
#     LSY_Date=csy_first_date()-relativedelta(years=1)
#     #     print("LSY", LSY_Date)
#     #     print("CSY",csy_first_date())
    
#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
#     db=client.compass
#     collection = db.audio_track_master
#     df1 = DataFrame(list(collection.aggregate([
#         {"$match":{
#      '$and':[

#      {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#       {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#      {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}}, 
#       {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#             {'USER_ID.EMAIL_ID':{'$ne':''}},
#              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#          { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},   
      
#      { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#         {"MODIFIED_DATE":{"$gte": LSY_Date,
#                                         "$lt":csy_first_date()}}]}},
#        {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID._id'}}},
#        {'$project':{'_id':1,'TOTAL_LSY':{'$size':'$auc'}}}])))
#     df1.rename(columns = { '_id': 'Month'}, inplace = True)
#     d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
#     df1['Month'] = df1['Month'].map(d)
#     print('LSY:', LSY_Date)
#     print('CSY',csy_first_date())
#     # print(df1)
#     df2 = DataFrame(list(collection.aggregate([
#         {"$match":{
#      '$and':[
#          {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#              {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#              {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
#      {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#       {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#      {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}}, 
#               {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#             {'USER_ID.EMAIL_ID':{'$ne':''}},
#              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#          { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},   
#      { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#         {"MODIFIED_DATE":{"$gte": csy_first_date(),
# #                                         "$lt":datetime.datetime(2021,8,1)
#                          }}]}},
#        {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID._id'}}},
#        {'$project':{'_id':1,'teacher_CSY':{'$size':'$auc'}}}])))
#     if df2.empty == True:
#         df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
#     else:
#         df2
#     df2.rename(columns = { '_id': 'Month'}, inplace = True)
#     d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
#     df2['Month'] = df2['Month'].map(d)
#     # df2
#     practice_left= pd.merge(df1, df2,on='Month', how='outer')
#     practice_left=practice_left.fillna(0)
#     #print(practice_left)
    
    
#     dfschoology = DataFrame(list(collection.aggregate([
#         {"$match":{
#      '$and':[
# #          {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
#             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
#      {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#       {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#      {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#               {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#             {'USER_ID.EMAIL_ID':{'$ne':''}},
#              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#          { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},   
#      { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#         {"MODIFIED_DATE":{"$gte": csy_first_date(),
# #                                         "$lt":datetime.datetime(2021,8,1)
#                          }}]}},
#        {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID._id'}}},
#        {'$project':{'_id':1,'schoology_CSY':{'$size':'$auc'}}}])))
    
#     if dfschoology.empty == True:
#         dfschoology=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'schoology_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
#     else:
#         dfschoology
#     dfschoology.rename(columns = { '_id': 'Month'}, inplace = True)
#     d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
#     dfschoology['Month'] = dfschoology['Month'].map(d)
#     dfschoology=dfschoology.fillna(0)
    
    
#     dfclever = DataFrame(list(collection.aggregate([
#         {"$match":{
#      '$and':[
# #          {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#             {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
#      {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#       {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#      {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#               {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#             {'USER_ID.EMAIL_ID':{'$ne':''}},
#              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#          { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},   
#      { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#         {"MODIFIED_DATE":{"$gte": csy_first_date(),
# #                                         "$lt":datetime.datetime(2021,8,1)
#                          }}]}},
#        {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID._id'}}},
#        {'$project':{'_id':1,'clever_CSY':{'$size':'$auc'}}}])))
#     if dfclever.empty == True:
#         dfclever=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'clever_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
#     else:
#         dfclever
#     dfclever.rename(columns = { '_id': 'Month'}, inplace = True)
#     d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
#     dfclever['Month'] = dfclever['Month'].map(d)
#     dfclever=dfclever.fillna(0)
    
#     df4 = DataFrame(list(collection.aggregate([
#         {"$match":{
#      '$and':[{'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
#              {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#            {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
#              { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                          {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#               {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#               {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
#              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#               {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#             {'USER_ID.EMAIL_ID':{'$ne':''}},
#              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#          { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},   
#               {"USER_ID.CREATED_DATE":{"$gte": datetime.datetime(2020,3,17)}},
#         {"MODIFIED_DATE":{"$gte": csy_first_date(),
# #                                         "$lt":datetime.datetime(2021,8,1)
#                          }}]}},
#        {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID._id'}}},
#        {'$project':{'_id':1,'parents_CSY':{'$size':'$auc'}}}])))
#     if df4.empty == True:
#         df4=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
#     else:
#         df4
#     df4.rename(columns = { '_id': 'Month'}, inplace = True)
#     d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
#     df4['Month'] = df4['Month'].map(d)
#     # df2
#     practice_LSY= pd.merge(df1, df2,on='Month', how='left')
#     practice_CSY =pd.merge(practice_LSY, dfschoology, on='Month', how='left')
#     practice_CSY =pd.merge(practice_CSY, dfclever, on='Month', how='left')
#     practice_CSY =pd.merge(practice_CSY, df4, on='Month', how='left').fillna(0)
    
#     mon=pd.DataFrame({'Month':[8,9,10,11,12,1,2,3,4,5,6,7]})
#     d = dict(enumerate(calendar.month_abbr))
#     mon['Month'] = mon['Month'].map(d)
    
#     data=pd.merge(mon,practice_CSY,on='Month',how='left')
#     Month=data['Month'].tolist()
#     TOTAL_LSY=data['TOTAL_LSY'].tolist()
#     teacher_CSY=data['teacher_CSY'].tolist()
#     parents_CSY=data['parents_CSY'].tolist()
#     schoology_CSY=data['schoology_CSY'].tolist()
#     clever_CSY=data['clever_CSY'].tolist()
#     temp=[{'Month':Month,'curve':TOTAL_LSY,'bar':teacher_CSY},{'bar2':parents_CSY},{'bars':schoology_CSY},{'barc': clever_CSY}]
    
#     return json.dumps(temp)
    

#>>>>>>>>>>>>>>>>--------- PRACTICE BIFURCATION API-------------->>>>>>>>>>>>>>>>>>>>>>>>>
@app.route('/activetrendnew/<charttype>')
def active_trend_new_(charttype):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    from datetime import datetime
    
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold= 0.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        df0 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
              { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
             {"MODIFIED_DATE":{"$gte": LSYTOLSY_Date(),
                                            "$lt":LSY_Date()}}]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID'}}},
           {'$project':{'_id':1,'TOTAL_LSYTOLSY':{'$size':'$auc'}}}])))
        df0.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df0['Month'] = df0['Month'].map(d)
         
        df1 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
              { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": LSY_Date(),
                                            "$lt":csy_first_date()}}]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID'}}},
           {'$project':{'_id':1,'TOTAL_LSY':{'$size':'$auc'}}}])))
        df1.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df1['Month'] = df1['Month'].map(d)
        print('LSY:', LSY_Date)
        print('CSY',csy_first_date())
        # print(df1)
        df2 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                  { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID'}}},
           {'$project':{'_id':1,'teacher_CSY':{'$size':'$auc'}}}])))
        if df2.empty == True:
            df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            df2
        df2.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df2['Month'] = df2['Month'].map(d)
        # df2
        practice_left= pd.merge(df1, df2,on='Month', how='outer')
        practice_left=practice_left.fillna(0)
        #print(practice_left)


        dfschoology = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                  { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID'}}},
           {'$project':{'_id':1,'schoology_CSY':{'$size':'$auc'}}}])))

        if dfschoology.empty == True:
            dfschoology=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'schoology_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfschoology
        dfschoology.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfschoology['Month'] = dfschoology['Month'].map(d)
        dfschoology=dfschoology.fillna(0)


        dfclever = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
             {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}}, 
                  { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID'}}},
           {'$project':{'_id':1,'clever_CSY':{'$size':'$auc'}}}])))
        if dfclever.empty == True:
            dfclever=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'clever_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfclever
        dfclever.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfclever['Month'] = dfclever['Month'].map(d)
        dfclever=dfclever.fillna(0)
        
        
        dfcanvas = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$in":db.canvas_user_master.distinct("USER_ID._id")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}}, 
                  { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID'}}},
           {'$project':{'_id':1,'canvas_CSY':{'$size':'$auc'}}}])))
        if dfcanvas.empty == True:
            dfcanvas=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'canvas_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfcanvas
        dfcanvas.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfcanvas['Month'] = dfcanvas['Month'].map(d)
        dfcanvas=dfcanvas.fillna(0)
        

        df4 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[{'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
                 {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {"USER_ID.CREATED_DATE":{"$gte": datetime(2020,3,17)}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID'}}},
           {'$project':{'_id':1,'parents_CSY':{'$size':'$auc'}}}])))
        if df4.empty == True:
            df4=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            df4
        df4.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df4['Month'] = df4['Month'].map(d)
        # df2
        practice_LSY_lsy= pd.merge(df1, df0,on='Month', how='left')
        practice_LSY= pd.merge(practice_LSY_lsy, df2,on='Month', how='left')
        practice_CSY =pd.merge(practice_LSY, dfschoology, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, dfclever, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, dfcanvas, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, df4, on='Month', how='left').fillna(0)

        mon=pd.DataFrame({'Month':[8,9,10,11,12,1,2,3,4,5,6,7]})
        d = dict(enumerate(calendar.month_abbr))
        mon['Month'] = mon['Month'].map(d)

        data=pd.merge(mon,practice_CSY,on='Month',how='left')
        Month=data['Month'].tolist()
        TOTAL_LSY=data['TOTAL_LSY'].tolist()
        TOTAL_LSYTOLSY=data['TOTAL_LSYTOLSY'].tolist()
        teacher_CSY=data['teacher_CSY'].tolist()
        parents_CSY=data['parents_CSY'].tolist()
        schoology_CSY=data['schoology_CSY'].tolist()
        clever_CSY=data['clever_CSY'].tolist()
        canvas_CSY=data['canvas_CSY'].tolist()
        temp=[{'Month':Month,'curve':TOTAL_LSY,'curve_LYTOLY':TOTAL_LSYTOLSY,'bar':teacher_CSY},{'bar2':parents_CSY},{'bars':schoology_CSY},{'barc': clever_CSY},{'barcan': canvas_CSY}]

        return json.dumps(temp)
    
    else:
        df0 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
              { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
             {"MODIFIED_DATE":{"$gte": LSYTOLSY_Date(),
                                            "$lt":LSY_Date()}}]}},
#             practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID._id'}}},
           {'$project':{'_id':1,'TOTAL_LSYTOLSY':{'$size':'$auc'}}}])))
#         print(df0)
        df0.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df0['Month'] = df0['Month'].map(d)
         
        df1 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
              { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": LSY_Date(),
                                            "$lt":csy_first_date()}}]}},
#             practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID._id'}}},
           {'$project':{'_id':1,'TOTAL_LSY':{'$size':'$auc'}}}])))
        df1.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df1['Month'] = df1['Month'].map(d)
        print('LSY:', LSY_Date)
        print('CSY',csy_first_date())
        # print(df1)
        df2 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                  { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
#             practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID._id'}}},
           {'$project':{'_id':1,'teacher_CSY':{'$size':'$auc'}}}])))
        if df2.empty == True:
            df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            df2
        df2.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df2['Month'] = df2['Month'].map(d)
        # df2
        practice_left= pd.merge(df1, df2,on='Month', how='outer')
        practice_left=practice_left.fillna(0)
        #print(practice_left)


        dfschoology = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},

         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                  { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
#             practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID'}}},
           {'$project':{'_id':1,'schoology_CSY':{'$size':'$auc'}}}])))

        if dfschoology.empty == True:
            dfschoology=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'schoology_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfschoology
        dfschoology.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfschoology['Month'] = dfschoology['Month'].map(d)
        dfschoology=dfschoology.fillna(0)


        dfclever = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
             {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}}, 
                  { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
#             practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID._id'}}},
           {'$project':{'_id':1,'clever_CSY':{'$size':'$auc'}}}])))
        if dfclever.empty == True:
            dfclever=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'clever_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfclever
        dfclever.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfclever['Month'] = dfclever['Month'].map(d)
        dfclever=dfclever.fillna(0)
        
        
        dfcanvas = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$in":db.canvas_user_master.distinct("USER_ID._id")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}}, 
                  { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
#             practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID._id'}}},
           {'$project':{'_id':1,'canvas_CSY':{'$size':'$auc'}}}])))
        if dfcanvas.empty == True:
            dfcanvas=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'canvas_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            dfcanvas
        dfcanvas.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        dfcanvas['Month'] = dfcanvas['Month'].map(d)
        dfcanvas=dfcanvas.fillna(0)
        

        df4 = DataFrame(list(collection.aggregate([
            {"$match":{
         '$and':[{'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},  
                 {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {"USER_ID.CREATED_DATE":{"$gte": datetime(2020,3,17)}},
            {"MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                         "$lt":datetime.datetime(2021,8,1)
                             }}]}},
#             practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
           {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'auc':{'$addToSet':'$USER_ID._id'}}},
           {'$project':{'_id':1,'parents_CSY':{'$size':'$auc'}}}])))
        if df4.empty == True:
            df4=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
        else:
            df4
        df4.rename(columns = { '_id': 'Month'}, inplace = True)
        d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
        df4['Month'] = df4['Month'].map(d)
        # df2
        practice_LSY_lsy= pd.merge(df1, df0,on='Month', how='left')
        practice_LSY= pd.merge(practice_LSY_lsy, df2,on='Month', how='left')
        practice_CSY =pd.merge(practice_LSY, dfschoology, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, dfclever, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, dfcanvas, on='Month', how='left')
        practice_CSY =pd.merge(practice_CSY, df4, on='Month', how='left').fillna(0)

        mon=pd.DataFrame({'Month':[8,9,10,11,12,1,2,3,4,5,6,7]})
        d = dict(enumerate(calendar.month_abbr))
        mon['Month'] = mon['Month'].map(d)

        data=pd.merge(mon,practice_CSY,on='Month',how='left')
        Month=data['Month'].tolist()
        TOTAL_LSY=data['TOTAL_LSY'].tolist()
        TOTAL_LSYTOLSY=data['TOTAL_LSYTOLSY'].tolist()
        teacher_CSY=data['teacher_CSY'].tolist()
        parents_CSY=data['parents_CSY'].tolist()
        schoology_CSY=data['schoology_CSY'].tolist()
        clever_CSY=data['clever_CSY'].tolist()
        canvas_CSY=data['canvas_CSY'].tolist()
        temp=[{'Month':Month,'curve':TOTAL_LSY,'curve_LYTOLY':TOTAL_LSYTOLSY,'bar':teacher_CSY},{'bar2':parents_CSY},{'bars':schoology_CSY},{'barc': clever_CSY},{'barcan': canvas_CSY}]

        return json.dumps(temp)
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>END
    





@app.route('/week_feed_rating_chart')
def weekly_chart__():
    username=urllib.parse.quote_plus('admin')
    password=urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client=MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)+timedelta(days=1)
    yester= yesterday+timedelta(hours=4)+timedelta(days=1)
    start_15day=tod-timedelta(days=15)+timedelta(days=1)

    querya=[
    {"$match":{"$and":[
    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.IS_DISABLE':{"$ne":'Y'}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
        {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}},
    {"MODIFIED_DATE":{"$gte": start, '$lt': yester}}
    ]}},

    {'$group':{'_id':'$RATING', 
    'parents_rating': {'$sum':{'$cond':[{'$eq':['$USER.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_rating': {'$sum':{'$cond':[{'$ne':['$USER.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},

    }}, {'$sort':{'_id':-1}}
    ]

    rating=list(collection2.aggregate(querya))
    rating_wise=pd.DataFrame(rating)


    query_before_last_week=[
    {"$match":{"$and":[
    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.IS_DISABLE':{"$ne":'Y'}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
        {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}},
    {"MODIFIED_DATE":{"$gte": start_15day, '$lt': start}}
    ]}},

    {'$group':{'_id':'$RATING', 
    'parents_rating': {'$sum':{'$cond':[{'$eq':['$USER.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_rating': {'$sum':{'$cond':[{'$ne':['$USER.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},

    }}, {'$sort':{'_id':-1}}
    ]

    rating_before_last_week=list(collection2.aggregate(query_before_last_week))
    rating_wise_before_last_week=pd.DataFrame(rating_before_last_week)


    rating=rating_wise_before_last_week['_id'].tolist()
    Parents_rating_before_lastweek=rating_wise_before_last_week['parents_rating'].tolist()
    teachers_rating_before_lastweek=rating_wise_before_last_week['teachers_rating'].tolist()
    Parents_rating_last_week=rating_wise['parents_rating'].tolist()
    Teachers_rating_last_week=rating_wise['teachers_rating'].tolist()


    temp1={'rating':rating, 'Parents_rating_before_lastweek':Parents_rating_before_lastweek,
          'teachers_rating_before_lastweek':teachers_rating_before_lastweek,
          'Parents_rating_last_week':Parents_rating_last_week,'Teachers_rating_last_week':Teachers_rating_last_week
         }

    temp={'rating_data':temp1}
    return json.dumps(temp)
# weekly_chart()


@app.route('/top_20_district_daily/<datestr>')
def district_daily_(datestr):  
    username=urllib.parse.quote_plus('admin')
    password=urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client=MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))


    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    mydatetime= dateutil.parser.parse(datestr)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
#     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)

    qr1=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID._id':{'$in':db.user_master.distinct('_id', {'DISTRICT_ID._id':{'$exists':1}})}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": yester, '$lt': tod}}
        ]}},

        {'$group':{'_id':'$USER_ID.DISTRICT_ID.DISTRICT_NAME', 'practice':{'$sum':1}
        }}, 
    #     {'$count':'count'}
        ]

    dis= list(collection.aggregate(qr1))
    df= DataFrame(dis)

    df0=df.nlargest(20,['practice'])

    df1= df0.reset_index(drop=True)
    df1[['_id','practice']]
    distid=df1['_id'].values.tolist()
    distpract=df1['practice'].values.tolist()

    temp={'district':distid, 'practice':distpract}


    return json.dumps(temp)


#>>>>>>>>>>>>>>>>>----------- PRACTICE BIFURCATION API------------------->>>>>>>>
@app.route('/top_20_district_daily/<datestr>/<charttype>')
def district___daily___(datestr,charttype):  
    username=urllib.parse.quote_plus('admin')
    password=urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client=MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))



    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    mydatetime= dateutil.parser.parse(datestr)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
#     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)
    
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]

        qr1=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                    {'USER_ID._id':{'$in':db.user_master.distinct('_id', {'DISTRICT_ID._id':{'$exists':1}})}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": yester, '$lte': tod}}
            ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],

            {'$group':{'_id':'$DISTRICT_NAME', 'practice':{'$sum':1}
            }}, 
        #     {'$count':'count'}
            ]

        dis= list(collection.aggregate(qr1))
        df= DataFrame(dis)

        df0=df.nlargest(20,['practice'])

        df1= df0.reset_index(drop=True)
        df1[['_id','practice']]
        distid=df1['_id'].values.tolist()
        distpract=df1['practice'].values.tolist()

        temp={'district':distid, 'practice':distpract}


        return json.dumps(temp)
    else:
        qr1=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                    {'USER_ID._id':{'$in':db.user_master.distinct('_id', {'DISTRICT_ID._id':{'$exists':1}})}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": yester, '$lte': tod}}
            ]}},

            {'$group':{'_id':'$USER_ID.DISTRICT_ID.DISTRICT_NAME', 'practice':{'$sum':1}
            }}, 
        #     {'$count':'count'}
            ]

        dis= list(collection.aggregate(qr1))
        df= DataFrame(dis)

        df0=df.nlargest(20,['practice'])

        df1= df0.reset_index(drop=True)
        df1[['_id','practice']]
        distid=df1['_id'].values.tolist()
        distpract=df1['practice'].values.tolist()

        temp={'district':distid, 'practice':distpract}


        return json.dumps(temp)








@app.route('/top_20_district_weekly/<datestr>')
def district_weeklyyy_(datestr):  
    username=urllib.parse.quote_plus('admin')
    password=urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client=MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))



    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    print(start_15day)
    # district=disdic[districtid]

    qr1=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID._id':{'$in':db.user_master.distinct('_id', {'DISTRICT_ID._id':{'$exists':1}})}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": start, '$lt': yester}}
        ]}},

        {'$group':{'_id':'$USER_ID.DISTRICT_ID.DISTRICT_NAME', 'practice':{'$sum':1}
        }}, 
    #     {'$count':'count'}
        ]

    dis= list(collection.aggregate(qr1))
    df= DataFrame(dis)

    df0=df.nlargest(20,['practice'])

    df1= df0.reset_index(drop=True)
    df1[['_id','practice']]
    distid=df1['_id'].values.tolist()
    distpract=df1['practice'].values.tolist()

    temp={'district':distid, 'practice':distpract}


    return json.dumps(temp)

#>>>>>>>>>>>>>>>>>>-------------------PRACTICE BIFURCATION API--------------->
@app.route('/top_20_district_weekly/<datestr>/<charttype>')
def district___weeklyyy___(datestr,charttype):  
    username=urllib.parse.quote_plus('admin')
    password=urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client=MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))



    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    print(start_15day)
    # district=disdic[districtid]
    
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]

        qr1=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                    {'USER_ID._id':{'$in':db.user_master.distinct('_id', {'DISTRICT_ID._id':{'$exists':1}})}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": start, '$lt': yester}}
            ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],

            {'$group':{'_id':'$DISTRICT_NAME', 'practice':{'$sum':1}
            }}, 
        #     {'$count':'count'}
            ]

        dis= list(collection.aggregate(qr1))
        df= DataFrame(dis)

        df0=df.nlargest(20,['practice'])

        df1= df0.reset_index(drop=True)
        df1[['_id','practice']]
        distid=df1['_id'].values.tolist()
        distpract=df1['practice'].values.tolist()

        temp={'district':distid, 'practice':distpract}


        return json.dumps(temp)
    else:
        qr1=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                    {'USER_ID._id':{'$in':db.user_master.distinct('_id', {'DISTRICT_ID._id':{'$exists':1}})}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {"MODIFIED_DATE":{"$gte": start, '$lt': yester}}
            ]}},

            {'$group':{'_id':'$USER_ID.DISTRICT_ID.DISTRICT_NAME', 'practice':{'$sum':1}
            }}, 
        #     {'$count':'count'}
            ]

        dis= list(collection.aggregate(qr1))
        df= DataFrame(dis)

        df0=df.nlargest(20,['practice'])

        df1= df0.reset_index(drop=True)
        df1[['_id','practice']]
        distid=df1['_id'].values.tolist()
        distpract=df1['practice'].values.tolist()

        temp={'district':distid, 'practice':distpract}


        return json.dumps(temp)




@app.route('/word_cloud_feedback_daily/<datestr>/')
def word_freq_daily_(datestr):
    import nltk
    from nltk.corpus import stopwords
    from textblob import TextBlob

    clean_list=[]
    news_headlines_senti = []
    news_headlines_dict = {}
    pnews_headlines=0
    nnews_headlines=0
    nenews_headlines = 0

    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    ollection = db.audio_track_master
    collection2=db.audio_feedback
    mydatetime= dateutil.parser.parse(datestr)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)
    
    collection = db.audio_feedback
    user=[
    {"$match":{'$and':[ {"USER.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                {"USER.USER_NAME":{ "$ne": ""}},
                {"USER.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                {"USER.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                {"USER.EMAIL_ID":{ "$ne": ""}},  
                {'USER.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER.IS_DISABLED':{"$ne":'Y'}},
                {'MODIFIED_DATE':{'$gte': yester, '$lt':tod}},
                       {'COMMENT':{'$nin':['',' ', None]}},
#                   {'RATING':{'$nin':rating}},     
                {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    #                   {"COMMENT":{"$exists":1 }} 
                        ]}},
    { "$project": { "USER_ID": "$USER._id", "USER_NAME": "$USER.USER_NAME","_id":0, "EMAIL": "$USER.EMAIL_ID", "RATING":1,
    "LAST_COMMENT_DATE": "$MODIFIED_DATE", "AUDIO_NAME": "$AUDIO_ID.AUDIO_NAME", "NARRATOR_NAME": "$AUDIO_ID.NARRATEDBY",
    "COMMENT":1, "PROGRAM_NAME": "$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME"}}
    ]
    update=list(collection.aggregate(user))
    df123=pd.DataFrame(update).fillna("no info")
    list_of_names=df123["USER_ID"].to_list()
#     print(1)
#     collection = db.user_master
#     user=[
#     {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                 {"USER_NAME":{ "$ne": ""}},
#                 {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                 {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                 {"EMAIL_ID":{ "$ne": ""}},  
#                 {'IS_BLOCKED':{"$ne":'Y'}}, 
#                 {'IS_DISABLED':{"$ne":'Y'}}, 
#                 {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                 {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#                 {"_id":{"$in":list_of_names}}   
#                         ]}},
#     { "$project": {"SCHOOL_NAME":"$schoolId.NAME", "CITY":"$schoolId.CITY","STATE":"$schoolId.STATE",
#           "USER_ID":"$_id","_id":0}}
#     ]
#     update=list(collection.aggregate(user))
#     df1=pd.DataFrame(update).fillna("no info")
#     print(2)
#     df01=pd.merge(df,df1,on="USER_ID",how="left")
#     collection = db.subscription_master
#     user=[
#     {"$match":{'$and':[{"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                 {"USER_ID.USER_NAME":{ "$ne": ""}},
#                 {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                 {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                 {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
#                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
#                 {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                 {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
# #                 {'PLAN_ID.PLAN_NAME':{"$in":product}},
#                 {"USER_ID._id":{"$in":list_of_names}}
#                   ]}},
#     { "$project": {"RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE","PLAN_NAME":"$PLAN_ID.PLAN_NAME",  
#            "USER_ID":"$USER_ID._id","_id":0}}
#     ]
#     update=list(collection.aggregate(user))
#     df2=pd.DataFrame(update).fillna("no info")
#     print(3)
#     df12=pd.merge(df01,df2,on="USER_ID",how="left")
#     collection = db.audio_track_master
#     user=[
#     {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                 {"USER_ID.USER_NAME":{ "$ne": ""}},
#                 {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                 {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                 {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
#                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
#                 {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                 {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#                 { "USER_ID._id":{"$in":list_of_names}},
#     ]}},
#     {"$group":{"_id": "$USER_ID._id","PRACTICE_COUNT":{"$sum":1}, 
#         "LAST_PRACTICE_DATE": {"$last": "$MODIFIED_DATE"},
#                     }},
#     { "$project": {"PRACTICE_COUNT":1,"_id":0,"USER_ID":"$_id","LAST_PRACTICE_DATE":1}}
#     ]
#     update=list(collection.aggregate(user))
#     df3=pd.DataFrame(update)
#     print(4)
#     df123=pd.merge(df12,df3,on="USER_ID",how="left")
#     xxt=df123[df123.PLAN_NAME.isin(product)]
#     df123=xxt
#     def Average(lst):
#         return sum(lst) / len(lst)

#     # Driver Code
#     lst =df123["RATING"].to_list()
#     average = Average(lst)


    #     print(df123["COMMENT"],"lola")
    xx=df123[df123["COMMENT"]!="no info"]
    xxc=xx[xx["COMMENT"]!=""]

    comment_list=xxc["COMMENT"].to_list()

    newtexttoken=[]
    for i in comment_list:
        text_tokens = nltk.tokenize.word_tokenize(i)
        newtexttoken.append(text_tokens)
    newlist=[]
    for i in newtexttoken:
        for z in i:
            newlist.append(z.lower())
    st_word=stopwords.words('english')
    tokens_without_sw= [word for word in newlist if not word in st_word]
    token5=[]
    for sentence in tokens_without_sw:
    #     print(sentence)
        text3 = sentence.split('ing')
    #     print(text3,"text3")
        for i in text3:
    #         print(i)
            token5.append(i)
    words = [w.replace('liked', 'like') for w in token5]
    words2 = [w.replace('relaxed', 'relax') for w in words]
    words3 = [w.replace('relaxing', 'relax') for w in words2]
    words4 = [w.replace('excitinging', 'excited') for w in words3]
    #     print(words4)
    zxc=""
    name=""
    count=""
    try:
        xcvv=[x for x in words4 if len(x)>3]
        fdist=FreqDist(xcvv)
        df_fdist = pd.DataFrame.from_dict(fdist, orient='index')
    #         print(df_fdist)
        df_fdist.columns = ['Frequency']
        df_fdist.index.name = 'Term'
        xc=df_fdist.sort_values(by='Frequency', ascending=False, na_position='first')
        #     tt=xc.drop(["i","it","we","made","us","the","feeling","some","students"])
        cc=xc[0:10]
        name=cc.index.to_list()
        count=cc["Frequency"].to_list()
        zxc=' '.join(word for word in xcvv)
    except:
        pass
    for item in comment_list:
        # trim
        item = item.strip()
        # Removing RT
        item = item.replace('RT', '')
        # Removing new line character
        item = item.replace('\\n', '')
        # Replace #word with word
        news_headlines = re.sub(r'#([^\s]+)', r'\1', item)
        # Convert @username to username
        news_headlines = re.sub(r'@([^\s]+)', r'\1', item)
        item = " ".join(re.findall("[a-zA-Z]+", item))
        tmp_var = re.sub(r'^\S*\s', '', item)
        clean_list.append(tmp_var)
    for item in clean_list:
            #print(item)
            # create TextBlob object of passed news_headlines text
            analysis = TextBlob(item)
            # set sentiment
            if analysis.sentiment.polarity > 0:
                # saving sentiment of news_headlines
                news_headlines_score = 'positive'
                pnews_headlines = pnews_headlines + 1
                news_headlines_dict[item] = news_headlines_score
            elif analysis.sentiment.polarity == 0:
                # saving sentiment of news_headlines
                news_headlines_score = 'neutral'
                nenews_headlines = nenews_headlines + 1
                news_headlines_dict[item] = news_headlines_score
            else:
                # saving sentiment of news_headlines
                news_headlines_score = 'negative'
                nnews_headlines = nnews_headlines + 1
                news_headlines_dict[item] = news_headlines_score
    # print(clean_list)
    newssentiment=[]
    # for k, v in news_headlines_dict.items():
    #     print(k,':',v)
    for k, v in news_headlines_dict.items():

        if v == "positive":
            newssentiment.append({"sentiment":int(1),"text":k})
        elif v == "negative":
            newssentiment.append({"sentiment":int(-1),"text":k})
        else:
            newssentiment.append({"sentiment":int(0),"text":k})

    #print(newssentiment)
    newssentiment_dataframe=pd.DataFrame.from_dict(newssentiment)
    # newssentiment_dataframe.to_csv("news_headlines_sentiment.csv", encoding='utf-8', index=False)
    neg = 100 * (nnews_headlines) / ((nnews_headlines) + (pnews_headlines))
    pos = 100 * (pnews_headlines) / ((nnews_headlines) + (pnews_headlines))
    # print(len(clean_list))
    # print("\nNegative news_headliness percentage: {} %".format(neg))
    # print("Positive news_headliness percentage: {} %".format(pos))
    df123["SCORE"]=""

    for i in range(len(df123)):
        try:
            analysis = TextBlob(df123["COMMENT"][i])
            if analysis.sentiment.polarity > 0:

                df123.at[i,"SCORE"]= 1
    #             

            elif analysis.sentiment.polarity == 0:

                df123.at[i,"SCORE"]= 0

            else:

                df123.at[i,"SCORE"]= -1
        except:
            df123.at[i,"SCORE"]= 0

    df123['just_date'] = df123['LAST_COMMENT_DATE'].dt.date
    xccx=df123.sort_values(by='just_date')
    xccx=df123.dropna()
    negdf=xccx[xccx["SCORE"]==-1]
    posdf=xccx[xccx["SCORE"]==1]
    
    df123['LAST_COMMENT_DATE']=pd.to_datetime(df123["LAST_COMMENT_DATE"]).dt.strftime('%Y-%m-%d')
    positivep=df123[df123["SCORE"]==1]
    df1234=positivep.groupby(["LAST_COMMENT_DATE"])["SCORE"].count().reset_index()
    df14i=df1234[["LAST_COMMENT_DATE","SCORE"]]
    df14i['LAST_COMMENT_DATE'] = pd.to_datetime(df14i['LAST_COMMENT_DATE'])
    df15i=df14i.sort_values(by='LAST_COMMENT_DATE')
    df15i['LAST_COMMENT_DATE']=df15i['LAST_COMMENT_DATE'].astype(np.int64)/int(1e6)
    shp1=df15i[["LAST_COMMENT_DATE","SCORE"]].values.tolist()
    negativen=df123[df123["SCORE"]==-1]
    df12345=negativen.groupby(["LAST_COMMENT_DATE"])["SCORE"].count().reset_index()
    df14ii=df12345[["LAST_COMMENT_DATE","SCORE"]]
    df14ii['LAST_COMMENT_DATE'] = pd.to_datetime(df14ii['LAST_COMMENT_DATE'])
    df15ii=df14ii.sort_values(by='LAST_COMMENT_DATE')
    df15ii['LAST_COMMENT_DATE']=df15ii['LAST_COMMENT_DATE'].astype(np.int64)/int(1e6)
    shp2=df15ii[["LAST_COMMENT_DATE","SCORE"]].values.tolist()
    df123['LAST_COMMENT_DATE']=pd.to_datetime(df123["LAST_COMMENT_DATE"]).dt.strftime('%Y-%m-%d')
#     negtable=negativen[["SCHOOL_NAME","STATE","CITY","USER_NAME","EMAIL","COMMENT","AUDIO_NAME","NARRATOR_NAME","PROGRAM_NAME","just_date","LAST_PRACTICE_DATE","PRACTICE_COUNT"]]   
#     negtable["just_date"]=negtable["just_date"].apply(lambda x: x.strftime('%d %b %Y'))
#     negtable["LAST_PRACTICE_DATE"]=negtable["LAST_PRACTICE_DATE"].dt.strftime('%d %b %Y')
#     negtable1=negtable.fillna(" ")
#     negtablef=pd.DataFrame(negtable1)
#     postable=positivep[["SCHOOL_NAME","STATE","CITY","USER_NAME","EMAIL","COMMENT","AUDIO_NAME","NARRATOR_NAME","PROGRAM_NAME","just_date","LAST_PRACTICE_DATE","PRACTICE_COUNT"]]   
#     postable["just_date"]=postable["just_date"].apply(lambda x: x.strftime('%d %b %Y'))
#     postable["LAST_PRACTICE_DATE"]=postable["LAST_PRACTICE_DATE"].dt.strftime('%d %b %Y')
#     postable1=postable.fillna(" ")
#     postablef=pd.DataFrame(postable1)
#     overalltable=df123[["SCHOOL_NAME","STATE","CITY","USER_NAME","EMAIL","COMMENT","AUDIO_NAME","NARRATOR_NAME","PROGRAM_NAME","just_date","LAST_PRACTICE_DATE","PRACTICE_COUNT"]]
#     overalltable1=overalltable.dropna()
#     overalltable1["just_date"]=overalltable1["just_date"].apply(lambda x: x.strftime('%d %b %Y'))
#     overalltable1["LAST_PRACTICE_DATE"]=overalltable1["LAST_PRACTICE_DATE"].dt.strftime('%d %b %Y')
#     overalltable11=overalltable1.fillna(" ")
#     overalltable1f=pd.DataFrame(overalltable1)
    word_chart={'positive':shp1,'negative':shp2,"word_cloud":zxc,"label":name,"count":count,"donut":{"pos":round(pos, 2),"neg":round(neg, 2)}}

    return json.dumps(word_chart)


from nltk.tokenize import word_tokenize
from nltk.probability import FreqDist
from nltk.corpus import stopwords
from textblob import TextBlob, Word, Blobber

@app.route('/weekly_sentiment/<datestr>/<rating>')
def sentiment_weeklyfeedbacks__(datestr,rating):
    clean_list=[]
    news_headlines_senti = []
    news_headlines_dict = {}
    pnews_headlines=0
    nnews_headlines=0
    nenews_headlines = 0
    # datestr='2021-09-21'
    # rating=5
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)

    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    today = date.today()
    if rating == "all":
        rating=[0,1,2,3,4,5]
    else : 
        rating=[int(rating)]

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback
    user_feed=[
    {"$match":{'$and':[ {"USER.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
    {"USER.USER_NAME":{ "$ne": ""}},
    {"USER.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
    {"USER.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
    {'USER.EMAIL_ID':{ "$not": { "$regex": "tech@innerexplorer.org",'$options':'i'}}},
    {"USER.EMAIL_ID":{ "$ne": ""}},{'USER.IS_BLOCKED':{"$ne":'Y'}}, {'USER.IS_DISABLED':{"$ne":'Y'}},
       {'MODIFIED_DATE':{'$gte': start, '$lt':yester}}, 
                           {'RATING':{'$in':rating}},     
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}}
    ]}},
    { "$project": { "_id": "$USER._id", "USER_NAME": "$USER.USER_NAME","EMAIL": "$USER.EMAIL_ID", "RATING":1,
    "LAST_COMMENT_DATE": "$MODIFIED_DATE", "AUDIO_NAME": "$AUDIO_ID.AUDIO_NAME", "NARRATOR_NAME": "$AUDIO_ID.NARRATEDBY",
    "COMMENT":1, "PROGRAM_NAME": "$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME"}}
    ]
    update_feed=list(collection.aggregate(user_feed))
    df_feed=pd.DataFrame(update_feed).fillna("no info")

    # list_of_names=df_feed["_id"].tolist()

    collection1 = db.user_master
    user_master=[
    {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_NAME":{ "$ne": ""}},
    {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
    {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
    {"EMAIL_ID":{ "$ne": ""}},  {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}
    # ,{"_id":{"$in":list_of_names}}   
    ]}},
    { "$project": {"_id":"$_id",
        "SCHOOL_NAME":"$schoolId.NAME", 'District_name':'$DISTRICT_ID.DISTRICT_NAME',
    "CITY":"$schoolId.CITY","STATE":"$schoolId.STATE"}}
    ]
    update_user=list(collection1.aggregate(user_master))
    df_user=pd.DataFrame(update_user).fillna("no info")

    df01=pd.merge(df_feed,df_user,on="_id",how="left")

    collection2 = db.subscription_master
    user_sub=[
    {"$match":{'$and':[{"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_ID.USER_NAME":{ "$ne": ""}},
    {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
    {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
    {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    # {"USER_ID._id":{"$in":list_of_names}}
    ]}},
    { "$project": {"_id":"$USER_ID._id","RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE","PLAN_NAME":"$PLAN_ID.PLAN_NAME"}}]

    update_sub=list(collection2.aggregate(user_sub))
    df2_sub=pd.DataFrame(update_sub).fillna("no info")

    df12=pd.merge(df01,df2_sub,on="_id",how="left")

    collection_atm = db.audio_track_master
    atm=[
    {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_ID.USER_NAME":{ "$ne": ""}},
    {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
    {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
    {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    # { "USER_ID._id":{"$in":list_of_names}},
    ]}},
    {"$group":{"_id": "$USER_ID._id","PRACTICE_COUNT":{"$sum":1}, 
    "LAST_PRACTICE_DATE": {"$last": "$MODIFIED_DATE"},
    }}
    # { "$project": {"_id":"$USER_ID._id","PRACTICE_COUNT":1,"LAST_PRACTICE_DATE":1}}
    ]
    update_atm=list(collection_atm.aggregate(atm))
    df3=pd.DataFrame(update_atm)


    df123=pd.merge(df12,df3,on="_id",how="left")

    def average(listt):
        return sum(listt)/len(listt) 
    df_rating=df123[df123['RATING']!=0]
    listt=df_rating['RATING'].tolist()
    Avg= round(average(listt),1)

    xx=df123[df123["COMMENT"]!="no info"]
    df_comments=xx[xx["COMMENT"]!=""]

    comment_list=df_comments["COMMENT"].to_list()

    # df_comments


    newtexttoken=[]
    for i in comment_list:
        text_tokens= word_tokenize(i)
        newtexttoken.append(text_tokens)
    # newtexttoken    

    newlist=[]
    for i in newtexttoken:
        for z in i:
            newlist.append(z.lower())

    # newlist 

    st_words=stopwords.words('english')
    st_words_spanish=stopwords.words('spanish')
    tokens_without_sw= [word for word in newlist if not word in st_words]

    # tokens_without_sw


    token5=[]
    for sentence in tokens_without_sw:
        text3 = sentence.split('ing')

        for i in text3:
            token5.append(i)

    words = [w.replace('liked', 'like') for w in token5]
    words2 = [w.replace('relaxed', 'relax') for w in words]
    words3 = [w.replace('relaxing', 'relax') for w in words2]
    words4 = [w.replace('excitinging', 'excited') for w in words3]
    # words

    zxc=""
    name=""
    count=""

    try:
        xxx=[x for x in words4 if len(x)>3]
        fdist=FreqDist(xxx)
        df_fdist = pd.DataFrame.from_dict(fdist, orient='index')
        df_fdist.columns = ['Frequency']
        df_fdist.index.name = 'Term'
        xc=df_fdist.sort_values(by='Frequency', ascending=False, na_position='first')
        cc=xc[0:10]
        name=cc.index.to_list()
        count=cc["Frequency"].to_list()
        zxc=' '.join(word for word in xxx)
    except:
        pass

    for item in comment_list:
        # trim
        item = item.strip()
        # Removing RT
        item = item.replace('RT', '')
        # Removing new line character
        item = item.replace('\\n', '')
        # Replace #word with word
        news_headlines = re.sub(r'#([^\s]+)', r'\1', item)
        # Convert @username to username
        news_headlines = re.sub(r'@([^\s]+)', r'\1', item)
        item = " ".join(re.findall("[a-zA-Z]+", item))
        tmp_var = re.sub(r'^\S*\s', '', item)
        clean_list.append(tmp_var)

    for item in clean_list:
        #print(item)
        # create TextBlob object of passed news_headlines text
        analysis = TextBlob(item)
        # set sentiment
        if analysis.sentiment.polarity > 0:
            # saving sentiment of news_headlines
            news_headlines_score = 'positive'
            pnews_headlines = pnews_headlines + 1
            news_headlines_dict[item] = news_headlines_score
        elif analysis.sentiment.polarity == 0:
            # saving sentiment of news_headlines
            news_headlines_score = 'neutral'
            nenews_headlines = nenews_headlines + 1
            news_headlines_dict[item] = news_headlines_score
        else:
            # saving sentiment of news_headlines
            news_headlines_score = 'negative'
            nnews_headlines = nnews_headlines + 1
            news_headlines_dict[item] = news_headlines_score


    newssentiment=[]
    for k, v in news_headlines_dict.items():
        if v == "positive":
            newssentiment.append({"sentiment":int(1),"text":k})
        elif v == "negative":
            newssentiment.append({"sentiment":int(-1),"text":k})
        else:
            newssentiment.append({"sentiment":int(0),"text":k})


    newssentiment_dataframe=pd.DataFrame.from_dict(newssentiment)

    neg = 100 * (nnews_headlines) / ((nnews_headlines) + (pnews_headlines))
    pos = 100 * (pnews_headlines) / ((nnews_headlines) + (pnews_headlines))

    df123["SCORE"]=""

    for i in range(len(df123)):
        try:
            analysis = TextBlob(df123["COMMENT"][i])
            if analysis.sentiment.polarity > 0:

                df123.at[i,"SCORE"]= 1
    #             

            elif analysis.sentiment.polarity == 0:

                df123.at[i,"SCORE"]= 0

            else:

                df123.at[i,"SCORE"]= -1

        except:
                df123.at[i,"SCORE"]= 0


    df123['just_date'] = df123['LAST_COMMENT_DATE'].dt.date
    xccx=df123.sort_values(by='just_date')
    xccx=df123.dropna()
    negdf=xccx[xccx["SCORE"]==-1]
    posdf=xccx[xccx["SCORE"]==1]


    Positive=df123[df123['SCORE']==1]
    Negative=df123[df123['SCORE']==-1]
    Neutral=df123[df123['SCORE']==0]

    df123=df123.drop_duplicates(keep=False)


    df123=df123[df123['District_name']!='no info']

    df=df123[['RATING','District_name','SCORE','PRACTICE_COUNT']]

    df['SCORE']=df['SCORE'].replace({1:'Positive',-1:'Negative',0:'Neutral'})

    df123['LAST_COMMENT_DATE']=pd.to_datetime(df123["LAST_COMMENT_DATE"]).dt.strftime('%Y-%m-%d')
    positivep=df123[df123["SCORE"]==1]
    df1234=positivep.groupby(["LAST_COMMENT_DATE"])["SCORE"].count().reset_index()
    df14i=df1234[["LAST_COMMENT_DATE","SCORE"]]
    df14i['LAST_COMMENT_DATE'] = pd.to_datetime(df14i['LAST_COMMENT_DATE'])
    df15i=df14i.sort_values(by='LAST_COMMENT_DATE')
    df15i['LAST_COMMENT_DATE']=df15i['LAST_COMMENT_DATE'].astype(np.int64)/int(1e6)
    shp1=df15i[["LAST_COMMENT_DATE","SCORE"]].values.tolist()
    negativen=df123[df123["SCORE"]==-1]
    df12345=negativen.groupby(["LAST_COMMENT_DATE"])["SCORE"].count().reset_index()
    df14ii=df12345[["LAST_COMMENT_DATE","SCORE"]]
    df14ii['LAST_COMMENT_DATE'] = pd.to_datetime(df14ii['LAST_COMMENT_DATE'])
    df15ii=df14ii.sort_values(by='LAST_COMMENT_DATE')
    df15ii['LAST_COMMENT_DATE']=df15ii['LAST_COMMENT_DATE'].astype(np.int64)/int(1e6)
    shp2=df15ii[["LAST_COMMENT_DATE","SCORE"]].values.tolist()
    df123['LAST_COMMENT_DATE']=pd.to_datetime(df123["LAST_COMMENT_DATE"]).dt.strftime('%Y-%m-%d')
    negtable=negativen[["SCHOOL_NAME","District_name","USER_NAME","EMAIL","COMMENT","AUDIO_NAME","NARRATOR_NAME","PROGRAM_NAME","just_date","LAST_PRACTICE_DATE","PRACTICE_COUNT","STATE","CITY"]]   
    negtable["just_date"]=negtable["just_date"].apply(lambda x: x.strftime('%d %b %Y'))
    negtable["LAST_PRACTICE_DATE"]=negtable["LAST_PRACTICE_DATE"].dt.strftime('%d %b %Y')
    negtable1=negtable.fillna(" ")
    negtablef=pd.DataFrame(negtable1)
    postable=positivep[["SCHOOL_NAME","District_name","USER_NAME","EMAIL","COMMENT","AUDIO_NAME","NARRATOR_NAME","PROGRAM_NAME","just_date","LAST_PRACTICE_DATE","PRACTICE_COUNT", "STATE","CITY"]]   
    postable["just_date"]=postable["just_date"].apply(lambda x: x.strftime('%d %b %Y'))
    postable["LAST_PRACTICE_DATE"]=postable["LAST_PRACTICE_DATE"].dt.strftime('%d %b %Y')
    postable1=postable.fillna(" ")
    postablef=pd.DataFrame(postable1)
    overalltable=df123[["SCHOOL_NAME","District_name","USER_NAME","EMAIL","COMMENT","AUDIO_NAME","NARRATOR_NAME","PROGRAM_NAME","just_date","LAST_PRACTICE_DATE","PRACTICE_COUNT","STATE","CITY"]]
    overalltable1=overalltable.dropna()
    overalltable1["just_date"]=overalltable1["just_date"].apply(lambda x: x.strftime('%d %b %Y'))
    overalltable1["LAST_PRACTICE_DATE"]=overalltable1["LAST_PRACTICE_DATE"].dt.strftime('%d %b %Y')
    overalltable11=overalltable1.fillna(" ")
    overalltable1f=pd.DataFrame(overalltable1)
    word_chart={'positivetable':postablef.values.tolist(),'negtable':negtablef.values.tolist(),'overalltable':overalltable1f.values.tolist(),'positive':str(shp1),'negative':shp2,"word_cloud":zxc,"label":name,"count":count,"donut":{"pos":round(pos, 2),"neg":round(neg, 2)}}

    return json.dumps(word_chart)


@app.route('/word_cloud_feedback_weekly/<datestr>/')
def word_freq__(datestr):
    import nltk
    from nltk.corpus import stopwords
    from textblob import TextBlob
    from nltk import FreqDist
    import re
    clean_list=[]
    news_headlines_senti = []
    news_headlines_dict = {}
    pnews_headlines=0
    nnews_headlines=0
    nenews_headlines = 0

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    ollection = db.audio_track_master
    collection2=db.audio_feedback
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    #     print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    #     print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    #     print(start_15day)

    collection = db.audio_feedback
    user=[
    {"$match":{'$and':[ {"USER.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                {"USER.USER_NAME":{ "$ne": ""}},
                {"USER.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                {"USER.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                {"USER.EMAIL_ID":{ "$ne": ""}},  
                {'USER.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER.IS_DISABLED':{"$ne":'Y'}},
                {'MODIFIED_DATE':{'$gte': start, '$lt':yester}},
                       {'COMMENT':{'$nin':['',' ', None]}},
    #                   {'RATING':{'$nin':rating}},     
                {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    #                   {"COMMENT":{"$exists":1 }} 
                        ]}},
    { "$project": { "USER_ID": "$USER._id", "USER_NAME": "$USER.USER_NAME","_id":0, "EMAIL": "$USER.EMAIL_ID", "RATING":1,
    "LAST_COMMENT_DATE": "$MODIFIED_DATE", "AUDIO_NAME": "$AUDIO_ID.AUDIO_NAME", "NARRATOR_NAME": "$AUDIO_ID.NARRATEDBY",
    "COMMENT":1, "PROGRAM_NAME": "$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME"}}
    ]
    update=list(collection.aggregate(user))
    df123=pd.DataFrame(update).fillna("no info")
    list_of_names=df123["USER_ID"].to_list()

    xx=df123[df123["COMMENT"]!="no info"]
    xxc=xx[xx["COMMENT"]!=""]
    comment_list=xxc["COMMENT"].to_list()

    newtexttoken=[]
    for i in comment_list:
        text_tokens = nltk.tokenize.word_tokenize(i)
        newtexttoken.append(text_tokens)
    newlist=[]
    for i in newtexttoken:
        for z in i:
            newlist.append(z.lower())
    st_word=stopwords.words('english')
    tokens_without_sw= [word for word in newlist if not word in st_word]


    token5=[]
    for sentence in tokens_without_sw:
        text3 = sentence.split('ing')    
        for i in text3:
            token5.append(i)


    words = [w.replace('liked', 'like') for w in token5]
    words2 = [w.replace('relaxed', 'relax') for w in words]
    words3 = [w.replace('relaxing', 'relax') for w in words2]
    words4 = [w.replace('excitinging', 'excited') for w in words3]
    zxc=""
    name=""
    count=""

    try:
        xcvv=[x for x in words4 if len(x)>3]
        fdist=FreqDist(xcvv)
        df_fdist = pd.DataFrame.from_dict(fdist, orient='index')
    #         print(df_fdist)
        df_fdist.columns = ['Frequency']
        df_fdist.index.name = 'Term'
        xc=df_fdist.sort_values(by='Frequency', ascending=False, na_position='first')
        #     tt=xc.drop(["i","it","we","made","us","the","feeling","some","students"])
        cc=xc[0:10]
        name=cc.index.to_list()
        count=cc["Frequency"].to_list()
        zxc=' '.join(word for word in xcvv)
    except:
        pass

    for item in comment_list:
        # trim
        item = item.strip()
        # Removing RT
        item = item.replace('RT', '')
        # Removing new line character
        item = item.replace('\\n', '')
        # Replace #word with word
        news_headlines = re.sub(r'#([^\s]+)', r'\1', item)
        # Convert @username to username
        news_headlines = re.sub(r'@([^\s]+)', r'\1', item)
        item = " ".join(re.findall("[a-zA-Z]+", item))
        tmp_var = re.sub(r'^\S*\s', '', item)
        clean_list.append(tmp_var)
    for item in clean_list:
            #print(item)
            # create TextBlob object of passed news_headlines text
            analysis = TextBlob(item)
            # set sentiment
            if analysis.sentiment.polarity > 0:
                # saving sentiment of news_headlines
                news_headlines_score = 'positive'
                pnews_headlines = pnews_headlines + 1
                news_headlines_dict[item] = news_headlines_score
            elif analysis.sentiment.polarity == 0:
                # saving sentiment of news_headlines
                news_headlines_score = 'neutral'
                nenews_headlines = nenews_headlines + 1
                news_headlines_dict[item] = news_headlines_score
            else:
                # saving sentiment of news_headlines
                news_headlines_score = 'negative'
                nnews_headlines = nnews_headlines + 1
                news_headlines_dict[item] = news_headlines_score
    # print(clean_list)
    newssentiment=[]
    # for k, v in news_headlines_dict.items():
    #     print(k,':',v)
    for k, v in news_headlines_dict.items():

        if v == "positive":
            newssentiment.append({"sentiment":int(1),"text":k})
        elif v == "negative":
            newssentiment.append({"sentiment":int(-1),"text":k})
        else:
            newssentiment.append({"sentiment":int(0),"text":k})

    #print(newssentiment)
    newssentiment_dataframe=pd.DataFrame.from_dict(newssentiment)
    # newssentiment_dataframe.to_csv("news_headlines_sentiment.csv", encoding='utf-8', index=False)
    neg = 100 * (nnews_headlines) / ((nnews_headlines) + (pnews_headlines))
    pos = 100 * (pnews_headlines) / ((nnews_headlines) + (pnews_headlines))
    # print(len(clean_list))
    # print("\nNegative news_headliness percentage: {} %".format(neg))
    # print("Positive news_headliness percentage: {} %".format(pos))
    df123["SCORE"]=""

    for i in range(len(df123)):
        try:
            analysis = TextBlob(df123["COMMENT"][i])
            if analysis.sentiment.polarity > 0:

                df123.at[i,"SCORE"]= 1
    #             

            elif analysis.sentiment.polarity == 0:

                df123.at[i,"SCORE"]= 0

            else:

                df123.at[i,"SCORE"]= -1
        except:
            df123.at[i,"SCORE"]= 0

    df123['just_date'] = df123['LAST_COMMENT_DATE'].dt.date
    xccx=df123.sort_values(by='just_date')
    xccx=df123.dropna()
    negdf=xccx[xccx["SCORE"]==-1]
    posdf=xccx[xccx["SCORE"]==1]

    df123['LAST_COMMENT_DATE']=pd.to_datetime(df123["LAST_COMMENT_DATE"]).dt.strftime('%Y-%m-%d')
    positivep=df123[df123["SCORE"]==1]
    df1234=positivep.groupby(["LAST_COMMENT_DATE"])["SCORE"].count().reset_index()
    df14i=df1234[["LAST_COMMENT_DATE","SCORE"]]
    df14i['LAST_COMMENT_DATE'] = pd.to_datetime(df14i['LAST_COMMENT_DATE'])
    df15i=df14i.sort_values(by='LAST_COMMENT_DATE')
    df15i['LAST_COMMENT_DATE']=df15i['LAST_COMMENT_DATE'].astype(np.int64)/int(1e6)
    shp1=df15i[["LAST_COMMENT_DATE","SCORE"]].values.tolist()
    negativen=df123[df123["SCORE"]==-1]
    df12345=negativen.groupby(["LAST_COMMENT_DATE"])["SCORE"].count().reset_index()
    df14ii=df12345[["LAST_COMMENT_DATE","SCORE"]]
    df14ii['LAST_COMMENT_DATE'] = pd.to_datetime(df14ii['LAST_COMMENT_DATE'])
    df15ii=df14ii.sort_values(by='LAST_COMMENT_DATE')
    df15ii['LAST_COMMENT_DATE']=df15ii['LAST_COMMENT_DATE'].astype(np.int64)/int(1e6)
    shp2=df15ii[["LAST_COMMENT_DATE","SCORE"]].values.tolist()
    df123['LAST_COMMENT_DATE']=pd.to_datetime(df123["LAST_COMMENT_DATE"]).dt.strftime('%Y-%m-%d')
    word_chart={'positive':shp1,'negative':shp2,"word_cloud":zxc,"label":name,"count":count,"donut":{"pos":round(pos, 2),"neg":round(neg, 2)}}
    
    
#     negtable=negativen[["SCHOOL_NAME","STATE","CITY","USER_NAME","EMAIL","COMMENT","AUDIO_NAME","NARRATOR_NAME","PROGRAM_NAME","just_date","LAST_PRACTICE_DATE","PRACTICE_COUNT"]]   
#     negtable["just_date"]=negtable["just_date"].apply(lambda x: x.strftime('%d %b %Y'))
#     negtable["LAST_PRACTICE_DATE"]=negtable["LAST_PRACTICE_DATE"].dt.strftime('%d %b %Y')
#     negtable1=negtable.fillna(" ")
#     negtablef=pd.DataFrame(negtable1)
#     postable=positivep[["SCHOOL_NAME","STATE","CITY","USER_NAME","EMAIL","COMMENT","AUDIO_NAME","NARRATOR_NAME","PROGRAM_NAME","just_date","LAST_PRACTICE_DATE","PRACTICE_COUNT"]]   
#     postable["just_date"]=postable["just_date"].apply(lambda x: x.strftime('%d %b %Y'))
#     postable["LAST_PRACTICE_DATE"]=postable["LAST_PRACTICE_DATE"].dt.strftime('%d %b %Y')
#     postable1=postable.fillna(" ")
#     postablef=pd.DataFrame(postable1)
#     overalltable=df123[["SCHOOL_NAME","STATE","CITY","USER_NAME","EMAIL","COMMENT","AUDIO_NAME","NARRATOR_NAME","PROGRAM_NAME","just_date","LAST_PRACTICE_DATE","PRACTICE_COUNT"]]
#     overalltable1=overalltable.dropna()
#     overalltable1["just_date"]=overalltable1["just_date"].apply(lambda x: x.strftime('%d %b %Y'))
#     overalltable1["LAST_PRACTICE_DATE"]=overalltable1["LAST_PRACTICE_DATE"].dt.strftime('%d %b %Y')
#     overalltable11=overalltable1.fillna(" ")
#     overalltable1f=pd.DataFrame(overalltable1)
 

    return json.dumps(word_chart)


@app.route('/week_feed_rating_chart/<datestr>')
def weekly_chart___(datestr):
    username=urllib.parse.quote_plus('admin')
    password=urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client=MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    print(start_15day)

    querya=[
    {"$match":{"$and":[
    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.IS_DISABLE':{"$ne":'Y'}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
        {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}},
    {"MODIFIED_DATE":{"$gte": start, '$lt': yester}}
    ]}},

    {'$group':{'_id':'$RATING', 
    'parents_rating': {'$sum':{'$cond':[{'$eq':['$USER.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_rating': {'$sum':{'$cond':[{'$ne':['$USER.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},

    }}, {'$sort':{'_id':-1}}
    ]

    rating=list(collection2.aggregate(querya))
    rating_wise=pd.DataFrame(rating)


    query_before_last_week=[
    {"$match":{"$and":[
    {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
    {'USER.IS_DISABLE':{"$ne":'Y'}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
        {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}},
    {"MODIFIED_DATE":{"$gte": start_15day, '$lt': start}}
    ]}},

    {'$group':{'_id':'$RATING', 
    'parents_rating': {'$sum':{'$cond':[{'$eq':['$USER.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_rating': {'$sum':{'$cond':[{'$ne':['$USER.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},

    }}, {'$sort':{'_id':-1}}
    ]

    rating_before_last_week=list(collection2.aggregate(query_before_last_week))
    rating_wise_before_last_week=pd.DataFrame(rating_before_last_week)


    rating=rating_wise_before_last_week['_id'].tolist()
    Parents_rating_before_lastweek=rating_wise_before_last_week['parents_rating'].tolist()
    teachers_rating_before_lastweek=rating_wise_before_last_week['teachers_rating'].tolist()
    Parents_rating_last_week=rating_wise['parents_rating'].tolist()
    Teachers_rating_last_week=rating_wise['teachers_rating'].tolist()


    temp1={'rating':rating, 'Parents_rating_before_lastweek':Parents_rating_before_lastweek,
          'teachers_rating_before_lastweek':teachers_rating_before_lastweek,
          'Parents_rating_last_week':Parents_rating_last_week,'Teachers_rating_last_week':Teachers_rating_last_week
         }

    temp={'rating_data':temp1}
    return json.dumps(temp)





@app.route('/weekprac')
def week_prac():
    
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username,       password))
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)

    new_date = today - relativedelta(years=1)
    print(new_date,"check1")
    
    db=client.compass
    collection = db.audio_track_master
    df1 = DataFrame(list(collection.aggregate([
        {"$match":{'$and':[{'USER_id.ROLE_ID.ROLE_ID' :{'$ne':3}},
        { "USER_id.IS_DISABLED":{"$ne":"Y"}},
         { "USER_id.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_id.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
       { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],
#        "MODIFIED_DATE":{"$gte": datetime.datetime(2020,8,1)}
                   'MODIFIED_DATE':{'$gte': csy_first_date()}
                   
    }},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'},'pc':{'$sum':1},'auc':{'$addToSet':'$USER_ID._id'}}},
    {'$project':{'_id':1,'prac1':'$pc','user1':{'$size':'$auc'}}},
         { "$sort":{'_id' : 1 }}
    ])))
    df1.rename(columns = { '_id': 'DAY1'}, inplace = True)  
    df1.insert(1, "DAY_name", ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'], True)
    # d = dict(enumerate(calendar.day_name))    # to convert monthnumber of dataframe into monthname
    # df1['DAY_name'] = df1['DAY_name'].map(d)
    #print(df1)
    df2 = DataFrame(list(collection.aggregate([                   
    {"$match":{
        'USER_id.ROLE_ID.ROLE_ID' :{'$ne':3},
         "USER_id.IS_DISABLED":{"$ne":"Y"},
          "USER_id.IS_BLOCKED":{"$ne":"Y"},
         "USER_id.INCOMPLETE_SIGNUP":{"$ne":"Y"},    
      '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],
#        "MODIFIED_DATE":{"$gt": datetime.datetime(2019,8,1),"$lt":new_date}
         'MODIFIED_DATE':{'$gt':LSY_Date,'$lt':new_date}
    }},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'},'pc':{'$sum':1},'auc':{'$addToSet':'$USER_ID._id'}}},
    {'$project':{'_id':1,'prac2':'$pc','user2':{'$size':'$auc'}}},
         { "$sort":{'_id' : 1 }}
    ])))
    df2.rename(columns = { '_id': 'DAY2'}, inplace = True)
    df2.insert(1, "DAY_name", ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'], True)
    # d = dict(enumerate(calendar.day_abbr))    # to convert monthnumber of dataframe into monthname
    # df2['DAY_name'] = df2['DAY_name'].map(d)
    #print(df2)
    df= pd.merge(df1, df2,on='DAY_name', how='outer')
    #print(df)
    week=df['DAY_name'].tolist()
    user2021=df['user1'].tolist()
    prac2021=df['prac1'].tolist()
    user1920=df['user2'].tolist()
    prac1920=df['prac2'].tolist()
    data={'week':week,'user1920':user2021,'prac1920':prac2021,'user1819':user1920,'prac1819':prac1920}
    temp={"data":data}
    return json.dumps(temp)


#>>>>>>>>>>>>>>>>>>>>>--------------PRACTICE BIFURCATION API--------------------->>>>>>>>
@app.route('/weekprac/<charttype>')
# @app.route('/weekprac/<charttype>')
def week___prac___(charttype):
    
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username,       password))
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)

    new_date = today - relativedelta(years=1)
    print(new_date,"check1")
    
    db=client.compass
    collection = db.audio_track_master
    
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        df1 = DataFrame(list(collection.aggregate([
            {"$match":{'$and':[{'USER_id.ROLE_ID.ROLE_ID' :{'$ne':3}},
            { "USER_id.IS_DISABLED":{"$ne":"Y"}},
             { "USER_id.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_id.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
           { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],
    #        "MODIFIED_DATE":{"$gte": datetime.datetime(2020,8,1)}
                       'MODIFIED_DATE':{'$gte': csy_first_date()}

        }},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'},'pc':{'$sum':1},'auc':{'$addToSet':'$USER_ID'}}},
        {'$project':{'_id':1,'prac1':'$pc','user1':{'$size':'$auc'}}},
             { "$sort":{'_id' : 1 }}
        ])))
        df1.rename(columns = { '_id': 'DAY1'}, inplace = True)  
        df1.insert(1, "DAY_name", ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'], True)
        # d = dict(enumerate(calendar.day_name))    # to convert monthnumber of dataframe into monthname
        # df1['DAY_name'] = df1['DAY_name'].map(d)
        #print(df1)
        df2 = DataFrame(list(collection.aggregate([                   
        {"$match":{
            'USER_id.ROLE_ID.ROLE_ID' :{'$ne':3},
             "USER_id.IS_DISABLED":{"$ne":"Y"},
              "USER_id.IS_BLOCKED":{"$ne":"Y"},
             "USER_id.INCOMPLETE_SIGNUP":{"$ne":"Y"},    
          '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],
    #        "MODIFIED_DATE":{"$gt": datetime.datetime(2019,8,1),"$lt":new_date}
             'MODIFIED_DATE':{'$gt':LSY_Date,'$lt':new_date}
        }},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'},'pc':{'$sum':1},'auc':{'$addToSet':'$USER_ID'}}},
        {'$project':{'_id':1,'prac2':'$pc','user2':{'$size':'$auc'}}},
             { "$sort":{'_id' : 1 }}
        ])))
        df2.rename(columns = { '_id': 'DAY2'}, inplace = True)
        df2.insert(1, "DAY_name", ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'], True)
        # d = dict(enumerate(calendar.day_abbr))    # to convert monthnumber of dataframe into monthname
        # df2['DAY_name'] = df2['DAY_name'].map(d)
        #print(df2)
        df= pd.merge(df1, df2,on='DAY_name', how='outer')
        #print(df)
        week=df['DAY_name'].tolist()
        user2021=df['user1'].tolist()
        prac2021=df['prac1'].tolist()
        user1920=df['user2'].tolist()
        prac1920=df['prac2'].tolist()
        data={'week':week,'user1920':user2021,'prac1920':prac2021,'user1819':user1920,'prac1819':prac1920}
        temp={"data":data}
        return json.dumps(temp)
    
    else:
        df1 = DataFrame(list(collection.aggregate([
            {"$match":{'$and':[{'USER_id.ROLE_ID.ROLE_ID' :{'$ne':3}},
            { "USER_id.IS_DISABLED":{"$ne":"Y"}},
             { "USER_id.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_id.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
           { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],
    #        "MODIFIED_DATE":{"$gte": datetime.datetime(2020,8,1)}
                       'MODIFIED_DATE':{'$gte': csy_first_date()}

        }},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'},'pc':{'$sum':1},'auc':{'$addToSet':'$USER_ID._id'}}},
        {'$project':{'_id':1,'prac1':'$pc','user1':{'$size':'$auc'}}},
             { "$sort":{'_id' : 1 }}
        ])))
        df1.rename(columns = { '_id': 'DAY1'}, inplace = True)  
        df1.insert(1, "DAY_name", ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'], True)
        # d = dict(enumerate(calendar.day_name))    # to convert monthnumber of dataframe into monthname
        # df1['DAY_name'] = df1['DAY_name'].map(d)
        #print(df1)
        df2 = DataFrame(list(collection.aggregate([                   
        {"$match":{
            'USER_id.ROLE_ID.ROLE_ID' :{'$ne':3},
             "USER_id.IS_DISABLED":{"$ne":"Y"},
              "USER_id.IS_BLOCKED":{"$ne":"Y"},
             "USER_id.INCOMPLETE_SIGNUP":{"$ne":"Y"},    
          '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],
    #        "MODIFIED_DATE":{"$gt": datetime.datetime(2019,8,1),"$lt":new_date}
             'MODIFIED_DATE':{'$gt':LSY_Date,'$lt':new_date}
        }},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'},'pc':{'$sum':1},'auc':{'$addToSet':'$USER_ID._id'}}},
        {'$project':{'_id':1,'prac2':'$pc','user2':{'$size':'$auc'}}},
             { "$sort":{'_id' : 1 }}
        ])))
        df2.rename(columns = { '_id': 'DAY2'}, inplace = True)
        df2.insert(1, "DAY_name", ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday'], True)
        # d = dict(enumerate(calendar.day_abbr))    # to convert monthnumber of dataframe into monthname
        # df2['DAY_name'] = df2['DAY_name'].map(d)
        #print(df2)
        df= pd.merge(df1, df2,on='DAY_name', how='outer')
        #print(df)
        week=df['DAY_name'].tolist()
        user2021=df['user1'].tolist()
        prac2021=df['prac1'].tolist()
        user1920=df['user2'].tolist()
        prac1920=df['prac2'].tolist()
        data={'week':week,'user1920':user2021,'prac1920':prac2021,'user1819':user1920,'prac1819':prac1920}
        temp={"data":data}
        return json.dumps(temp)






# week_prac()

# @app.route('/renewal19/<month>/Active20')
# def renewalact2019(month):
#     db = mysql.connector.connect(host="54.184.165.106",    # your host, usually localhost
#                      user="IE-tech",         # your username
#                      passwd="IE-tech@2O2O",  # your password
#                      db="compassJul")  
#     q1="""select sm.ID,year(sub.SUBSCRIPTION_EXPIRE_DATE) as year,monthname(sub.SUBSCRIPTION_EXPIRE_DATE) as month, sm.NAME as school_name,um.USER_NAME AS admin_name,um.EMAIL_ID AS admin_email  ,sub.SUBSCRIPTION_EXPIRE_DATE as renewal_date from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and um.IS_BLOCKED !='Y'   and admin_col ='ADMIN' and date(sub.SUBSCRIPTION_EXPIRE_DATE)>'2019-06-31' and date(sub.SUBSCRIPTION_EXPIRE_DATE) <'2020-04-01'
#      GROUP BY sm.ID"""
#     q1=pd.read_sql(q1,con=db)
#     q1['month'] = q1['month'].str.upper()
#     year=str(q1.loc[q1['month'].str.contains(month), 'year'].iloc[0])
#     renewal="""select school_name,admin_name,admin_email,renewal_date,USER_COUNT,school_practice_count,last_login_date,last_practice_date from
#     (select sm.ID, sm.NAME as school_name,um.USER_NAME AS admin_name,um.EMAIL_ID AS admin_email  ,sub.SUBSCRIPTION_EXPIRE_DATE as renewal_date from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and um.IS_BLOCKED !='Y'   and admin_col ='ADMIN' and year(sub.SUBSCRIPTION_EXPIRE_DATE)="""+year+""" and monthname(sub.SUBSCRIPTION_EXPIRE_DATE) like '%"""+month+"""%'
#      GROUP BY sm.ID) q1
#      inner join 
#      (select sm.ID, count(distinct(up.USER_ID)) AS USER_COUNT, count(atd.USER_ID) as school_practice_count, max(ll.LAST_LOGGED_IN) as last_login_date,max(atd.MODIFIED_DATE) as last_practice_date  from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     inner join audio_track_detail atd on atd.USER_ID=up.USER_ID
#     left join login_logs ll on ll.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%"  and sm.ID in (select sm.ID  from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     inner join audio_track_detail atd on atd.USER_ID=up.USER_ID
#     left join login_logs ll on ll.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and year(atd.MODIFIED_DATE)>2019 and um.IS_BLOCKED !='Y'   and year(sub.SUBSCRIPTION_EXPIRE_DATE)=2020 and monthname(sub.SUBSCRIPTION_EXPIRE_DATE) like '%"""+month+"""%'
#      GROUP BY sm.ID) and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and um.IS_BLOCKED !='Y'   and year(sub.SUBSCRIPTION_EXPIRE_DATE)="""+year+""" and monthname(sub.SUBSCRIPTION_EXPIRE_DATE) like '%"""+month+"""%'
#      GROUP BY sm.ID) q2
#      ON  q1.ID =q2.ID"""
#     renewal=pd.read_sql(renewal,con=db)
#     renewal['last_practice_date'].fillna("NO PRACTICE", inplace=True)
#     renewal['renewal_date'].fillna(" ", inplace=True)
#     renewal['last_login_date'].fillna("NO LOGIN", inplace=True)
#     LAST_PRACTICE_DATE=[]
#     for i in renewal['last_practice_date']:
#         if  i != 'NO PRACTICE' :
#             LAST_PRACTICE_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             LAST_PRACTICE_DATE.append("NO PRACTICE")
#     LAST_LOGIN_DATE=[]
#     for i in renewal['last_login_date']:
#         if  i != 'NO LOGIN' :
#             LAST_LOGIN_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             LAST_LOGIN_DATE.append("NO LOGIN")
#     RENEWAL_DATE =[]
#     for i in renewal['renewal_date']:
#         if  i != ' ' :
#             RENEWAL_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             RENEWAL_DATE.append("NO PRACTICE")
#     data=[]
#     for i,k,l,m,o,p,q,r in zip(renewal['school_name'].tolist(),renewal['admin_name'].tolist(),renewal['admin_email'].tolist(),RENEWAL_DATE,LAST_PRACTICE_DATE,LAST_LOGIN_DATE,renewal['school_practice_count'].tolist(),renewal['USER_COUNT'].tolist()) :
#         data.append([i,k,l,m,o,p,q,r])
#     temp ={"data":data}
# #     print(len(data))
#     return json.dumps(temp)

@app.route('/proguser')
def prog_user():
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1
        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')
        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db=client.compass
    collection = db.audio_track_master
    prog_prac_table1 = DataFrame(list(collection.aggregate([
     {"$match":{
         '$and':[
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
               {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},   
                
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],
                   'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None},
    "MODIFIED_DATE":{"$gte": csy_first_date(),
    #                                 "$lt":datetime.datetime(2021,8,1)
                    }}},
    {'$group':{'_id':{'pn':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME','Month':{'$month':'$MODIFIED_DATE'}}, 'auc': {'$addToSet':'$USER_ID._id'},
               'pg':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'}}},
    {'$project':{'pg':'$pg','_id':1, 'Active_usercount in 2020-2021':{'$size':'$auc'}}},
      { "$sort":{'pg' : 1 }}])))
    df1 = pd.DataFrame(prog_prac_table1)
    df1 = pd.json_normalize(df1['_id'])
    prog_prac_table = pd.concat([df1,prog_prac_table1], axis =1)
    del prog_prac_table['_id']
    prog_prac_table['Month'] = pd.to_datetime(prog_prac_table['Month'], format='%m').dt.month_name()
    month=['August','September','October','November','December','January','February','March','April','May','June','July']
    elem=[]
    mid=[]
    pre=[]
    high=[]
    alls=[]
    for i in set(prog_prac_table.pg.tolist()):
        for j in month:
            if i==2:
                df=prog_prac_table[prog_prac_table['pg']==i]
                try:
                    df=df[df['Month']==j]['Active_usercount in 2020-2021']
                    pre.append(int(df))
                except:
                    pre.append(0)
            elif i==1:
                df=prog_prac_table[prog_prac_table['pg']==i]
                try:
                    df=df[df['Month']==j]['Active_usercount in 2020-2021']
                    elem.append(int(df))
                except:
                    elem.append(0)
            elif i==3:
                df=prog_prac_table[prog_prac_table['pg']==i]
                try:
                    df=df[df['Month']==j]['Active_usercount in 2020-2021']
                    mid.append(int(df))
                except:
                    mid.append(0)
            elif i==4:
                df=prog_prac_table[prog_prac_table['pg']==i]
                try:
                    df=df[df['Month']==j]['Active_usercount in 2020-2021']
                    high.append(int(df))
                except:
                    high.append(0)
            elif i==8:
                df=prog_prac_table[prog_prac_table['pg']==i]
                try:
                    df=df[df['Month']==j]['Active_usercount in 2020-2021']
                    alls.append(int(df))
                except:
                    alls.append(0)
            else:
                break
    data=[{'elem':elem,'prek':pre,'mid':mid,'high':high,'all':alls}]
    return json.dumps(data)
#     print(data)

@app.route('/progprac')
def prog_prac():
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db=client.compass
    collection = db.audio_track_master
    prog_prac_table1 = DataFrame(list(collection.aggregate([
    {"$match":{
    
        '$and':[{'USER_ID.ROLE_ID.ROLE_ID' :{'$ne':3}},
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
   { "USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},                      
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],
            'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None},
    "MODIFIED_DATE":{"$gte": datetime.datetime(2020,8,1),
                                "$lt":datetime.datetime(2021,8,1)}}},
    {'$group':{'_id':{'pn':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME','Month':{'$month':'$MODIFIED_DATE'}}, 'pc':{'$sum':1},
        'pg':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'}}},
    {'$project':{'pg':'$pg','_id':1, 'Practice_count in 2020-2021':'$pc'}},
    { "$sort":{'pg' : 1 }}])))
    df1 = pd.DataFrame(prog_prac_table1)
    df1 = pd.json_normalize(df1['_id'])
    prog_prac_table = pd.concat([df1,prog_prac_table1], axis =1)
    del prog_prac_table['_id']
    prog_prac_table['Month'] = pd.to_datetime(prog_prac_table['Month'], format='%m').dt.month_name()
    month=['August','September','October','November','December','January','February','March','April','May','June','July']
    elem=[]
    mid=[]
    pre=[]
    high=[]
    alls=[]
    
    
    for i in set(prog_prac_table.pg.tolist()):
        
        for j in month:
            
            if i==2:
                df=prog_prac_table[prog_prac_table['pg']==i]
                try:
                    df=df[df['Month']==j]['Practice_count in 2020-2021']
                    pre.append(int(df))
                except:
                    pre.append(0)
            elif i==1:
                df=prog_prac_table[prog_prac_table['pg']==i]
                try:
                    df=df[df['Month']==j]['Practice_count in 2020-2021']
                    elem.append(int(df))
                except:
                    elem.append(0)
            elif i==3:
                df=prog_prac_table[prog_prac_table['pg']==i]
                try:
                    df=df[df['Month']==j]['Practice_count in 2020-2021']
                    mid.append(int(df))
                except:
                    mid.append(0)
            elif i==4:
                df=prog_prac_table[prog_prac_table['pg']==i]
                try:
                    df=df[df['Month']==j]['Practice_count in 2020-2021']
                    high.append(int(df))
                except:
                    high.append(0)
            elif i==8:
                df=prog_prac_table[prog_prac_table['pg']==i]
                try:
                    df=df[df['Month']==j]['Practice_count in 2020-2021']
                    alls.append(int(df))
                except:
                    alls.append(0)
            else:
                break
    data=[{'elem':elem,'prek':pre,'mid':mid,'high':high,'all':alls}]
    
    return json.dumps(data)
#     print(data)


@app.route('/canada')
def canada():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,       password))
    db=client.compass
    collection1= db.subscription_master
    qr1=[{'$match':{'USER_ID.schoolId':{'$exists':True}}},
        {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}},{'USER_ID.schoolId.COUNTRY':{'$regex':'Canada', '$options':'i'}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
                        {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
                        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id' , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}}
    },
         {'$project':{'_id':1, 'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}
                     }
    ]
    collection2= db.audio_track_master
    qrB= [{'$match':{'USER_ID.schoolId._id':{'$exists':True}}},
        {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},
   {'USER_ID.schoolId.COUNTRY':{'$regex':'Canada', '$options':'i'}},
                        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id','SCHOOL_PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
          {'$project':{'_id':1,'SCHOOL_PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date": "$practice_date" }}}}
    ]
    collection3= db.user_master
    qrC=[
        {'$match':{"schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'BLOCKED_BY_CAP':{'$ne':'Y'}},{'IS_ADMIN':{'$eq':'Y'}}, {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'schoolId._id':{'$not':{'$regex':'null'}}},
   {'schoolId.COUNTRY':{'$regex':'Canada', '$options':'i'}},
                        {'schoolId._id':{'$not':{'$regex':''}}},
                        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$schoolId._id','USER_COUNT':{'$addToSet':'$_id'}, 'STATE':{'$first':'$schoolId.STATE'}
              }},
    {'$project':{'_id':1, 'USER_COUNT':{'$size':'$USER_COUNT'}, 'STATE':1}}
     ]
    list1= list(collection1.aggregate(qr1))
    df_sub= DataFrame(list1)
    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join1= pd.merge(df_sub, df_atma, how='left', on='_id')
    join_final1= pd.merge(join1, df_um, how='left', on='_id')
    collection11= db.user_master
    qr11=[
    {'$match':{"schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'BLOCKED_BY_CAP':{'$ne':'Y'}},{'IS_ADMIN':{'$eq':'Y'}}, {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'schoolId._id':{'$not':{'$regex':'null'}}},
                        {'schoolId.COUNTRY':{'$regex':'Canada', '$options':'i'}},
                        {'schoolId._id':{'$not':{'$regex':''}}},{'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$schoolId._id','ADMIN_NAME':{'$first':'$USER_NAME'},'user_id':{'$first':'$_id'},
    'SCHOOL_NAME':{'$first':'$schoolId.NAME'}, 'ADMIN_EMAIL':{'$first':'$EMAIL_ID'}
    }}
        ]
    collection12=db.audio_track_master
    qr12=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}}, {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.schoolId.COUNTRY':{'$regex':'Canada', '$options':'i'}},
    {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 'user_id':{'$first':'$USER_ID._id'}
    }}
        ]
    collection13= db.subscription_master
    qr13=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
{'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}}, {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.schoolId.COUNTRY':{'$regex':'Canada', '$options':'i'}},
        {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id'
               , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}
              }},
        {'$project':{'_id':1,
                     'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}}
    ]
    list11= list(collection11.aggregate(qr11))
    df_um= DataFrame(list11)
    list12=list(collection12.aggregate(qr12))
    df_atm= DataFrame(list12)
    list13= list(collection13.aggregate(qr13))
    df_sbm= DataFrame(list13)
    join12= pd.merge(df_sbm, df_atm, how='left', on='_id')
    join_final12= pd.merge(join12,df_um, how='left', on='_id')
    inner_join_df= pd.merge(join_final1, join_final12,  on='_id', how='inner')
    
# inner_join_df
    data_final1= inner_join_df[['SCHOOL_NAME','ADMIN_NAME','ADMIN_EMAIL','RENEWAL_DATE_x','SCHOOL_PRACTICE_COUNT','LAST_PRACTICE_DATE','USER_COUNT','STATE']]
    data_final1['SCHOOL_NAME'].fillna('NO SCHOOL FOUND', inplace=True)
    data_final1['ADMIN_NAME'].fillna('NO USER INFO', inplace=True)
    data_final1['SCHOOL_PRACTICE_COUNT'].fillna('NO PRACTICE', inplace=True)
    data_final1['STATE'].fillna('NO INFO', inplace=True)
    data_final1['ADMIN_EMAIL'].fillna('NO INFO', inplace=True)
    data_final1['USER_COUNT'].fillna('NO USER', inplace=True)
    data_final1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    data_final1['RENEWAL_DATE_x'].fillna('NO RENEWAL DATE', inplace=True)
    data1 = pd.DataFrame(data_final1)
    temp={'data':data1.values.tolist()}
    return json.dumps(temp)




@app.route('/mexico')
def mexico():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,       password))
    db=client.compass
    collection1= db.subscription_master
    qr1=[{'$match':{'USER_ID.schoolId':{'$exists':True}}},
        {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}},{'USER_ID.schoolId.COUNTRY':{'$regex':'Mexico', '$options':'i'}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
                        {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
                        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id' , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}}
    },
         {'$project':{'_id':1, 'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}
                     }
    ]
    collection2= db.audio_track_master
    qrB= [{'$match':{'USER_ID.schoolId._id':{'$exists':True}}},
        {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}}, {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},
   {'USER_ID.schoolId.COUNTRY':{'$regex':'Mexico', '$options':'i'}},
                        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id','SCHOOL_PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
          {'$project':{'_id':1,'SCHOOL_PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date": "$practice_date" }}}}
    ]
    collection3= db.user_master
    qrC=[
        {'$match':{"schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'BLOCKED_BY_CAP':{'$ne':'Y'}},{'IS_ADMIN':{'$eq':'Y'}}, {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'schoolId._id':{'$not':{'$regex':'null'}}},
   {'schoolId.COUNTRY':{'$regex':'Mexico', '$options':'i'}},
                        {'schoolId._id':{'$not':{'$regex':''}}},
                        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$schoolId._id','USER_COUNT':{'$addToSet':'$_id'}, 'STATE':{'$first':'$schoolId.STATE'}
              }},
    {'$project':{'_id':1, 'USER_COUNT':{'$size':'$USER_COUNT'}, 'STATE':1}}
     ]
    list1= list(collection1.aggregate(qr1))
    df_sub= DataFrame(list1)
    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join1= pd.merge(df_sub, df_atma, how='left', on='_id')
    join_final1= pd.merge(join1, df_um, how='left', on='_id')
    collection11= db.user_master
    qr11=[
    {'$match':{"schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'BLOCKED_BY_CAP':{'$ne':'Y'}},{'IS_ADMIN':{'$eq':'Y'}}, {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'schoolId._id':{'$not':{'$regex':'null'}}},
                        {'schoolId.COUNTRY':{'$regex':'Mexico', '$options':'i'}},
                        {'schoolId._id':{'$not':{'$regex':''}}},{'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$schoolId._id','ADMIN_NAME':{'$first':'$USER_NAME'},'user_id':{'$first':'$_id'},
    'SCHOOL_NAME':{'$first':'$schoolId.NAME'}, 'ADMIN_EMAIL':{'$first':'$EMAIL_ID'}
    }}
        ]
    collection12=db.audio_track_master
    qr12=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}}, {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.schoolId.COUNTRY':{'$regex':'Mexico', '$options':'i'}},
    {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 'user_id':{'$first':'$USER_ID._id'}
    }}
        ]
    collection13= db.subscription_master
    qr13=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
{'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}}, {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.schoolId.COUNTRY':{'$regex':'Mexico', '$options':'i'}},
        {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id'
               , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}
              }},
        {'$project':{'_id':1,
                     'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}}
    ]
    list11= list(collection11.aggregate(qr11))
    df_um= DataFrame(list11)
    list12=list(collection12.aggregate(qr12))
    df_atm= DataFrame(list12)
    list13= list(collection13.aggregate(qr13))
    df_sbm= DataFrame(list13)
    join12= pd.merge(df_sbm, df_atm, how='left', on='_id')
    join_final12= pd.merge(join12,df_um, how='left', on='_id')
    inner_join_df= pd.merge(join_final1, join_final12,  on='_id', how='inner')
    
# inner_join_df
    data_final1= inner_join_df[['SCHOOL_NAME','ADMIN_NAME','ADMIN_EMAIL','RENEWAL_DATE_x','SCHOOL_PRACTICE_COUNT','LAST_PRACTICE_DATE','USER_COUNT','STATE']]
    data_final1['SCHOOL_NAME'].fillna('NO SCHOOL FOUND', inplace=True)
    data_final1['ADMIN_NAME'].fillna('NO USER INFO', inplace=True)
    data_final1['SCHOOL_PRACTICE_COUNT'].fillna('NO PRACTICE', inplace=True)
    data_final1['STATE'].fillna('NO INFO', inplace=True)
    data_final1['ADMIN_EMAIL'].fillna('NO INFO', inplace=True)
    data_final1['USER_COUNT'].fillna('NO USER', inplace=True)
    data_final1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    data_final1['RENEWAL_DATE_x'].fillna('NO RENEWAL DATE', inplace=True)
    data1 = pd.DataFrame(data_final1)
    temp={'data':data1.values.tolist()}
    return json.dumps(temp)



@app.route('/india')
def india():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,       password))
    db=client.compass
    collection1= db.subscription_master
    qr1=[{'$match':{'USER_ID.schoolId':{'$exists':True}}},
        {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}},{'USER_ID.schoolId.COUNTRY':{'$regex':'India', '$options':'i'}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
                        {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
                        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id' , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}}
    },
         {'$project':{'_id':1, 'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}
                     }
    ]
    collection2= db.audio_track_master
    qrB= [{'$match':{'USER_ID.schoolId._id':{'$exists':True}}},
        {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}}, {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},
   {'USER_ID.schoolId.COUNTRY':{'$regex':'India', '$options':'i'}},
                        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id','SCHOOL_PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
          {'$project':{'_id':1,'SCHOOL_PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date": "$practice_date" }}}}
    ]
    collection3= db.user_master
    qrC=[
        {'$match':{"schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'BLOCKED_BY_CAP':{'$ne':'Y'}},{'IS_ADMIN':{'$eq':'Y'}}, {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'schoolId._id':{'$not':{'$regex':'null'}}},
   {'schoolId.COUNTRY':{'$regex':'India', '$options':'i'}},
                        {'schoolId._id':{'$not':{'$regex':''}}},
                        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$schoolId._id','USER_COUNT':{'$addToSet':'$_id'}, 'STATE':{'$first':'$schoolId.STATE'}
              }},
    {'$project':{'_id':1, 'USER_COUNT':{'$size':'$USER_COUNT'}, 'STATE':1}}
     ]
    list1= list(collection1.aggregate(qr1))
    df_sub= DataFrame(list1)
    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join1= pd.merge(df_sub, df_atma, how='left', on='_id')
    join_final1= pd.merge(join1, df_um, how='left', on='_id')
    collection11= db.user_master
    qr11=[
    {'$match':{"schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'BLOCKED_BY_CAP':{'$ne':'Y'}},{'IS_ADMIN':{'$eq':'Y'}}, {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'schoolId._id':{'$not':{'$regex':'null'}}},
                        {'schoolId.COUNTRY':{'$regex':'India', '$options':'i'}},
                        {'schoolId._id':{'$not':{'$regex':''}}},{'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$schoolId._id','ADMIN_NAME':{'$first':'$USER_NAME'},'user_id':{'$first':'$_id'},
    'SCHOOL_NAME':{'$first':'$schoolId.NAME'}, 'ADMIN_EMAIL':{'$first':'$EMAIL_ID'}
    }}
        ]
    collection12=db.audio_track_master
    qr12=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}}, {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.schoolId.COUNTRY':{'$regex':'India', '$options':'i'}},
    {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 'user_id':{'$first':'$USER_ID._id'}
    }}
        ]
    collection13= db.subscription_master
    qr13=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
{'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}}, {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.schoolId.COUNTRY':{'$regex':'India', '$options':'i'}},
        {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id'
               , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}
              }},
        {'$project':{'_id':1,
                     'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}}
    ]
    list11= list(collection11.aggregate(qr11))
    df_um= DataFrame(list11)
    list12=list(collection12.aggregate(qr12))
    df_atm= DataFrame(list12)
    list13= list(collection13.aggregate(qr13))
    df_sbm= DataFrame(list13)
    join12= pd.merge(df_sbm, df_atm, how='left', on='_id')
    join_final12= pd.merge(join12,df_um, how='left', on='_id')
    inner_join_df= pd.merge(join_final1, join_final12,  on='_id', how='inner')
    
# inner_join_df
    data_final1= inner_join_df[['SCHOOL_NAME','ADMIN_NAME','ADMIN_EMAIL','RENEWAL_DATE_x','SCHOOL_PRACTICE_COUNT','LAST_PRACTICE_DATE','USER_COUNT','STATE']]
    data_final1['SCHOOL_NAME'].fillna('NO SCHOOL FOUND', inplace=True)
    data_final1['ADMIN_NAME'].fillna('NO USER INFO', inplace=True)
    data_final1['SCHOOL_PRACTICE_COUNT'].fillna('NO PRACTICE', inplace=True)
    data_final1['STATE'].fillna('NO INFO', inplace=True)
    data_final1['ADMIN_EMAIL'].fillna('NO INFO', inplace=True)
    data_final1['USER_COUNT'].fillna('NO USER', inplace=True)
    data_final1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    data_final1['RENEWAL_DATE_x'].fillna('NO RENEWAL DATE', inplace=True)
    data1 = pd.DataFrame(data_final1)
    temp={'data':data1.values.tolist()}
    return json.dumps(temp)



@app.route('/other')
def other():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,       password))
    db=client.compass
    collection1= db.subscription_master
    qr1=[{'$match':{'USER_ID.schoolId':{'$exists':True}}},
        {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}},{'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'india', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'canada', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'mexico', '$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'united states', '$options':'i'}}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
                        {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
                        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id' , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}}
    },
         {'$project':{'_id':1, 'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}
                     }
    ]
    collection2= db.audio_track_master
    qrB= [{'$match':{'USER_ID.schoolId._id':{'$exists':True}}},
        {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},
  {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'india', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'canada', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'mexico', '$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'united states', '$options':'i'}}},
                        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id','SCHOOL_PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
          {'$project':{'_id':1,'SCHOOL_PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date": "$practice_date" }}}}
    ]
    collection3= db.user_master
    qrC=[
        {'$match':{"schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'BLOCKED_BY_CAP':{'$ne':'Y'}},{'IS_ADMIN':{'$eq':'Y'}}, {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'schoolId._id':{'$not':{'$regex':'null'}}},
   {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'india', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'canada', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'mexico', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'united states', '$options':'i'}}},
                        {'schoolId._id':{'$not':{'$regex':''}}},
                        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$schoolId._id','USER_COUNT':{'$addToSet':'$_id'}, 'STATE':{'$first':'$schoolId.STATE'}
              }},
    {'$project':{'_id':1, 'USER_COUNT':{'$size':'$USER_COUNT'}, 'STATE':1}}
     ]
    list1= list(collection1.aggregate(qr1))
    df_sub= DataFrame(list1)
    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join1= pd.merge(df_sub, df_atma, how='left', on='_id')
    join_final1= pd.merge(join1, df_um, how='left', on='_id')
    collection11= db.user_master
    qr11=[
    {'$match':{"schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'BLOCKED_BY_CAP':{'$ne':'Y'}},{'IS_ADMIN':{'$eq':'Y'}}, {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'schoolId._id':{'$not':{'$regex':'null'}}},
                        {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'india', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'canada', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'mexico', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'united states', '$options':'i'}}},
                        {'schoolId._id':{'$not':{'$regex':''}}},{'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {'$group':{'_id':'$schoolId._id','ADMIN_NAME':{'$first':'$USER_NAME'},'user_id':{'$first':'$_id'},
    'SCHOOL_NAME':{'$first':'$schoolId.NAME'}, 'ADMIN_EMAIL':{'$first':'$EMAIL_ID'}
    }}
        ]
    collection12=db.audio_track_master
    qr12=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}}, {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'india', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'canada', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'mexico', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'united states', '$options':'i'}}},
    {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 'user_id':{'$first':'$USER_ID._id'}
    }}
        ]
    collection13= db.subscription_master
    qr13=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
{'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}}, {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'india', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'canada', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'mexico', '$options':'i'}}},
            {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'united states', '$options':'i'}}},
        {'USER_ID.schoolId._id':{'$not':{'$regex':''}}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}
]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}}
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id'
               , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}
              }},
        {'$project':{'_id':1,
                     'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}}
    ]
    list11= list(collection11.aggregate(qr11))
    df_um= DataFrame(list11)
    list12=list(collection12.aggregate(qr12))
    df_atm= DataFrame(list12)
    list13= list(collection13.aggregate(qr13))
    df_sbm= DataFrame(list13)
    join12= pd.merge(df_sbm, df_atm, how='left', on='_id')
    join_final12= pd.merge(join12,df_um, how='left', on='_id')
    inner_join_df= pd.merge(join_final1, join_final12,  on='_id', how='inner')
    
# inner_join_df
    data_final1= inner_join_df[['SCHOOL_NAME','ADMIN_NAME','ADMIN_EMAIL','RENEWAL_DATE_x','SCHOOL_PRACTICE_COUNT','LAST_PRACTICE_DATE','USER_COUNT','STATE']]
    data_final1['SCHOOL_NAME'].fillna('NO SCHOOL FOUND', inplace=True)
    data_final1['ADMIN_NAME'].fillna('NO USER INFO', inplace=True)
    data_final1['SCHOOL_PRACTICE_COUNT'].fillna('NO PRACTICE', inplace=True)
    data_final1['STATE'].fillna('NO INFO', inplace=True)
    data_final1['ADMIN_EMAIL'].fillna('NO INFO', inplace=True)
    data_final1['USER_COUNT'].fillna('NO USER', inplace=True)
    data_final1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    data_final1['RENEWAL_DATE_x'].fillna('NO RENEWAL DATE', inplace=True)
    data1 = pd.DataFrame(data_final1)
    temp={'data':data1.values.tolist()}
    return json.dumps(temp)




@app.route('/journey/<emailid>')


def school_journey(emailid):
    graph={}
    from datetime import datetime
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = MongoClient(mongo_uri)
#     from datetime import datetime
    today1= datetime.utcnow().replace(day=27) + timedelta(days=3)
    print(today1)
    tod1= today1+ timedelta(hours=4)
    print(tod1)
    start= tod1-timedelta(days=180)
    start1=start.replace(day=1)
    
    database = client["compass"]
    collection = database["user_master"]
    query = {}
    query["$and"] = [{
            u"EMAIL_ID": emailid
        },{u"USER_NAME": {
                u"$not": Regex(u".*TEST.*", "i")
            }},{
            u"EMAIL_ID": {
                u"$not": Regex(u".*TEST.*", "i")
            }}]
    projection = {}
    projection["schoolId.NAME"] = 1.0
    projection["_id"] = 1.0
    projection["schoolId._id"] = 1.0
    projection["schoolId.COUNTRY"] = 1.0
    projection["schoolId.CITY"] = 1.0
    projection["schoolId.STATE"] = 1.0
    cursor = collection.find(query, projection = projection)
    school_info=pd.DataFrame(list(cursor))
    school_name=school_info.schoolId[0]['NAME']
    school_id=school_info.schoolId[0]['_id']
    school_country=school_info.schoolId[0]['COUNTRY']
    school_city=school_info.schoolId[0]['CITY']
    school_state=school_info.schoolId[0]['STATE']
    school_id=school_info.schoolId[0]['_id']
    query = {}
    query["schoolId._id"] = school_id
    query["USER_NAME"] = {
        u"$not": Regex(u".*TEST.*", "i")
    }

    query["EMAIL_ID"] = {
        u"$not": Regex(u".*TEST.*", "i")
    }
    query["EMAIL_ID"] = {
        u"$not": Regex(u".*1gen.*", "i")
    }

    query["IS_DISABLED"] = {
        u"$ne": u"Y"
    }

    query["IS_BLOCKED"] = {
        u"$ne": u"Y"
    }

    query["INCOMPLETE_SIGNUP"] = {
        u"$ne": u"Y"
    }
    
    query["ROLE_ID.ROLE_NAME"] = {
        u"$not": Regex(u".*PRESENT.*", "i")
    }

#     query["DEVICE_USED"] = Regex(u".*webapp.*", "i")

    projection = {}
    projection["EMAIL_ID"] = 1.0

    cursor = collection.find(query, projection = projection)
    email_info=pd.DataFrame(list(cursor))
    email=list(email_info['_id'])
    total_user=len(email)
    collection = database["subscription_master"]
    query = {}
    query["USER_ID.EMAIL_ID"] =emailid
    projection = {}
    projection["SUBSCRIPTION_EXPIRE_DATE"] = 1.0
    cursor = collection.find(query, projection = projection)
    expiry=pd.DataFrame(list(cursor))
    total_practice=0
    total_mindfulnesminutes=0
    dfatd = pd.DataFrame()
    try:
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
        client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
        
        db=client.compass
        collection = db.audio_track_master.aggregate(
        [{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID._id':{"$in":email}},
                         
             {'MODIFIED_DATE':{'$gte':csy_first_date()}} ,     
              ]}},   
         
        {'$project':{"cursorStart" : 1.0, 
            "CURSOR_END" : 1.0,'EMAIL_ID':'$USER_ID.EMAIL_ID',"MODIFIED_DATE" : 1.0,}},

        ])
        dfatd=pd.DataFrame(list(collection))
        total_practice=len(dfatd)
        dfatd['mm']=round((dfatd['CURSOR_END']-dfatd['cursorStart'])/60)
        dfatd=dfatd.fillna(0)
        total_mindfulnesminutes=sum(list(dfatd['mm']))
        dfatd['year'] = pd.DatetimeIndex(dfatd['MODIFIED_DATE']).year
        dfatd['month'] = pd.DatetimeIndex(dfatd['MODIFIED_DATE']).month
#         print(dfatd,"dfatd")
        dfatdchart1=dfatd[dfatd['year']>2019]
#         dfatdchart=dfatdchart1[dfatdchart1['month']>7]
        dfatdchart=dfatdchart1
#         print(dfatdchart)
        dfatdchart.drop('_id',axis='columns', inplace=True)
        dfatdchart.drop('MODIFIED_DATE',axis='columns', inplace=True)
        dfatdchart.drop('mm',axis='columns', inplace=True)
        dfatdchart.drop('CURSOR_END',axis='columns', inplace=True)
        dfatdchart.drop('cursorStart',axis='columns', inplace=True)
        dfatdchartprac=dfatdchart
        dfuniqueprac= dfatdchartprac.groupby('month')['EMAIL_ID'].nunique()
        dfprac=dfatdchartprac.groupby('month')['EMAIL_ID'].count()
#         print(dfprac,"prac")
        dfuniqueprac11=pd.DataFrame(dfuniqueprac)
        dfprac1=pd.DataFrame(dfprac)
        dfuniqueprac11.reset_index(level=0, inplace=True)
        dfprac1.reset_index(level=0, inplace=True)
        import calendar
        dfuniqueprac11['month'] = dfuniqueprac11['month'].apply(lambda x: calendar.month_abbr[x])
        dfprac1['month'] = dfprac1['month'].apply(lambda x: calendar.month_abbr[x])
        month1=dfuniqueprac11['month'].tolist()
        unique1=dfuniqueprac11['EMAIL_ID'].tolist()
        prac=dfprac1['EMAIL_ID'].tolist()
    except:
        total_practice=0
        total_mindfulnesminutes=0
        dfatd = pd.DataFrame()
    
        month1=""
        unique1=""
        prac=""
        tooo=""
        import calendar
        import datetime

        MONTHS_NUM = 6
        today_month = datetime.datetime.now().month
        first_month = max(today_month - MONTHS_NUM, 0)
        month1 = calendar.month_abbr[1:][first_month:today_month][::1]

#         month1=["Dec","Jan","Feb","Mar","Apr","May"]
        unique1=[0,0,0,0,0,0,0,0,0,0]
        prac=[0,0,0,0,0,0,0,0,0,0]
        
    data4 = [['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7],['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12]] 
    df9 = pd.DataFrame(data4, columns = ['Monthname', 'Month'])   
    month12=df9['Monthname'].tolist()
#     month12=["Dec","Jan","Feb","Mar","Apr","May"]
    for i in month12:
        if i not in month1:
            month1.append(i)
            unique1.append(0)
            prac.append(0)
    hell=dict(zip(month1,unique1))
#     print(hell)
    hell2=dict(zip(month1,prac))
    
    
     
    import calendar
    import datetime

    MONTHS_NUM = 6
    today_month = datetime.datetime.now().month
    first_month = max(today_month - MONTHS_NUM, 0)
    month1 = calendar.month_abbr[1:][first_month:today_month][::1]
    prac=[]
    unique1=[]
    for i in month1:
        
        unique_=hell[i]
        prac_=hell2[i]
        prac.append(prac_)
        unique1.append(unique_)
       
        
#     month1=["Dec","Jan","Feb","Mar","Apr","May"]
#     unique1=[hell["Dec"],hell["Jan"],hell["Feb"],hell["Mar"],hell["Apr"],hell["May"]]
#     prac=[hell2["Dec"],hell2["Jan"],hell2["Feb"],hell2["Mar"],hell2["Apr"],hell2["May"]]
    
    star_rating_cout=""
    try:
        collection = database["audio_feedback"]
        query = {}
        query["USER._id"] = {
            u"$in":email
        }
        query["RATING"] = 5
        cursor = collection.find(query)
        star_rating=pd.DataFrame(list(cursor))
        star_rating_cout=len(star_rating)
    except:
        star_rating_cout=0
    graph={'Star_5_Ratings_Recieved':[str(star_rating_cout)],'mindfulness_minutes':[str(total_mindfulnesminutes)],"schoolid":[str(school_id)],'school_name':[school_name],'state':[school_state],'city':[school_city],'country':[school_country],'user_count':[total_user],'school_practice_count':[total_practice],'month':month1,'unique_user':unique1,'practice_count':prac,'renewal_date':[expiry['SUBSCRIPTION_EXPIRE_DATE'][0].strftime("%d %b %Y ")]}
    data=[graph]
#     print(hell['Sep'])
    return json.dumps(data)




@app.route('/mapinfo')
def state_Info():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collectionMap=db.user_master
    querymap=[{'$match':{"schoolId":{'$exists':True}}},       
    {"$match": {"$and":[{"schoolId._id":{"$nin":db.school_master.distinct( "_id", { "CATEGORY": "LAUSD" } )}},
        {'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},


        {'$group':{'_id':'$schoolId.STATE', 'Count':{'$addToSet':'$schoolId._id'}, 
        'STATE_SHORT':{'$first':'$schoolId.STATE_SHORT'}
        }},
        {'$project':{'_id':1, 'Count':{'$size':'$Count'}, 'STATE_SHORT':1}}
        ]
    map_list= list(collectionMap.aggregate(querymap))
    df_map= DataFrame(map_list)
    df_map=df_map.groupby('STATE_SHORT').sum().reset_index()
    df_map['STATE_SHORT'].str.lower()
    df_map.loc[df_map.STATE_SHORT.isin(["ca"]), 'Count'] += 1299
    #     df_map.to_csv("")
    data=[]
    for i, j in zip(df_map['STATE_SHORT'], df_map['Count']):
        try:
            data.append({"code":i.lower(), "value":j,'hc-key':'us-'+i.lower()})
        except:
            pass
    return json.dumps(data)



@app.route('/map/<states>')
def shool_dash_map_table(states):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.subscription_master
    qr1=[{'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'USER_ID.schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{'_id':'$USER_ID.schoolId._id' , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}}
    },
         {'$project':{'_id':1, 'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}
                     }
    ]
    collection2= db.audio_track_master
    qrB= [
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'USER_ID.schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{'_id':'$USER_ID.schoolId._id','SCHOOL_PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
          {'$project':{'_id':1,'SCHOOL_PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date": "$practice_date" }}}}
    ]
    
    collection3= db.user_master
    qrC=[
        {'$match':{"schoolId":{'$exists':True}}},
    {'$match':{"schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},{'IS_ADMIN':{'$eq':'Y'}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{'_id':'$schoolId._id','STATE':{'$first':'$schoolId.STATE'}
              }},
    {'$project':{'_id':1, 'STATE':1}}
     ]
    
    collection30= db.user_master
    qrC0=[
        {'$match':{"schoolId":{'$exists':True}}},
    {'$match':{"schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{'_id':'$schoolId._id','USER_COUNT':{'$addToSet':'$_id'}
              }},
    {'$project':{'_id':1, 'USER_COUNT':{'$size':'$USER_COUNT'}}}
     ]
    
    
    
    list1= list(collection1.aggregate(qr1))
    df_sub= DataFrame(list1)
    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    list30= list(collection30.aggregate(qrC0))
    df_um30= DataFrame(list30)
    
    join1= pd.merge(df_sub, df_atma, how='left', on='_id')
    join2= pd.merge(df_um, df_um30, how='left', on='_id')
    join_final1= pd.merge(join1, join2, how='left', on='_id')
    
    
    collection11= db.user_master
    qr11=[
    {'$match':{"schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},{'IS_ADMIN':{'$eq':'Y'}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},

    {'$group':{'_id':'$schoolId._id','ADMIN_NAME':{'$first':'$USER_NAME'},'user_id':{'$first':'$_id'},
    'SCHOOL_NAME':{'$first':'$schoolId.NAME'}, 'ADMIN_EMAIL':{'$first':'$EMAIL_ID'}
    }}
        ]
    
    
    collection12=db.audio_track_master
    qr12=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'USER_ID.schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
        
    {'$group':{'_id':'$USER_ID.schoolId._id', 'user_id':{'$first':'$USER_ID._id'}
    }}
        ]
    collection13= db.subscription_master
    qr13=[
        {'$match':{"USER_ID.schoolId":{'$exists':True}}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}, {'USER_ID.schoolId.STATE':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.CITY':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId.COUNTRY':{'$regex':'United States', '$options':'i'}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
    {'$group':{'_id':'$USER_ID.schoolId._id'
               , 'SUBSCRIPTION_EXPIRE_DATE':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}
              }},
        {'$project':{'_id':1,
                     'RENEWAL_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date":"$SUBSCRIPTION_EXPIRE_DATE"}}}}
    ]
    list11= list(collection11.aggregate(qr11))
    df_um= DataFrame(list11)
    list12=list(collection12.aggregate(qr12))
    df_atm= DataFrame(list12)
    list13= list(collection13.aggregate(qr13))
    df_sbm= DataFrame(list13)
    join12= pd.merge(df_sbm, df_atm, how='left', on='_id')
    join_final12= pd.merge(join12,df_um, how='left', on='_id')
    inner_join_df= pd.merge(join_final1, join_final12,  on='_id', how='inner')
    inner_join_df['SCHOOL_NAME'].fillna('NO SCHOOL FOUND', inplace=True)
    inner_join_df['ADMIN_NAME'].fillna('NO USER INFO', inplace=True)
    inner_join_df['SCHOOL_PRACTICE_COUNT'].fillna('NO PRACTICE', inplace=True)
    inner_join_df['STATE'].fillna('NO INFO', inplace=True)
    inner_join_df['ADMIN_EMAIL'].fillna('NO INFO', inplace=True)
    inner_join_df['USER_COUNT'].fillna('NO USER', inplace=True)
    inner_join_df['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
#     inner_join_df['RENEWAL_DATE'].fillna('NO SUBSCRIPTION', inplace=True)
# inner_join_df
    data_final1= inner_join_df[['SCHOOL_NAME','ADMIN_NAME','ADMIN_EMAIL','RENEWAL_DATE_x','SCHOOL_PRACTICE_COUNT','LAST_PRACTICE_DATE','USER_COUNT','STATE']]
    final_group=data_final1.groupby(data_final1['STATE'])
    data=final_group.get_group(""+states+"")
    data1 = pd.DataFrame(data)
    temp={'data':data1.values.tolist()}
    return json.dumps(temp)








@app.route('/billmelater/<daate>')

def billme_table(daate):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username,       password))
    db=client.compass

    collection1= db.subscription_master
    qr1=[
    {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}}, {'LAST_PAYMENT_AMOUNT':1000}, 
            {'MODE_OF_PAYMENT':{'$regex':'later', '$options':'i'}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
         {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'null', '$options':'i'}}},
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},

        ]}},

        {'$group':{'_id':'$USER_ID.schoolId._id'}}
        ]


    collection2= db.audio_track_master
    qrB= [{"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
       {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}},
        ]}},
        {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},

        ]}},
        {'$group':{'_id':'$USER_ID.schoolId._id','practice_count':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
        }}
    #     {'$project':{'_id':1, 'Practice_count':{'$size':'$count'}, 'practice_date':1
    #     }}
        ]


    collection3= db.user_master
    qrC=[{'$match':{"schoolId":{'$exists':True}}},

    {"$match":
        {"$and":[
        {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
                            {'schoolId._id':{'$not':{'$regex':'null'}}},{'EMAIL_ID':{'$not':{'$regex':'null', '$options':'i'}}},
            {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, {'EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},

        ]}},

        {'$group':{'_id':'$schoolId._id','count':{'$addToSet':'$_id'}, 'state':{'$first':'$schoolId.STATE'}}},
        {'$project':{'_id':1, 'count':{'$size':'$count'}, 'state':1}}

         ]


    list1= list(collection1.aggregate(qr1))
    df_sub= DataFrame(list1)
    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join1= pd.merge(df_sub, df_atma, how='left', on='_id')
    join_final1= pd.merge(join1, df_um, how='left', on='_id')
    join_final1
    # final= join_final1.groupby('_id')
    # final.first()
    # df_sub





    collection11= db.user_master
    qr11=[
        {"$match":
        {"$and":[
        {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},{'IS_ADMIN':{'$eq':'Y'}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
         {'schoolId._id':{'$not':{'$regex':'null'}}},{'EMAIL_ID':{'$not':{'$regex':'null', '$options':'i'}}},
            {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
            {'EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}}

        ]}},
        {'$group':{'_id':'$schoolId._id','user_id':{'$first':'$_id'}, 'user_name':{'$first':'$USER_NAME'}, 
                   'email_id':{'$first':'$EMAIL_ID'}, 'school_name':{'$first':'$schoolId.NAME'}}}
    ]



    collection12=db.audio_track_master
    qr12=[{"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}}, {'USER_ID.IS_ADMIN':{'$eq':'Y'}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
         {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'null', '$options':'i'}}},
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},

        ]}},

        {'$group':{'_id':'$USER_ID.schoolId._id', 'user_id':{'$first':'$USER_ID._id'}

        }}         
            ]


    collection13= db.subscription_master
    qr13=[
    {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}}, {'LAST_PAYMENT_AMOUNT':1000}, 
            {'USER_ID.IS_ADMIN':{'$eq':'Y'}},
            {'MODE_OF_PAYMENT':{'$regex':'later', '$options':'i'}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
         {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'null', '$options':'i'}}},
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},

        ]}},
        {'$group':{'_id':'$USER_ID.schoolId._id', 'SUBSCRIPTION_EXPIRE_DATE':{'$first':'$SUBSCRIPTION_EXPIRE_DATE'}}}
    ]


    list11= list(collection11.aggregate(qr11))
    df_um= DataFrame(list11)

    list12=list(collection12.aggregate(qr12))
    df_atm= DataFrame(list12)

    list13= list(collection13.aggregate(qr13))
    df_sbm= DataFrame(list13)

    join12= pd.merge(df_sbm, df_atm, how='left', on='_id')
    join_final12= pd.merge(join12,df_um, how='left', on='_id')
    # join_final12


    inner_join_df= pd.merge(join_final1, join_final12,  on='_id', how='inner')
    # finalllll= inner_join_df.groupby('_id')
    inner_join_df

    # data_final=inner_join_df[['_id','practice_count','practice_date','state','count','SUBSCRIPTION_EXPIRE_DATE',
    #                         'user_id_y', 'user_name', 'email_id','school_name']]
    data_final=inner_join_df[['school_name','user_name','email_id','state','practice_count','practice_date','count','SUBSCRIPTION_EXPIRE_DATE'
                             ]]

    data_final=data_final['practice_count'].fillna("NO PRACTICE")
    data_final['school_name'].fillna('NO SCHOOL INFO', inplace=True)
    data_final['user_name'].fillna('NO USER INFO', inplace=True)
    data_final['practice_count'].fillna('NO PRACTICE', inplace=True)
    data_final['SUBSCRIPTION_EXPIRE_DATE'].fillna(" ", inplace=True)
    data_final['practice_date'].fillna('NO PRACTICE', inplace=True)
    data_final['state'].fillna('NO INFO', inplace=True)
    data_final['email_id'].fillna('NO INFO', inplace=True)



    # data_final

    SCHOOL_NAME=data_final['school_name'].tolist()
    USER_NAME=data_final['user_name'].tolist()
    USER_EMAIL=data_final['email_id'].tolist()
    STATE=data_final['state'].tolist()
    PRACTICE_COUNT=data_final['practice_count'].tolist()

    COUNT=data_final['count'].tolist()
    SUBSCRIPTION_EXPIRE_DATE=data_final['SUBSCRIPTION_EXPIRE_DATE'].tolist()

    Renewal_Date=[]
    prac_date=[]

    for i in range(len(SUBSCRIPTION_EXPIRE_DATE)):
            Renewal_Date.append(SUBSCRIPTION_EXPIRE_DATE[i].strftime("%d %b %Y "))        
    for i in range(len(practice_date)):
        try:
            prac_date.append(practice_date[i].strftime("%d %b %Y "))
        except:
            prac_date.append('NO PRACTICE')
    # for j in data_final['practice_date']:
    # practice_date.append(j.strftime("%d %b %Y "))
    data={'SCHOOL_NAME':SCHOOL_NAME,'USER_NAME':USER_NAME,'USER_EMAIL':USER_EMAIL,'STATE':STATE,'PRACTICE_COUNT':PRACTICE_COUNT,'COUNT':COUNT,
          'SUBSCRIPTION_EXPIRE_DATE':Renewal_Date,'LAST_PRACTICE_DATE':prac_date} 
#     print(data)
    return json.dumps(data)



@app.route('/renewal20/<month>/')
def renewal20(month):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    # query=[
    #     {"$match":{
    #          '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    #                    {'USER_ID._id.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    #                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #           {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    #           {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #           {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    #           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}]}},
    #           {'$project':{'_id':0,
    #               'School_Object_Id':
    #               '$USER_ID.schoolId._id','USER_ObjectId':'$USER_ID._id',
    #               'Practice_Date':'$MODIFIED_DATE'
    #               }}]
    query=[
        {"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId._id':{'$ne':None}}
                  ]}},
              {'$project':{'_id':0,
                  'School_Object_Id':
                  '$USER_ID.schoolId._id','USER_ObjectId':'$USER_ID._id',
                  'Practice_Date':'$MODIFIED_DATE'}},
                  {'$group':{'_id':'$School_Object_Id','Overall':{'$sum':1},'lpractice':{'$max':"$Practice_Date"}
                      }},
                  {'$sort':{'Overall':-1}}]
    collection2=db.subscription_master
    query2=[
    {"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}}
              ]}},
    {'$group':{"_id":'$USER_ID.schoolId._id',
        'auc':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}}},
        {'$match':{"auc":{"$gte":datetime.datetime(2020,7,1),
                                         "$lt":datetime.datetime(2020,12,31)}}},
        {'$project':{'_id':0,'School_Object_Id':'$_id','Renewal_Date':'$auc'}}
        ]
    sub_master_list=list(collection2.aggregate(query2))
    df_sub_master=pd.DataFrame(sub_master_list)
    atm=list(collection.aggregate(query))
    atm_df=pd.DataFrame(atm)
    df=pd.merge(df_sub_master, atm_df, how='left', left_on=['School_Object_Id'], right_on=['_id']).fillna(0)
    df1=df[["School_Object_Id","Renewal_Date","Overall","lpractice"]]
    school_list=df1["School_Object_Id"].tolist()
    collection3=db.user_master
    query3=[{"$match":{"schoolId._id":{"$in":school_list}}},
    {"$match":{"IS_ADMIN":"Y"}},
    {"$group":{"_id":{"ID":"$schoolId._id"},
            "ID":{"$addToSet":"$schoolId._id"},
            "USER_COUNT":{"$sum":1},

            "USER_NAME": { "$first": "$USER_NAME" },
            "EMAIL": { "$first": "$EMAIL_ID" },
            "ADMIN": { "$first": "$IS_ADMIN" },
                "SCHOOL_NAME": { "$first": "$schoolId.NAME" }
            }},
        #   //{"$match":{"ADMIN":"Y"}},
            {"$project":{"School_Object_Id":"$_id.ID","_id":0,"USER_NAME":1,"EMAIL":1,"SCHOOL_NAME":1}}

    #//{"$match":{"count":{"gt":1}}}
    #//,{"$count":"count"}
    ]
    collection4=db.user_master
    query4=[{"$match":{"schoolId._id":{"$in":school_list}}},
    #//{"$match":{"IS_ADMIN":"Y"}},
    {"$group":{"_id":{"ID":"$schoolId._id"},
            "ID":{"$addToSet":"$schoolId._id"},
            "USER_COUNT":{"$sum":1}

        
            }},
        
    {"$project":{"School_Object_Id":"$_id.ID","USER_COUNT":1}},

    #{"$match":{"USER_COUNT":{"$gt":1}}}
    #//,{"$count":"count"}
            ]

    user_master_detail1=pd.DataFrame(list(collection4.aggregate(query4)))


    user_master_detail=pd.DataFrame(list(collection3.aggregate(query3)))
    final0=pd.merge(user_master_detail, df1, how='left', left_on=['School_Object_Id'], right_on=['School_Object_Id']).fillna(0)
    final1=pd.merge(final0, user_master_detail1, how='left', left_on=['School_Object_Id'], right_on=['School_Object_Id']).fillna(0)
    final1["lpractice"]=final1["lpractice"].replace(0,"NO PRACTICE")
    final_date=final1[["SCHOOL_NAME","USER_NAME","EMAIL","Renewal_Date","lpractice","Overall","USER_COUNT"]]
    final_date1=final_date[["SCHOOL_NAME","USER_NAME","EMAIL","Renewal_Date","lpractice","Overall","USER_COUNT"]]
    final_group=final_date1.groupby(final_date1['Renewal_Date'].dt.strftime('%b'))
    data=final_group.get_group(""+month+"")
    data1=pd.DataFrame(data)
    temp ={"data":data1.values.tolist()}
    return json.dumps(temp)

# @app.route('/renewal20/<month>/Active20')
# def renewalact2020(month):
#     db = mysql.connector.connect(host="54.184.165.106",    # your host, usually localhost
#                      user="IE-tech",         # your username
#                      passwd="IE-tech@2O2O",  # your password
#                      db="compassJul")  
#     renewal="""select school_name,admin_name,admin_email,renewal_date,USER_COUNT,school_practice_count,last_login_date,last_practice_date from(
#     (select sm.ID, sm.NAME as school_name,um.USER_NAME AS admin_name,um.EMAIL_ID AS admin_email  ,sub.SUBSCRIPTION_EXPIRE_DATE as renewal_date from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and um.IS_BLOCKED !='Y'   and admin_col ='ADMIN' and year(sub.SUBSCRIPTION_EXPIRE_DATE)=2020 and monthname(sub.SUBSCRIPTION_EXPIRE_DATE) like '%"""+month+"""%'
#      GROUP BY sm.ID) q1
#      inner join 
#      (select sm.ID, count(distinct(up.USER_ID)) AS USER_COUNT, count(atd.USER_ID) as school_practice_count, max(ll.LAST_LOGGED_IN) as last_login_date,max(atd.MODIFIED_DATE) as last_practice_date  from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     inner join audio_track_detail atd on atd.USER_ID=up.USER_ID
#     left join login_logs ll on ll.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and sm.ID in (select sm.ID  from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     inner join audio_track_detail atd on atd.USER_ID=up.USER_ID
#     left join login_logs ll on ll.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and year(atd.MODIFIED_DATE)>2019 and um.IS_BLOCKED !='Y'   and year(sub.SUBSCRIPTION_EXPIRE_DATE)=2020 and monthname(sub.SUBSCRIPTION_EXPIRE_DATE) like '%"""+month+"""%'
#      GROUP BY sm.ID)  and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and um.IS_BLOCKED !='Y'   and year(sub.SUBSCRIPTION_EXPIRE_DATE)=2020 and monthname(sub.SUBSCRIPTION_EXPIRE_DATE) like '%"""+month+"""%'
#      GROUP BY sm.ID) q2
#      ON  q1.ID =q2.ID)"""
#     renewal=pd.read_sql(renewal,con=db)
#     renewal['last_practice_date'].fillna("NO PRACTICE", inplace=True)
#     renewal['renewal_date'].fillna(" ", inplace=True)
#     renewal['last_login_date'].fillna("NO LOGIN", inplace=True)
#     LAST_PRACTICE_DATE=[]
#     for i in renewal['last_practice_date']:
#         if  i != 'NO PRACTICE' :
#             LAST_PRACTICE_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             LAST_PRACTICE_DATE.append("NO PRACTICE")
#     LAST_LOGIN_DATE=[]
#     for i in renewal['last_login_date']:
#         if  i != 'NO LOGIN' :
#             LAST_LOGIN_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             LAST_LOGIN_DATE.append("NO LOGIN")
#     RENEWAL_DATE =[]
#     for i in renewal['renewal_date']:
#         if  i != ' ' :
#             RENEWAL_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             RENEWAL_DATE.append("NO PRACTICE")
#     data=[]
#     for i,k,l,m,o,p,q,r in zip(renewal['school_name'].tolist(),renewal['admin_name'].tolist(),renewal['admin_email'].tolist(),RENEWAL_DATE,LAST_PRACTICE_DATE,LAST_LOGIN_DATE,renewal['school_practice_count'].tolist(),renewal['USER_COUNT'].tolist()) :
#         data.append([i,k,l,m,o,p,q,r])
#     temp ={"data":data}
#     return json.dumps(temp)


# =============================
@app.route('/renewal20/<month>/Active')
def renewalact20(month):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    # query=[
    #     {"$match":{
    #          '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    #                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    #                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #           {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    #           {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #           {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    #           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}]}},
    #           {'$project':{'_id':0,
    #               'School_Object_Id':
    #               '$USER_ID.schoolId._id','USER_ObjectId':'$USER_ID._id',
    #               'Practice_Date':'$MODIFIED_DATE'
    #               }}]
    query=[
        {"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {'USER_ID.schoolId._id':{'$ne':None}}
                ]}},
            {'$project':{'_id':0,
                'School_Object_Id':
                '$USER_ID.schoolId._id','USER_ObjectId':'$USER_ID._id',
                'Practice_Date':'$MODIFIED_DATE'}},
                {'$group':{'_id':'$School_Object_Id','Overall':{'$sum':1},'lpractice':{'$max':"$Practice_Date"}
                    }},
                {'$sort':{'Overall':-1}}]
    collection2=db.subscription_master
    query2=[
    {"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}}
            ]}},
    {'$group':{"_id":'$USER_ID.schoolId._id',
        'auc':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'}}},
        {'$match':{"auc":{"$gte":datetime.datetime(2020,7,1),
                                        "$lt":datetime.datetime(2020,12,31)}}},
        {'$project':{'_id':0,'School_Object_Id':'$_id','Renewal_Date':'$auc'}}
        ]
    sub_master_list=list(collection2.aggregate(query2))
    df_sub_master=pd.DataFrame(sub_master_list)
    atm=list(collection.aggregate(query))
    atm_df=pd.DataFrame(atm)
    df=pd.merge(df_sub_master, atm_df, how='left', left_on=['School_Object_Id'], right_on=['_id']).fillna(0)
    df1=df[["School_Object_Id","Renewal_Date","Overall","lpractice"]]
    school_list=df1["School_Object_Id"].tolist()
    collection3=db.user_master
    query3=[{"$match":{"schoolId._id":{"$in":school_list}}},
    {"$match":{"IS_ADMIN":"Y"}},
    {"$group":{"_id":{"ID":"$schoolId._id"},
            "ID":{"$addToSet":"$schoolId._id"},
            "USER_COUNT":{"$sum":1},

            "USER_NAME": { "$first": "$USER_NAME" },
            "EMAIL": { "$first": "$EMAIL_ID" },
            "ADMIN": { "$first": "$IS_ADMIN" },
                "SCHOOL_NAME": { "$first": "$schoolId.NAME" }
            }},
        #   //{"$match":{"ADMIN":"Y"}},
            {"$project":{"School_Object_Id":"$_id.ID","_id":0,"USER_NAME":1,"EMAIL":1,"SCHOOL_NAME":1}}

    #//{"$match":{"count":{"gt":1}}}
    #//,{"$count":"count"}
    ]
    collection4=db.user_master
    query4=[{"$match":{"schoolId._id":{"$in":school_list}}},
    #//{"$match":{"IS_ADMIN":"Y"}},
    {"$group":{"_id":{"ID":"$schoolId._id"},
            "ID":{"$addToSet":"$schoolId._id"},
            "USER_COUNT":{"$sum":1}

        
            }},
        
    {"$project":{"School_Object_Id":"$_id.ID","USER_COUNT":1}},

    #{"$match":{"USER_COUNT":{"$gt":1}}}
    #//,{"$count":"count"}
            ]

    user_master_detail1=pd.DataFrame(list(collection4.aggregate(query4)))


    user_master_detail=pd.DataFrame(list(collection3.aggregate(query3)))
    final0=pd.merge(user_master_detail, df1, how='left', left_on=['School_Object_Id'], right_on=['School_Object_Id']).fillna(0)
    final1=pd.merge(final0, user_master_detail1, how='left', left_on=['School_Object_Id'], right_on=['School_Object_Id']).fillna(0)
    final1["lpractice"]=final1["lpractice"].replace(0,"NO PRACTICE")
    final_date=final1[["SCHOOL_NAME","USER_NAME","EMAIL","Renewal_Date","lpractice","Overall","USER_COUNT"]]
    final_date = final_date.drop(final_date[final_date.lpractice == "NO PRACTICE"].index)
    final_date1=final_date[["SCHOOL_NAME","USER_NAME","EMAIL","Renewal_Date","lpractice","Overall","USER_COUNT"]]
    final_group=final_date1.groupby(final_date1['Renewal_Date'].dt.strftime('%b'))
    data=final_group.get_group(""+month+"")
    data1=pd.DataFrame(data)
    temp ={"data":data1.values.tolist()}
    return json.dumps(temp)


# @app.route('/renewal19/<month>/')
# def renewal19(month):
#     db = mysql.connector.connect(host="54.184.165.106",    # your host, usually localhost
#                      user="IE-tech",         # your username
#                      passwd="IE-tech@2O2O",  # your password
#                      db="compassJul") 
    
#     q1="""select sm.ID,year(sub.SUBSCRIPTION_EXPIRE_DATE) as year,monthname(sub.SUBSCRIPTION_EXPIRE_DATE) as month, sm.NAME as school_name,um.USER_NAME AS admin_name,um.EMAIL_ID AS admin_email  ,sub.SUBSCRIPTION_EXPIRE_DATE as renewal_date from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and um.IS_BLOCKED !='Y'   and admin_col ='ADMIN' and date(sub.SUBSCRIPTION_EXPIRE_DATE)>'2019-06-31' and date(sub.SUBSCRIPTION_EXPIRE_DATE) <'2020-04-01'
#      GROUP BY sm.ID"""
#     q1=pd.read_sql(q1,con=db)
#     q1['month'] = q1['month'].str.upper()
#     year=str(q1.loc[q1['month'].str.contains(month), 'year'].iloc[0])
#     renewal="""select school_name,admin_name,admin_email,renewal_date,USER_COUNT,school_practice_count,last_login_date,last_practice_date from
#     (select sm.ID, sm.NAME as school_name,um.USER_NAME AS admin_name,um.EMAIL_ID AS admin_email  ,sub.SUBSCRIPTION_EXPIRE_DATE as renewal_date from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and um.IS_BLOCKED !='Y'   and admin_col ='ADMIN' and year(sub.SUBSCRIPTION_EXPIRE_DATE)="""+year+""" and monthname(sub.SUBSCRIPTION_EXPIRE_DATE) like '%"""+month+"""%'
#      GROUP BY sm.ID) q1
#      inner join 
#      (select sm.ID, count(distinct(up.USER_ID)) AS USER_COUNT, count(atd.USER_ID) as school_practice_count, max(ll.LAST_LOGGED_IN) as last_login_date,max(atd.MODIFIED_DATE) as last_practice_date  from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     left join audio_track_detail atd on atd.USER_ID=up.USER_ID
#     left join login_logs ll on ll.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and um.IS_BLOCKED !='Y'   and year(sub.SUBSCRIPTION_EXPIRE_DATE)="""+year+""" and monthname(sub.SUBSCRIPTION_EXPIRE_DATE) like '%"""+month+"""%'
#      GROUP BY sm.ID) q2
#      ON  q1.ID =q2.ID"""
#     renewal=pd.read_sql(renewal,con=db)
#     renewal['last_practice_date'].fillna("NO PRACTICE", inplace=True)
#     renewal['renewal_date'].fillna(" ", inplace=True)
#     renewal['last_login_date'].fillna("NO LOGIN", inplace=True)
#     LAST_PRACTICE_DATE=[]
#     for i in renewal['last_practice_date']:
#         if  i != 'NO PRACTICE' :
#             LAST_PRACTICE_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             LAST_PRACTICE_DATE.append("NO PRACTICE")
#     LAST_LOGIN_DATE=[]
#     for i in renewal['last_login_date']:
#         if  i != 'NO LOGIN' :
#             LAST_LOGIN_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             LAST_LOGIN_DATE.append("NO LOGIN")
#     RENEWAL_DATE =[]
#     for i in renewal['renewal_date']:
#         if  i != ' ' :
#             RENEWAL_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             RENEWAL_DATE.append("NO PRACTICE")
#     data=[]
#     for i,k,l,m,o,p,q,r in zip(renewal['school_name'].tolist(),renewal['admin_name'].tolist(),renewal['admin_email'].tolist(),RENEWAL_DATE,LAST_PRACTICE_DATE,LAST_LOGIN_DATE,renewal['school_practice_count'].tolist(),renewal['USER_COUNT'].tolist()) :
#         data.append([i,k,l,m,o,p,q,r])
#     temp ={"data":data}
#     return json.dumps(temp)

# @app.route('/renewal19/<month>/Active')
# def renewalact19(month):
#     db = mysql.connector.connect(host="54.184.165.106",    # your host, usually localhost
#                      user="IE-tech",         # your username
#                      passwd="IE-tech@2O2O",  # your password
#                      db="compassJul")  
#     q1="""select sm.ID,year(sub.SUBSCRIPTION_EXPIRE_DATE) as year,monthname(sub.SUBSCRIPTION_EXPIRE_DATE) as month, sm.NAME as school_name,um.USER_NAME AS admin_name,um.EMAIL_ID AS admin_email  ,sub.SUBSCRIPTION_EXPIRE_DATE as renewal_date from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and um.IS_BLOCKED !='Y'   and admin_col ='ADMIN' and date(sub.SUBSCRIPTION_EXPIRE_DATE)>'2019-06-31' and date(sub.SUBSCRIPTION_EXPIRE_DATE) <'2020-04-01'
#      GROUP BY sm.ID"""
#     q1=pd.read_sql(q1,con=db)
#     q1['month'] = q1['month'].str.upper()
#     year=str(q1.loc[q1['month'].str.contains(month), 'year'].iloc[0])
#     renewal="""select school_name,admin_name,admin_email,renewal_date,USER_COUNT,school_practice_count,last_login_date,last_practice_date from
#     (select sm.ID, sm.NAME as school_name,um.USER_NAME AS admin_name,um.EMAIL_ID AS admin_email  ,sub.SUBSCRIPTION_EXPIRE_DATE as renewal_date from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and um.IS_BLOCKED !='Y'   and admin_col ='ADMIN' and year(sub.SUBSCRIPTION_EXPIRE_DATE)="""+year+""" and monthname(sub.SUBSCRIPTION_EXPIRE_DATE) like '%"""+month+"""%'
#      GROUP BY sm.ID) q1
#      inner join 
#      (select sm.ID, count(distinct(up.USER_ID)) AS USER_COUNT, count(atd.USER_ID) as school_practice_count, max(ll.LAST_LOGGED_IN) as last_login_date,max(atd.MODIFIED_DATE) as last_practice_date  from 
#     user_profile as up inner join user_master as um on um.USER_ID=up.USER_ID
#     inner join school_master as sm on sm.id=up.SCHOOL_ID 
#     INNER join subscription_master sub on sub.USER_ID=up.USER_ID
#     inner join audio_track_detail atd on atd.USER_ID=up.USER_ID
#     left join login_logs ll on ll.USER_ID=up.USER_ID
#     WHERE um.USER_NAME not like "%test%" and um.EMAIL_ID not like "%1gen%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.role_id !=3 and um.IS_BLOCKED !='Y'   and year(sub.SUBSCRIPTION_EXPIRE_DATE)="""+year+""" and monthname(sub.SUBSCRIPTION_EXPIRE_DATE) like '%"""+month+"""%'
#      GROUP BY sm.ID) q2
#      ON  q1.ID =q2.ID"""
#     renewal=pd.read_sql(renewal,con=db)
#     renewal['last_practice_date'].fillna("NO PRACTICE", inplace=True)
#     renewal['renewal_date'].fillna(" ", inplace=True)
#     renewal['last_login_date'].fillna("NO LOGIN", inplace=True)
#     LAST_PRACTICE_DATE=[]
#     for i in renewal['last_practice_date']:
#         if  i != 'NO PRACTICE' :
#             LAST_PRACTICE_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             LAST_PRACTICE_DATE.append("NO PRACTICE")
#     LAST_LOGIN_DATE=[]
#     for i in renewal['last_login_date']:
#         if  i != 'NO LOGIN' :
#             LAST_LOGIN_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             LAST_LOGIN_DATE.append("NO LOGIN")
#     RENEWAL_DATE =[]
#     for i in renewal['renewal_date']:
#         if  i != ' ' :
#             RENEWAL_DATE.append(i.strftime("%d %b %Y "))
#         else:
#             RENEWAL_DATE.append("NO PRACTICE")
#     data=[]
#     for i,k,l,m,o,p,q,r in zip(renewal['school_name'].tolist(),renewal['admin_name'].tolist(),renewal['admin_email'].tolist(),RENEWAL_DATE,LAST_PRACTICE_DATE,LAST_LOGIN_DATE,renewal['school_practice_count'].tolist(),renewal['USER_COUNT'].tolist()) :
#         data.append([i,k,l,m,o,p,q,r])
#     temp ={"data":data}
#     return json.dumps(temp)

@app.route('/school_search_name/')
def school_search():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    query=[
    {"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
              {'IS_ADMIN':'Y'},
    # //           {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
     {'$group':{
         '_id':'$schoolId._id',
         'NAME':{'$first':'$schoolId.NAME'},
         'CITY':{'$first':'$schoolId.CITY'},
         'STATE':{'$first':'$schoolId.STATE'},
         'COUNTRY':{'$first':'$schoolId.COUNTRY'}
         }}]
    schools=list(collection.aggregate(query))
    schools_info=pd.DataFrame(schools)
    dffinalnew=schools_info.copy()
    dffinalnew['CITY']=dffinalnew['CITY'].str.upper()
    dffinalnew['STATE']=dffinalnew['STATE'].str.upper()
    dffinalnew['concatenate']=dffinalnew['NAME'].map(str)+','+dffinalnew['CITY'].map(str)+','+dffinalnew['STATE'].map(str)
    dffinalnew['_id']=dffinalnew['_id'].astype('str')
    d=[]    
    for i in range(len(dffinalnew['_id'])):
        x={dffinalnew['concatenate'][i]:dffinalnew['_id'][i]}
        d.append(x)
    return json.dumps({'data':d})




@app.route('/schoolsearch/<name>')
def school_search_mongo1(name):
    name1=name.replace("%20"," ")
    print(name1,"hola")
    from bson.regex import Regex
    from pymongo import MongoClient
    from flask import Flask,json

    import urllib 
    import pandas as pd
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = MongoClient(mongo_uri)
    # client = MongoClient("mongodb://host:port/")
    database = client["compass"]
    collection = database["user_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com
    query = {}
#     query["schoolId.NAME"] = name1
    query["schoolId.NAME"] = Regex(u""+name1+"", "i")
    #     query["EMAIL_ID"] = Regex(u".*amorgan@methacton\\.org.*", "i")
    query["USER_NAME"] = {
        u"$not": Regex(u".*TEST.*", "i")
    }

    query["IS_BLOCKED"] = {
        u"$ne": u"Y"
    }

    query["IS_DISABLED"] = {
        u"$ne": u"Y"
    }

    query["INCOMPLETE_SIGNUP"] = {
        u"$ne": u"Y"
    }

    # query["DEVICE_USED"] = Regex(u".*webapp.*", "i")

    projection = {}
    projection["USER_ID.USER_ID"] = 1.0
    projection["EMAIL_ID"] = 1.0
    projection["CREATED_DATE"] = 1.0

    projection["USER_NAME"] = 1.0
    projection["IS_ADMIN"] = 1.0
    projection["schoolId.ADDRESS"] = 1.0
    projection["schoolId.CITY"] = 1.0
    projection["schoolId.STATE"] = 1.0
    projection["schoolId.COUNTRY"] = 1.0
    projection["schoolId.NAME"] = 1.0

    cursor = collection.find(query, projection = projection)
    dfum=(list(cursor))
    dfum=pd.json_normalize(dfum, max_level=1)
    schoolname=dfum["schoolId.NAME"][0]
    country=dfum["schoolId.COUNTRY"][0]
    city=dfum["schoolId.CITY"][0]
    state=dfum["schoolId.STATE"][0]
    address=dfum["schoolId.ADDRESS"][0]

    admin1=dfum[dfum['IS_ADMIN']=='Y']

    admin2=admin1['USER_NAME']
    admin3=list(admin2)
    admin=admin3[0]
    adminemail1=admin1['EMAIL_ID']
    admine=list(adminemail1)
    # adminemail=[dfum['EMAIL_ID'][dfum['IS_ADMIN']=='Y']][0]
    adminemail=admine[0]
#     print(adminemail)
    email=list(dfum['EMAIL_ID'])
#     print(email)
    totaluser=len(email)
    collection = database["audio_track_master"]

#     Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(MODIFIED_DATE)": {
                    u"$max": u"$MODIFIED_DATE"
                },
                u"COUNT(USER_ID\u1390_id)": {
                    u"$sum": 1
                }
            }
        }, 
        {
            u"$project": {
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"MAX(MODIFIED_DATE)": u"$MAX(MODIFIED_DATE)",
                u"COUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfatd=list(cursor)
    dfatd=pd.json_normalize(dfatd, max_level=1)
#     print(dfatd)
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {
            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfsbm=list(cursor)
    dfsbm=pd.json_normalize(dfsbm, max_level=1)
#     print(dfatd,"atd")
    
    try:
        dffinal=pd.merge(dfum,dfatd,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
    except:
        dfum['MAX(MODIFIED_DATE)']='NO PRACTICE'
        dfum['COUNT(USER_ID᎐_id)']=0
        dffinal=dfum
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
        
        
        
#     schoolname=dfum["schoolId.NAME"][0]
    country=dfum["schoolId.COUNTRY"][0]
    city=dfum["schoolId.CITY"][0]
    state=dfum["schoolId.STATE"][0]
    address=dfum["schoolId.ADDRESS"][0]
#     admin=[dfum['USER_NAME'][dfum['IS_ADMIN']=='Y']][0]
#     admin=admin[0]
#     adminemail=[dfum['EMAIL_ID'][dfum['IS_ADMIN']=='Y']][0]
#     adminemail=adminemail[0]
    email=list(dfum['EMAIL_ID'])
    totaluser=len(email)
    dffinalnew['MAX(MODIFIED_DATE)'].fillna("NO PRACTICE", inplace=True)
    dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)'].fillna(" ", inplace=True)
    dffinalnew['COUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
    pracsum=sum(list(dffinalnew['COUNT(USER_ID᎐_id)']))
    dffinalnew.fillna(value=pd.np.nan, inplace=True)

    MAX=[]
    for i in dffinalnew['MAX(MODIFIED_DATE)']:
        if  i != 'NO PRACTICE' :
            MAX.append(i.strftime("%d %b %Y "))
        else:
            MAX.append("NO PRACTICE")
    SUBSCRIPTION_EXPIRE_DATE=[]
    for i in dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)']:
        if  i != ' ' :
            SUBSCRIPTION_EXPIRE_DATE.append(i.strftime("%d %b %Y "))
        else:
            SUBSCRIPTION_EXPIRE_DATE.append(" ")        
    CREATED_DATE=[]
    for i in dffinalnew['CREATED_DATE']:
        if  i != ' ' :
            CREATED_DATE.append(i.strftime("%d %b %Y "))
        else: 
            CREATED_DATE.append(" ")
    data=[]

    for T,k,l,m,o,p in zip(dffinalnew['USER_NAME'].tolist(),dffinalnew['EMAIL_ID'].tolist(),CREATED_DATE,MAX,SUBSCRIPTION_EXPIRE_DATE,dffinalnew['COUNT(USER_ID᎐_id)'].tolist()):
        #print(p,q,r)
        data.append([T,k,l,m,o,p])
    temp={"data":data,"school_practice_count":str(pracsum),"school_name":name,"country":country,"state":state,"city":city,"address":address,"admin_name":admin,"admin_email":adminemail,"user_count":totaluser}
#     ,"school_practice_count":str(card_detail['school_practice_count1'][0])
#     temp={"data":data}
    return json.dumps(temp)

@app.route('/teachersfeedback/<date>') #26 oct
def feedbackssss(date):
    date_object = datetime.datetime.strptime(date, '%Y-%m-%d')
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1 =db.audio_track_master
    collection2 = db.audio_feedback
    #     date_str = datetime.date(date)
    #     datetime.datetime.utcfromtimestamp(time.mktime(date_str.timetuple()))
    qr1= [{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
   {'MODIFIED_DATE':{'$gte':date_object,
                             '$lt':date_object+timedelta(hours=24)
                             }},
    ]}},
    {'$group':{'_id':'$USER_ID._id',
           'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
           'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
           'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
           'COUNTRY':{'$first':'$USER_ID.schoolId.COUNTRY'},
           'CITY':{'$first':'$USER_ID.schoolId.CITY'},
           'STATE':{'$first':'$USER_ID.schoolId.STATE'}
    }}, 
         ]
    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    qr2= [{"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
             {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':date_object,
                             '$lt':date_object+timedelta(hours=24)
                             }},
                {'RATING':{'$nin':[None,''," "]}},
    {'COMMENT':{'$nin':[None,''," ", 'false']}},
    ]}},
#     {'$group':{'_id':'$USER._id', 'USER_NAME':{'$first':'$USER.USER_NAME'},
#                'EMAIL':{'$first':'$USER.EMAIL_ID'},
#                'SCHOOL':{'$first':'$USER.schoolId.NAME'},
#                'CREATED_DATE':{'$first':'$CREATED_DATE'},
#                'COMMENT':{'$first':'$COMMENT'}, 'ACTION_DATE':{'$first':'$MODIFIED_DATE'},
#          'RATING':{'$first':'$RATING'},
#          'COMMENT':{'$first':'$COMMENT'}
#         }} ,
    {'$project':{'_id':'$USER._id', 'USER_NAME':'$USER.USER_NAME', 'EMAIL':'$USER.EMAIL_ID',
                 'SCHOOL':'$USER.schoolId.NAME', 'CREATED_DATE':'$CREATED_DATE',
                 'RATING':'$RATING','COMMENT':'$COMMENT',
    'ACTION_DATE':'$MODIFIED_DATE'
              }},
    {'$sort':{'RATING':-1}}    ]   
    list2= list(collection2.aggregate(qr2))
    audio1= DataFrame(list2)
    audio=pd.merge(audio1,df_atm1, on='_id', how='left')
    audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'PROGRAM_NAME','RATING','COMMENT','AUDIO_DAY','COUNTRY', 'STATE','ACTION_DATE'
            ,'CITY', 'CREATED_DATE']]
    audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['RATING'].fillna('NO RATING GIVEN', inplace=True)
    audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
    audio2['AUDIO_DAY'].fillna('NO AUDIO DAY', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
#     print(len(audio2))
    Msg='No feedback has been captured on this date'
    if audio2.empty is False:
        # audio2['CREATED_DATE']=audio2['CREATED_DATE']-timedelta(hours=4)
        # audio3=audio2[audio2['CREATED_DATE']]-timedelta
        audio2['RATING']=audio2['RATING'].replace(0,'NO RATING')
        
        return {"data":audio2.values.tolist()}
    else:               
        return {"data":Msg.values.tolist()}
# feedbackssss('2020-10-13')


@app.route('/lowstarweekly')
def lowstartable():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1 =db.audio_track_master
    collection2 = db.audio_feedback
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)

    qr1= [{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
    ]}},
    {'$group':{'_id':'$USER_ID._id',
           'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
           'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
           'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
           'COUNTRY':{'$first':'$USER_ID.schoolId.COUNTRY'},
           'CITY':{'$first':'$USER_ID.schoolId.CITY'},
           'STATE':{'$first':'$USER_ID.schoolId.STATE'}
    }}, 
         ]
    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    qr2= [{"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
                {'RATING':{'$nin':[None,''," "]}}
    ]}},
           {'$match':{'$or':[{'RATING':{'$eq':1}},
    {'RATING':{'$eq':2}}, 
    {'RATING':{'$eq':3}}]}},

    {'$group':{'_id':'$USER._id', 'USER_NAME':{'$first':'$USER.USER_NAME'},
               'EMAIL':{'$first':'$USER.EMAIL_ID'},
               'SCHOOL':{'$first':'$USER.schoolId.NAME'},
               'CREATED_DATE':{'$first':'$CREATED_DATE'},
               'COMMENT':{'$first':'$COMMENT'}, 'ACTION_DATE':{'$first':'$MODIFIED_DATE'},
         'RATING':{'$first':'$RATING'},
         'COMMENT':{'$first':'$COMMENT'}
        }} ,


         {'$project':{'_id':1, 'USER_NAME':1, 'EMAIL':1, 'SCHOOL':1, 
                       
                       'CREATED_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE"}}, 'COMMENT':1,
                  'RATING':1  
                      
                      }},



    {'$sort':{'RATING':-1}}    ]   
    list2= list(collection2.aggregate(qr2))
    audio1= DataFrame(list2)
    audio=pd.merge(audio1,df_atm1, on='_id', how='left')
    audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'PROGRAM_NAME','RATING','COMMENT','AUDIO_DAY','CREATED_DATE','COUNTRY', 'STATE'
            ,'CITY']]
    audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['RATING'].fillna('NO RATING GIVEN', inplace=True)
    audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
    audio2['AUDIO_DAY'].fillna('NO AUDIO DAY', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['RATING']=str(audio2['RATING'].iloc[0])

    Msg='No feedback has been captured on this date'
    if audio2.empty is False:
    #     # audio2['CREATED_DATE']=audio2['CREATED_DATE']
    #     # audio3=audio2[audio2['CREATED_DATE']>=date_object]
        audio2['RATING']=audio2['RATING'].replace(0,'NO RATING')
        return {"data":audio2.values.tolist()}
    else:               
        return {"data":Msg.values.tolist()}


@app.route('/teach_practice_tablee_weekly/<week>')
def playbackdatateachers(week):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)
    
    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start , '$lt':yester
    }},
    ]}},
         {'$project':{'_id':'$USER_ID._id','PRACTICE_DATE':'$MODIFIED_DATE',
     'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
    'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY', 'AUDIO_NAME':'$PROGRAM_AUDIO_ID.AUDIO_NAME',
                      'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP'
                          
                     }}

    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    ]}},
    {'$group':{'_id':'$_id', 
    'CREATED_DATE':{'$first':'$CREATED_DATE'}, 'schoolNAME':{'$first':'$schoolId.NAME'},
    'USER_NAME':{'$first':'$USER_NAME'}, 'EMAIL':{'$first':'$EMAIL_ID'},
    'COUNTRY':{'$first':'$schoolId.COUNTRY'}, 'STATE':{'$first':'$schoolId.STATE'}, 'CITY':{'$first':'$schoolId.CITY'}         
    }}         

    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    df_final= pd.merge(df_atm, df_um,how='left', on='_id')
   
    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','CREATED_DATE','PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY','AGE_GROUP','COUNTRY','STATE','CITY']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME']=audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['PRACTICE_DATE'].dt.strftime('%d %b %Y')
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    audio20= audio2.groupby(audio2['PRACTICE_DATE'].dt.strftime('%A'))

    audio3=audio20.get_group(''+week+'')
    audio30= pd.DataFrame(audio3)

    temp={'data':audio30.values.tolist()}

    return json.dumps(temp)



# playbackdatateachers('Sunday')







@app.route('/parents_practice_tablee_weekly/<week>')
def playbackdataparents(week):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)
    
    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start , '$lt':yester
    }},
    ]}},
         {'$project':{'_id':'$USER_ID._id','PRACTICE_DATE':'$MODIFIED_DATE',
     'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
    'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY', 'AUDIO_NAME':'$PROGRAM_AUDIO_ID.AUDIO_NAME',
                      'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP'
                          
                     }}

    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    ]}},
    {'$group':{'_id':'$_id', 
    'CREATED_DATE':{'$first':'$CREATED_DATE'}, 'schoolNAME':{'$first':'$schoolId.NAME'},
    'USER_NAME':{'$first':'$USER_NAME'}, 'EMAIL':{'$first':'$EMAIL_ID'},
    'COUNTRY':{'$first':'$schoolId.COUNTRY'}, 'STATE':{'$first':'$schoolId.STATE'}, 'CITY':{'$first':'$schoolId.CITY'}         
    }}         

    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    df_final= pd.merge(df_atm, df_um,how='left', on='_id')
   
    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','CREATED_DATE','PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY','AGE_GROUP','COUNTRY','STATE','CITY']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME']=audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['PRACTICE_DATE'].dt.strftime('%d %b %Y')
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    audio20= audio2.groupby(audio2['PRACTICE_DATE'].dt.strftime('%A'))

    audio3=audio20.get_group(''+week+'')
    audio30= pd.DataFrame(audio3)

    temp={'data':audio30.values.tolist()}

    return json.dumps(temp)



# playbackdataparents('Sunday')








# #testttt
# @app.route('/coomentperfeedbacktable/<ratinggg>')
# def weekly_feedback_table(ratinggg):
#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
#     db=client.compass
#     collection1 =db.audio_track_master
#     collection2 = db.audio_feedback
    
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     tod= today+ timedelta(hours=4)
#     # yester-timedelta(days=8)
#     start= tod-timedelta(days=8)
#     yester= yesterday+timedelta(hours=4)
#     start_15day=tod-timedelta(days=15)


#     qr1= [{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
#             {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte':start,
#                              '$lt':yester
#                              }},
#     ]}},
#     {'$group':{'_id':'$USER_ID._id',
#                'PRACTICE_COUNT':{'$sum':1},
#                'LAST_PRACTICE_DATE':{'$max':'$MODIFIED_DATE'},
#            'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
#            'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
#            'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
#            'COUNTRY':{'$first':'$USER_ID.schoolId.COUNTRY'},
#            'CITY':{'$first':'$USER_ID.schoolId.CITY'},
#            'STATE':{'$first':'$USER_ID.schoolId.STATE'}
#     }}, 
#          ]
#     list1= list(collection1.aggregate(qr1))
#     df_atm1= DataFrame(list1)
    
#     qr2= [{"$match":{
#     '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#            {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#              {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#     {'USER.IS_DISABLED':{"$ne":'Y'}},
#     {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
#     {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
#             {'MODIFIED_DATE':{'$gte':start,
#                              '$lt':yester
#                              }},
#                 {'RATING':{'$nin':[None,''," "]}},
#     {'COMMENT':{'$nin':[None,''," ", 'false']}},
#     ]}},
    

#     {'$group':{'_id':'$USER._id', 'USER_NAME':{'$first':'$USER.USER_NAME'},
#                'EMAIL':{'$first':'$USER.EMAIL_ID'},
#                'SCHOOL':{'$first':'$USER.schoolId.NAME'},
#                'CREATED_DATE':{'$first':'$CREATED_DATE'},
#                'COMMENT':{'$first':'$COMMENT'}, 'ACTION_DATE':{'$first':'$MODIFIED_DATE'},
#          'RATING':{'$first':'$RATING'},
#          'COMMENT':{'$first':'$COMMENT'}
#         }} ,
#      {'$project':{'_id':1, 'USER_NAME':1, 'EMAIL':1, 'SCHOOL':1, 
                       
#                        'CREATED_DATE':1, 'COMMENT':1,
#                   'RATING':1  
                      
#                       }},


#     {'$sort':{'RATING':-1}}    ]  
    
    
#     list2= list(collection2.aggregate(qr2))
#     audio1= DataFrame(list2)
#     audio=pd.merge(audio1,df_atm1, on='_id', how='left')
#     audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'PROGRAM_NAME','RATING','COMMENT','AUDIO_DAY','PRACTICE_COUNT',
#                   'LAST_PRACTICE_DATE',
#                   'CREATED_DATE','COUNTRY', 'STATE'
#             ,'CITY']]
#     audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
#     audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
#     audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
#     audio2['RATING'].fillna('NO RATING GIVEN', inplace=True)
#     audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
#     audio2['AUDIO_DAY'].fillna('NO AUDIO DAY', inplace=True)
#     audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
#     audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
#     audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
#     audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
#     audio2['RATING']=str(audio2['RATING'].iloc[0])
#     audio2['RATING']=audio2['RATING'].replace(0, 'No Rating')
#     audio2['LAST_PRACTICE_DATE']=audio2['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
#     audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')
    
#     audio20= audio2.groupby(audio2['RATING'])
#     audio3= audio20.get_group(''+ratinggg+'')
#     audio30= pd.DataFrame(audio3)
# #     audio4=audio30.values.tolist()
    
#     temp={'data':audio30.values.tolist()}

    
# #     data=[]
# #     for i,j,k,l,m,n,o,p,q,r,s,t,u in zip(audio4,audio2['SCHOOL_NAME'].tolist(),audio2['USER_NAME'].tolist(),audio2['EMAIL'].tolist(),audio2['PROGRAM_NAME'].tolist(),audio2['AUDIO_DAY'].tolist(),audio2['COMMENT'].tolist(),audio2['PRACTICE_COUNT'].tolist(),audio2['LAST_PRACTICE_DATE'].tolist(),audio2['CREATED_DATE'].tolist(),audio2['COUNTRY'].tolist(),audio2['STATE'].tolist(),audio2['CITY'].tolist()):                       
# #         data.append([i,j,k,l,m,n,o,p,q,r,s,t,u])
# #     temp={"data":data}
#     return json.dumps(temp)
    
    
    
# #     Msg='No feedback has been captured on this date'
# #     if audio2.empty is False:
# #     #     # audio2['CREATED_DATE']=audio2['CREATED_DATE']
# #     #     # audio3=audio2[audio2['CREATED_DATE']>=date_object]
# #         audio2['RATING']=audio2['RATING'].replace(0,'NO RATING')
# #         return {"data":audio2.values.tolist()}
# #     else:               
# #         return {"data":Msg.values.tolist()}


    

# # weekly_feedback_table('5') 

# @app.route('/teachers_practice_tablee_weekly/<week>')
# def playbackdatateachers(week):
#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
#     db=client.compass
#     collection1= db.audio_track_master
#     collection2= db.user_master
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     tod= today+ timedelta(hours=4)
#     # yester-timedelta(days=8)
#     start= tod-timedelta(days=8)
#     yester= yesterday+timedelta(hours=4)
#     start_15day=tod-timedelta(days=15)
    
#     qr1=[{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte':start , '$lt':yester
#     }},
#     ]}},
#     {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
#      'LAST_PRACTICE_DATE':{'$max':'$MODIFIED_DATE'}, 
#      'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
#     }}, 

#     {'$sort':{'_id':1}}
#     ]

#     list1= list(collection1.aggregate(qr1))
#     df_atm= DataFrame(list1)

    
#     qr2=[{"$match":{
#     '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
#     {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     ]}},
#     {'$group':{'_id':'$_id', 
#     'CREATED_DATE':{'$first':'$CREATED_DATE'}, 'schoolNAME':{'$first':'$schoolId.NAME'},
#     'USER_NAME':{'$first':'$USER_NAME'}, 'EMAIL':{'$first':'$EMAIL_ID'},
#      'COUNTRY':{'$first':'$schoolId.COUNTRY'}, 'STATE':{'$first':'$schoolId.STATE'}, 'CITY':{'$first':'$schoolId.CITY'},
#       'uc_id':{'$addToSet':'$_id'}
               
#     }}, 
#          {'$project':{'_id':1,'CREATED_DATE':1, 'schoolNAME':1, 'USER_NAME':1,'EMAIL':1,
#                      'COUNTRY':1, 'STATE':1, 'CITY':1, 'USER_COUNT':{'$size':'$uc_id'}
#                      }}
         

#     ]

#     list2= list(collection2.aggregate(qr2))
#     df_um= DataFrame(list2)
    
#     df_final= pd.merge(df_atm, df_um,how='left', on='_id')
   
#     audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','LAST_PRACTICE_DATE','USER_COUNT', 'COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
#     audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
#     audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
#     audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
#     audio2['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
#     audio2['USER_COUNT'].fillna(0, inplace=True)
#     audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
#     audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
#     audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
#     audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
#     audio2['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
#     audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

#     audio20= audio2.groupby(audio2['LAST_PRACTICE_DATE'].dt.strftime('%A'))

#     audio3=audio20.get_group(''+week+'')
#     audio30= pd.DataFrame(audio3)

#     temp={'data':audio30.values.tolist()}


#     # #     data=[]
#     # #     for i,j,k,l,m,n,o,p,q,r,s,t,u in zip(audio4,audio2['SCHOOL_NAME'].tolist(),audio2['USER_NAME'].tolist(),audio2['EMAIL'].tolist(),audio2['PROGRAM_NAME'].tolist(),audio2['AUDIO_DAY'].tolist(),audio2['COMMENT'].tolist(),audio2['PRACTICE_COUNT'].tolist(),audio2['LAST_PRACTICE_DATE'].tolist(),audio2['CREATED_DATE'].tolist(),audio2['COUNTRY'].tolist(),audio2['STATE'].tolist(),audio2['CITY'].tolist()):                       
#     # #         data.append([i,j,k,l,m,n,o,p,q,r,s,t,u])
#     # #     temp={"data":data}
#     return json.dumps(temp)



# # playbackdatateachers('Monday')






# @app.route('/parents_practice_tablee_weekly/<week>')
# def playbackdata(week):
#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
#     db=client.compass
#     collection1= db.audio_track_master
#     collection2= db.user_master
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     tod= today+ timedelta(hours=4)
#     # yester-timedelta(days=8)
#     start= tod-timedelta(days=8)
#     yester= yesterday+timedelta(hours=4)
#     start_15day=tod-timedelta(days=15)
    
#     qr1=[{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte':start , '$lt':yester
#     }},
#     ]}},
#     {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
#      'LAST_PRACTICE_DATE':{'$max':'$MODIFIED_DATE'}, 
#      'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
#     }}, 

#     {'$sort':{'_id':1}}
#     ]

#     list1= list(collection1.aggregate(qr1))
#     df_atm= DataFrame(list1)

    
#     qr2=[{"$match":{
#     '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
#     {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     ]}},
#     {'$group':{'_id':'$_id', 
#     'CREATED_DATE':{'$first':'$CREATED_DATE'}, 'schoolNAME':{'$first':'$schoolId.NAME'},
#     'USER_NAME':{'$first':'$USER_NAME'}, 'EMAIL':{'$first':'$EMAIL_ID'},
#      'COUNTRY':{'$first':'$schoolId.COUNTRY'}, 'STATE':{'$first':'$schoolId.STATE'}, 'CITY':{'$first':'$schoolId.CITY'},
#       'uc_id':{'$addToSet':'$_id'}
               
#     }}, 
#          {'$project':{'_id':1,'CREATED_DATE':1, 'schoolNAME':1, 'USER_NAME':1,'EMAIL':1,
#                      'COUNTRY':1, 'STATE':1, 'CITY':1, 'USER_COUNT':{'$size':'$uc_id'}
#                      }}
         

#     ]

#     list2= list(collection2.aggregate(qr2))
#     df_um= DataFrame(list2)
    
#     df_final= pd.merge(df_atm, df_um,how='left', on='_id')
   
#     audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','LAST_PRACTICE_DATE','USER_COUNT', 'COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
#     audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
#     audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
#     audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
#     audio2['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
#     audio2['USER_COUNT'].fillna(0, inplace=True)
#     audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
#     audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
#     audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
#     audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
#     audio2['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
#     audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

#     audio20= audio2.groupby(audio2['LAST_PRACTICE_DATE'].dt.strftime('%A'))

#     audio3=audio20.get_group(''+week+'')
#     audio30= pd.DataFrame(audio3)

#     temp={'data':audio30.values.tolist()}


#     # #     data=[]
#     # #     for i,j,k,l,m,n,o,p,q,r,s,t,u in zip(audio4,audio2['SCHOOL_NAME'].tolist(),audio2['USER_NAME'].tolist(),audio2['EMAIL'].tolist(),audio2['PROGRAM_NAME'].tolist(),audio2['AUDIO_DAY'].tolist(),audio2['COMMENT'].tolist(),audio2['PRACTICE_COUNT'].tolist(),audio2['LAST_PRACTICE_DATE'].tolist(),audio2['CREATED_DATE'].tolist(),audio2['COUNTRY'].tolist(),audio2['STATE'].tolist(),audio2['CITY'].tolist()):                       
#     # #         data.append([i,j,k,l,m,n,o,p,q,r,s,t,u])
#     # #     temp={"data":data}
#     return json.dumps(temp)



# # playbackdata('Monday')






# @app.route('/calenderFEEDBACKteachers_7days/<date>') #26 oct
# def feedback_of_7days_teach(date):
#     date_object = datetime.datetime.strptime(date, '%Y-%m-%d')
#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
#     db=client.compass
#     collection1 =db.audio_track_master
#     collection2 = db.audio_feedback
#     #     date_str = datetime.date(date)
#     #     datetime.datetime.utcfromtimestamp(time.mktime(date_str.timetuple()))
#     qr1= [{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#    {'MODIFIED_DATE':{'$gte':date_object,
#                              '$lt':date_object+timedelta(days=7)
#                              }},
#     ]}},
#     {'$group':{'_id':'$USER_ID._id',
#            'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
#            'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
#            'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
#            'COUNTRY':{'$first':'$USER_ID.schoolId.COUNTRY'},
#            'CITY':{'$first':'$USER_ID.schoolId.CITY'},
#            'STATE':{'$first':'$USER_ID.schoolId.STATE'}
#     }}, 
#          ]
#     list1= list(collection1.aggregate(qr1))
#     df_atm1= DataFrame(list1)
#     qr2= [{"$match":{
#     '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#            {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#              {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#     {'USER.IS_DISABLED':{"$ne":'Y'}},
#     {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
#              {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
#     {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
#             {'MODIFIED_DATE':{'$gte':date_object,
#                              '$lt':date_object+timedelta(days=7)
#                              }},
#                 {'RATING':{'$nin':[None,''," "]}},
#     {'COMMENT':{'$nin':[None,''," ", 'false']}},
#     ]}},
#     {'$group':{'_id':'$USER._id', 'USER_NAME':{'$first':'$USER.USER_NAME'},
#                'EMAIL':{'$first':'$USER.EMAIL_ID'},
#                'SCHOOL':{'$first':'$USER.schoolId.NAME'},
#                'CREATED_DATE':{'$first':'$CREATED_DATE'},
#                'COMMENT':{'$first':'$COMMENT'}, 'ACTION_DATE':{'$first':'$MODIFIED_DATE'},
#          'RATING':{'$first':'$RATING'},
#          'COMMENT':{'$first':'$COMMENT'}
#         }} ,
# #     {'$project':{'_id':1, 'USER_NAME':1, 'EMAIL':1,'SCHOOL':1,'STATE':1, 
# #                  'RATING':1,'COMMENT':1,
# #                  'CREATED_DATE':1,
# #               }},
#     {'$sort':{'RATING':-1}}    ]   
#     list2= list(collection2.aggregate(qr2))
#     audio1= DataFrame(list2)
#     audio=pd.merge(audio1,df_atm1, on='_id', how='left')
#     audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'PROGRAM_NAME','RATING','COMMENT','AUDIO_DAY','CREATED_DATE','COUNTRY', 'STATE','ACTION_DATE'
#             ,'CITY']]
#     audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
#     audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
#     audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
#     audio2['RATING'].fillna('NO RATING GIVEN', inplace=True)
#     audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
#     audio2['AUDIO_DAY'].fillna('NO AUDIO DAY', inplace=True)
#     audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
#     audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
#     audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
#     audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
# #     print(len(audio2))
#     Msg='No feedback has been captured on this date'
#     if audio2.empty is False:
#         # audio2['CREATED_DATE']=audio2['CREATED_DATE']
#         # audio3=audio2[audio2['CREATED_DATE']>=date_object]
#         audio2['RATING']=audio2['RATING'].replace(0,'NO RATING')
#         return {"data":audio2.values.tolist()}
#     else:               
#         return {"data":Msg.values.tolist()}
# # feedback_of_7days_teach('2020-10-20')


@app.route('/parents_practice_tablee_last_week/<week>')
def playbackdataparents_last_week(week):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)
    
    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start_15day , '$lt':start
    }},
    ]}},
         {'$project':{'_id':'$USER_ID._id','PRACTICE_DATE':'$MODIFIED_DATE',
     'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
    'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY', 'AUDIO_NAME':'$PROGRAM_AUDIO_ID.AUDIO_NAME',
                      'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP'
                          
                     }}

    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    ]}},
    {'$group':{'_id':'$_id', 
    'CREATED_DATE':{'$first':'$CREATED_DATE'}, 'schoolNAME':{'$first':'$schoolId.NAME'},
    'USER_NAME':{'$first':'$USER_NAME'}, 'EMAIL':{'$first':'$EMAIL_ID'},
    'COUNTRY':{'$first':'$schoolId.COUNTRY'}, 'STATE':{'$first':'$schoolId.STATE'}, 'CITY':{'$first':'$schoolId.CITY'}         
    }}         

    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    df_final= pd.merge(df_atm, df_um,how='left', on='_id')
   
    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','CREATED_DATE','PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY','AGE_GROUP','COUNTRY','STATE','CITY']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME']=audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['PRACTICE_DATE'].dt.strftime('%d %b %Y')
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    audio20= audio2.groupby(audio2['PRACTICE_DATE'].dt.strftime('%A'))

    audio3=audio20.get_group(''+week+'')
    audio30= pd.DataFrame(audio3)

    temp={'data':audio30.values.tolist()}

    return json.dumps(temp)



# playbackdataparents_last_week('Sunday')






@app.route('/teach_practice_tablee_last_week/<week>')
def playbackdatateachers_last_week(week):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)
    
    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start_15day , '$lt':start
    }},
    ]}},
         {'$project':{'_id':'$USER_ID._id','PRACTICE_DATE':'$MODIFIED_DATE',
     'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
    'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY', 'AUDIO_NAME':'$PROGRAM_AUDIO_ID.AUDIO_NAME',
                      'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP'
                          
                     }}

    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    ]}},
    {'$group':{'_id':'$_id', 
    'CREATED_DATE':{'$first':'$CREATED_DATE'}, 'schoolNAME':{'$first':'$schoolId.NAME'},
    'USER_NAME':{'$first':'$USER_NAME'}, 'EMAIL':{'$first':'$EMAIL_ID'},
    'COUNTRY':{'$first':'$schoolId.COUNTRY'}, 'STATE':{'$first':'$schoolId.STATE'}, 'CITY':{'$first':'$schoolId.CITY'}         
    }}         

    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    df_final= pd.merge(df_atm, df_um,how='left', on='_id')
   
    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','CREATED_DATE','PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY','AGE_GROUP','COUNTRY','STATE','CITY']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME']=audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['PRACTICE_DATE'].dt.strftime('%d %b %Y')
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')

    audio20= audio2.groupby(audio2['PRACTICE_DATE'].dt.strftime('%A'))

    audio3=audio20.get_group(''+week+'')
    audio30= pd.DataFrame(audio3)

    temp={'data':audio30.values.tolist()}

    return json.dumps(temp)



# playbackdatateachers_last_week('Sunday')





#testtt
# to be updated as on nov 17
@app.route('/weeklyfeedcard')
def feedweekcardssss():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
    yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
    today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    tod= today+ timedelta(hours=4)
    # yester-timedelta(days=8)
    start= tod-timedelta(days=8)
    yester= yesterday+timedelta(hours=4)
    start_15day=tod-timedelta(days=15)
    
#TEACHERS COMMENT PER FEEDBACK LAST WEEK
    query1=[
    {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
               {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed=list(collection2.aggregate(query1))
    commentsonfeedback=pd.DataFrame(commentsonfeed)
    comments_per_feedback_teacher=commentsonfeedback[['rating']]
    
    
#PARENTS COMMENT PER FEEDBACK LAST WEEK
    querya=[
    {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
               {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed2=list(collection2.aggregate(querya))
    commentsonfeedback2=pd.DataFrame(commentsonfeed2)
    comments_per_feedback_parents=commentsonfeedback2[['rating']]
    

    
#TEACHERS COMMENT PER FEEDBACK before LAST WEEK
    query4=[
    {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start_15day,
                             '$lt':start
                             }},
               {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed11=list(collection2.aggregate(query4))
    commentsonfeedback11=pd.DataFrame(commentsonfeed11)
    comments_per_feedback_before_last_week_teachers=commentsonfeedback11[['rating']]
    

    
#  PARENTS COMMENT PER FEEDBACK before LAST WEEK
    queryB=[
     {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start_15day,
                             '$lt':start
                             }},
               {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed200=list(collection2.aggregate(queryB))
    commentsonfeedback20=pd.DataFrame(commentsonfeed200)
    comments_per_feedback_before_last_week_parents=commentsonfeedback20[['rating']]
    

    
# AVERAGE FEEDBACK RATING LAST WEEK
    query6=[
    {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
#             {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
               {'RATING':{'$ne':0}}]}},
    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rating=list(collection2.aggregate(query6))
    avg_ratings=pd.DataFrame(avg_rating)
    avg_ratings_lastweek=avg_ratings[['RATING']]

    avg_ratings_last_week=pd.DataFrame({'avg_ratings_lastweek':round(avg_ratings_lastweek[avg_ratings_lastweek['RATING']!=0]['RATING'].mean(),1)}, index=[0])

    
   
    query60=[
     {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start_15day,
                             '$lt':yester
                             }},
               {'RATING':{'$ne':0}}]}},
    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rate=list(collection2.aggregate(query60))
    avg_ratin=pd.DataFrame(avg_rate)
    avg_ratings_before_lastweek=avg_ratin[['RATING']]

    avg_ratings_beforee_last_week=pd.DataFrame({'avg_ratings_before_lastweek':round(avg_ratings_before_lastweek[avg_ratings_before_lastweek['RATING']!=0]['RATING'].mean(),1)}, index=[0])



    
    TEACHER_Comment_per_feedbackchange=[]
    teacher_PERCENTAGE_change=[]
    if comments_per_feedback_teacher['rating'].iloc[0] > comments_per_feedback_before_last_week_teachers['rating'].iloc[0]:
        xx=comments_per_feedback_teacher['rating'].iloc[0]-comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        yy= xx/comments_per_feedback_teacher['rating'].iloc[0]
        zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('-1')
        teacher_PERCENTAGE_change.append(zz)
        
    elif comments_per_feedback_teacher['rating'].iloc[0] == comments_per_feedback_before_last_week_teachers['rating'].iloc[0]:
        xx=comments_per_feedback_teacher['rating'].iloc[0]-comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        yy= xx/comments_per_feedback_teacher['rating'].iloc[0]
        zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('0')
        teacher_PERCENTAGE_change.append(zz)
        
    else:
        xx=comments_per_feedback_before_last_week_teachers['rating'].iloc[0]-comments_per_feedback_teacher['rating'].iloc[0]
        yy= xx/comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('1')
        teacher_PERCENTAGE_change.append(zz)
        


    PARENT_Comment_per_feedbackchange=[]
    parent_PERCENTAGE_change=[]
    if comments_per_feedback_before_last_week_parents['rating'].iloc[0]> comments_per_feedback_parents['rating'].iloc[0]:
        xx=comments_per_feedback_before_last_week_parents['rating'].iloc[0]-comments_per_feedback_parents['rating'].iloc[0]
        yy= xx/comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        zz= round(yy*100,2)
        PARENT_Comment_per_feedbackchange.append('-1')
        parent_PERCENTAGE_change.append(zz)
        
    elif comments_per_feedback_before_last_week_parents['rating'].iloc[0] ==comments_per_feedback_parents['rating'].iloc[0]:
        xx=comments_per_feedback_before_last_week_parents['rating'].iloc[0]-comments_per_feedback_parents['rating'].iloc[0]
        yy= xx/comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        zz= round(yy*100,2)
        PARENT_Comment_per_feedbackchange.append('0')
        parent_PERCENTAGE_change.append(zz)
        
    else:
        xx=comments_per_feedback_parents['rating'].iloc[0]-comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        yy= xx/comments_per_feedback_parents['rating'].iloc[0]
        zz= round(yy*100,2)
        PARENT_Comment_per_feedbackchange.append('1')
        parent_PERCENTAGE_change.append(zz)
        


    Average_FEEDBACK_Rating_change=[]
    Average_feedback_PERCENTAGE=[]
    if avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]> avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]:
        xx=avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]-avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
        yy= xx/avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        zz= round(yy*100,2)
        Average_FEEDBACK_Rating_change.append('-1')
        Average_feedback_PERCENTAGE.append(zz)
        
        
    elif avg_ratings_last_week['avg_ratings_lastweek'].iloc[0] == avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]:
        xx=avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]-avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
        yy= xx/avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        zz= round(yy*100,2)
        Average_FEEDBACK_Rating_change.append('0')
        Average_feedback_PERCENTAGE.append(zz)
        
    else:
        xx=avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]-avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        yy= xx/avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
        zz= round(yy*100,2)
        Average_FEEDBACK_Rating_change.append('1')
        Average_feedback_PERCENTAGE.append(zz)



    data_final=pd.DataFrame({'TEACHER_FEEDBACK_RATING_LAST_WEEK':comments_per_feedback_teacher['rating'].tolist(),
                             'TEACHER_FEEDBACK_RATING_BEFORE_LAST_WEEK':comments_per_feedback_before_last_week_teachers['rating'].tolist(),
                             
    'PARENT_FEEDBACK_RATING_LAST_WEEK':comments_per_feedback_parents['rating'].tolist(),
    'PARENT_FEEDBACK_RATING_BEFORE_LAST_WEEK':comments_per_feedback_before_last_week_parents['rating'].tolist(),
                                 
     'Average_Rating_lastweek':avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].tolist(),
     'Average_Rating_lastweek':avg_ratings_last_week['avg_ratings_lastweek'].tolist(),
                             
      'TEACHER_Comment_per_feedbackchange':TEACHER_Comment_per_feedbackchange,
       'teacher_PERCENTAGE_change':teacher_PERCENTAGE_change,                      
      'PARENT_Comment_per_feedbackchange':PARENT_Comment_per_feedbackchange,
       'parent_PERCENTAGE_change':parent_PERCENTAGE_change,                      
      'Average_FEEDBACK_Rating_change':Average_FEEDBACK_Rating_change,
       'Average_feedback_PERCENTAGE':Average_feedback_PERCENTAGE                      
                                })   
    
    temp={}
    for j in range(len(data_final.columns)):
        key = data_final.columns[j]
        value = [str(data_final[data_final.columns[j]].iloc[0])]
        temp.update({key:value})
    return json.dumps(temp)


    
@app.route('/schengtop20table')
def schoolengtabletop20():
    dflife=pd.read_csv("engschool_id.csv")
    lifelist=list(dflife["school id"])
    lifetimelist=[]
    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }   
    },
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    #   {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #   {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
    #   {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'IS_ADMIN':'Y'}

    ]
    }},

    {"$project":{"_id":0,
    'UMUSER_ID':'$_id',"USER_NAME":'$USER_NAME',
    "UMEMAIL":'$EMAIL_ID',  
    "CREATED_DATE":'$CREATED_DATE',
    "UMSCHOOLID":'$schoolId._id',
                 "UMSCHOOLNAME":'$schoolId.NAME',
                 "CITY":'$schoolId.CITY',
                 "STATE":'$schoolId.STATE',
                 "COUNTRY":'$schoolId.COUNTRY',
                }},
    ]
    merge1=list(collection.aggregate(query))
    overallum=pd.DataFrame(merge1)
    overallum["CREATED_DATE"]=overallum["CREATED_DATE"].dt.strftime('%d %b %Y')
#     overallum.to_csv("comcheck12.csv")
    email=list(overallum["UMUSER_ID"])
    schoolid=list(overallum["UMSCHOOLID"])
    ################################sub_master################################
    # db.subscription_master.ensureIndex("USER_ID._id", 1) 
    collection = db.subscription_master
    qr=[
    {"$match":{"$and":[{'USER_ID._id':{"$in":email}},
#     {'PLAN_ID.PLAN_NAME':"Community"}
    ]}},
    {"$project":{"_id":0,
    'SMUSER_ID':'$USER_ID._id',
    "SMEMAIL":'$USER_ID.EMAIL_ID',
    "PLANID":"$PLAN_ID.PLAN_NAME",
    "comment":"$COMMENT_BY_DS_TEAM",
    "RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE",
    }},]
    merge=list(collection.aggregate(qr))
    overall=pd.DataFrame(merge)
    overall["RENEWAL_DATE"]=overall["RENEWAL_DATE"].dt.strftime('%d %b %Y')
#     mergeddf=pd.merge(overallum, overall, how='left', left_on='UMEMAIL', right_on='SMEMAIL')
    mergeddf=pd.merge(overallum, overall, how='left', left_on='UMUSER_ID', right_on='SMUSER_ID')
    db=client.compass
    collection = db.audio_track_master
    qra=[
    {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},
    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id', 
    'atdLastpractice':{'$max':'$MODIFIED_DATE'},
    'atdPracticecount':{'$sum':1},
    'atdTotal_Mindful_Minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}}]
    merge11=list(collection.aggregate(qra))
    atd=pd.DataFrame(merge11)
    atd["atdLastpractice"]=atd["atdLastpractice"].dt.strftime('%d %b %Y')
    finalmerge=pd.merge(mergeddf, atd, how='left', left_on='UMSCHOOLID', right_on='_id')
    finalmerge['atdLastpractice'].fillna("NO PRACTICE", inplace=True)
    finalmerge['atdPracticecount'].fillna(0, inplace=True)
    finalmerge.fillna("NO INFO AVAILABLE", inplace=True)
    finaldata=finalmerge[["UMSCHOOLNAME","STATE","CITY","USER_NAME","UMEMAIL","CREATED_DATE","atdLastpractice","RENEWAL_DATE","atdPracticecount"]]
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('int')
    finaldata["atdPracticecount"] = finaldata['atdPracticecount'].astype('str')
    print(len(lifetimelist),len(finaldata))
    return json.dumps({"data":finaldata.values.tolist()})


@app.route('/top_20')

def school_engagement12():    
    
    
    mongo_uri = "mongodb://admin:" + urllib.parse.quote('I#L@teST^m0NGO_2o20!') + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass

    collection=db.school_master.aggregate([ {"$match":{'$and':[
                {"_id":{"$in":db.user_master.distinct( "schoolId._id" )}},
                {'CATEGORY':{"$regex":"null",'$options':'i'}},    
                ]}
                    },
                {"$project":{"school_id":"$_id","CATEGORY":1
                           }}])

    df1=pd.DataFrame(list(collection)).fillna(0)
    #df1
    school_list=df1["school_id"].to_list()

    #school_list
    collection=db.user_master.aggregate([{"$match":{"USER_NAME":{"$not":{"$regex":"test","$options":"i"}},
    "EMAIL_ID":{"$not":{"$regex":"1gen","$options":"i"}},"schoolId._id":{"$in":school_list},
    "IS_BLOCKED":{"$ne":"Y"},"INCOMPLETE_SIGNUP":{"$ne":"Y"},"IS_DISABLED":{"$ne":"Y"},"DISTRICT_ID._id":{"$exists":0}}},
    {"$project":{"_id":1,"USER_NAME":1,
        "EMAIL_ID":1,"CREATED_DATE":1,
        "School Name":"$schoolId.NAME",
        "school id":"$schoolId._id","city":"$schoolId.CITY","state":"$schoolId.STATE","country":"$schoolId.COUNTRY"}}])

    df2=pd.DataFrame(list(collection)).fillna(0)
    #df2

    user_list=df2["_id"].to_list()

    #user_list

    collection=db.subscription_master.aggregate([{"$match":{"USER_ID._id":{"$in":user_list}}},
    {"$project":{"user_id":"$USER_ID._id","SUBSCRIPTION_EXPIRE_DATE":1,"LAST_PAYMENT_AMOUNT":1,"plan_name":"$PLAN_ID.PLAN_NAME","_id":0}}])

    df3= pd.DataFrame(list(collection)).fillna(0)

    use_sub=pd.merge(
        df2,
        df3,
        how="inner",
        left_on="_id",
        right_on="user_id"
    )

    #use_sub
    collection=db.audio_track_master.aggregate([{"$match":{"USER_ID._id":{"$in":user_list}}},
    {"$group":{"_id":"$USER_ID._id","pract_count":{"$sum":1}, 'last_practice_date':{'$max':'$MODIFIED_DATE'}}}])

    df4=pd.DataFrame(list(collection)).fillna(0)
    df4["last_practice_date"]=df4["last_practice_date"].dt.strftime("%d %b %Y")
    #df4
    use_sub_audi=pd.merge(
        use_sub,
        df4,
        how="left",
        left_on="_id",
        right_on="_id"
    )
    
    
#     print(df4)

    over_all=use_sub_audi.fillna(0)
    
    df5=pd.merge(
        use_sub,
        df4,
        how="inner",
        left_on="_id",
        right_on="_id"
    )
    

    group_by= df5.groupby(["school id","School Name"])["_id"].count().reset_index(name="count")
    #group_by
    pract_count_gr_than_five= group_by[group_by['count']>=5]

    #pract_count_gr_than_five

    sort_by_counts = pract_count_gr_than_five.sort_values('count',
                                         ascending=False)

    #sort_by_counts
    top_20=sort_by_counts[0:20]
    #top_20
    #over_all
    pract_count0 = over_all[over_all['pract_count'] == 0.0]

    #pract_count0

    #top_20
    group_by_sum= df5.groupby(["school id"])["pract_count"].sum().reset_index(name="pract_count")

#     group_by_sum["school id"]=="5f2bca13ba0be61b0c1ca1af"

    overall_n_group_by_sum=pd.merge(
        over_all,
        group_by_sum,
        how="left",
        left_on="school id",
        right_on="school id"
    )

    www=overall_n_group_by_sum["school id"]
    www.to_csv("engschool_id.csv")
    columns=overall_n_group_by_sum[["School Name","city","state","USER_NAME","EMAIL_ID","CREATED_DATE","SUBSCRIPTION_EXPIRE_DATE","last_practice_date","pract_count_x"]]
    columns["CREATED_DATE"]=columns["CREATED_DATE"].dt.strftime("%d %b %Y")
    columns["SUBSCRIPTION_EXPIRE_DATE"]=columns["SUBSCRIPTION_EXPIRE_DATE"].dt.strftime("%d %b %Y")

    
    #columns
    final=pd.merge(
        top_20,
        overall_n_group_by_sum,
        how="inner",
        left_on="school id",
        right_on="school id"
    )

    #final
    school_name=final[["School Name_x","count","pract_count_y"]]
    final_df=school_name.drop_duplicates()
    #final_df
    school_name_list=final_df["School Name_x"].to_list()
    count_list=final_df["count"].to_list()
    pract_count_y=final_df["pract_count_y"].to_list()
    #columns
#     print(columns)
    tabular_columns=columns.values.tolist()

    dicnry={"school_name":school_name_list,"Active_user":count_list,"school_pract_count":pract_count_y}
    #dicnry
    
    return json.dumps(dicnry)

@app.route('/schoolpracticetrendnew/<schoolid>')
def school_practice_trend(schoolid):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    from datetime import datetime
    df00 = DataFrame(list(db.user_master.aggregate([
        {"$match":
            {'schoolId._id':ObjectId(""+schoolid+"")}
        },
        {'$project':{'_id':1,'school':'$schoolId._id'}}])))
    school=df00['_id'].tolist()
    
    df1 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[

     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}}, 
         {'USER_ID._id':{'$in':school}},
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},  
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},

                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": LSY_Date(),
                                        "$lt":csy_first_date()}}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
       {'$project':{'_id':1,'TOTAL_LSY':'$pc'}}])))
    if df1.empty == True:
        df1=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'TOTAL_LSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        df1
    df1.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df1['Month'] = df1['Month'].map(d)

    df2 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[{'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
             {'USER_ID._id':{'$in':school}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#              {'USER_ID.schoolId._id':ObjectId("5f2bcad8ba0be61b0c1e9d5e")},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},  
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
       {'$project':{'_id':1,'teacher_CSY':'$pc'}}])))
    if df2.empty == True:
        df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'teacher_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        df2
    df2.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df2['Month'] = df2['Month'].map(d)

    practice_left= pd.merge(df1, df2,on='Month', how='outer')
    practice_left=practice_left.fillna(0)    

    dfschoology = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
            {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
         {'USER_ID._id':{'$in':school}},
#          {'USER_ID.schoolId._id':ObjectId("5f2bcad8ba0be61b0c1e9d5e")},
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},  
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
       {'$project':{'_id':1,'schoology_CSY':'$pc'}}])))

    if dfschoology.empty == True:
        dfschoology=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'schoology_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        dfschoology
    dfschoology.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    dfschoology['Month'] = dfschoology['Month'].map(d)
    dfschoology=dfschoology.fillna(0)


    dfclever = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
          {'USER_ID._id':{'$in':school}},
#          {'USER_ID.schoolId._id':ObjectId("5f2bcad8ba0be61b0c1e9d5e")},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},  
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
       {'$project':{'_id':1,'clever_CSY':'$pc'}}])))
    if dfclever.empty == True:
        dfclever=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'clever_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        dfclever
    dfclever.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    dfclever['Month'] = dfclever['Month'].map(d)
    dfclever=dfclever.fillna(0)

    df4 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[{'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
           {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID._id':{'$in':school}},
#              {'USER_ID.schoolId._id':ObjectId("5f2bcad8ba0be61b0c1e9d5e")},
             {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {"USER_ID.CREATED_DATE":{"$gte": datetime(2020,3,17)}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1}}},
       {'$project':{'_id':1,'parents_CSY':'$pc'}}])))
    if df4.empty == True:
        df4=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        df4
    df4.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df4['Month'] = df4['Month'].map(d)
    # df2
    mon=pd.DataFrame({'Month':[8,9,10,11,12,1,2,3,4,5,6,7]})
    d = dict(enumerate(calendar.month_abbr))
    mon['Month'] = mon['Month'].map(d)
   
    practice_LSYy= pd.merge(mon, df1,on='Month', how='left')
    practice_LSY= pd.merge(practice_LSYy, df2,on='Month', how='left')
    practice_CSY =pd.merge(practice_LSY, dfschoology, on='Month', how='left')
    practice_CSY =pd.merge(practice_CSY, dfclever, on='Month', how='left')
    data =pd.merge(practice_CSY, df4, on='Month', how='left').fillna(0)

    

#     data=pd.merge(mon,practice_CSY,on='Month',how='left').fillna(0)
    Month=data['Month'].tolist()
    TOTAL_LSY=data['TOTAL_LSY'].tolist()
   
    teacher_CSY=data['teacher_CSY'].tolist()
    parents_CSY=data['parents_CSY'].tolist()
    schoology_CSY=data['schoology_CSY'].tolist()
    clever_CSY=data['clever_CSY'].tolist()
    temp=[{'Month':Month,'curve':TOTAL_LSY,'bar':teacher_CSY},{'bar2':parents_CSY},{'bars':schoology_CSY},{'barc': clever_CSY}]

    return  json.dumps(temp)
# school_practice_trend('5f2bcad8ba0be61b0c1e9d5e')

@app.route('/schoolactivetrendnew/<schoolid>')
def school_active_trend(schoolid):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    from datetime import datetime
    df00 = DataFrame(list(db.user_master.aggregate([
        {"$match":
            {'schoolId._id':ObjectId(""+schoolid+"")}
        },
        {'$project':{'_id':1,'school':'$schoolId._id'}}])))
    school=df00['_id'].tolist()
    
    df1 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[

     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}}, 
         {'USER_ID._id':{'$in':school}},
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},  
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},

                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": LSY_Date(),
                                        "$lt":csy_first_date()}}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$addToSet':'$USER_ID._id'}}},
       {'$project':{'_id':1,'TOTAL_LSY':{'$size':'$pc'}}}])))
    if df1.empty == True:
        df1=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'TOTAL_LSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        df1
    df1.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df1['Month'] = df1['Month'].map(d)

    df2 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[{'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
             {'USER_ID._id':{'$in':school}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#              {'USER_ID.schoolId._id':ObjectId("5f2bcad8ba0be61b0c1e9d5e")},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},  
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$addToSet':'$USER_ID._id'}}},
       {'$project':{'_id':1,'teacher_CSY':{'$size':'$pc'}}}])))
    if df2.empty == True:
        df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'teacher_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        df2
    df2.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df2['Month'] = df2['Month'].map(d)

    practice_left= pd.merge(df1, df2,on='Month', how='outer')
    practice_left=practice_left.fillna(0)    

    dfschoology = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
            {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
         {'USER_ID._id':{'$in':school}},
#          {'USER_ID.schoolId._id':ObjectId("5f2bcad8ba0be61b0c1e9d5e")},
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},  
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$addToSet':'$USER_ID._id'}}},
       {'$project':{'_id':1,'schoology_CSY':{'$size':'$pc'}}}])))

    if dfschoology.empty == True:
        dfschoology=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'schoology_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        dfschoology
    dfschoology.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    dfschoology['Month'] = dfschoology['Month'].map(d)
    dfschoology=dfschoology.fillna(0)


    dfclever = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
          {'USER_ID._id':{'$in':school}},
#          {'USER_ID.schoolId._id':ObjectId("5f2bcad8ba0be61b0c1e9d5e")},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},  
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$addToSet':'$USER_ID._id'}}},
       {'$project':{'_id':1,'clever_CSY':{'$size':'$pc'}}}])))
    if dfclever.empty == True:
        dfclever=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'clever_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        dfclever
    dfclever.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    dfclever['Month'] = dfclever['Month'].map(d)
    dfclever=dfclever.fillna(0)

    df4 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[{'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
           {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
             { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},  
             {'USER_ID._id':{'$in':school}},
#              {'USER_ID.schoolId._id':ObjectId("5f2bcad8ba0be61b0c1e9d5e")},
             {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {"USER_ID.CREATED_DATE":{"$gte": datetime(2020,3,17)}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$addToSet':'$USER_ID._id'}}},
       {'$project':{'_id':1,'parents_CSY':{'$size':'$pc'}}}])))
    if df4.empty == True:
        df4=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        df4
    df4.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df4['Month'] = df4['Month'].map(d)
    # df2
    mon=pd.DataFrame({'Month':[8,9,10,11,12,1,2,3,4,5,6,7]})
    d = dict(enumerate(calendar.month_abbr))
    mon['Month'] = mon['Month'].map(d)

    practice_LSYy= pd.merge(mon, df1,on='Month', how='left')
    practice_LSY= pd.merge(practice_LSYy, df2,on='Month', how='left')
    practice_CSY =pd.merge(practice_LSY, dfschoology, on='Month', how='left')
    practice_CSY =pd.merge(practice_CSY, dfclever, on='Month', how='left')
    data =pd.merge(practice_CSY, df4, on='Month', how='left').fillna(0)

    
    
    Month=data['Month'].tolist()
    TOTAL_LSY=data['TOTAL_LSY'].tolist()
   
    teacher_CSY=data['teacher_CSY'].tolist()
    parents_CSY=data['parents_CSY'].tolist()
    schoology_CSY=data['schoology_CSY'].tolist()
    clever_CSY=data['clever_CSY'].tolist()
    temp=[{'Month':Month,'curve':TOTAL_LSY,'bar':teacher_CSY},{'bar2':parents_CSY},{'bars':schoology_CSY},{'barc': clever_CSY}]

    return json.dumps(temp)
# school_active_trend('5f2bcad8ba0be61b0c1e9d5e')



@app.route('/user_audio_completion/<emailid>')
def user_audio_completion_____(emailid):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass

    collection1= db.audio_track_master

    qr1=[{"$match":{
    '$and':[
        {'USER_ID.EMAIL_ID':""+emailid+""},
        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #         {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    #     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    #     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

    #     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    #     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    #     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    #     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
#         {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':csy_first_date()
    }},
    ]}},


    {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
                 'AUDIO_ID':'$PROGRAM_AUDIO_ID._id', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
              'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

    }}]

    list1= list(collection1.aggregate(qr1))
    userprac_trend= DataFrame(list1)
    if userprac_trend.empty is True:
        data={'Result':0}
        return json.dumps(data)
    else:
        userprac_trend.start.fillna(0, inplace=True)
#         userprac_trend=userprac_trend.fillna(0)
        columns=userprac_trend.columns
        #     print(columns)
        if not 'Start' in columns :
            userprac_trend['Start']=0
        else:
            userprac_trend

        userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

        userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

        userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

        dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

        userprac_trend[userprac_trend.completed_precentage < 0]=0


        userprac_trend['start']=userprac_trend['start'].fillna(0)
        userprac_trend['end']=userprac_trend['end'].fillna(0)
        userprac_trend['completed_precentage']=userprac_trend['completed_precentage'].fillna(0)
        userprac_trend['AUDIO_ID']=userprac_trend['AUDIO_ID'].fillna(0)


        dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

        dd['cumulativesum_line']= dd['Audio_Count'].cumsum()


        percentage_of_audio_completed= dd.completed_precentage.tolist(),
        number_of_audios_compelted=dd.Audio_Count.tolist()
        cumulative_audio_completion=dd.cumulativesum_line.tolist()

        temp1={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
             'cumulative_audio_completion':cumulative_audio_completion}
#         data={'temp':temp}
        
        qr1=[{"$match":{
        '$and':[
            {'USER_ID.EMAIL_ID':""+emailid+""},
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        #         {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        #     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        #     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},


        #     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        #     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        #     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        #     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        # {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{"$not":{"$regex":"wellness",'$options':'i'}}},
        #             {'PROGRAM_AUDIO_ID.AUDIO_DAY':{"$not":{"$regex":"bonus",'$options':'i'}}},
        #           {'PROGRAM_AUDIO_ID.AUDIO_DAY':{"$not":{"$regex":"sound",'$options':'i'}}},
        #             {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'Counselor','$options':'i'}}},    
        #             {"PROGRAM_AUDIO_ID.AUDIO_DAY":{"$not":{"$regex":'Bonus','$options':'i'}}},

        {'MODIFIED_DATE':{'$gte':csy_first_date()
        }},
        ]}},


        {'$group':{'_id':'$PROGRAM_AUDIO_ID._id','audio_day':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'}, 'modified_date':{'$max':'$MODIFIED_DATE'},
                     'Program_Name':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
                  'Audio_Length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'}, 'start':{'$min':'$cursorStart'},'end':{'$max':'$CURSOR_END'  }           

        }}]

        list1= list(collection1.aggregate(qr1))
        userprac_trend= DataFrame(list1)
        columns=userprac_trend.columns
        #     print(columns)
        if not 'Start' in columns :
            userprac_trend['Start']=0
        else:
            userprac_trend
        # userprac_trend
        userprac_trend.start.fillna(0, inplace=True)

        userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

        userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

        userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

        userprac_trend[userprac_trend.completed_precentage < 0]=0


        userprac_trend['start']=userprac_trend['start'].fillna(0)
        userprac_trend['end']=userprac_trend['end'].fillna(0)
        userprac_trend['completed_precentage']=userprac_trend['completed_precentage'].fillna(0)
        userprac_trend['_id']=userprac_trend['_id'].fillna(0)


        dd=userprac_trend.groupby('completed_precentage')['_id'].count().reset_index().rename({'_id':'Audio_Count'},axis=1)
        dd['cumulativesum_line']= dd['Audio_Count'].cumsum()


        percentage_of_audio_completed= dd.completed_precentage.tolist(),
        number_of_audios_compelted=dd.Audio_Count.tolist()
        cumulative_audio_completion=dd.cumulativesum_line.tolist()

        temp2={'percentage_of_uniuqe_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
             'cumulative_unique_audio_played':cumulative_audio_completion}

        data = {'temp1':temp1,'temp2':temp2}      
        
        return json.dumps(data)
# user_audio_completion_____('sadhna@1gen.io')


@app.route('/family_audio_completion/<emailid>')
def family_audio_completion_____(emailid):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass

    collection1= db.audio_track_master

    qr1=[{"$match":{
    '$and':[
        {'USER_ID.EMAIL_ID':""+emailid+""},
        {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    #         {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    #     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    #     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

    #     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    #     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    #     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    #     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
#         {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':csy_first_date()
    }},
    ]}},


    {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
                 'AUDIO_ID':'$PROGRAM_AUDIO_ID._id', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
              'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

    }}]

    list1= list(collection1.aggregate(qr1))
    userprac_trend= DataFrame(list1)
    if userprac_trend.empty is True:
        data={'Result':0}
        return json.dumps(data)
    else:
        userprac_trend.start.fillna(0, inplace=True)
#         userprac_trend=userprac_trend.fillna(0)
        columns=userprac_trend.columns
        #     print(columns)
        if not 'Start' in columns :
            userprac_trend['Start']=0
        else:
            userprac_trend

        userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

        userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

        userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

        dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

        userprac_trend[userprac_trend.completed_precentage < 0]=0


        userprac_trend['start']=userprac_trend['start'].fillna(0)
        userprac_trend['end']=userprac_trend['end'].fillna(0)
        userprac_trend['completed_precentage']=userprac_trend['completed_precentage'].fillna(0)
        userprac_trend['AUDIO_ID']=userprac_trend['AUDIO_ID'].fillna(0)


        dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

        dd['cumulativesum_line']= dd['Audio_Count'].cumsum()


        percentage_of_audio_completed= dd.completed_precentage.tolist(),
        number_of_audios_compelted=dd.Audio_Count.tolist()
        cumulative_audio_completion=dd.cumulativesum_line.tolist()

        temp1={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
             'cumulative_audio_completion':cumulative_audio_completion}
#         data={'temp':temp}
        
        qr1=[{"$match":{
        '$and':[
            {'USER_ID.EMAIL_ID':""+emailid+""},
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        #         {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        #     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        #     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},


        #     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        #     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        #     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        #     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        # {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{"$not":{"$regex":"wellness",'$options':'i'}}},
        #             {'PROGRAM_AUDIO_ID.AUDIO_DAY':{"$not":{"$regex":"bonus",'$options':'i'}}},
        #           {'PROGRAM_AUDIO_ID.AUDIO_DAY':{"$not":{"$regex":"sound",'$options':'i'}}},
        #             {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'Counselor','$options':'i'}}},    
        #             {"PROGRAM_AUDIO_ID.AUDIO_DAY":{"$not":{"$regex":'Bonus','$options':'i'}}},

        {'MODIFIED_DATE':{'$gte':csy_first_date()
        }},
        ]}},


        {'$group':{'_id':'$PROGRAM_AUDIO_ID._id','audio_day':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'}, 'modified_date':{'$max':'$MODIFIED_DATE'},
                     'Program_Name':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
                  'Audio_Length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'}, 'start':{'$min':'$cursorStart'},'end':{'$max':'$CURSOR_END'  }           

        }}]

        list1= list(collection1.aggregate(qr1))
        userprac_trend= DataFrame(list1)
        columns=userprac_trend.columns
        #     print(columns)
        if not 'Start' in columns :
            userprac_trend['Start']=0
        else:
            userprac_trend
        # userprac_trend
        userprac_trend.start.fillna(0, inplace=True)

        userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

        userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

        userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

        userprac_trend[userprac_trend.completed_precentage < 0]=0


        userprac_trend['start']=userprac_trend['start'].fillna(0)
        userprac_trend['end']=userprac_trend['end'].fillna(0)
        userprac_trend['completed_precentage']=userprac_trend['completed_precentage'].fillna(0)
        userprac_trend['_id']=userprac_trend['_id'].fillna(0)


        dd=userprac_trend.groupby('completed_precentage')['_id'].count().reset_index().rename({'_id':'Audio_Count'},axis=1)
        dd['cumulativesum_line']= dd['Audio_Count'].cumsum()


        percentage_of_audio_completed= dd.completed_precentage.tolist(),
        number_of_audios_compelted=dd.Audio_Count.tolist()
        cumulative_audio_completion=dd.cumulativesum_line.tolist()

        temp2={'percentage_of_uniuqe_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
             'cumulative_unique_audio_played':cumulative_audio_completion}

        data = {'temp1':temp1,'temp2':temp2}      
        
        return json.dumps(data)
# user_audio_completion_____('sadhna@1gen.io')





@app.route('/schoolaudio_completion/<schoolid>')
def school_audio_completion_____(schoolid):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass

    collection1= db.audio_track_master
    
    df1=DataFrame(list(db.user_master.aggregate([
        {"$match":{"$and":[
        {"schoolId._id":ObjectId(""+schoolid+"")},
             {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'EMAIL_ID':{"$ne":''}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
      {'schoolId.NAME':{"$not":{"$regex":'test', '$options':'i'}}},
         {'EMAIL_ID':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":"TEST",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}
        ]}},
    {"$project":{"_id":"$_id","ID":"$schoolId._id",
                }}
    ])))
    df1
    if df1.empty == True:
        data={'Result':0}
    else:
        df1=df1.fillna('No info')
    column1 =['_id',"ID"]
    for i in column1:
        if i not in df1.columns:
            df1[i] = 0
    email=df1['_id'].tolist()
    school=df1['ID'].tolist()

    qr1=[{"$match":{
    '$and':[
        {'USER_ID._id':{'$in':email}},
    {'MODIFIED_DATE':{'$gte':csy_first_date()
    }},
    ]}},


    {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
                 'AUDIO_ID':'$PROGRAM_AUDIO_ID._id', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
              'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

    }}]

    list1= list(collection1.aggregate(qr1))
    userprac_trend= DataFrame(list1)
    if userprac_trend.empty is True:
        data={'Result':0}
        return json.dumps(data)
    else:
        userprac_trend.start.fillna(0, inplace=True)
#         userprac_trend=userprac_trend.fillna(0)
        columns=userprac_trend.columns
        #     print(columns)
        if not 'Start' in columns :
            userprac_trend['Start']=0
        else:
            userprac_trend

        userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

        userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

        userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

        dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

        userprac_trend[userprac_trend.completed_precentage < 0]=0


        userprac_trend['start']=userprac_trend['start'].fillna(0)
        userprac_trend['end']=userprac_trend['end'].fillna(0)
        userprac_trend['completed_precentage']=userprac_trend['completed_precentage'].fillna(0)
        userprac_trend['AUDIO_ID']=userprac_trend['AUDIO_ID'].fillna(0)


        dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

        dd['cumulativesum_line']= dd['Audio_Count'].cumsum()


        percentage_of_audio_completed= dd.completed_precentage.tolist(),
        number_of_audios_compelted=dd.Audio_Count.tolist()
        cumulative_audio_completion=dd.cumulativesum_line.tolist()

        temp1={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
             'cumulative_audio_completion':cumulative_audio_completion}
#         data={'temp':temp}
        
        qr1=[{"$match":{
        '$and':[
           {'USER_ID._id':{'$in':email}},
        {'MODIFIED_DATE':{'$gte':csy_first_date()
        }},
        ]}},


        {'$group':{'_id':'$PROGRAM_AUDIO_ID._id','audio_day':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'}, 'modified_date':{'$max':'$MODIFIED_DATE'},
                     'Program_Name':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
                  'Audio_Length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'}, 'start':{'$min':'$cursorStart'},'end':{'$max':'$CURSOR_END'  }           

        }}]

        list1= list(collection1.aggregate(qr1))
        userprac_trend= DataFrame(list1)
        columns=userprac_trend.columns
        #     print(columns)
        if not 'Start' in columns :
            userprac_trend['Start']=0
        else:
            userprac_trend
        # userprac_trend
        userprac_trend.start.fillna(0, inplace=True)

        userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

        userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

        userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

        userprac_trend[userprac_trend.completed_precentage < 0]=0


        userprac_trend['start']=userprac_trend['start'].fillna(0)
        userprac_trend['end']=userprac_trend['end'].fillna(0)
        userprac_trend['completed_precentage']=userprac_trend['completed_precentage'].fillna(0)
        userprac_trend['_id']=userprac_trend['_id'].fillna(0)


        dd=userprac_trend.groupby('completed_precentage')['_id'].count().reset_index().rename({'_id':'Audio_Count'},axis=1)
        dd['cumulativesum_line']= dd['Audio_Count'].cumsum()


        percentage_of_audio_completed= dd.completed_precentage.tolist(),
        number_of_audios_compelted=dd.Audio_Count.tolist()
        cumulative_audio_completion=dd.cumulativesum_line.tolist()

        temp2={'percentage_of_uniuqe_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
             'cumulative_unique_audio_played':cumulative_audio_completion}

        data = {'temp1':temp1,'temp2':temp2}      
        
        return json.dumps(data)


@app.route('/schoolsearchid/<schoolid>')
def schoolsearch_em_id(schoolid):
    from datetime import datetime
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = MongoClient(mongo_uri)
    
    db = client["compass"]
    df1=DataFrame(list(db.user_master.aggregate([
        {"$match":{"$and":[
        {"schoolId._id":ObjectId(""+schoolid+"")},
             {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'EMAIL_ID':{"$ne":''}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
      {'schoolId.NAME':{"$not":{"$regex":'test', '$options':'i'}}},
         {'EMAIL_ID':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":"TEST",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}
        ]}},
    {"$project":{"_id":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME",'user':"$USER_NAME",'CREATED_DATE':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$CREATED_DATE'}}},

                 "Address":"$schoolId.ADDRESS","COUNTRY":"$schoolId.COUNTRY","CITY":"$schoolId.CITY","STATE":"$schoolId.STATE","USER_NAME":"$USER_NAME",
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME","ROLE":'$ROLE_ID.ROLE_NAME'
                }}
    ])))
    df1
    if df1.empty == True:
        data={'Result':0}
    else:
        df1=df1.fillna('No info')
    column1 =['_id',"ID","school_name",'user',"Address","COUNTRY","CITY","STATE","USER_NAME","email_id","district_name","ROLE"]
    for i in column1:
        if i not in df1.columns:
            df1[i] = 'No info'
    email=df1['_id'].tolist()
    school=df1['ID'].tolist()
    
    df3=DataFrame(list(db.audio_track_master.aggregate([
        {"$match":{'$and':[
                       {'USER_ID._id':{"$in":email}},
                            {'MODIFIED_DATE':{'$gte':csy_first_date()}}
        ]}},    


        {'$group':{'_id' : '$USER_ID._id', 'pc':{'$sum':1},'Mindful_Minutes_csy':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}},
        'AUDIO_DAY':{'$last':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
        'PROGRAM':{'$last':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
        'AUDIO':{'$last':'$PROGRAM_AUDIO_ID.AUDIO_NAME'},
        'last_practice_date_csy':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}}}, }}

        ]))).fillna(0)
    
    
    if df3.empty==True:
        df3=pd.DataFrame({'_id':email})
        df3['last_practice_date_csy'] = pd.Series(['NO PRACTICE' for x in range(len(df3.index))])
        df3['pc'] = pd.Series([0 for x in range(len(df3.index))])
        df3['Mindful_Minutes_csy'] = pd.Series([0 for x in range(len(df3.index))])
#         df3 = df3.transpose()
    column3 =['_id','last_practice_date_csy','pc','Mindful_Minutes_csy']
    for i in column3:
        df3=df3.fillna('')
        if i not in df3.columns:
            df3[i] = 'No info'
            
    df0=DataFrame(list(db.audio_track_master.aggregate([
        {"$match":{'$and':[
                       {'USER_ID._id':{"$in":email}},
#                             {'MODIFIED_DATE':{'$gte':csy_first_date()}}
        ]}},    


        {'$group':{'_id' : '$USER_ID._id', 'pc_overall':{'$sum':1},'Mindful_Minutes_overall':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}},
        'AUDIO_DAY':{'$last':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
        'PROGRAM':{'$last':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
        'AUDIO':{'$last':'$PROGRAM_AUDIO_ID.AUDIO_NAME'},
        'last_practice_date':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}}}, }}

        ])))
    
    if df0.empty==True:
        df0=pd.DataFrame({'_id':email})
        df0['last_practice_date'] = pd.Series(['NO PRACTICE' for x in range(len(df0.index))])
        df0['pc_overall'] = pd.Series([0 for x in range(len(df0.index))])
        df0['Mindful_Minutes_overall'] = pd.Series([0 for x in range(len(df0.index))])
    column0 =['_id','last_practice_date','pc_overall','Mindful_Minutes_overall']
    for i in column0:
        df0=df0.fillna('')
        if i not in df0.columns:
            df0[i] = 'No info'        
            
    


    df4=DataFrame(list(db.subscription_master.aggregate([
        {"$match":{'$and':[
                       {'USER_ID._id':{"$in":email}},
                          ]}},    


        {'$project':{'_id' : '$USER_ID._id',
        'PLAN':'$PLAN_ID.PLAN_NAME',
        'Renewal_date':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$SUBSCRIPTION_EXPIRE_DATE'}}}, }}

        ])))
    if df4.empty==True:
        df4=pd.DataFrame({'_id':email})
        df4['PLAN'] = pd.Series(['NO INFO' for x in range(len(df4.index))])
        df4['Renewal_date'] = pd.Series(['NO INFO' for x in range(len(df4.index))])
    column4 =['Renewal_date',"PLAN"]
    for i in column4:
        if i not in df4.columns:
            df4[i] = 'No info'

    df=pd.merge(df1,df3,on='_id',how='left')
    df['pc']=df['pc'].fillna(0)
    df['Mindful_Minutes_csy']=df['Mindful_Minutes_csy'].fillna(0)
    dff=pd.merge(df,df0,on='_id',how='left')
    dff['pc_overall']=dff['pc_overall'].fillna(0)
    dff['last_practice_date']=dff['last_practice_date'].fillna('NO PRACTICE')
    dff['Mindful_Minutes_overall']=dff['Mindful_Minutes_overall'].fillna(0)
    dfff=pd.merge(dff,df4,on='_id',how='left')
    dfff['Renewal_date']=dfff['Renewal_date'].fillna('0')
    DF=dfff[['user','email_id','CREATED_DATE','last_practice_date','Renewal_date','pc_overall','pc','last_practice_date','Mindful_Minutes_csy','Mindful_Minutes_overall']]
    DFF=dfff[['user','email_id','CREATED_DATE','last_practice_date','Renewal_date','pc_overall','pc']]
    table=DFF.values.tolist()
           
    
    
    
    pc=DF['pc'].sum()
    pc_overall=DF['pc_overall'].sum()
    Mindful_Minutes_csy=DF['Mindful_Minutes_csy'].sum()
    Mindful_Minutes_overall=DF['Mindful_Minutes_overall'].sum()
    
    
    
    
    df00=DataFrame(list(db.user_master.aggregate([
        {"$match":{"$and":[
       {'_id':{"$in":email}},
#              {'IS_ADMIN':'Y'},
        ]}},
        {'$group':{'_id':'','uc':{'$addToSet':'$_id'}}},
    {"$project":{"_id":0,"user_count":{"$size":'$uc'}}}
    ])))
#     column2 =['ADMIN_NAME',"ADMIN_EMAIL"]


    if df00.empty==True:
        df00=pd.DataFrame({"user_count":[0]})
    else:
        df00

    df2=DataFrame(list(db.user_master.aggregate([
        {"$match":{"$and":[
        {"schoolId._id":{"$in":school}},

             {'IS_ADMIN':'Y'},
        ]}},
    {"$project":{"ADMIN_EMAIL":"$EMAIL_ID","ADMIN_NAME":"$USER_NAME",'ADMIN_ID':'$_id',}}
    ])))
    column2 =['ADMIN_NAME',"ADMIN_EMAIL",'ADMIN_ID']


    if df2.empty==True:
        df2=pd.DataFrame({"ADMIN_EMAIL":['No info'],'ADMIN_NAME':['No info'],'ADMIN_ID':['No info']})

    for i in column2:       
        if i not in df2.columns:
            df2[i] = 'No info'
#        
    ADMIN_NAME=df2['ADMIN_NAME'].tolist()
    ADMIN_EMAIL=df2['ADMIN_EMAIL'].tolist()
    ADMIN_ID=df2['ADMIN_ID'].tolist()
    
    
    
    df44=DataFrame(list(db.invite_master.aggregate([
        {"$match":{'$and':[
                       {'USER_ID._id':{"$in":ADMIN_ID}},
#             {'MODIFIED_DATE':{'$gte':csy_first_date()}}
#             {'COMMENT':{'$ne':None}}
                          ]}},    
#         {'$project':{'_id':0,'ADMIN':'$USER_ID._id'}}

        {'$group':{'_id' : '$USER_ID._id' ,'user':{'$sum':1} }}

        ])))
    
    
    
    if df44.empty == True:
        actual_admin =ADMIN_ID[0]
    else:
        df45=df44.loc[df44['user'] == df44['user'].max()]
#         print(df44)
        actual_admin=df45['_id'].tolist()
        
    
 
    df5=DataFrame(list(db.audio_feedback.aggregate([
        {"$match":{'$and':[
                       {'USER._id':{"$in":email}},
            {'MODIFIED_DATE':{'$gte':csy_first_date()}}
#             {'COMMENT':{'$ne':None}}
                          ]}},    


        {'$group':{'_id' : '$USER.schoolId._id', 'rating':{"$avg":"$RATING"},'COMMENT':{'$last':'$COMMENT'},

        'COMMENT_DATE':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}}},}}

        ])))
    if df5.empty==True:
        df5=pd.DataFrame({"COMMENT_DATE":['No info'],'rating':[0],'COMMENT':['No info']})
    column5 =['COMMENT_DATE',"rating","COMMENT"]
    for i in column5:
        if i not in df5.columns:
            df5[i] = 'No info'

    if "export" in request.args:
        try:
            DFF=DFF.rename(columns={'user':'USER NAME','email_id':'EMAIL ID','CREATED_DATE':'SIGNUP DATE','last_practice_date':'LAST PRACTICE DATE','Renewal_date':'RENEWAL DATE','pc_overall':'PLAYBACK COUNT','pc':'PLAYBACK COUNT(CSY)'})
            schoolname=db.school_master.find_one({'_id':ObjectId(str(schoolid))})['NAME']
            csv = DFF.to_csv(index=False)
            return Response(
                csv,
                mimetype="text/csv",
                headers={"Content-disposition":
                        "attachment; filename="+str(schoolname)+".csv"})
        except:
            return jsonify("Unauthorized Access")

    else:        
        data={'user_count':str(df00['user_count'][0]),'actual_admin':actual_admin, 'ADMIN_ID':ADMIN_ID,
            'Star_5_Ratings_Recieved':str(int(round(df5['rating'][0]))),'DISTRICT':df1['district_name'][0],
            'SCHOOL_MINDFUL_MINUTES_csy':str(int(Mindful_Minutes_csy)),
                    'SCHOOL_MINDFUL_MINUTES_overall':str(int(Mindful_Minutes_overall)),
            'school_name':df1['school_name'][0],'address':df1['Address'][0],'state':df1['STATE'][0],'city':df1['CITY'][0],'country':df1['COUNTRY'][0],
            'admin_email':ADMIN_EMAIL,'admin_name':ADMIN_NAME,'PRACTICE_COUNT_csy':str(int(pc)),'school_practice_count':str(int(pc_overall)),
            'RENEWAL_DATE':max(DF['Renewal_date']),
            'plan':df4['PLAN'][0],'data':table
                    }
        return json.dumps(data, default=str)
    # schoolsearch_em_id('5f2bcad6ba0be61b0c1e98fa')




# schoolsearch_em_id('5f2bca23ba0be61b0c1cc67c')
# schoolsearch_em_id('5f2bca32ba0be61b0c1cf643')

# schoolsearch_em_id('5f2bcadaba0be61b0c1ea1ee')

# new0('5f2bcad8ba0be61b0c1e9d5e')
# '5f2bcad8ba0be61b0c1e9d5e'
# lamundson@thecapitolschool.com


@app.route('/wordcloud_schoolsearch/<schoolid>')
def wordcloud_schoolsearch(schoolid):
    import nltk
    from nltk.corpus import stopwords
    from textblob import TextBlob
    from nltk import FreqDist
    import re
    clean_list=[]
    news_headlines_senti = []
    news_headlines_dict = {}
    pnews_headlines=0
    nnews_headlines=0
    nenews_headlines = 0
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass


    collection1=db.user_master
    query=[{"$match":{"$and":[
        {"schoolId._id":ObjectId(""+schoolid+"")},
             {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'EMAIL_ID':{"$ne":''}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
      {'schoolId.NAME':{"$not":{"$regex":'test', '$options':'i'}}},
         {'EMAIL_ID':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":"TEST",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}
        ]}},
        {'$project':{
            '_id':0,
            'USER_ID':'$_id',
            'schoolId':'$schoolId._id'
            }}]
    schoolinfo=DataFrame(list(collection1.aggregate(query)))
    list_of_names1=schoolinfo["USER_ID"].to_list()
#     schoolId=schoolinfo[0].get('schoolId')
    collection=db.audio_feedback
#     mydatetime= dateutil.parser.parse(datestr)
#     yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
#     tod=mydatetime+ timedelta(hours=4)
#     start= tod- timedelta(days=8)+timedelta(days=1)
#     start_15day= start-timedelta(days=8)+timedelta(days=1)
    user=[
    {"$match":{'$and':[ 
        
        { "USER._id":{"$in":list_of_names1}},
               
#                 {'MODIFIED_DATE':{'$gte': start, '$lt':yester}},
#                 {'USER._id':{'$in':db.user_master.distinct('_id',{'schoolId._id':schoolId})}},
                 {'MODIFIED_DATE':{'$gte':csy_first_date()}},
                       
            
                       {'COMMENT':{'$nin':['',' ', None,'.']}},
                  {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        ]}},
    { "$project": { "USER_ID": "$USER._id", "USER_NAME": "$USER.USER_NAME","_id":0, "EMAIL": "$USER.EMAIL_ID", "RATING":1,
    "LAST_COMMENT_DATE": "$MODIFIED_DATE", "AUDIO_NAME": "$AUDIO_ID.AUDIO_NAME", "NARRATOR_NAME": "$AUDIO_ID.NARRATEDBY",
    "COMMENT":1, "PROGRAM_NAME": "$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME"}}
    ]
    update=list(collection.aggregate(user))
    df123=pd.DataFrame(update).fillna("no info")
    if df123.empty:
        return json.dumps({'Result':0})
    else:
        list_of_names=df123["USER_ID"].to_list()
        xx=df123[df123["COMMENT"]!="no info"]
        xxc=xx[xx["COMMENT"]!=""]
        comment_list=xxc["COMMENT"].to_list()
        newtexttoken=[]
        
        import nltk
    #     nltk.download('punkt')
    #     nltk.download()
        nltk.download('stopwords')
    
        for i in comment_list:
            text_tokens = nltk.tokenize.word_tokenize(i)
            newtexttoken.append(text_tokens)
        newlist=[]
        for i in newtexttoken:
            for z in i:
                newlist.append(z.lower())
        st_word=stopwords.words('english')
        tokens_without_sw= [word for word in newlist if not word in st_word]
        token5=[]
        for sentence in tokens_without_sw:
            text3 = sentence.split('ing')    
            for i in text3:
                token5.append(i)
        words = [w.replace('liked', 'like') for w in token5]
        words2 = [w.replace('relaxed', 'relax') for w in words]
        words3 = [w.replace('relaxing', 'relax') for w in words2]
        words4 = [w.replace('excitinging', 'excited') for w in words3]
        zxc=""
        name=""
        count=""
        try:
            xcvv=[x for x in words4 if len(x)>3]
            fdist=FreqDist(xcvv)
            df_fdist = pd.DataFrame.from_dict(fdist, orient='index')
        #         print(df_fdist)
            df_fdist.columns = ['Frequency']
            df_fdist.index.name = 'Term'
            xc=df_fdist.sort_values(by='Frequency', ascending=False, na_position='first')
            #     tt=xc.drop(["i","it","we","made","us","the","feeling","some","students"])
            cc=xc[0:10]
            name=cc.index.to_list()
            count=cc["Frequency"].to_list()
            zxc=' '.join(word for word in xcvv)
        except:
            pass
        for item in comment_list:
            # trim
            item = item.strip()
            # Removing RT
            item = item.replace('RT', '')
            # Removing new line character
            item = item.replace('\\n', '')
            # Replace #word with word
            news_headlines = re.sub(r'#([^\s]+)', r'\1', item)
            # Convert @username to username
            news_headlines = re.sub(r'@([^\s]+)', r'\1', item)
            item = " ".join(re.findall("[a-zA-Z]+", item))
            tmp_var = re.sub(r'^\S*\s', '', item)
            clean_list.append(tmp_var)
        for item in clean_list:
                #print(item)
                # create TextBlob object of passed news_headlines text
                analysis = TextBlob(item)
                # set sentiment
                if analysis.sentiment.polarity > 0:
                    # saving sentiment of news_headlines
                    news_headlines_score = 'positive'
                    pnews_headlines = pnews_headlines + 1
                    news_headlines_dict[item] = news_headlines_score
                elif analysis.sentiment.polarity == 0:
                    # saving sentiment of news_headlines
                    news_headlines_score = 'neutral'
                    nenews_headlines = nenews_headlines + 1
                    news_headlines_dict[item] = news_headlines_score
                else:
                    # saving sentiment of news_headlines
                    news_headlines_score = 'negative'
                    nnews_headlines = nnews_headlines + 1
                    news_headlines_dict[item] = news_headlines_score
        # print(clean_list)
        newssentiment=[]
        # for k, v in news_headlines_dict.items():
        #     print(k,':',v)
        for k, v in news_headlines_dict.items():
            if v == "positive":
                newssentiment.append({"sentiment":int(1),"text":k})
            elif v == "negative":
                newssentiment.append({"sentiment":int(-1),"text":k})
            else:
                newssentiment.append({"sentiment":int(0),"text":k})
        newssentiment_dataframe=pd.DataFrame.from_dict(newssentiment)
#         neg = 100 * (nnews_headlines) / ((nnews_headlines) + (pnews_headlines))
#         pos = 100 * (pnews_headlines) / ((nnews_headlines) + (pnews_headlines))
        
        try:
            neg = 100 * (nnews_headlines) / ((nnews_headlines) + (pnews_headlines))
        except ZeroDivisionError:
            neg = 0

        try:
            pos = 100 * (pnews_headlines) / ((nnews_headlines) + (pnews_headlines))
        except ZeroDivisionError:
            pos = 0
        
        df123["SCORE"]=""
        for i in range(len(df123)):
            try:
                analysis = TextBlob(df123["COMMENT"][i])
                if analysis.sentiment.polarity > 0:
                    df123.at[i,"SCORE"]= 1
        #             
                elif analysis.sentiment.polarity == 0:
                    df123.at[i,"SCORE"]= 0
                else:
                    df123.at[i,"SCORE"]= -1
            except:
                df123.at[i,"SCORE"]= 0
#         df123['just_date'] = df123['LAST_COMMENT_DATE'].dt.date
        df123['just_date']=pd.to_datetime(df123['LAST_COMMENT_DATE'], errors='coerce')
    
        xccx=df123.sort_values(by='just_date')
        xccx=df123.dropna()
        negdf=xccx[xccx["SCORE"]==-1]
        posdf=xccx[xccx["SCORE"]==1]
        df123['LAST_COMMENT_DATE']=pd.to_datetime(df123["LAST_COMMENT_DATE"]).dt.strftime('%Y-%m-%d')
        positivep=df123[df123["SCORE"]==1]
        df1234=positivep.groupby(["LAST_COMMENT_DATE"])["SCORE"].count().reset_index()
        df14i=df1234[["LAST_COMMENT_DATE","SCORE"]]
        df14i['LAST_COMMENT_DATE'] = pd.to_datetime(df14i['LAST_COMMENT_DATE'])
        df15i=df14i.sort_values(by='LAST_COMMENT_DATE')
        df15i['LAST_COMMENT_DATE']=df15i['LAST_COMMENT_DATE'].astype(np.int64)/int(1e6)
        shp1=df15i[["LAST_COMMENT_DATE","SCORE"]].values.tolist()
        negativen=df123[df123["SCORE"]==-1]
        df12345=negativen.groupby(["LAST_COMMENT_DATE"])["SCORE"].count().reset_index()
        df14ii=df12345[["LAST_COMMENT_DATE","SCORE"]]
        df14ii['LAST_COMMENT_DATE'] = pd.to_datetime(df14ii['LAST_COMMENT_DATE'])
        df15ii=df14ii.sort_values(by='LAST_COMMENT_DATE')
        df15ii['LAST_COMMENT_DATE']=df15ii['LAST_COMMENT_DATE'].astype(np.int64)/int(1e6)
        shp2=df15ii[["LAST_COMMENT_DATE","SCORE"]].values.tolist()
        df123['LAST_COMMENT_DATE']=pd.to_datetime(df123["LAST_COMMENT_DATE"]).dt.strftime('%Y-%m-%d')
        word_chart={"word_cloud":zxc}
#         word_chart={'positive':shp1,'negative':shp2,"word_cloud":zxc,"label":name,"count":count,"donut":{"pos":round(pos, 2),"neg":round(neg, 2)}}
        return json.dumps(word_chart)
# wordcloud('5f2bcad8ba0be61b0c1e9d5e')


@app.route('/schoolseacrhprogram_chart/<schoolid>')
def prog_prac_admin_search(schoolid):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass

    
    collection = db.user_master
    user=[
        {"$match":{"$and":[
        {"schoolId._id":ObjectId(""+schoolid+"")},
             {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'EMAIL_ID':{"$ne":''}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
      {'schoolId.NAME':{"$not":{"$regex":'test', '$options':'i'}}},
         {'EMAIL_ID':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":"TEST",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}
        ]}},
              { "$project": { "USER_ID":"$_id","_id":0,
                            }}
        ]
    update=list(collection.aggregate(user))
    df00=pd.DataFrame(update)
#     print(df00,'DF00')
    list_of_names1=df00["USER_ID"].to_list()
    collection = db.audio_track_master
    prog_prac_table1 = DataFrame(list(collection.aggregate([
     {"$match":{
         '$and':[ { "USER_ID._id":{"$in":list_of_names1}},
        
        {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{"$not":{"$regex":"wellness",'$options':'i'}}},
            {'PROGRAM_AUDIO_ID.AUDIO_DAY':{"$not":{"$regex":"bonus",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.AUDIO_DAY':{"$not":{"$regex":"sound",'$options':'i'}}},
            {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'Counselor','$options':'i'}}},    
            {"PROGRAM_AUDIO_ID.AUDIO_DAY":{"$not":{"$regex":'Bonus','$options':'i'}}},
                  {"MODIFIED_DATE":{'$gte':csy_first_date()}},
#               
#                       {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':{'$nin':[1,2,3,4,5,6,7,8]}},
#         {'MODIFIED_DATE':{'$gte': startdate, '$lte':enddate}}
                ]}},
    {'$group':{'_id':{'pn':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID','Month':{'$month':'$MODIFIED_DATE'}}, 'auc': {'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},
               'pg':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}}},
    {'$project':{'pg':'$pg','pn':'$_id.pn','Month':'$_id.Month', 'Active_usercount in 2020-2021':{'$size':'$auc'},'_id':0,'pc':'$pc'}},
      { "$sort":{'pg' : 1 }}])))
    df1 = pd.DataFrame(prog_prac_table1)

#     print(df1,'DF1')
    index=[0,1,2,3,4,5,6,7,8,9,10,11]
    if df1.empty:
        data={"month": ["Aug", "Sep", "Oct", "Nov", "Dec", "Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul"], 
              "elem": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "prek": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 
              "mid": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "high": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
             "elem_pc": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "prek_pc": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 
              "mid_pc": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], "high_pc": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}
    else:
        df1["pn"]=df1["pn"].replace({1:11, 2:12, 3:13, 4:9})
        data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 
        df9 = pd.DataFrame(data, columns = ['Monthname', 'Month']) 

        DF=pd.merge(df9,df1, on='Month',how='left').fillna(0)
        DF=DF.sort_values(by=['pn'])
        month=DF['Month'].tolist()
        prog_prac_table=DF
        month=['Aug','Sep','Oct','Nov','Dec','Jan','Feb','Mar','Apr','May','Jun','Jul']

        elem=[]
        mid=[]
        pre=[]
        high=[]
        elem_pc=[]
        mid_pc=[]
        pre_pc=[]
        high_pc=[]


        for i in set(prog_prac_table.pn.tolist()):
            for j in month:
#                     print(j)
                if i==11:
                    df=prog_prac_table[prog_prac_table['pn']==i]

                    try:
                        df__=df[df['Monthname']==j]['Active_usercount in 2020-2021']
                        pre.append(int(df__))
                        
                        df_=df[df['Monthname']==j]['pc']
                        pre_pc.append(int(df_))

                    except:
                        pre_pc.append(0)
                        pre.append(0)
            
                elif i==12:
                    df=prog_prac_table[prog_prac_table['pn']==i]
                    try:
                        df__=df[df['Monthname']==j]['Active_usercount in 2020-2021']
                        elem.append(int(df__))
                        df_=df[df['Monthname']==j]['pc']
                        elem_pc.append(int(df_))

                    except:
                        elem_pc.append(0)
                        elem.append(0)
                elif i==13:
                    df=prog_prac_table[prog_prac_table['pn']==i]
                    try:
                        df__=df[df['Monthname']==j]['Active_usercount in 2020-2021']
                        mid.append(int(df__))
                        df_=df[df['Monthname']==j]['pc']
                        mid_pc.append(int(df_))

                    except:
                        mid_pc.append(0)
                        mid.append(0)
                elif i==9:
                    df=prog_prac_table[prog_prac_table['pn']==i]
#                         print(df)
                    try:
                        df__=df[df['Monthname']==j]['Active_usercount in 2020-2021']
#                             print(df)
                        high.append(int(df__))
                        df_=df[df['Monthname']==j]['pc']
                        high_pc.append(int(df_))

                    except:
                        high_pc.append(0)
                        high.append(0)            
                else:
                    break

            ll=[0,0,0,0,0,0,0,0,0,0,0,0]
        if len(elem)==0:    elem = ll
        if len(pre)==0:    pre =  ll
        if len(mid)==0:    mid =  ll
        if len(high)==0:    high = ll
#             if len(alls)==0:    alls = ll
        data={'month':month,'elem':elem,'prek':pre,'mid':mid,'high':high,'elem_pc':elem_pc,'prek_pc':pre_pc,'mid_pc':mid_pc,'high_pc':high_pc}
    return json.dumps(data)
#     return df1
# prog_prac_admin('5f2bcad8ba0be61b0c1e9d5e')




# @app.route('/schoolsearchid/<name>')
# def schoolsearch_em_id(name):
#     if "@" in name:
#         print( "Found!")
# #         def school_search_email_d1_mongo1(emaail):
#         from bson.regex import Regex
#         from pymongo import MongoClient
#         from flask import Flask,json

#         import urllib 
#         import pandas as pd
#         mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
#         client = pymongo.MongoClient(mongo_uri)
#         # db = client.compass
#         # client = MongoClient("mongodb://host:port/")
#         database = client["compass"]
#         collection = database["user_master"]
#         query = {}
#         query["EMAIL_ID"] = Regex(name, "i")
#         query["ROLE_ID.ROLE_NAME"] = {
#                     u"$not": Regex(u".*PRESENT.*", "i")
#                 }

#         projection = {}
#         projection["schoolId._id"] = 1.0
    
#         cursor1 = collection.find(query, projection = projection)
#         dfum1=(list(cursor1))
# #         print(dfum1)
#         dfm2=pd.json_normalize(dfum1, max_level=1)
#         xvbnm=dfm2["schoolId._id"][0]
# #         print(xvbnm)
#         name1=name.replace("%20"," ")
# #         print(name1,"hola")
#         from bson.regex import Regex
#         from pymongo import MongoClient
#         from flask import Flask,json

#         import urllib 
#         import pandas as pd
#         mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
#         client = pymongo.MongoClient(mongo_uri)
#         # client = MongoClient("mongodb://host:port/")
#         database = client["compass"]
#         collection = database["user_master"]
#         name=xvbnm
#         # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com
#         query = {}
#     #     query["schoolId.NAME"] = name1
#         query["schoolId._id"] = ObjectId(name)
#         #     query["EMAIL_ID"] = Regex(u".*amorgan@methacton\\.org.*", "i")
#         query["USER_NAME"] = {
#             u"$not": Regex(u".*TEST.*", "i")
#         }
#         query["EMAIL_ID"] = {
#             u"$not": Regex(u".*TEST.*", "i")
#         }
#         query["EMAIL_ID"] = {
#             u"$not": Regex(u".*1gen.*", "i")
#         }

#         query["IS_BLOCKED"] = {
#             u"$ne": u"Y"
#         }

#         query["ROLE_ID.ROLE_NAME"] = {
#             u"$not": Regex(u".*PRESENT.*", "i")
#         }

#         query["IS_DISABLED"] = {
#             u"$ne": u"Y"
#         }

#         query["INCOMPLETE_SIGNUP"] = {
#             u"$ne": u"Y"
#         }

#         # query["DEVICE_USED"] = Regex(u".*webapp.*", "i")

#         projection = {}
#         projection["USER_ID.USER_ID"] = 1.0
#         projection["EMAIL_ID"] = 1.0
#         projection["CREATED_DATE"] = 1.0

#         projection["USER_NAME"] = 1.0
#         projection["IS_ADMIN"] = 1.0
#         projection["schoolId.ADDRESS"] = 1.0
#         projection["schoolId.CITY"] = 1.0
#         projection["schoolId.STATE"] = 1.0
#         projection["schoolId.COUNTRY"] = 1.0
#         projection["schoolId.NAME"] = 1.0

#         cursor = collection.find(query, projection = projection)
#         dfum=(list(cursor))
#         dfum=pd.json_normalize(dfum, max_level=1)
#         schoolname=dfum["schoolId.NAME"][0]
#         country=dfum["schoolId.COUNTRY"][0]
#         city=dfum["schoolId.CITY"][0]
#         state=dfum["schoolId.STATE"][0]
#         address=dfum["schoolId.ADDRESS"][0]

#         admin1=dfum[dfum['IS_ADMIN']=='Y']

#         admin2=admin1['USER_NAME']
#         admin3=list(admin2)
#         admin=admin3[0]
#         adminemail1=admin1['EMAIL_ID']
#         admine=list(adminemail1)
#         # adminemail=[dfum['EMAIL_ID'][dfum['IS_ADMIN']=='Y']][0]
#         adminemail=admine[0]
#     #     print(adminemail)
#         email=list(dfum['EMAIL_ID'])
#     #     print(email)
#         totaluser=len(email)
#         collection = database["audio_track_master"]

#     #     Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

#         pipeline = [
#             {
#                 u"$match": {
#                     u"USER_ID.EMAIL_ID": {
#                         u"$in": email
#                     }
#                 }

#             }, 
#             {
#                 u"$group": {
#                     u"_id": {
#                         u"USER_ID\u1390_id": u"$USER_ID._id"
#                     },
#                     u"MAX(MODIFIED_DATE)": {
#                         u"$max": u"$MODIFIED_DATE"
#                     },
#                     u"COUNT(USER_ID\u1390_id)": {
#                         u"$sum": 1
#                     }
#                 }
#             }, 
#             {
#                 u"$project": {
#                     u"USER_ID._id": u"$_id.USER_ID\u1390_id",
#                     u"MAX(MODIFIED_DATE)": u"$MAX(MODIFIED_DATE)",
#                     u"COUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
#                     u"_id": 0
#                 }
#             }
#         ]

#         cursor = collection.aggregate(
#             pipeline, 
#             allowDiskUse = True
#         )
#         dfatd=list(cursor)
#         dfatd=pd.json_normalize(dfatd, max_level=1)
#     #     print(dfatd)
#         collection = database["subscription_master"]

#         # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

#         pipeline = [
#             {
#                 u"$match": {
#                     u"USER_ID.EMAIL_ID": {
#                         u"$in": email
#                     }
#                 }
#             }, 
#             {
#                 u"$group": {
#                     u"_id": {
#                         u"USER_ID\u1390_id": u"$USER_ID._id"
#                     },
#                     u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
#                         u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
#                     }
#                 }
#             }, 
#             {
#                 u"$project": {
#                     u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
#                     u"USER_ID._id": u"$_id.USER_ID\u1390_id",
#                     u"_id": 0
#                 }
#             }
#         ]

#         cursor = collection.aggregate(
#             pipeline, 
#             allowDiskUse = True
#         )
#         dfsbm=list(cursor)
#         dfsbm=pd.json_normalize(dfsbm, max_level=1)
#     #     print(dfatd,"atd")
#         ############################################################
#         collection = database["audio_track_master"]

#     #     Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

#         pipeline = [
#             {
#                 u"$match": {
#                     u"USER_ID.EMAIL_ID": {
#                         u"$in": email
#                     },
                     
#              u"MODIFIED_DATE" : { 
#                  u"$gte" :  csy_first_date()
            
#         }
#                 }

#             }, 
#             {
#                 u"$group": {
#                     u"_id": {
#                         u"USER_ID\u1390_id": u"$USER_ID._id"
#                     },
#                     u"MAX(MODIFIED_DATE)": {
#                         u"$max": u"$MODIFIED_DATE"
#                     },
#                     u"COUNT(USER_ID\u1390_id)": {
#                         u"$sum": 1
#                     }
#                 }
#             }, 
#             {
#                 u"$project": {
#                     u"CSYUSER_ID._id": u"$_id.USER_ID\u1390_id",
#                     u"CSYCOUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
#                     u"_id": 0
#                 }
#             }
#         ]

#         cursor1 = collection.aggregate(
#             pipeline, 
#             allowDiskUse = True
#         )
#         dfatdcsy=list(cursor1)
#         dfatdcsy1=pd.json_normalize(dfatdcsy, max_level=1)
#         ####################################################################

#         try:
#             dffinal=pd.merge(dfum,dfatd,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
#             dffinal1=pd.merge(dffinal,dfatdcsy1,left_on='_id',right_on='CSYUSER_ID._id',how='left',suffixes=('_',''))
#             dffinalnew=pd.merge(dffinal1,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
#         except:
#             dfum['MAX(MODIFIED_DATE)']='NO PRACTICE'
#             dfum['COUNT(USER_ID᎐_id)']=0
#             dffinal=dfum
#             dffinal1=dffinal
#             dffinal1['CSYCOUNT(USER_ID᎐_id)']=0
#             dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))



#     #     schoolname=dfum["schoolId.NAME"][0]
#         country=dfum["schoolId.COUNTRY"][0]
#         city=dfum["schoolId.CITY"][0]
#         state=dfum["schoolId.STATE"][0]
#         address=dfum["schoolId.ADDRESS"][0]
#     #     admin=[dfum['USER_NAME'][dfum['IS_ADMIN']=='Y']][0]
#     #     admin=admin[0]
#     #     adminemail=[dfum['EMAIL_ID'][dfum['IS_ADMIN']=='Y']][0]
#     #     adminemail=adminemail[0]
#         email=list(dfum['EMAIL_ID'])
#         totaluser=len(email)
#         dffinalnew['MAX(MODIFIED_DATE)'].fillna("NO PRACTICE", inplace=True)
#         dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)'].fillna(" ", inplace=True)
#         dffinalnew['COUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
#         dffinalnew['CSYCOUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
#         pracsum=sum(list(dffinalnew['COUNT(USER_ID᎐_id)']))
#         dffinalnew.fillna(value=pd.np.nan, inplace=True)
        

#         MAX=[]
#         for i in dffinalnew['MAX(MODIFIED_DATE)']:
#             if  i != 'NO PRACTICE' :
#                 MAX.append(i.strftime("%d %b %Y "))
#             else:
#                 MAX.append("NO PRACTICE")
#         SUBSCRIPTION_EXPIRE_DATE=[]
#         for i in dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)']:
#             if  i != ' ' :
#                 SUBSCRIPTION_EXPIRE_DATE.append(i.strftime("%d %b %Y "))
#             else:
#                 SUBSCRIPTION_EXPIRE_DATE.append(" ")        
#         CREATED_DATE=[]
#         for i in dffinalnew['CREATED_DATE']:
#             if  i != ' ' :
#                 CREATED_DATE.append(i.strftime("%d %b %Y "))
#             else: 
#                 CREATED_DATE.append(" ")
#         data=[]

#         for T,k,l,m,o,p,q in zip(dffinalnew['USER_NAME'].tolist(),dffinalnew['EMAIL_ID'].tolist(),CREATED_DATE,MAX,SUBSCRIPTION_EXPIRE_DATE,dffinalnew['COUNT(USER_ID᎐_id)'].tolist(),dffinalnew['CSYCOUNT(USER_ID᎐_id)'].tolist()):
#             #print(p,q,r)
#             data.append([T,k,l,m,o,p,q])
#         database = client["compass"]
#         collection = database["subscription_master"]
#         query = {}
#         query["USER_ID.EMAIL_ID"] = {
#             u"$in": [
#                 adminemail
#             ]
#         }
#         projection = {}
#         projection["PLAN_ID.PLAN_NAME"] = 1.0
#         cursor = collection.find(query, projection = projection)
#         plandf=list(cursor)
#         plandf=pd.json_normalize(plandf, max_level=1)
#         plannameadmin=plandf["PLAN_ID.PLAN_NAME"][0]
#         temp={"data":data,"school_practice_count":str(pracsum),"school_name":schoolname,"country":country,"state":state,"city":city,"address":address,"admin_name":admin,"admin_email":adminemail,"plan":plannameadmin,"user_count":totaluser}
#     #     ,"school_practice_count":str(card_detail['school_practice_count1'][0])
#     #     temp={"data":data}
#         return json.dumps(temp)
#     else:
#         print ("Not found!")
# #         def school_searchid_mongo1(name):
#         name1=name.replace("%20"," ")
#         print(name1,"hola")
#         from bson.regex import Regex
#         from pymongo import MongoClient
#         from flask import Flask,json

#         import urllib 
#         import pandas as pd
#         mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
#         client = pymongo.MongoClient(mongo_uri)
#         # client = MongoClient("mongodb://host:port/")
#         database = client["compass"]
#         collection = database["user_master"]

#         # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com
#         query = {}
#     #     query["schoolId.NAME"] = name1
#         query["schoolId._id"] = ObjectId(name)
#         #     query["EMAIL_ID"] = Regex(u".*amorgan@methacton\\.org.*", "i")
#         query["USER_NAME"] = {
#             u"$not": Regex(u".*TEST.*", "i")
#         }
#         query["EMAIL_ID"] = {
#             u"$not": Regex(u".*1gen.*", "i")
#         }
#         query["EMAIL_ID"] = {
#             u"$not": Regex(u".*TEST.*", "i")
#         }

#         query["IS_BLOCKED"] = {
#             u"$ne": u"Y"
#         }

#         query["ROLE_ID.ROLE_NAME"] = {
#             u"$not": Regex(u".*PRESENT.*", "i")
#         }

#         query["IS_DISABLED"] = {
#             u"$ne": u"Y"
#         }

#         query["INCOMPLETE_SIGNUP"] = {
#             u"$ne": u"Y"
#         }

#         # query["DEVICE_USED"] = Regex(u".*webapp.*", "i")

#         projection = {}
#         projection["USER_ID.USER_ID"] = 1.0
#         projection["EMAIL_ID"] = 1.0
#         projection["CREATED_DATE"] = 1.0

#         projection["USER_NAME"] = 1.0
#         projection["IS_ADMIN"] = 1.0
#         projection["schoolId.ADDRESS"] = 1.0
#         projection["schoolId.CITY"] = 1.0
#         projection["schoolId.STATE"] = 1.0
#         projection["schoolId.COUNTRY"] = 1.0
#         projection["schoolId.NAME"] = 1.0

#         cursor = collection.find(query, projection = projection)
#         dfum=(list(cursor))
#         dfum=pd.json_normalize(dfum, max_level=1)
#         schoolname=dfum["schoolId.NAME"][0]
#         country=dfum["schoolId.COUNTRY"][0]
#         city=dfum["schoolId.CITY"][0]
#         state=dfum["schoolId.STATE"][0]
#         address=dfum["schoolId.ADDRESS"][0]

#         admin1=dfum[dfum['IS_ADMIN']=='Y']

#         admin2=admin1['USER_NAME']
#         admin3=list(admin2)
#         admin=admin3[0]
#         adminemail1=admin1['EMAIL_ID']
#         admine=list(adminemail1)
#         # adminemail=[dfum['EMAIL_ID'][dfum['IS_ADMIN']=='Y']][0]
#         adminemail=admine[0]
#     #     print(adminemail)
#         email=list(dfum['EMAIL_ID'])
#     #     print(email)
#         totaluser=len(email)
#         collection = database["audio_track_master"]

#     #     Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

#         pipeline = [
#             {
#                 u"$match": {
#                     u"USER_ID.EMAIL_ID": {
#                         u"$in": email
#                     }
#                 }

#             }, 
#             {
#                 u"$group": {
#                     u"_id": {
#                         u"USER_ID\u1390_id": u"$USER_ID._id"
#                     },
#                     u"MAX(MODIFIED_DATE)": {
#                         u"$max": u"$MODIFIED_DATE"
#                     },
#                     u"COUNT(USER_ID\u1390_id)": {
#                         u"$sum": 1
#                     }
#                 }
#             }, 
#             {
#                 u"$project": {
#                     u"USER_ID._id": u"$_id.USER_ID\u1390_id",
#                     u"MAX(MODIFIED_DATE)": u"$MAX(MODIFIED_DATE)",
#                     u"COUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
#                     u"_id": 0
#                 }
#             }
#         ]

#         cursor = collection.aggregate(
#             pipeline, 
#             allowDiskUse = True
#         )
#         dfatd=list(cursor)
#         dfatd=pd.json_normalize(dfatd, max_level=1)
#     #     print(dfatd)
#         collection = database["subscription_master"]

#         # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

#         pipeline = [
#             {
#                 u"$match": {
#                     u"USER_ID.EMAIL_ID": {
#                         u"$in": email
#                     }
#                 }
#             }, 
#             {
#                 u"$group": {
#                     u"_id": {
#                         u"USER_ID\u1390_id": u"$USER_ID._id"
#                     },
#                     u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
#                         u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
#                     }
#                 }
#             }, 
#             {
#                 u"$project": {
#                     u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
#                     u"USER_ID._id": u"$_id.USER_ID\u1390_id",
#                     u"_id": 0
#                 }
#             }
#         ]

#         cursor = collection.aggregate(
#             pipeline, 
#             allowDiskUse = True
#         )
#         dfsbm=list(cursor)
#         dfsbm=pd.json_normalize(dfsbm, max_level=1)
#     #     print(dfatd,"atd")
#         ############################################################
#         collection = database["audio_track_master"]

#     #     Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

#         pipeline = [
#             {
#                 u"$match": {
#                     u"USER_ID.EMAIL_ID": {
#                         u"$in": email
#                     },
                     
#              u"MODIFIED_DATE" : { 
#                  u"$gte" :  csy_first_date()
            
#         }
#                 }

#             }, 
#             {
#                 u"$group": {
#                     u"_id": {
#                         u"USER_ID\u1390_id": u"$USER_ID._id"
#                     },
#                     u"MAX(MODIFIED_DATE)": {
#                         u"$max": u"$MODIFIED_DATE"
#                     },
#                     u"COUNT(USER_ID\u1390_id)": {
#                         u"$sum": 1
#                     }
#                 }
#             }, 
#             {
#                 u"$project": {
#                     u"CSYUSER_ID._id": u"$_id.USER_ID\u1390_id",
#                     u"CSYCOUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
#                     u"_id": 0
#                 }
#             }
#         ]

#         cursor1 = collection.aggregate(
#             pipeline, 
#             allowDiskUse = True
#         )
#         dfatdcsy=list(cursor1)
#         dfatdcsy1=pd.json_normalize(dfatdcsy, max_level=1)
#         ####################################################################

#         try:
#             dffinal=pd.merge(dfum,dfatd,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
#             dffinal1=pd.merge(dffinal,dfatdcsy1,left_on='_id',right_on='CSYUSER_ID._id',how='left',suffixes=('_',''))
#             dffinalnew=pd.merge(dffinal1,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
#         except:
#             dfum['MAX(MODIFIED_DATE)']='NO PRACTICE'
#             dfum['COUNT(USER_ID᎐_id)']=0
#             dffinal=dfum
#             dffinal1=dffinal
#             dffinal1['CSYCOUNT(USER_ID᎐_id)']=0
#             dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))



#     #     schoolname=dfum["schoolId.NAME"][0]
#         country=dfum["schoolId.COUNTRY"][0]
#         city=dfum["schoolId.CITY"][0]
#         state=dfum["schoolId.STATE"][0]
#         address=dfum["schoolId.ADDRESS"][0]
#     #     admin=[dfum['USER_NAME'][dfum['IS_ADMIN']=='Y']][0]
#     #     admin=admin[0]
#     #     adminemail=[dfum['EMAIL_ID'][dfum['IS_ADMIN']=='Y']][0]
#     #     adminemail=adminemail[0]
#         email=list(dfum['EMAIL_ID'])
#         totaluser=len(email)
#         dffinalnew['MAX(MODIFIED_DATE)'].fillna("NO PRACTICE", inplace=True)
#         dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)'].fillna(" ", inplace=True)
#         dffinalnew['COUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
#         dffinalnew['CSYCOUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
#         pracsum=sum(list(dffinalnew['COUNT(USER_ID᎐_id)']))
#         dffinalnew.fillna(value=pd.np.nan, inplace=True)
        

#         MAX=[]
#         for i in dffinalnew['MAX(MODIFIED_DATE)']:
#             if  i != 'NO PRACTICE' :
#                 MAX.append(i.strftime("%d %b %Y "))
#             else:
#                 MAX.append("NO PRACTICE")
#         SUBSCRIPTION_EXPIRE_DATE=[]
#         for i in dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)']:
#             if  i != ' ' :
#                 SUBSCRIPTION_EXPIRE_DATE.append(i.strftime("%d %b %Y "))
#             else:
#                 SUBSCRIPTION_EXPIRE_DATE.append(" ")        
#         CREATED_DATE=[]
#         for i in dffinalnew['CREATED_DATE']:
#             if  i != ' ' :
#                 CREATED_DATE.append(i.strftime("%d %b %Y "))
#             else: 
#                 CREATED_DATE.append(" ")
#         data=[]

#         for T,k,l,m,o,p,q in zip(dffinalnew['USER_NAME'].tolist(),dffinalnew['EMAIL_ID'].tolist(),CREATED_DATE,MAX,SUBSCRIPTION_EXPIRE_DATE,dffinalnew['COUNT(USER_ID᎐_id)'].tolist(),dffinalnew['CSYCOUNT(USER_ID᎐_id)'].tolist()):
#             #print(p,q,r)
#             data.append([T,k,l,m,o,p,q])
#         database = client["compass"]
#         collection = database["subscription_master"]
#         query = {}
#         query["USER_ID.EMAIL_ID"] = {
#             u"$in": [
#                 adminemail
#             ]
#         }
#         projection = {}
#         projection["PLAN_ID.PLAN_NAME"] = 1.0
#         cursor = collection.find(query, projection = projection)
#         plandf=list(cursor)
#         plandf=pd.json_normalize(plandf, max_level=1)
#         plannameadmin=plandf["PLAN_ID.PLAN_NAME"][0]
#         temp={"data":data,"school_practice_count":str(pracsum),"school_name":schoolname,"country":country,"state":state,"city":city,"address":address,"admin_name":admin,"admin_email":adminemail,"plan":plannameadmin,"user_count":totaluser}
#     #     ,"school_practice_count":str(card_detail['school_practice_count1'][0])
#     #     temp={"data":data}
#         return json.dumps(temp)




@app.route('/usersearch/<name>')
def user_search_mongo(name):
    name1=name.replace("%20"," ")
    from bson.regex import Regex
    from pymongo import MongoClient
    from flask import Flask,json

    import urllib 
    import pandas as pd
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = MongoClient(mongo_uri)
    database = client["compass"]
    collection = database["user_master"]
    query = {}
    query["EMAIL_ID"] = Regex(name1, "i")
    query["ROLE_ID.ROLE_NAME"] = {
        u"$not": Regex(u".*PRESENT.*", "i")
    }
    query["USER_NAME"] = {
        u"$not": Regex(u".*TEST.*", "i")
    }
    query["IS_DISABLED"] = {
        u"$ne": u"Y"
    }

    query["INCOMPLETE_SIGNUP"] = {
        u"$ne": u"Y"
    }

    

    projection = {}
    projection["USER_ID.USER_ID"] = 1.0
    projection["EMAIL_ID"] = 1.0
    projection["CREATED_DATE"] = 1.0

    projection["USER_NAME"] = 1.0
    
    projection["schoolId.ADDRESS"] = 1.0
    projection["schoolId.CITY"] = 1.0
    projection["schoolId.STATE"] = 1.0
    projection["schoolId.COUNTRY"] = 1.0
    projection["schoolId.NAME"] = 1.0

    cursor = collection.find(query, projection = projection)
    dfum=(list(cursor))
    dfum=pd.json_normalize(dfum, max_level=1)
    print(dfum,"usermaster")
    email=list(dfum['EMAIL_ID'])
    totaluser=len(email)
    collection = database["audio_track_master"]
    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(MODIFIED_DATE)": {
                    u"$max": u"$MODIFIED_DATE"
                },
                u"COUNT(USER_ID\u1390_id)": {
                    u"$sum": 1
                }
            }
        }, 
        {
            u"$project": {
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"MAX(MODIFIED_DATE)": u"$MAX(MODIFIED_DATE)",
                u"COUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfatd=list(cursor)
    dfatd=pd.json_normalize(dfatd, max_level=1)
#     print(dfatd)
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {
            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfsbm=list(cursor)
    dfsbm=pd.json_normalize(dfsbm, max_level=1)
#     print(dfatd,"atd pracice data")
    
    try:
        dffinal=pd.merge(dfum,dfatd,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
    except:
        dfum['MAX(MODIFIED_DATE)']='NO PRACTICE'
        dfum['COUNT(USER_ID᎐_id)']=0
        dffinal=dfum
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
        
        
    email=list(dfum['EMAIL_ID'])
    totaluser=len(email)
    dffinalnew['MAX(MODIFIED_DATE)'].fillna("NO PRACTICE", inplace=True)
    dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)'].fillna(" ", inplace=True)
    dffinalnew['COUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
#     pracsum=sum(list(dffinalnew['COUNT(USER_ID᎐_id)']))
    dffinalnew.fillna(value=pd.np.nan, inplace=True)
#     print(dffinalnew)
    schname=["NO SCHOOL INFO"]
    try:
        schname=dffinalnew["schoolId.NAME"].tolist()
    except:
        schname=["NO SCHOOL INFO"]
        

    MAX=[]
    for i in dffinalnew['MAX(MODIFIED_DATE)']:
        if  i != 'NO PRACTICE' :
            MAX.append(i.strftime("%d %b %Y "))
        else:
            MAX.append("NO PRACTICE")
    SUBSCRIPTION_EXPIRE_DATE=[]
    for i in dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)']:
        if  i != ' ' :
            SUBSCRIPTION_EXPIRE_DATE.append(i.strftime("%d %b %Y "))
        else:
            SUBSCRIPTION_EXPIRE_DATE.append(" ")        
    CREATED_DATE=[]
    for i in dffinalnew['CREATED_DATE']:
        if  i != ' ' :
            CREATED_DATE.append(i.strftime("%d %b %Y "))
        else:
            CREATED_DATE.append(" ")
    data=[]

    for Z,T,k,l,m,o,p in zip(schname,dffinalnew['USER_NAME'].tolist(),dffinalnew['EMAIL_ID'].tolist(),CREATED_DATE,MAX,SUBSCRIPTION_EXPIRE_DATE,dffinalnew['COUNT(USER_ID᎐_id)'].tolist()):
        #print(p,q,r)
        data.append([Z,T,k,l,m,o,p])
    temp={"data":data}
    return json.dumps(temp)


# change by sadhna 6240
@app.route('/schoolsearch/<month>/<n>')
def rating_month_info(month,n):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1 = db.audio_feedback
    collection2 = db.audio_track_master
#     feedback=[n]
    df1 = DataFrame(list(collection1.aggregate([
       {"$match":
        {'$and': [
             {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER.IS_DISABLED":{"$ne":"Y"}},
              {"USER.IS_BLOCKED":{"$ne":"Y"}},
             {"USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                         {'RATING':{'$ne':0}},
             {'RATING':{"$eq":int(""+n+"")}}
#              {'RATING':{'$in':feedback}}

#             {'MODIFIED_DATE':{'month':{'$in':monthname}}},
            ]}},
        {'$group':{'_id':'$_id','um':{'$first':'$USER.USER_NAME'},'email':{'$first':'$USER.EMAIL_ID'},
                   'COMMENT':{'$first':'$COMMENT'},'an':{'$first':'$AUDIO_ID.AUDIO_NAME'}, 
     'rating':{'$first':'$RATING'},
        'comment_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }}}}},
        {'$project':{'_id':1, 'USER_NAME':'$um','COMMENT':'$COMMENT','EMAIL_ID':'$email', 'AUDIO_NAME':'$an', 'RATING':'$rating','last_comment_rating_date':'$comment_date'}}
    # //     ,{'$count':'count'}
        ])))
    df1.rename(columns={'_id':'user'},inplace=True)
    # print(df)
    # d=dict(enumerate(calendar.month_name))
    # df['month']=df['month'].map(d)
    # #df
   #'month':{'$first':{'$monthname':'$MODIFIED_DATE'}},
    df2 = DataFrame(list(collection2.aggregate([
       {"$match":{
         '$and':[{'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}
                                            ]}},
           {'$group':{'_id':'$USER_ID._id','sm':{'$first':'$USER_ID.schoolId.NAME'},'pc':{'$sum':1},'email':{'$first':'$USER_ID.EMAIL_ID'},'COUNTRY':{'$first':'$USER_ID.schoolId.COUNTRY'},'STATE':{'$first':'$USER_ID.schoolId.STATE'},
           'CITY':{'$first':'$USER_ID.schoolId.CITY'},'LAST_PRACTICE':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}}}}},
           {'$project':{'_id':1,'school_name':'$sm','country':'$COUNTRY','Practice_Count':'$pc','EMAIL_ID':'$email','State':'$STATE','city':'$CITY','last_practice_date':'$LAST_PRACTICE'}}
    # //        ,{'$count':'count'}
           ])))
    df2.rename(columns={'_id':'user'},inplace=True)
    df=pd.merge(df1,df2,on='EMAIL_ID',how='left')
    # df
   

    
    df['school_name'].fillna("NO INFO", inplace=True)
    df['country'].fillna("NO INFO", inplace=True)
    
    df['USER_NAME'].fillna("NO INFO", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
   
    df['EMAIL_ID'].fillna("NO INFO", inplace=True)
    df['EMAIL_ID'].replace("",'NO INFO', inplace=True)
    df['school_name'].replace("",'NO INFO', inplace=True)
    df['city'].replace("",'NO INFO', inplace=True)
    df['State'].replace("",'NO INFO', inplace=True)
    df['country'].replace("",'NO INFO', inplace=True)
    df['USER_NAME'].replace("",'NO INFO', inplace=True)
    df['city'].fillna("NO INFO", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['State'].fillna("NO INFO", inplace=True)
    df['State'].replace("NULL","NO INFO", inplace=True)


    df['last_comment_rating_date']=df['last_comment_rating_date'].dropna()
    df=df.reset_index(drop=True)
    df['COMMENT']=df['COMMENT'].replace('','NO COMMENT')
    df['COMMENT']=df['COMMENT'].replace(' ','NO COMMENT')
    df['COMMENT']=df['COMMENT'].fillna('NO COMMENT')
    df['last_practice_date']=pd.to_datetime(df['last_practice_date'])
    df['last_comment_rating_date']=pd.to_datetime(df['last_comment_rating_date'])
    df['last_practice_date']=df['last_practice_date'].fillna('NO PRACTICE')
#     print(df)
#     df= df.groupby(by=['RATING'])
#     df= df.get_group((''+n+'') )
#     df= df.groupby(df['RATING'])
#     df= df.get_group(''+rating+'')
    df=df.groupby(df['last_comment_rating_date'].dt.strftime('%b'))
    df=df.get_group(''+month+'')
    LAST_PRACTICE_DATE=[]
    for i in df['last_practice_date']:
        if  i != 'NO PRACTICE' :
            LAST_PRACTICE_DATE.append(i.strftime("%d %b %Y "))
        else:
            LAST_PRACTICE_DATE.append("NO PRACTICE")
    last_comment_rating_date=[]
    for i in df['last_comment_rating_date']:
        if  i != ' ' :
            last_comment_rating_date.append(i.strftime("%d %b %Y "))
        else:
            last_comment_rating_date.append(" ")
        # print(last_comment_rating_date)
#     df=df.groupby(df['last_practice_date'].dt.strftime('%b'))
#     df=df.get_group(''+month+'')
    data=[]
    for i,j,k,l,m,n,o,p,q,r in zip(df['school_name'].tolist(),df['State'].tolist(),df['city'].tolist(),df['Practice_Count'].tolist(),df['USER_NAME'].tolist(),df['EMAIL_ID'].tolist(),df['AUDIO_NAME'].tolist(),df['COMMENT'].tolist(),last_comment_rating_date,LAST_PRACTICE_DATE):
        data.append([i,j,k,l,m,n,o,p,q,r])
    temp={"data":data}
    return json.dumps(temp)

#changes by sarthak check 6276
@app.route('/parpracticeprograme')
def parpracticeprogramactive():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                         {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,18)}},                
                        ]}},

    {"$project":{'USER_ID':'$USER_ID.USER_ID','PROGRAM_AUDIO_ID.AUDIO_ID':1,
        'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
        'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
        'AUDIO_NAME':1,'AUDIO_LENGTH':1,
        'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

        'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
            ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
        {"$match":{'PlayBack_Time_Percent':{"$gte":.5}}},


    { "$project": { 'USER_ID':1,'AGE_GROUP':1,

        "status": {
          "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": 'bonus','options': "i"  }}


              , 
          "then": 'Bonus', "else": {
             "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": "sound",'options': "i" }}, 
             "then": 'Sound', "else": 'daily'
             }}}}}}   
    ]
             

    x=list(collection.aggregate(query))
    df=pd.DataFrame(x)
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

    practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].count()).reset_index().rename(columns={'USER_ID':'Count'})
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
    dailydf=practice_count_overall[practice_count_overall.status=='daily']
    dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
    dailycompdf['status'].fillna('daily',inplace=True)
    dailycompdf['Count'].fillna(0,inplace=True)
    Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
    Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
    Soundcompdf['status'].fillna('Sound',inplace=True)
    Soundcompdf['Count'].fillna(0,inplace=True)
    Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
    Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
    Bonuscompdf['status'].fillna('Bonus',inplace=True)
    Bonuscompdf['Count'].fillna(0,inplace=True)
    temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
      'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
       'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}
    return json.dumps(temp)


#>>>>>>>>>>>>--------------- PRACTICE BIFURCATION API--------------------
@app.route('/parpracticeprograme/<charttype>')
def parpractice__program__active(charttype):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=0.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
    
        query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                             {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,18)}},                
                            ]}},
           

        {"$project":{'USER_ID':'$USER_ID.USER_ID','PROGRAM_AUDIO_ID.AUDIO_ID':1,
            'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
            'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
            'AUDIO_NAME':1,'AUDIO_LENGTH':1,
            'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

            'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
            {"$match":{'Completion_Percentage':{"$gte":.5}}},
            
#              practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
                         threshcond[0],


        { "$project": { 'USER_ID':1,'AGE_GROUP':1,

            "status": {
              "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": 'bonus','options': "i"  }}


                  , 
              "then": 'Bonus', "else": {
                 "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": "sound",'options': "i" }}, 
                 "then": 'Sound', "else": 'daily'
                 }}}}}}   
        ]


        x=list(collection.aggregate(query))
        df=pd.DataFrame(x)
#         print(df)
        if 'AGE_GROUP' not in df.columns:
            df['AGE_GROUP'] = 0
        if 'USER_ID' not in df.columns:
            df['USER_ID'] = 0
        if 'status' not in df.columns:
            df['status'] = 0
#         if 'USER_ID' not in df.columns:
#             df['USER_ID'] = 0
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

        practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].count()).reset_index().rename(columns={'USER_ID':'Count'})
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
        dailydf=practice_count_overall[practice_count_overall.status=='daily']
        dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
        dailycompdf['status'].fillna('daily',inplace=True)
        dailycompdf['Count'].fillna(0,inplace=True)
        Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
        Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
        Soundcompdf['status'].fillna('Sound',inplace=True)
        Soundcompdf['Count'].fillna(0,inplace=True)
        Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
        Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
        Bonuscompdf['status'].fillna('Bonus',inplace=True)
        Bonuscompdf['Count'].fillna(0,inplace=True)

        
        temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
          'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
           'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}
        return json.dumps(temp, default=str)
    
    else:
        query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                             {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,18)}},                
                            ]}},

        {"$project":{'USER_ID':'$USER_ID.USER_ID','PROGRAM_AUDIO_ID.AUDIO_ID':1,
            'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
            'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
            'AUDIO_NAME':1,'AUDIO_LENGTH':1,
            'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

            'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
#             {"$match":{'PlayBack_Time_Percent':{"$gte":.5}}},


        { "$project": { 'USER_ID':1,'AGE_GROUP':1,

            "status": {
              "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": 'bonus','options': "i"  }}


                  , 
              "then": 'Bonus', "else": {
                 "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": "sound",'options': "i" }}, 
                 "then": 'Sound', "else": 'daily'
                 }}}}}}   
        ]


        x=list(collection.aggregate(query))
        df=pd.DataFrame(x)
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

        practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].count()).reset_index().rename(columns={'USER_ID':'Count'})
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
        dailydf=practice_count_overall[practice_count_overall.status=='daily']
        dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
        dailycompdf['status'].fillna('daily',inplace=True)
        dailycompdf['Count'].fillna(0,inplace=True)
        Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
        Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
        Soundcompdf['status'].fillna('Sound',inplace=True)
        Soundcompdf['Count'].fillna(0,inplace=True)
        Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
        Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
        Bonuscompdf['status'].fillna('Bonus',inplace=True)
        Bonuscompdf['Count'].fillna(0,inplace=True)
     
        temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
          'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
           'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}
        return json.dumps(temp)





#Changes by Anil Mehra

@app.route('/parpracticeprogg/<d>')
def parents_tableprogram(d):
    
    # def parents_tableprogram(d):    
    x=''
    query=''
    if d=='D':        
        reader = geolite2.reader()
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
        client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
        db=client.compass
        collection = db.audio_track_master
        query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                      {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                        {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'bonus','$options':'i'}}},
                        {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                        ]}},

            {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                'Mindful_Minutes':{"$round":[{"$divide":
                    [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                    ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},

            { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'AGE_GROUP':1     
                }},
        {'$group':
                    {'_id':{'user':'$User_ObjectId','agegp':'$AGE_GROUP'},
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'EMAIL_ID':{'$first':'$USER_EMAIL'},
                        'SCHOOL':{'$first':'$SCHOOL_NAME'},
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'CITY':{'$first':'$CITY'},
                        'STATE':{'$first':'$STATE'},
                        'IP':{'$first':'$IP'},
                        'CREATED_DATE':{'$first':'$CREATED_DATE'},
                        'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                        'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                        'PHONE':{'$first':'$PHONE'},
                        }},
        { "$project": { '_id':0,

            'USER_ID':'$_id.user','USER_NAME':1,'EMAIL_ID':1,
                'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                }}]
        
    elif d=='T':
        reader = geolite2.reader()
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
        client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
        db=client.compass
        collection = db.audio_track_master
        query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                        {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                 
                        {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$regex':'bonus','$options':'i'}},
#                         {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                        ]}},

            {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                'Mindful_Minutes':{"$round":[{"$divide":
                    [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                    ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},

            { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'AGE_GROUP':1     
                }},
        {'$group':
                    {'_id':{'user':'$User_ObjectId','agegp':'$AGE_GROUP'},
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'EMAIL_ID':{'$first':'$USER_EMAIL'},
                        'SCHOOL':{'$first':'$SCHOOL_NAME'},
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'CITY':{'$first':'$CITY'},
                        'STATE':{'$first':'$STATE'},
                        'IP':{'$first':'$IP'},
                        'CREATED_DATE':{'$first':'$CREATED_DATE'},
                        'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                        'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                        'PHONE':{'$first':'$PHONE'},
                        }},
        { "$project": { '_id':0,

            'USER_ID':'$_id.user','USER_NAME':1,'EMAIL_ID':1,
                'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                }}]
    elif d=='S':


        reader = geolite2.reader()
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
        client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
        db=client.compass
        collection = db.audio_track_master
        query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                         {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                        {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$regex':'sound','$options':'i'}},
#                         {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                        ]}},

            {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                'Mindful_Minutes':{"$round":[{"$divide":
                    [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                    ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},

            { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'AGE_GROUP':1     
                }},
        {'$group':
                    {'_id':'$User_ObjectId',
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'EMAIL_ID':{'$first':'$USER_EMAIL'},
                        'SCHOOL':{'$first':'$SCHOOL_NAME'},
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'CITY':{'$first':'$CITY'},
                        'STATE':{'$first':'$STATE'},
                        'IP':{'$first':'$IP'},
                        'CREATED_DATE':{'$first':'$CREATED_DATE'},
                        'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                        'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                        'PHONE':{'$first':'$PHONE'},
                        }},
        { "$project": { '_id':0,

            'USER_ID':'$_id','USER_NAME':1,'EMAIL_ID':1,
                'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                }}]
    else:
        pass  
    daily=list(collection.aggregate(query))
    daily_df=pd.DataFrame(daily)
    daily_df.Mindful_minutes=daily_df.Mindful_minutes.astype('int64')
    daily_df['MODIFIED_DATE']=pd.to_datetime(daily_df['MODIFIED_DATE'])
    daily_df['CREATED_DATE']=pd.to_datetime(daily_df['CREATED_DATE'])
    daily_df['SCHOOL'].fillna("NO SCHOOL INFO", inplace=True)
    daily_df['EMAIL_ID'].fillna("EMAIL_ID NOT AVAILABLE", inplace=True)
    daily_df['EMAIL_ID'].replace("",'EMAIL_ID NOT AVAILABLE', inplace=True)
    daily_df['USER_NAME'].replace("",'USER NAME NOT AVAILABLE', inplace=True)
    daily_df['CITY'].fillna("NO CITY INFO AVAILABLE", inplace=True)
    daily_df['STATE'].fillna("NO STATE INFO AVAILABLE", inplace=True)


    
    def country1(i):

        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=daily_df['IP'].tolist()
    phone_number=daily_df['PHONE'].tolist()
    Parents_Name=daily_df['USER_NAME'].tolist()
    Parents_Email=daily_df.EMAIL_ID.tolist()
    School_Name=daily_df['SCHOOL'].tolist()
    state=daily_df['STATE'].tolist()
    city=daily_df['CITY'].tolist()
    sign_up_date=daily_df['CREATED_DATE'].tolist()
    last_prac_date=daily_df['MODIFIED_DATE'].tolist()
    #     practice_count=df['Practice_Count'].tolist()
    mindful_minutes=daily_df['Mindful_minutes'].tolist()

    for i in range(len(ip)):            
        if city[i] is None:
            try:
                city[i]=city1(ip[i])
            except:
                pass
        elif city[i]=='NO CITY INFO AVAILABLE':
            try:
                city[i]=city1(ip[i])
            except:
                pass                        
        
        if state[i] is None:
            try:
                state[i]=state1(ip[i])
            except:
                pass
        elif state[i] =='NO STATE INFO AVAILABLE':
            try:
                state[i]=state1(ip[i])
            except:
                pass    
        if state[i] is None:
            state[i]=''
        if  last_prac_date[i] != 'NO PRACTICE' :
            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:
            last_prac_date[i]="NO PRACTICE"

        if sign_up_date[i] is not None:        
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')


    state12 =  [each_string.upper() for each_string in state]
    city12= [each_string.upper() for each_string in city]
    school= [each_string.upper() for each_string in School_Name]



    cv={'pnn':Parents_Name,'pe':Parents_Email,'pn':phone_number,'sn':school,'ct':city12,
       'st':state12,'sp':sign_up_date,
       'lp':last_prac_date,'mm':mindful_minutes}
    dftry = pd.DataFrame.from_dict(cv)
    print(dftry.shape)

    return json.dumps({"data":dftry.values.tolist()})

#>>>>>>>>>>>---------- PRACTICE BIFURCATION API----------------
@app.route('/parpracticeprogg/<d>/<charttype>')
def parents__table__program(d,charttype):
    
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
    
        # def parents_tableprogram(d):    
        x=''
        query=''
        if d=='D':        
            reader = geolite2.reader()
            username = urllib.parse.quote_plus('admin')
            password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
            client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
            db=client.compass
            collection = db.audio_track_master
            query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                          {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                            {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'bonus','$options':'i'}}},
                            {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                            ]}},
             

                {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                    'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                    'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                    'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                    'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                    'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                    'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                    'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                    'Mindful_Minutes':{"$round":[{"$divide":
                        [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                    'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
                
#                    practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
                         threshcond[0],

                { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                    'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'AGE_GROUP':1     
                    }},
                
                
            {'$group':
                        {'_id':{'user':'$User_ObjectId','agegp':'$AGE_GROUP'},
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'EMAIL_ID':{'$first':'$USER_EMAIL'},
                            'SCHOOL':{'$first':'$SCHOOL_NAME'},
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'CITY':{'$first':'$CITY'},
                            'STATE':{'$first':'$STATE'},
                            'IP':{'$first':'$IP'},
                            'CREATED_DATE':{'$first':'$CREATED_DATE'},
                            'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                            'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                            'PHONE':{'$first':'$PHONE'},
                            }},
            { "$project": { '_id':0,

                'USER_ID':'$_id.user','USER_NAME':1,'EMAIL_ID':1,
                    'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                    }}]

        elif d=='T':
            reader = geolite2.reader()
            username = urllib.parse.quote_plus('admin')
            password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
            client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
            db=client.compass
            collection = db.audio_track_master
            query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                            {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                 
                            {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$regex':'bonus','$options':'i'}},
    #                         {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                            ]}},
              
                {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                    'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                    'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                    'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                    'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                    'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                    'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                    'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                    'Mindful_Minutes':{"$round":[{"$divide":
                        [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                    'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
#                   practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
                         threshcond[0],


                { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                    'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'AGE_GROUP':1     
                    }},
                
            {'$group':
                        {'_id':{'user':'$User_ObjectId','agegp':'$AGE_GROUP'},
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'EMAIL_ID':{'$first':'$USER_EMAIL'},
                            'SCHOOL':{'$first':'$SCHOOL_NAME'},
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'CITY':{'$first':'$CITY'},
                            'STATE':{'$first':'$STATE'},
                            'IP':{'$first':'$IP'},
                            'CREATED_DATE':{'$first':'$CREATED_DATE'},
                            'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                            'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                            'PHONE':{'$first':'$PHONE'},
                            }},
            { "$project": { '_id':0,

                'USER_ID':'$_id.user','USER_NAME':1,'EMAIL_ID':1,
                    'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                    }}]
        elif d=='S':


            reader = geolite2.reader()
            username = urllib.parse.quote_plus('admin')
            password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
            client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
            db=client.compass
            collection = db.audio_track_master
            query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                             {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                            {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$regex':'sound','$options':'i'}},
    #                         {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                            ]}},
              

                {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                    'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                    'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                    'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                    'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                    'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                    'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                    'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                    'Mindful_Minutes':{"$round":[{"$divide":
                        [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                    'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
#                   practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
                         threshcond[0],

                { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                    'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'AGE_GROUP':1     
                    }},
            {'$group':
                        {'_id':'$User_ObjectId',
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'EMAIL_ID':{'$first':'$USER_EMAIL'},
                            'SCHOOL':{'$first':'$SCHOOL_NAME'},
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'CITY':{'$first':'$CITY'},
                            'STATE':{'$first':'$STATE'},
                            'IP':{'$first':'$IP'},
                            'CREATED_DATE':{'$first':'$CREATED_DATE'},
                            'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                            'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                            'PHONE':{'$first':'$PHONE'},
                            }},
            { "$project": { '_id':0,

                'USER_ID':'$_id','USER_NAME':1,'EMAIL_ID':1,
                    'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                    }}]
        else:
            pass  
        daily=list(collection.aggregate(query))
        daily_df=pd.DataFrame(daily)
        daily_df.Mindful_minutes=daily_df.Mindful_minutes.astype('int64')
        daily_df['MODIFIED_DATE']=pd.to_datetime(daily_df['MODIFIED_DATE'])
        daily_df['CREATED_DATE']=pd.to_datetime(daily_df['CREATED_DATE'])
        daily_df['SCHOOL'].fillna("NO SCHOOL INFO", inplace=True)
        daily_df['EMAIL_ID'].fillna("EMAIL_ID NOT AVAILABLE", inplace=True)
        daily_df['EMAIL_ID'].replace("",'EMAIL_ID NOT AVAILABLE', inplace=True)
        daily_df['USER_NAME'].replace("",'USER NAME NOT AVAILABLE', inplace=True)
        daily_df['CITY'].fillna("NO CITY INFO AVAILABLE", inplace=True)
        daily_df['STATE'].fillna("NO STATE INFO AVAILABLE", inplace=True)
        daily_df = daily_df.replace(np.nan, 0)
        daily_df['CREATED_DATE'].replace("NaT", "")


        def country1(i):

            location = reader.get(i)
            c=(location['country']['names']['en'])
            return c
        def state1(i):
            location = reader.get(i)
            s=(location['subdivisions'][0]['names']['en'])
            return s
        def city1(i):
            location = reader.get(i)
            city=location['city']['names']['en']
            return city
        def pn_country(i):
            import phonenumbers
            import pycountry
            from phonenumbers.phonenumberutil import (
            region_code_for_country_code,
            region_code_for_number,)
            pn = phonenumbers.parse('+'+i)   
            country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
            con=country.name
            return con
        ip=daily_df['IP'].tolist()
        phone_number=daily_df['PHONE'].tolist()
        Parents_Name=daily_df['USER_NAME'].tolist()
        Parents_Email=daily_df.EMAIL_ID.tolist()
        School_Name=daily_df['SCHOOL'].tolist()
        state=daily_df['STATE'].tolist()
        city=daily_df['CITY'].tolist()
        sign_up_date=daily_df['CREATED_DATE'].tolist()
        last_prac_date=daily_df['MODIFIED_DATE'].tolist()
        #     practice_count=df['Practice_Count'].tolist()
        mindful_minutes=daily_df['Mindful_minutes'].tolist()
        
        
        for i in range(len(ip)):            
            if city[i] is None:
                try:
                    city[i]=city1(ip[i])
                except:
                    pass
            elif city[i]=='NO CITY INFO AVAILABLE':
                try:
                    city[i]=city1(ip[i])
                except:
                    pass                        

            if state[i] is None:
                try:
                    state[i]=state1(ip[i])
                except:
                    pass
            elif state[i] =='NO STATE INFO AVAILABLE':
                try:
                    state[i]=state1(ip[i])
                except:
                    pass    
            if state[i] is None:
                state[i]=''
            if  last_prac_date[i] != 'NO PRACTICE' :
                last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
            else:
                last_prac_date[i]="NO PRACTICE"

            if sign_up_date[i] is not None and sign_up_date[i] != 0 :        
                sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')


        state12 =  [each_string.upper() for each_string in state]
        city12= [each_string.upper() for each_string in city]
        school= [each_string.upper() for each_string in School_Name]



        cv={'pnn':Parents_Name,'pe':Parents_Email,'pn':phone_number,'sn':school,'ct':city12,
           'st':state12,'sp':sign_up_date,
           'lp':last_prac_date,'mm':mindful_minutes}
        dftry = pd.DataFrame.from_dict(cv)

        return json.dumps({"data":dftry.values.tolist()})
    
    else:
        
        # def parents_tableprogram(d):    
        x=''
        query=''
        if d=='D':        
            reader = geolite2.reader()
            username = urllib.parse.quote_plus('admin')
            password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
            client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
            db=client.compass
            collection = db.audio_track_master
            query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                          {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                            {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'bonus','$options':'i'}}},
                            {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                            ]}},

                {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                    'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                    'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                    'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                    'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                    'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                    'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                    'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                    'Mindful_Minutes':{"$round":[{"$divide":
                        [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                    'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},

                { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                    'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'AGE_GROUP':1     
                    }},
            {'$group':
                        {'_id':{'user':'$User_ObjectId','agegp':'$AGE_GROUP'},
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'EMAIL_ID':{'$first':'$USER_EMAIL'},
                            'SCHOOL':{'$first':'$SCHOOL_NAME'},
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'CITY':{'$first':'$CITY'},
                            'STATE':{'$first':'$STATE'},
                            'IP':{'$first':'$IP'},
                            'CREATED_DATE':{'$first':'$CREATED_DATE'},
                            'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                            'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                            'PHONE':{'$first':'$PHONE'},
                            }},
            { "$project": { '_id':0,

                'USER_ID':'$_id.user','USER_NAME':1,'EMAIL_ID':1,
                    'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                    }}]

        elif d=='T':
            reader = geolite2.reader()
            username = urllib.parse.quote_plus('admin')
            password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
            client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
            db=client.compass
            collection = db.audio_track_master
            query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                            {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                 
                            {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$regex':'bonus','$options':'i'}},
    #                         {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                            ]}},

                {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                    'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                    'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                    'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                    'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                    'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                    'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                    'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                    'Mindful_Minutes':{"$round":[{"$divide":
                        [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                    'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},

                { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                    'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'AGE_GROUP':1     
                    }},
            {'$group':
                        {'_id':{'user':'$User_ObjectId','agegp':'$AGE_GROUP'},
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'EMAIL_ID':{'$first':'$USER_EMAIL'},
                            'SCHOOL':{'$first':'$SCHOOL_NAME'},
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'CITY':{'$first':'$CITY'},
                            'STATE':{'$first':'$STATE'},
                            'IP':{'$first':'$IP'},
                            'CREATED_DATE':{'$first':'$CREATED_DATE'},
                            'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                            'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                            'PHONE':{'$first':'$PHONE'},
                            }},
            { "$project": { '_id':0,

                'USER_ID':'$_id.user','USER_NAME':1,'EMAIL_ID':1,
                    'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                    }}]
        elif d=='S':


            reader = geolite2.reader()
            username = urllib.parse.quote_plus('admin')
            password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
            client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
            db=client.compass
            collection = db.audio_track_master
            query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                             {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                            {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$regex':'sound','$options':'i'}},
    #                         {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                            ]}},

                {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                    'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                    'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                    'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                    'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                    'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                    'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                    'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                    'Mindful_Minutes':{"$round":[{"$divide":
                        [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                    'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},

                { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                    'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'AGE_GROUP':1     
                    }},
            {'$group':
                        {'_id':'$User_ObjectId',
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'EMAIL_ID':{'$first':'$USER_EMAIL'},
                            'SCHOOL':{'$first':'$SCHOOL_NAME'},
                            'USER_NAME':{'$first':'$USER_NAME'},
                            'CITY':{'$first':'$CITY'},
                            'STATE':{'$first':'$STATE'},
                            'IP':{'$first':'$IP'},
                            'CREATED_DATE':{'$first':'$CREATED_DATE'},
                            'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                            'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                            'PHONE':{'$first':'$PHONE'},
                            }},
            { "$project": { '_id':0,

                'USER_ID':'$_id','USER_NAME':1,'EMAIL_ID':1,
                    'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                               'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                               'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                    }}]
        else:
            pass  
        daily=list(collection.aggregate(query))
        daily_df=pd.DataFrame(daily)
        daily_df.Mindful_minutes=daily_df.Mindful_minutes.astype('int64')
        daily_df['MODIFIED_DATE']=pd.to_datetime(daily_df['MODIFIED_DATE'])
        daily_df['CREATED_DATE']=pd.to_datetime(daily_df['CREATED_DATE'])
        daily_df['SCHOOL'].fillna("NO SCHOOL INFO", inplace=True)
        daily_df['EMAIL_ID'].fillna("EMAIL_ID NOT AVAILABLE", inplace=True)
        daily_df['EMAIL_ID'].replace("",'EMAIL_ID NOT AVAILABLE', inplace=True)
        daily_df['USER_NAME'].replace("",'USER NAME NOT AVAILABLE', inplace=True)
        daily_df['CITY'].fillna("NO CITY INFO AVAILABLE", inplace=True)
        daily_df['STATE'].fillna("NO STATE INFO AVAILABLE", inplace=True)



        def country1(i):

            location = reader.get(i)
            c=(location['country']['names']['en'])
            return c
        def state1(i):
            location = reader.get(i)
            s=(location['subdivisions'][0]['names']['en'])
            return s
        def city1(i):
            location = reader.get(i)
            city=location['city']['names']['en']
            return city
        def pn_country(i):
            import phonenumbers
            import pycountry
            from phonenumbers.phonenumberutil import (
            region_code_for_country_code,
            region_code_for_number,)
            pn = phonenumbers.parse('+'+i)   
            country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
            con=country.name
            return con
        ip=daily_df['IP'].tolist()
        phone_number=daily_df['PHONE'].tolist()
        Parents_Name=daily_df['USER_NAME'].tolist()
        Parents_Email=daily_df.EMAIL_ID.tolist()
        School_Name=daily_df['SCHOOL'].tolist()
        state=daily_df['STATE'].tolist()
        city=daily_df['CITY'].tolist()
        sign_up_date=daily_df['CREATED_DATE'].tolist()
        last_prac_date=daily_df['MODIFIED_DATE'].tolist()
        #     practice_count=df['Practice_Count'].tolist()
        mindful_minutes=daily_df['Mindful_minutes'].tolist()
        
        for i in range(len(ip)):            
            if city[i] is None:
                try:
                    city[i]=city1(ip[i])
                except:
                    pass
            elif city[i]=='NO CITY INFO AVAILABLE':
                try:
                    city[i]=city1(ip[i])
                except:
                    pass                        

            if state[i] is None:
                try:
                    state[i]=state1(ip[i])
                except:
                    pass
            elif state[i] =='NO STATE INFO AVAILABLE':
                try:
                    state[i]=state1(ip[i])
                except:
                    pass    
            if state[i] is None:
                state[i]=''
            if  last_prac_date[i] != 'NO PRACTICE' :
                last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
            else:
                last_prac_date[i]="NO PRACTICE"

            if sign_up_date[i] is not None:        
                sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')


        state12 =  [each_string.upper() for each_string in state]
        city12= [each_string.upper() for each_string in city]
        school= [each_string.upper() for each_string in School_Name]



        cv={'pnn':Parents_Name,'pe':Parents_Email,'pn':phone_number,'sn':school,'ct':city12,
           'st':state12,'sp':sign_up_date,
           'lp':last_prac_date,'mm':mindful_minutes}
        dftry = pd.DataFrame.from_dict(cv)

        return json.dumps({"data":dftry.values.tolist()})






# @app.route('/mitpracticeprogg/<d>')
# def mit_tableprogram(d):
#     x=''
#     query=''
#     if d=='D':
#         reader = geolite2.reader()
#         db = mysql.connector.connect(
#         host="52.35.73.200",
#         user="ieuser",
#         passwd="mijyBg96wtdDSAB5",
#         database="compass")
#         query="""select sm.id,sm.name,um.USER_ID as Parents_Id,um.USER_NAME as Parents_Name,up.ip_address,um.contact_number,
#         sm.city,sm.state,sm.country,um.EMAIL_ID as Parents_Email,um.user_type,
#         count(atd.USER_ID) as Practice_Count,max(date(atd.modified_date)) as Last_Practice_Date,date(um.created_date) Sign_Up_Date,
#         max(date(ll.LAST_LOGGED_IN)) as Last_Login_Date,
#         round((sum(atd.CURSOR_END)-sum(atd.CURSOR_START))/60) as mindful_minutes
#         from user_master as um left join user_profile as up
#         on um.user_id=up.user_id
#         inner join audio_track_detail as atd on atd.USER_ID=um.USER_ID
#         left join school_master as sm on sm.id=up.SCHOOL_ID
#         left join login_logs as ll on ll.USER_ID=um.USER_ID
#         inner join programs_audio pa on pa.AUDIO_ID=atd.PROGRAM_AUDIO_ID
#         inner join program_master pm on pm.PROGRAM_ID=pa.PROGRAM_ID
#         where um.ROLE_ID=3 and date(um.created_date)>'2020-03-17'  AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.email_id not like '%test%' and 
#         um.email_id not like '%1gen%' and um.user_name not like '%test%' and pa.audio_day  not like '%sound%' and pa.audio_day  not like '%bonus%' and um.user_name not like '%1gen%' and um.email_id <>''
#         group by um.user_id;"""
        
#     elif d=='T':
#         reader = geolite2.reader()
#         db = mysql.connector.connect(
#         host="52.35.73.200",
#         user="ieuser",
#         passwd="mijyBg96wtdDSAB5",
#         database="compass")
#         query="""select sm.id,sm.name,um.USER_ID as Parents_Id,um.USER_NAME as Parents_Name,up.ip_address,um.contact_number,
#         sm.city,sm.state,sm.country,um.EMAIL_ID as Parents_Email,um.user_type,
#         count(atd.USER_ID) as Practice_Count,max(date(atd.modified_date)) as Last_Practice_Date,date(um.created_date) Sign_Up_Date,
#         max(date(ll.LAST_LOGGED_IN)) as Last_Login_Date,
#         round((sum(atd.CURSOR_END)-sum(atd.CURSOR_START))/60) as mindful_minutes
#         from user_master as um left join user_profile as up
#         on um.user_id=up.user_id
#         inner join audio_track_detail as atd on atd.USER_ID=um.USER_ID
#         left join school_master as sm on sm.id=up.SCHOOL_ID
#         left join login_logs as ll on ll.USER_ID=um.USER_ID
#         inner join programs_audio pa on pa.AUDIO_ID=atd.PROGRAM_AUDIO_ID
#         inner join program_master pm on pm.PROGRAM_ID=pa.PROGRAM_ID
#         where um.ROLE_ID=3 and date(um.created_date)>'2020-03-17'  AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.email_id not like '%test%' and 
#         um.email_id not like '%1gen%' and um.user_name not like '%test%' and pa.audio_day   like '%bonus%' and um.user_name not like '%1gen%' and um.email_id <>''
#         group by um.user_id;"""
#     elif d=='S':
#         reader = geolite2.reader()
#         db = mysql.connector.connect(
#         host="52.35.73.200",
#         user="ieuser",
#         passwd="mijyBg96wtdDSAB5",
#         database="compass")
#         query="""select sm.id,sm.name,um.USER_ID as Parents_Id,um.USER_NAME as Parents_Name,up.ip_address,um.contact_number,
#         sm.city,sm.state,sm.country,um.EMAIL_ID as Parents_Email,um.user_type,
#         count(atd.USER_ID) as Practice_Count,max(date(atd.modified_date)) as Last_Practice_Date,date(um.created_date) Sign_Up_Date,
#         max(date(ll.LAST_LOGGED_IN)) as Last_Login_Date,
#         round((sum(atd.CURSOR_END)-sum(atd.CURSOR_START))/60) as mindful_minutes
#         from user_master as um left join user_profile as up
#         on um.user_id=up.user_id
#         inner join audio_track_detail as atd on atd.USER_ID=um.USER_ID
#         left join school_master as sm on sm.id=up.SCHOOL_ID
#         left join login_logs as ll on ll.USER_ID=um.USER_ID
#         inner join programs_audio pa on pa.AUDIO_ID=atd.PROGRAM_AUDIO_ID
#         inner join program_master pm on pm.PROGRAM_ID=pa.PROGRAM_ID
#         where um.ROLE_ID=3 and date(um.created_date)>'2020-03-17'  AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.email_id not like '%test%' and 
#         um.email_id not like '%1gen%' and um.user_name not like '%test%' and pa.audio_day   like '%sound%' and um.user_name not like '%1gen%' and um.email_id <>''
#         group by um.user_id;"""
#     else:
#         pass
#     df=pd.read_sql(query, con=db)
  
#     df.mindful_minutes=df.mindful_minutes.fillna(0)
#     df.mindful_minutes=df.mindful_minutes.astype('int64')
#     df['Last_Practice_Date']=pd.to_datetime(df['Last_Practice_Date'])
#     df['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
#     df['Last_Login_Date']=pd.to_datetime(df['Last_Login_Date'])
#     df['Last_Login_Date'].fillna("NO LOGIN", inplace=True)
#     df['Sign_Up_Date']=pd.to_datetime(df['Sign_Up_Date'])
#     df['name'].fillna("NO SCHOOL INFO", inplace=True)
#     def country1(i):
#         location = reader.get(i)
#         c=(location['country']['names']['en'])
#         return c
#     def state1(i):
#         location = reader.get(i)
#         s=(location['subdivisions'][0]['names']['en'])
#         return s
#     def city1(i):
#         location = reader.get(i)
#         city=location['city']['names']['en']
#         return city
#     def pn_country(i):
#         import phonenumbers
#         import pycountry
#         from phonenumbers.phonenumberutil import (
#         region_code_for_country_code,
#         region_code_for_number,)
#         pn = phonenumbers.parse('+'+i)   
#         country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
#         con=country.name
#         return con
#     ip=df['ip_address'].tolist()
#     phone_number=df['contact_number'].tolist()
#     Parents_Name=df['Parents_Name'].tolist()
#     Parents_Email=df.Parents_Email.tolist()
#     School_Name=df['name'].tolist()
#     state=df['state'].tolist()
#     country=df['country'].tolist()
#     city=df['city'].tolist()
#     sign_up_date=df['Sign_Up_Date'].tolist()
#     last_prac_date=df['Last_Practice_Date'].tolist()
#     last_login_date=df['Last_Login_Date'].tolist()
#     practice_count=df['Practice_Count'].tolist()
#     mindful_minutes=df['mindful_minutes'].tolist()
#     for i in range(len(ip)):
#         if country[i] is None:
#             try:
#                 country[i]=country1(ip[i])
#             except:
#                 pass
#         elif country[i]=='null':
#             try:
#                 country[i]=country1(ip[i])
#             except:
#                 pass
#         if city[i] is None:
#             try:
#                 city[i]=city1(ip[i])
#             except:
#                 pass
#         elif city[i]=='null':
#             try:
#                 city[i]=city1(ip[i])
#             except:
#                 pass
#         if state[i] is None:
#             try:
#                 state[i]=state1(ip[i])
#             except:
#                 pass
#         elif state[i] =='NO state info':
#             try:
#                 state[i]=state1(ip[i])
#             except:
#                 pass    
#         if country[i] is None:
#             try:
#                 country[i]=pn_country(phone_number[i])
#             except:
#                 pass
#         if country[i] is None:
#             country[i]=''
#         if state[i] is None:
#             state[i]=''
#         if  last_prac_date[i] != 'NO PRACTICE' :
#             last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
#         else:
#             last_prac_date[i]="NO PRACTICE"
#         if  last_login_date[i] != 'NO LOGIN' :
#             last_login_date[i]=last_login_date[i].strftime('%d %b %Y')
#         else:
#             last_login_date[i]="NO LOGIN"
#         if sign_up_date[i] is not None:
#             sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')
#     state12 =  [each_string.lower() for each_string in state]
#     cv={'pnn':Parents_Name,'pe':Parents_Email,'co':country,'pn':phone_number,'sn':School_Name,'ct':city,
#                                'st':state12,'sp':sign_up_date,
#                                'll':last_login_date,'lp':last_prac_date,'pc':practice_count}
#     dftry = pd.DataFrame.from_dict(cv)
#     dftry= dftry.drop("co", axis=1)
    
        
#     return json.dumps({"data":dftry.values.tolist()})


@app.route('/newcardpar')
def programwise_card():   

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass

    collection = db.audio_track_master
    query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                        {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                        ]}},
        {"$project":{'USER_ID':'$USER_ID._id','PROGRAM_AUDIO_ID.AUDIO_ID':1,
            'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
            'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
            'AUDIO_NAME':1,'AUDIO_LENGTH':1,
            'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
             'Mindful_Minutes':{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},        
            'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}}       

                 ]
    Overall=list(collection.aggregate(query))
    Overall_df=pd.DataFrame(Overall)
    card_df=pd.DataFrame({'engaged':len(set(Overall_df.USER_ID.tolist())),
                 'active':len(set(Overall_df[Overall_df['PlayBack_Time_Percent']>=.5]['USER_ID'].tolist())),
                  'passive':len(set(Overall_df.USER_ID.tolist()))-
                          len(set(Overall_df[Overall_df['PlayBack_Time_Percent']>=.5]['USER_ID'].tolist())),
                 'playbackpractice':len(Overall_df),
                  'minutespractice':round(Overall_df.Mindful_Minutes.sum(),2)
                 },index=[0]).reset_index(drop=True)

    temp2={}        
    for j in range(len(card_df.columns)):
        key = card_df.columns[j]
        value = [str(card_df[card_df.columns[j]].iloc[0])]
        temp2.update({key:value})
    return json.dumps(temp2)

# CHECKPOINT

# @app.route('/newcardmit')
# def mitpracticedatacard():
    
#     db = mysql.connector.connect(
#     host="52.35.73.200",
#     user="ieuser",
#     passwd="mijyBg96wtdDSAB5",
#     database="compass")
#     q1="""select count(distinct(case when y.Audio_Watched_above_50>0 then y.User_id end)) as Active_Parents,
#     count(distinct(case when y.Audio_Watched_above_50=0 then y.User_id end)) as Passive_Parents,
#     sum(y.Mindful_Minutes) as Total_Mindful_Minutes,
#     sum(y.Total_Playbacks) as Overall_PlayBacks
#     from(select x.USER_ID as User_id,count(distinct(x.PROGRAM_AUDIO_ID)) as Unique_Audio_Played,
#     count(distinct(case when x.audio_length*.50 <=x.Playback_Time then x.PROGRAM_AUDIO_ID end))
#     as Audio_Watched_above_50,
#     count(x.USER_ID) as Total_Playbacks,
#     count(case when x.audio_length*.50 <=x.Playback_Time then x.USER_ID end)
#     as Total_Playback_Above_50,
#      round(sum(Playback_Time/60)) as Mindful_Minutes
#     from (select um.USER_ID,atd.PROGRAM_AUDIO_ID,pa.AUDIO_LENGTH as audio_length,
#     (atd.CURSOR_END-atd.CURSOR_START) as Playback_Time
#     from user_master as um left join user_profile as up
#     on um.user_id=up.user_id
#     inner join audio_track_detail as atd on atd.USER_ID=um.USER_ID
#     left join school_master as sm on sm.id=up.SCHOOL_ID
#     left join programs_audio as pa on pa.AUDIO_ID=atd.PROGRAM_AUDIO_ID
#     where um.ROLE_ID=3 and date(um.created_date)>'2020-03-17'  AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y'
#     and um.email_id not like '%test%' and um.email_id not like '%1gen%' 
#     and um.user_name not like '%test%' and  um.USER_TYPE like "%mit%" and um.user_name not like '%1gen%' and um.email_id <>'') as x
#     group by x.USER_ID) as y"""
#     df1=pd.read_sql(q1, con=db)
#     temp={"playbackpractice":str(df1['Overall_PlayBacks'][0]),"minutespractice":str(df1['Total_Mindful_Minutes'][0]),"total":str(df1['Active_Parents'][0]+df1['Passive_Parents'][0]),"active":str(df1['Active_Parents'][0]),"passive":str(df1['Passive_Parents'][0])}
#     return json.dumps(temp)


@app.route('/paractweek')
def paractweek12():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus("I#L@teST^m0NGO_2o20!")
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.audio_track_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
        
    df_prac = DataFrame(list(collection2.aggregate([
            {"$match":{'$and':[{'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}, 
                       {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                       {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                       {"USER_ID.EMAIL_ID":{"$not":{"$regex" : 'test','$options':'i'}}},
                       {"USER_ID.EMAIL_ID":{"$nin": ["",None]}},
                       {"USER_ID.EMAIL_ID":{"$not":{"$regex" : '1gen','$options':'i'}}},
                       {"USER_ID.USER_NAME":{"$not":{"$regex" : 'test','$options':'i'}}},
                       {'USER_ID.USER_NAME':{'$ne':{'$regex':'1gen','$options':'i'}}},
                       {"USER_ID.CREATED_DATE":{"$gt": myDatetime}}]}},
            {'$group':{'_id':'$USER_ID._id',
                       'date':{'$first':'$MODIFIED_DATE'} }},
#             {"$project":{"_id":0, 'sign_up':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}},'practice_count':{'$size':'$distinct'}}},
#             { '$sort': { '_id': 1 }}
    ])))
    df_prac1 = df_prac.rename(columns={"date": "sign_up"})
#     df_prac1 = df_prac.sort_values(by = ['sign_up']).reset_index(drop = True)
    
    
#     final['practice_count'] = final['practice_count'].fillna(0)
    # print(df1)
    df_prac1['sign_up'] = pd.to_datetime(df_prac1['sign_up'], errors = 'coerce')
    
    df_prac1['sign_upn'] = pd.to_datetime(df_prac1['sign_up']) - timedelta(hours=4)
    
    
    
    from datetime import datetime
    from pytz import timezone
    tz = timezone('UTC')
    date=datetime.now(tz) 
    today = pd.to_datetime(date) - timedelta(hours=4)
    todaydate=today.strftime("%Y-%m-%d")
    # print(todaydate)
    
    
    df2 = df_prac1.groupby([df_prac1['sign_upn'].dt.date]).count()

    # print(df1)
    
    
    cdate=[]
    for i in df2.index:
        x=i.strftime('%s')
        cdate.append(float(x)*1000)
    count=[]
    for i in df2['sign_up'] :
        count.append(i)
    count1=np.cumsum(count)
    
    
    df3 = pd.DataFrame(list(zip(cdate,count)), 
                       columns =['date', 'count']) 
    df4 = pd.DataFrame(list(zip(cdate,count1)), 
                       columns =['date', 'count'])
    data = df3.values.tolist()
    data1 = df4.values.tolist()


    ##### hourly graph

    
    times = pd.to_datetime(df_prac1.sign_upn)
    times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
    timedf=times.groupby(['hour']).size().to_frame('count').reset_index()

    timedata={"hour":timedf['hour'].tolist(),"count":timedf['count'].tolist()}

    ###### week data
    df_data = pd.to_datetime(df_prac1['sign_upn'], format='%Y%m%d')
    week_df = df_data.groupby(df_prac1['sign_upn'].dt.strftime("%A")).count()

    weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],"count":[str(week_df['Monday']),str(week_df['Tuesday']),str(week_df['Wednesday']),str(week_df['Thursday']),str(week_df['Friday']),str(week_df['Saturday']),str(week_df['Sunday'])]}
    temp={"weekdata":weekdata,"timedata":timedata}
    return json.dumps(temp)

    return json.dumps(temp)
# paractweek12()

#>>>>>>>>>>>>>..-------------------PRACTICE BIFURCATION API------->>>>>>>>>>
@app.route('/paractweek/<charttype>')
def paract__week__12(charttype):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus("I#L@teST^m0NGO_2o20!")
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.audio_track_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        ############# DAY WISE #####################
        df_prac = DataFrame(list(collection2.aggregate([
                {"$match":{'$and':[{'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}, 
                           {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                           {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                           {"USER_ID.EMAIL_ID":{"$not":{"$regex" : 'test','$options':'i'}}},
                           {"USER_ID.EMAIL_ID":{"$nin": ["",None]}},
                           {"USER_ID.EMAIL_ID":{"$not":{"$regex" : '1gen','$options':'i'}}},
                           {"USER_ID.USER_NAME":{"$not":{"$regex" : 'test','$options':'i'}}},
                           {'USER_ID.USER_NAME':{'$ne':{'$regex':'1gen','$options':'i'}}},
                           {"USER_ID.CREATED_DATE":{"$gt": myDatetime}}]}},
                        practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
                {'$group':{'_id':'$USER_ID',
                           'date':{'$first':'$MODIFIED_DATE'} }},
    #             {"$project":{"_id":0, 'sign_up':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}},'practice_count':{'$size':'$distinct'}}},
    #             { '$sort': { '_id': 1 }}
        ])))
        df_prac1 = df_prac.rename(columns={"date": "sign_up"})
    #     df_prac1 = df_prac.sort_values(by = ['sign_up']).reset_index(drop = True)


    #     final['practice_count'] = final['practice_count'].fillna(0)
        # print(df1)
        df_prac1['sign_up'] = pd.to_datetime(df_prac1['sign_up'], errors = 'coerce')

        df_prac1['sign_upn'] = pd.to_datetime(df_prac1['sign_up']) - timedelta(hours=4)



        from datetime import datetime
        from pytz import timezone
        tz = timezone('UTC')
        date=datetime.now(tz) 
        today = pd.to_datetime(date) - timedelta(hours=4)
        todaydate=today.strftime("%Y-%m-%d")
        # print(todaydate)


        df2 = df_prac1.groupby([df_prac1['sign_upn'].dt.date]).count()

        # print(df1)


        cdate=[]
        for i in df2.index:
            x=i.strftime('%S')
            cdate.append(float(x)*1000)
        count=[]
        for i in df2['sign_up'] :
            count.append(i)
        count1=np.cumsum(count)


        df3 = pd.DataFrame(list(zip(cdate,count)), 
                           columns =['date', 'count']) 
        df4 = pd.DataFrame(list(zip(cdate,count1)), 
                           columns =['date', 'count'])
        data = df3.values.tolist()
        data1 = df4.values.tolist()


        ##### hourly graph


        times = pd.to_datetime(df_prac1.sign_upn)
        times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
        timedf=times.groupby(['hour']).size().to_frame('count').reset_index()

        timedata={"hour":timedf['hour'].tolist(),"count":timedf['count'].tolist()}
        ###### week data
        df_data = pd.to_datetime(df_prac1['sign_upn'], format='%Y%m%d')
        week_df = df_data.groupby(df_prac1['sign_upn'].dt.strftime("%A")).count()
        if len(week_df) < 7:
            dd = pd.DataFrame(week_df).transpose()
            if "Monday" not in dd.columns:
                dd["Monday"] = 0
            if "Tuesday" not in dd.columns:
                dd["Tuesday"] = 0
            if "Wednesday" not in dd.columns:
                dd["Wednesday"] = 0
            if "Thursday" not in dd.columns:
                dd["Thursday"] = 0
            if "Friday" not in dd.columns:
                dd["Friday"] = 0
            if "Saturday" not in dd.columns:
                dd["Saturday"] = 0
            if "Sunday" not in dd.columns:
                dd["Sunday"] = 0

            dd = dd.T
            week_df = pd.Series(dd.sign_upn)

    
        weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],
                  "count":[str(week_df['Monday']),str(week_df['Tuesday']),str(week_df['Wednesday']),
                           str(week_df['Thursday']),str(week_df['Friday']),str(week_df['Saturday']),str(week_df['Sunday'])]}
        temp={"weekdata":weekdata,"timedata":timedata}
        return json.dumps(temp)

    
    else:
        ############# DAY WISE #####################
        df_prac = DataFrame(list(collection2.aggregate([
                {"$match":{'$and':[{'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}, 
                           {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                           {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                           {"USER_ID.EMAIL_ID":{"$not":{"$regex" : 'test','$options':'i'}}},
                           {"USER_ID.EMAIL_ID":{"$nin": ["",None]}},
                           {"USER_ID.EMAIL_ID":{"$not":{"$regex" : '1gen','$options':'i'}}},
                           {"USER_ID.USER_NAME":{"$not":{"$regex" : 'test','$options':'i'}}},
                           {'USER_ID.USER_NAME':{'$ne':{'$regex':'1gen','$options':'i'}}},
                           {"USER_ID.CREATED_DATE":{"$gt": myDatetime}}]}},
                {'$group':{'_id':'$USER_ID._id',
                           'date':{'$first':'$MODIFIED_DATE'} }},
    #             {"$project":{"_id":0, 'sign_up':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}},'practice_count':{'$size':'$distinct'}}},
    #             { '$sort': { '_id': 1 }}
        ])))
        df_prac1 = df_prac.rename(columns={"date": "sign_up"})
    #     df_prac1 = df_prac.sort_values(by = ['sign_up']).reset_index(drop = True)


    #     final['practice_count'] = final['practice_count'].fillna(0)
        # print(df1)
        df_prac1['sign_up'] = pd.to_datetime(df_prac1['sign_up'], errors = 'coerce')

        df_prac1['sign_upn'] = pd.to_datetime(df_prac1['sign_up']) - timedelta(hours=4)



        from datetime import datetime
        from pytz import timezone
        tz = timezone('UTC')
        date=datetime.now(tz) 
        today = pd.to_datetime(date) - timedelta(hours=4)
        todaydate=today.strftime("%Y-%m-%d")
        # print(todaydate)


        df2 = df_prac1.groupby([df_prac1['sign_upn'].dt.date]).count()

        # print(df1)


        cdate=[]
        for i in df2.index:
            x=i.strftime('%S')
            cdate.append(float(x)*1000)
        count=[]
        for i in df2['sign_up'] :
            count.append(i)
        count1=np.cumsum(count)


        df3 = pd.DataFrame(list(zip(cdate,count)), 
                           columns =['date', 'count']) 
        df4 = pd.DataFrame(list(zip(cdate,count1)), 
                           columns =['date', 'count'])
        data = df3.values.tolist()
        data1 = df4.values.tolist()


        ##### hourly graph


        times = pd.to_datetime(df_prac1.sign_upn)
        times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
        timedf=times.groupby(['hour']).size().to_frame('count').reset_index()

        timedata={"hour":timedf['hour'].tolist(),"count":timedf['count'].tolist()}

        ###### week data
        df_data = pd.to_datetime(df_prac1['sign_upn'], format='%Y%m%d')
        week_df = df_data.groupby(df_prac1['sign_upn'].dt.strftime("%A")).count()

        weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],"count":[str(week_df['Monday']),str(week_df['Tuesday']),str(week_df['Wednesday']),str(week_df['Thursday']),str(week_df['Friday']),str(week_df['Saturday']),str(week_df['Sunday'])]}
        temp={"weekdata":weekdata,"timedata":timedata}
        return json.dumps(temp)







@app.route('/mitpracticeprogg')
def mitpracticeprog2():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID.ROLE_ID':{"$eq":3}},                  
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER_ID.USER_TYPE':{"$regex":'mit','$options':'i'}},          
                {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                {'USER_ID.EMAIL_ID':{'$nin':['',' ',None]}}

                ]}},

    {"$project":{'USER_ID':'$USER_ID.USER_ID','PROGRAM_AUDIO_ID.AUDIO_ID':1,
        'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
        'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
        'AUDIO_NAME':1,'AUDIO_LENGTH':1,
        'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

        'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
            ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},


    { "$project": { 'USER_ID':1,'AGE_GROUP':1,

        "status": {
        "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": 'bonus','options': "i"  }}
            , 
        "then": 'Bonus', "else": {
            "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": "sound",'options': "i" }}, 
            "then": 'Sound', "else": 'daily'
            }}}}}}         

            ]

    x=list(collection.aggregate(query))
    df=pd.DataFrame(x)
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

    practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].count()).reset_index().rename(columns={'USER_ID':'Count'})
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
    dailydf=practice_count_overall[practice_count_overall.status=='daily']
    dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
    dailycompdf['status'].fillna('daily',inplace=True)
    dailycompdf['Count'].fillna(0,inplace=True)
    Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
    Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
    Soundcompdf['status'].fillna('Sound',inplace=True)
    Soundcompdf['Count'].fillna(0,inplace=True)
    Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
    Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
    Bonuscompdf['status'].fillna('Bonus',inplace=True)
    Bonuscompdf['Count'].fillna(0,inplace=True)
    temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
    'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
    'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}
    return json.dumps(temp)



@app.route('/parpracticeprogg')
def parpracticeprogram():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                        {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                        ]}},

    {"$project":{'USER_ID':'$USER_ID._id','PROGRAM_AUDIO_ID.AUDIO_ID':1,
        'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
        'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
        'AUDIO_NAME':1,'AUDIO_LENGTH':1,
        'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

        'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
            ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},


    { "$project": { 'USER_ID':1,'AGE_GROUP':1,

        "status": {
          "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": 'bonus','options': "i"  }}
              , 
          "then": 'Bonus', "else": {
             "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": "sound",'options': "i" }}, 
             "then": 'Sound', "else": 'daily'
             }}}}}}         

             ]

    x=list(collection.aggregate(query))
    df=pd.DataFrame(x)
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

    practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].count()).reset_index().rename(columns={'USER_ID':'Count'})
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
    dailydf=practice_count_overall[practice_count_overall.status=='daily']
    dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
    dailycompdf['status'].fillna('daily',inplace=True)
    dailycompdf['Count'].fillna(0,inplace=True)
    Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
    Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
    Soundcompdf['status'].fillna('Sound',inplace=True)
    Soundcompdf['Count'].fillna(0,inplace=True)
    Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
    Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
    Bonuscompdf['status'].fillna('Bonus',inplace=True)
    Bonuscompdf['Count'].fillna(0,inplace=True)
    temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
      'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
       'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}

    return json.dumps(temp)

#>>>>>>>>>>>>------------ PRACTICE BIFURCATION API-------------------
@app.route('/parpracticeprogg_new/<charttype>')
def parpractice__program___(charttype):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                            {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                            ]}},
           

        {"$project":{'USER_ID':'$USER_ID._id','PROGRAM_AUDIO_ID.AUDIO_ID':1,
            'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
            'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
            'AUDIO_NAME':1,'AUDIO_LENGTH':1,
            'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

            'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
#               practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
                         threshcond[0],


        { "$project": { 'USER_ID':1,'AGE_GROUP':1,

            "status": {
              "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": 'bonus','options': "i"  }}
                  , 
              "then": 'Bonus', "else": {
                 "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": "sound",'options': "i" }}, 
                 "then": 'Sound', "else": 'daily'
                 }}}}}}         

                 ]

        x=list(collection.aggregate(query))
        df=pd.DataFrame(x)
        
        if 'AGE_GROUP' not in df.columns:
            df['AGE_GROUP'] = 0
        if 'USER_ID' not in df.columns:
            df['USER_ID'] = 0
            
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

        practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].count()).reset_index().rename(columns={'USER_ID':'Count'})
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
        dailydf=practice_count_overall[practice_count_overall.status=='daily']
        dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
        dailycompdf['status'].fillna('daily',inplace=True)
        dailycompdf['Count'].fillna(0,inplace=True)
        Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
        Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
        Soundcompdf['status'].fillna('Sound',inplace=True)
        Soundcompdf['Count'].fillna(0,inplace=True)
        Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
        Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
        Bonuscompdf['status'].fillna('Bonus',inplace=True)
        Bonuscompdf['Count'].fillna(0,inplace=True)
        temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
          'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
           'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}

        return json.dumps(temp, default=str)
    
    else:
        query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                            {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                            ]}},

        {"$project":{'USER_ID':'$USER_ID._id','PROGRAM_AUDIO_ID.AUDIO_ID':1,
            'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
            'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
            'AUDIO_NAME':1,'AUDIO_LENGTH':1,
            'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

            'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},


        { "$project": { 'USER_ID':1,'AGE_GROUP':1,

            "status": {
              "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": 'bonus','options': "i"  }}
                  , 
              "then": 'Bonus', "else": {
                 "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": "sound",'options': "i" }}, 
                 "then": 'Sound', "else": 'daily'
                 }}}}}}         

                 ]

        x=list(collection.aggregate(query))
        df=pd.DataFrame(x)
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

        practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].count()).reset_index().rename(columns={'USER_ID':'Count'})
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
        dailydf=practice_count_overall[practice_count_overall.status=='daily']
        dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
        dailycompdf['status'].fillna('daily',inplace=True)
        dailycompdf['Count'].fillna(0,inplace=True)
        Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
        Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
        Soundcompdf['status'].fillna('Sound',inplace=True)
        Soundcompdf['Count'].fillna(0,inplace=True)
        Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
        Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
        Bonuscompdf['status'].fillna('Bonus',inplace=True)
        Bonuscompdf['Count'].fillna(0,inplace=True)
        temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
          'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
           'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}

        return json.dumps(temp)




@app.route('/parpracprog')
def parpracticeprogram_unique():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                        {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                        ]}},

    {"$project":{'USER_ID':'$USER_ID._id','PROGRAM_AUDIO_ID.AUDIO_ID':1,
        'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
        'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
        'AUDIO_NAME':1,'AUDIO_LENGTH':1,
        'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

        'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
            ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},


    { "$project": { 'USER_ID':1,'AGE_GROUP':1,

        "status": {
          "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": 'bonus','options': "i"  }}
              , 
          "then": 'Bonus', "else": {
             "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": "sound",'options': "i" }}, 
             "then": 'Sound', "else": 'daily'
             }}}}}}         

             ]

    x=list(collection.aggregate(query))
    df=pd.DataFrame(x)
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

    practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].nunique()).reset_index().rename(columns={'USER_ID':'Count'})
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
    dailydf=practice_count_overall[practice_count_overall.status=='daily']
    dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
    dailycompdf['status'].fillna('daily',inplace=True)
    dailycompdf['Count'].fillna(0,inplace=True)
    Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
    Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
    Soundcompdf['status'].fillna('Sound',inplace=True)
    Soundcompdf['Count'].fillna(0,inplace=True)
    Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
    Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
    Bonuscompdf['status'].fillna('Bonus',inplace=True)
    Bonuscompdf['Count'].fillna(0,inplace=True)
    temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
      'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
       'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}
    return json.dumps(temp)

#>>>>>>>>>>>>>>----------- PRACTICE BIFURCATION API--------------->>>>>>>>>>>>
@app.route('/parpracprog/<charttype>')
def par__practice__program__unique(charttype):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                            {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                            ]}},
         

        {"$project":{'USER_ID':'$USER_ID._id','PROGRAM_AUDIO_ID.AUDIO_ID':1,
            'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
            'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
            'AUDIO_NAME':1,'AUDIO_LENGTH':1,
            'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

            'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
#                practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
                         threshcond[0],


        { "$project": { 'USER_ID':1,'AGE_GROUP':1,

            "status": {
              "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": 'bonus','options': "i"  }}
                  , 
              "then": 'Bonus', "else": {
                 "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": "sound",'options': "i" }}, 
                 "then": 'Sound', "else": 'daily'
                 }}}}}}         

                 ]

        x=list(collection.aggregate(query))
        df=pd.DataFrame(x)
        
        if 'AGE_GROUP' not in df.columns:
            df['AGE_GROUP'] = 0
        if 'USER_ID' not in df.columns:
            df['USER_ID'] = 0
            
            
            
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

        practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].nunique()).reset_index().rename(columns={'USER_ID':'Count'})
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
        dailydf=practice_count_overall[practice_count_overall.status=='daily']
        dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
        dailycompdf['status'].fillna('daily',inplace=True)
        dailycompdf['Count'].fillna(0,inplace=True)
        Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
        Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
        Soundcompdf['status'].fillna('Sound',inplace=True)
        Soundcompdf['Count'].fillna(0,inplace=True)
        Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
        Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
        Bonuscompdf['status'].fillna('Bonus',inplace=True)
        Bonuscompdf['Count'].fillna(0,inplace=True)
        temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
          'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
           'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}
        return json.dumps(temp, default=str)
    
    else:
        query=[
            {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                            {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                            {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                            ]}},

        {"$project":{'USER_ID':'$USER_ID._id','PROGRAM_AUDIO_ID.AUDIO_ID':1,
            'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
            'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
            'AUDIO_NAME':1,'AUDIO_LENGTH':1,
            'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

            'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},


        { "$project": { 'USER_ID':1,'AGE_GROUP':1,

            "status": {
              "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": 'bonus','options': "i"  }}
                  , 
              "then": 'Bonus', "else": {
                 "$cond": { "if": { "$regexMatch": { 
                                        "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                        "regex": "sound",'options': "i" }}, 
                 "then": 'Sound', "else": 'daily'
                 }}}}}}         

                 ]

        x=list(collection.aggregate(query))
        df=pd.DataFrame(x)
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

        practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].nunique()).reset_index().rename(columns={'USER_ID':'Count'})
        age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
        dailydf=practice_count_overall[practice_count_overall.status=='daily']
        dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
        dailycompdf['status'].fillna('daily',inplace=True)
        dailycompdf['Count'].fillna(0,inplace=True)
        Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
        Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
        Soundcompdf['status'].fillna('Sound',inplace=True)
        Soundcompdf['Count'].fillna(0,inplace=True)
        Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
        Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
        Bonuscompdf['status'].fillna('Bonus',inplace=True)
        Bonuscompdf['Count'].fillna(0,inplace=True)
        temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
          'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
           'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}
        return json.dumps(temp)






@app.route('/mitpracprog')
def mitpracprog():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER_ID.USER_TYPE':{"$regex":'mit','$options':'i'}}, 
                {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                {'USER_ID.EMAIL_ID':{'$nin':['',None,' ']}}

                ]}},

    {"$project":{'USER_ID':'$USER_ID.USER_ID','PROGRAM_AUDIO_ID.AUDIO_ID':1,
        'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
        'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
        'AUDIO_NAME':1,'AUDIO_LENGTH':1,
        'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

        'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
            ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},


    { "$project": { 'USER_ID':1,'AGE_GROUP':1,

        "status": {
        "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": 'bonus','options': "i"  }}
            , 
        "then": 'Bonus', "else": {
            "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": "sound",'options': "i" }}, 
            "then": 'Sound', "else": 'daily'
            }}}}}}         

            ]

    x=list(collection.aggregate(query))
    df=pd.DataFrame(x)
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

    practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].nunique()).reset_index().rename(columns={'USER_ID':'Count'})
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
    dailydf=practice_count_overall[practice_count_overall.status=='daily']
    dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
    dailycompdf['status'].fillna('daily',inplace=True)
    dailycompdf['Count'].fillna(0,inplace=True)
    Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
    Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
    Soundcompdf['status'].fillna('Sound',inplace=True)
    Soundcompdf['Count'].fillna(0,inplace=True)
    Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
    Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
    Bonuscompdf['status'].fillna('Bonus',inplace=True)
    Bonuscompdf['Count'].fillna(0,inplace=True)
    temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
    'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
    'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}
    return json.dumps(temp)



@app.route('/parsignupdaycompp')
def parents_anal_hourly_comparison():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass

    collection = db.user_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    ##################### TODAY ###########################
    df = df = DataFrame(list(collection.aggregate([
            {"$match":{'$and':[{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},

                  {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

            {"CREATED_DATE":{"$gt":myDatetime}}]}},
        {"$group":{"_id":{"$dateToString": {"date":'$CREATED_DATE'}}, 'distinct':{"$addToSet":'$_id'}}},
        {"$project":{"_id":1, 'Total_parents':{'$size':'$distinct'}}},
        { '$sort': { '_id': 1 }}])))
    df = df.rename(columns={"_id": "sign_up"})
    df=df.dropna()

    df['sign_up'] = pd.to_datetime(df['sign_up'], errors = 'coerce')
    df['sign_upn'] = pd.to_datetime(df['sign_up']) - timedelta(hours=4)
    df['date']=df['sign_upn'].apply(lambda x: x.strftime("%Y-%m-%d"))

    tz = timezone('US/Eastern')
    date=datetime.datetime.now(tz)
    yesterday=pd.to_datetime(date)-timedelta(days=1)
    todaydate=date.strftime("%Y-%m-%d")
    yesterdaydate=yesterday.strftime("%Y-%m-%d")
    print(yesterdaydate)
    print(todaydate)

    dfyes=df[df['date']==yesterdaydate]
    print("\n dfyes \n",dfyes)
    dftod=df[df['date']==todaydate]
    print("\n dftod \n",dftod)

    if len(dftod) != 0:
        times2 = pd.to_datetime(dftod.sign_upn)
        times2['hour'] = times2.map( lambda x: pd.to_datetime(x).hour )
        timedftod=times2.groupby(['hour']).size().to_frame('count').reset_index()

    else:
        timedftod = pd.DataFrame(index=[0], columns=['hour','count'])
        timedftod = timedftod.fillna(0) 


    if len(dfyes) != 0:
        times = pd.to_datetime(dfyes.sign_upn)
        times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
        timedfyes=times2.groupby(['hour']).size().to_frame('count').reset_index()

    else:
        timedfyes = pd.DataFrame(index=[0], columns=['hour','count'])
        timedfyes = timedfyes.fillna(0) 


    timedfyes = timedfyes.astype(int)
    timedftod = timedftod.astype(int)

    hour=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]
    countdf=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
    dftest = pd.DataFrame({'hour':hour,'countdf':countdf})

    result = pd.merge(dftest,timedfyes , how='left', on='hour')
    result=result.fillna(0)
    result= result.astype(int)
    result = result.sort_values(["hour", "count"], ascending = (True,False))
#     print("result \n",result)
    yescount=list(result['count'])
    totaly=sum(yescount)

    result2 = pd.merge(dftest,timedftod , how='left', on='hour')
    result2=result2.fillna(0)
    result2= result2.astype(int)
    result2 = result2.sort_values(["hour", "count"], ascending = (True,False))
#     print("result2 \n",result2)
    todcount=list(result2['count'])
    totalt=sum(todcount)

    temp={"tod":todcount,"yes":yescount,"totaly":[str(totaly)],"totalt":[str(totalt)]}

    return json.dumps(temp)
# parents_anal_hourly_comparison()

@app.route('/mitsignupdaycompp')
def mitsignupdaycomp211():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass

    collection = db.user_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    ##################### TODAY ###########################
    df = DataFrame(list(collection.aggregate([
        {"$match":{'ROLE_ID.ROLE_ID' :3, 
                "IS_DISTABLED":{"$ne":"Y"},
                "INCOMPLETE_SIGNUP":{"$ne":"Y"},
                "EMAIL_ID":{"$not":{"$regex" : 'test'}},
                'USER_TYPE':{"$regex":'mit','$options':'i'}, 
                "EMAIL_ID":{"$ne": ""},
                "EMAIL_ID":{"$not":{"$regex" : '1gen'}},
                "USER_NAME":{"$not":{"$regex" : 'test'}},
                "CREATED_DATE":{"$gt": myDatetime}}},
        {"$group":{"_id":{"$dateToString": {"date":'$CREATED_DATE'}}, 'distinct':{"$addToSet":'$_id'}}},
        {"$project":{"_id":1, 'Total_parents':{'$size':'$distinct'}}},
        { '$sort': { '_id': 1 }}])))
    df= df.rename(columns={"_id": "sign_up"})
    df1=df.dropna()
    df1['sign_up'] = pd.to_datetime(df1['sign_up'], errors = 'coerce')
    df1['sign_upn'] = pd.to_datetime(df1['sign_up']) - timedelta(hours=4)
    df1['date']=df1['sign_upn'].apply(lambda x: x.strftime("%Y-%m-%d"))
    from datetime import datetime
    from pytz import timezone
    tz = timezone('US/Eastern')
    date=datetime.now(tz)
    yesterday=pd.to_datetime(date)-timedelta(days=1)
    todaydate=date.strftime("%Y-%m-%d")
    yesterdaydate=yesterday.strftime("%Y-%m-%d")
    dfyes=df1[df1['date']==yesterdaydate]
    dftod=df1[df1['date']==todaydate]
    data = pd.DataFrame({'hour':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],'count':[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]} )
    times = pd.to_datetime(dfyes.sign_upn)
    times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
    timedfyes=times.groupby(['hour']).size().to_frame('count').reindex(data['hour']).fillna(0)
    times2 = pd.to_datetime(dftod.sign_upn)
    times2['hour'] = times2.map( lambda x: pd.to_datetime(x).hour )
    timedftod=times2.groupby(['hour']).size().to_frame('count').reindex(data['hour']).fillna(0)
    timedfyes = timedfyes.astype(int)
    hour=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]
    count=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
    dftest = pd.DataFrame({'hour':hour,'count':count})
    result = pd.merge(timedfyes , dftest,how='right', on='hour')
    result=result.fillna(0)
    result= result.astype(int)
    result = result.sort_values(["hour", "count_x"], ascending = (True,False))
    #yesterday count
    yescount=list(result['count_x'])
    timedftod = timedftod.astype(int)
    result12 = pd.merge(timedftod, dftest,how='right', on='hour')
    result12=result12.fillna(0)
    result12= result12.astype(int)
    result12 = result12.sort_values(["hour", "count_x"], ascending = (True,False))
    #todays count
    todcount=list(result12['count_x'])
    totaly=sum(yescount)
    totalt=sum(todcount)
    temp={"tod":todcount,"yes":yescount,"totaly":[str(totaly)],"totalt":[str(totalt)]}
    return json.dumps(temp)



@app.route('/parpracdaycompp')
def parsignupdaycomp12():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    df = DataFrame(list(collection.aggregate([
                {"$match":{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}},
                         'USER_ID.IS_DISABLED':{"$ne":'Y'},'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'},
                         'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}},
                         'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}},
                         'USER_ID.EMAIL_ID':{"$ne":""},
                         'USER_ID.CREATED_DATE':{"$gt":myDatetime},
                         'USER_ID.ROLE_ID.ROLE_ID':{"$eq":3}}},
                {"$group":{"_id":{"$dateToString": {"date":'$MODIFIED_DATE'}},'Count':{"$sum":1}}},
                {"$project":{"_id":1, 'Parents_Practice':'$Count'}},
                { '$sort': { '_id': 1 }}])))
    df = df.rename(columns={"_id": "sign_up"})
    df=df.dropna()
    df['sign_up'] = pd.to_datetime(df['sign_up'], errors = 'coerce')
    df['sign_upn'] = pd.to_datetime(df['sign_up']) - timedelta(hours=4)
    df['date']=df['sign_upn'].apply(lambda x: x.strftime("%Y-%m-%d"))
    tz = timezone('US/Eastern')
    date=datetime.datetime.now(tz)
    yesterday=pd.to_datetime(date)-timedelta(days=1)
    todaydate=date.strftime("%Y-%m-%d")
    yesterdaydate=yesterday.strftime("%Y-%m-%d")
    dfyes=df[df['date']==yesterdaydate]
    dftod=df[df['date']==todaydate]
    times = pd.to_datetime(dfyes.sign_upn)
    times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
    timedfyes=times.groupby(['hour']).size().to_frame('count').reset_index()
    times2 = pd.to_datetime(dftod.sign_upn)
    times2['hour'] = times2.map( lambda x: pd.to_datetime(x).hour )
    timedftod=times2.groupby(['hour']).size().to_frame('count').reset_index()
    timedfyes = timedfyes.astype(int)
    hour=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]
    count=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
    dftest = pd.DataFrame({'hour':hour,'count':count})
    result = pd.merge(timedfyes , dftest,how='right', on='hour')
    result=result.fillna(0)
    result= result.astype(int)
    result = result.sort_values(["hour", "count_x"], ascending = (True,False))
    #yesterday count
    yescount=list(result['count_x'])
    # timedftod = timedftod.astype(int)
    # result12 = pd.merge(timedftod, dftest,how='right', on='hour')
    # result12=result12.fillna(0)
    # result12= result12.astype(int)
    # result12 = result12.sort_values(["hour", "count_x"], ascending = (True,False))
    # #todays count
    todcount=list(result['count_y'])
    totaly=sum(yescount)
    totalt=sum(todcount)
    temp={"tod":todcount,"yes":yescount,"totaly":[str(totaly)],"totalt":[str(totalt)]}
    return json.dumps(temp)

#>>>>>>>>>>>>------------------- PRACTICE BIFURCATION API------------------>>>>>>>>>
@app.route('/parpracdaycompp/<charttype>')
def par_signup_day_comp_12_(charttype):
    from datetime import timedelta as tdelta
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        df = DataFrame(list(collection.aggregate([
                    {"$match":{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}},
                             'USER_ID.IS_DISABLED':{"$ne":'Y'},'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'},
                             'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}},
                             'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}},
                             'USER_ID.EMAIL_ID':{"$ne":""},
                             'USER_ID.CREATED_DATE':{"$gt":myDatetime},
                             'USER_ID.ROLE_ID.ROLE_ID':{"$eq":3}}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
                    {"$group":{"_id":{"$dateToString": {"date":'$MODIFIED_DATE'}},'Count':{"$sum":1}}},
                    {"$project":{"_id":1, 'Parents_Practice':'$Count'}},
                    { '$sort': { '_id': 1 }}])))
        df = df.rename(columns={"_id": "sign_up"})
        df=df.dropna()
        df['sign_up'] = pd.to_datetime(df['sign_up'], errors = 'coerce')
        df['sign_upn'] = pd.to_datetime(df['sign_up']) - timedelta(hours=4)
        df['date']=df['sign_upn'].apply(lambda x: x.strftime("%Y-%m-%d"))
        tz = timezone('US/Eastern')
        date=datetime.datetime.now(tz)
        yesterday=pd.to_datetime(date)-timedelta(days=1)
        todaydate=date.strftime("%Y-%m-%d")
        yesterdaydate=yesterday.strftime("%Y-%m-%d")
        dfyes=df[df['date']==yesterdaydate]
        dftod=df[df['date']==todaydate]
        times = pd.to_datetime(dfyes.sign_upn)
        times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
        timedfyes=times.groupby(['hour']).size().to_frame('count').reset_index()
        times2 = pd.to_datetime(dftod.sign_upn)
        times2['hour'] = times2.map( lambda x: pd.to_datetime(x).hour )
        timedftod=times2.groupby(['hour']).size().to_frame('count').reset_index()
        timedfyes = timedfyes.astype(int)
        hour=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]
        count=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
        dftest = pd.DataFrame({'hour':hour,'count':count})
        result = pd.merge(timedfyes , dftest,how='right', on='hour')
        result=result.fillna(0)
        result= result.astype(int)
        result = result.sort_values(["hour", "count_x"], ascending = (True,False))
        #yesterday count
        yescount=list(result['count_x'])
        # timedftod = timedftod.astype(int)
        # result12 = pd.merge(timedftod, dftest,how='right', on='hour')
        # result12=result12.fillna(0)
        # result12= result12.astype(int)
        # result12 = result12.sort_values(["hour", "count_x"], ascending = (True,False))
        # #todays count
        todcount=list(result['count_y'])
        totaly=sum(yescount)
        totalt=sum(todcount)
        temp={"tod":todcount,"yes":yescount,"totaly":[str(totaly)],"totalt":[str(totalt)]}
        return json.dumps(temp)
    
    else:
        df = DataFrame(list(collection.aggregate([
                    {"$match":{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}},
                             'USER_ID.IS_DISABLED':{"$ne":'Y'},'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'},
                             'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}},
                             'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}},
                             'USER_ID.EMAIL_ID':{"$ne":""},
                             'USER_ID.CREATED_DATE':{"$gt":myDatetime},
                             'USER_ID.ROLE_ID.ROLE_ID':{"$eq":3}}},
                    {"$group":{"_id":{"$dateToString": {"date":'$MODIFIED_DATE'}},'Count':{"$sum":1}}},
                    {"$project":{"_id":1, 'Parents_Practice':'$Count'}},
                    { '$sort': { '_id': 1 }}])))
        df = df.rename(columns={"_id": "sign_up"})
        df=df.dropna()
        df['sign_up'] = pd.to_datetime(df['sign_up'], errors = 'coerce')
        df['sign_upn'] = pd.to_datetime(df['sign_up']) - timedelta(hours=4)
        df['date']=df['sign_upn'].apply(lambda x: x.strftime("%Y-%m-%d"))
        tz = timezone('US/Eastern')
        date=datetime.datetime.now(tz)
        yesterday=pd.to_datetime(date)-timedelta(days=1)
        todaydate=date.strftime("%Y-%m-%d")
        yesterdaydate=yesterday.strftime("%Y-%m-%d")
        dfyes=df[df['date']==yesterdaydate]
        dftod=df[df['date']==todaydate]
        times = pd.to_datetime(dfyes.sign_upn)
        times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
        timedfyes=times.groupby(['hour']).size().to_frame('count').reset_index()
        times2 = pd.to_datetime(dftod.sign_upn)
        times2['hour'] = times2.map( lambda x: pd.to_datetime(x).hour )
        timedftod=times2.groupby(['hour']).size().to_frame('count').reset_index()
        timedfyes = timedfyes.astype(int)
        hour=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]
        count=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
        dftest = pd.DataFrame({'hour':hour,'count':count})
        result = pd.merge(timedfyes , dftest,how='right', on='hour')
        result=result.fillna(0)
        result= result.astype(int)
        result = result.sort_values(["hour", "count_x"], ascending = (True,False))
        #yesterday count
        yescount=list(result['count_x'])
        # timedftod = timedftod.astype(int)
        # result12 = pd.merge(timedftod, dftest,how='right', on='hour')
        # result12=result12.fillna(0)
        # result12= result12.astype(int)
        # result12 = result12.sort_values(["hour", "count_x"], ascending = (True,False))
        # #todays count
        todcount=list(result['count_y'])
        totaly=sum(yescount)
        totalt=sum(todcount)
        temp={"tod":todcount,"yes":yescount,"totaly":[str(totaly)],"totalt":[str(totalt)]}
        return json.dumps(temp)







# code  by ishwinder 

@app.route('/schoolname/<n>')
def school_name(n):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    df = DataFrame(list(db.user_master.aggregate([
     {"$match":
            {'$and': [
                 {'ROLE_ID._id' :{'$eq':ObjectId(""+n+"")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                 {"schoolId.NAME":{"$ne":""}},
                {"schoolId.NAME":{"$not":{"$regex":"None",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    { "$group":{ 
           "_id":"$schoolId._id",
        "NAME":{"$first":"$schoolId.NAME"}
    }}
        ,
        {"$project":{"_id":0,"NAME":1}}
     ]))).fillna("NO SCHOOL NAME")
    return json.dumps(df["NAME"].values.tolist())


@app.route('/mitpracdaycompp')
def mitsignupdaycomp12():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    
    collection = db.audio_track_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    ##################### TODAY ###########################
    df = DataFrame(list(collection.aggregate([
            {"$match":{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}},
                    'USER_ID.IS_DISABLED':{"$ne":'Y'},'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'},
                    'USER_ID.USER_TYPE':{"$regex":'mit','$options':'i'}, 
                    'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}},
                    'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}},
                    'USER_ID.EMAIL_ID':{"$ne":""},
                    'USER_ID.CREATED_DATE':{"$gt":myDatetime},
                    'USER_ID.ROLE_ID.ROLE_ID':{"$eq":3}}},
            {"$group":{"_id":{"$dateToString": {"date":'$MODIFIED_DATE'}},'Count':{"$sum":1}}},
            {"$project":{"_id":1, 'Parents_Practice':'$Count'}}])))
    df= df.rename(columns={"_id": "sign_up"})
    df1=df.dropna()
    df1['sign_up'] = pd.to_datetime(df1['sign_up'], errors = 'coerce')
    df1['sign_upn'] = pd.to_datetime(df1['sign_up']) - timedelta(hours=4)
    df1['date']=df1['sign_upn'].apply(lambda x: x.strftime("%Y-%m-%d"))
    from datetime import datetime
    from pytz import timezone
    tz = timezone('US/Eastern')
    date=datetime.now(tz)
    yesterday=pd.to_datetime(date)-timedelta(days=1)
    todaydate=date.strftime("%Y-%m-%d")
    yesterdaydate=yesterday.strftime("%Y-%m-%d")
    dfyes=df1[df1['date']==yesterdaydate]
    dftod=df1[df1['date']==todaydate]
    data = pd.DataFrame({'hour':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],'count':[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]} )
    times = pd.to_datetime(dfyes.sign_upn)
    times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
    timedfyes=times.groupby(['hour']).size().to_frame('count').reindex(data['hour']).fillna(0)
    times2 = pd.to_datetime(dftod.sign_upn)
    times2['hour'] = times2.map( lambda x: pd.to_datetime(x).hour )
    timedftod=times2.groupby(['hour']).size().to_frame('count').reindex(data['hour']).fillna(0)
    timedfyes = timedfyes.astype(int)
    hour=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]
    count=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
    dftest = pd.DataFrame({'hour':hour,'count':count})
    result = pd.merge(timedfyes , dftest,how='right', on='hour')
    result=result.fillna(0)
    result= result.astype(int)
    result = result.sort_values(["hour", "count_x"], ascending = (True,False))
    #yesterday count
    yescount=list(result['count_x'])
    timedftod = timedftod.astype(int)
    result12 = pd.merge(timedftod, dftest,how='right', on='hour')
    result12=result12.fillna(0)
    result12= result12.astype(int)
    result12 = result12.sort_values(["hour", "count_x"], ascending = (True,False))
    #todays count
    todcount=list(result12['count_x'])
    totaly=sum(yescount)
    totalt=sum(todcount)
    temp={"tod":todcount,"yes":yescount,"totaly":[str(totaly)],"totalt":[str(totalt)]}
    
    
    return json.dumps(temp)


# @app.route('/sarasotapracnew')
# def sarasotapracnew():
    
#     db = mysql.connector.connect(
#     host="52.35.73.200",
#     user="ieuser",
#     passwd="mijyBg96wtdDSAB5",
#     database="compass")
#     q1="""select atd.modified_date as sign_up ,count(atd.USER_ID) as count
#         from user_master as um left join user_profile as up on up.USER_ID=um.USER_ID
#         left join school_master as sm on sm.id=up.SCHOOL_ID
#         inner join audio_track_detail as atd on atd.USER_ID=um.USER_ID
#         where  um.ROLE_ID=3  and DATE(um.CREATED_DATE) > '2020-03-17' AND um.user_type like "%sarasota%" and um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.user_name not like "%test%"  AND
#         um.EMAIL_ID NOT LIKE "%TEST%" AND um.EMAIL_ID NOT LIKE "%1gen%"  AND um.EMAIL_ID <> ""
#         group by sign_up"""
#     df1=pd.read_sql(q1, con=db)
#     df1=df1.dropna()
#     # print(df1)
#     df1['sign_up'] = pd.to_datetime(df1['sign_up'], errors = 'coerce')
#     df1['sign_upn'] = pd.to_datetime(df1['sign_up']) - timedelta(hours=4)
#     df2 = df1.groupby([df1['sign_upn'].dt.date]).sum()
# #     print(df2)
    
#     cdate=[]
#     for i in df2.index:
#         x=i.strftime('%s')
#         cdate.append(float(x)*1000)
#     count=[]
#     for i in df2['count'] :
#         count.append(i)
#     count1=np.cumsum(count)
#     df3 = pd.DataFrame(list(zip(cdate,count)), 
#                        columns =['date', 'count']) 
#     df4 = pd.DataFrame(list(zip(cdate,count1)), 
#                        columns =['date', 'count'])
#     data = df3.values.tolist()
#     data1 = df4.values.tolist()
#     return json.dumps({"bar":data,"line":data1})


@app.route('/parpracnew')
def parpracnew():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))

    db=client.compass
    collection = db.audio_track_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)


    x =list(collection.aggregate([
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                   {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                   {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                   {'USER_ID.EMAIL_ID':{"$ne":[" ",'',None]}},
                   {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                   {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
        {"$group":{"_id":{"$dateToString": {"format": "%Y-%m-%d","date":'$CREATED_DATE'}},
                   'Count':{"$sum":1}}},
        {"$project":{"_id":1, 'Parents_Practice':'$Count'}}]))
    res = [] 
    for idx, sub in enumerate(x, start = 0): 
        if idx == 0: 
    #         res.append(list(sub.keys())) 
            res.append(list(sub.values())) 
        else: 
            res.append(list(sub.values())) 
    df = pd.DataFrame(res, columns = ['date', 'count'])
    df['date'] = pd.to_datetime(df['date'], errors = 'coerce')
    df['date'] = pd.to_datetime(df['date']) - timedelta(hours=4)
    df2 = df.groupby([df['date'].dt.date]).sum()
    cdate=[]
    for i in df2.index:
        x=i.strftime('%s')
        cdate.append(float(x)*1000)
    count=[]
    for i in df2['count'] :
        count.append(i)
    count1=np.cumsum(count)
    df3 = pd.DataFrame(list(zip(cdate,count)), 
                       columns =['date', 'count']) 
    df4 = pd.DataFrame(list(zip(cdate,count1)), 
                       columns =['date', 'count'])
    data = df3.values.tolist()
    data1 = df4.values.tolist()
    return json.dumps({"bar":data,"line":data1})

#>>>>>>>>>>>-------------------PRACTICE BIFURCATION API----------------------
@app.route('/parpracnew/<charttype>')
def par__pracnew__(charttype):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))

    db=client.compass
    collection = db.audio_track_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)


    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        x =list(collection.aggregate([
            {"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                       {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                       {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                       {'USER_ID.EMAIL_ID':{"$ne":[" ",'',None]}},
                       {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                       {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
              practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],

            {"$group":{"_id":{"$dateToString": {"format": "%Y-%m-%d","date":'$CREATED_DATE'}},
                       'Count':{"$sum":1}}},
                              
            {"$project":{"_id":1, 'Parents_Practice':'$Count'}}]))
        res = [] 
        for idx, sub in enumerate(x, start = 0): 
            if idx == 0: 
        #         res.append(list(sub.keys())) 
                res.append(list(sub.values())) 
            else: 
                res.append(list(sub.values())) 
        df = pd.DataFrame(res, columns = ['date', 'count'])
        df['date'] = pd.to_datetime(df['date'], errors = 'coerce')
        df['date'] = pd.to_datetime(df['date']) - timedelta(hours=4)
        df2 = df.groupby([df['date'].dt.date]).sum()
        cdate=[]
        for i in df2.index:
            x=i.strftime('%S')
            cdate.append(float(x)*1000)
        count=[]
        for i in df2['count'] :
            count.append(i)
        count1=np.cumsum(count)
        df3 = pd.DataFrame(list(zip(cdate,count)), 
                           columns =['date', 'count']) 
        df4 = pd.DataFrame(list(zip(cdate,count1)), 
                           columns =['date', 'count'])
        data = df3.values.tolist()
        data1 = df4.values.tolist()
        return json.dumps({"bar":data,"line":data1})
    
    else:
        x =list(collection.aggregate([
            {"$match":{'$and':[{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}}},
                       {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                       {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                       {'USER_ID.EMAIL_ID':{"$ne":[" ",'',None]}},
                       {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                       {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
            {"$group":{"_id":{"$dateToString": {"format": "%Y-%m-%d","date":'$CREATED_DATE'}},
                       'Count':{"$sum":1}}},
            {"$project":{"_id":1, 'Parents_Practice':'$Count'}}]))
        res = [] 
        for idx, sub in enumerate(x, start = 0): 
            if idx == 0: 
        #         res.append(list(sub.keys())) 
                res.append(list(sub.values())) 
            else: 
                res.append(list(sub.values())) 
        df = pd.DataFrame(res, columns = ['date', 'count'])
        df['date'] = pd.to_datetime(df['date'], errors = 'coerce')
        df['date'] = pd.to_datetime(df['date']) - timedelta(hours=4)
        df2 = df.groupby([df['date'].dt.date]).sum()
        cdate=[]
        for i in df2.index:
            x=i.strftime('%S')
            cdate.append(float(x)*1000)
        count=[]
        for i in df2['count'] :
            count.append(i)
        count1=np.cumsum(count)
        df3 = pd.DataFrame(list(zip(cdate,count)), 
                           columns =['date', 'count']) 
        df4 = pd.DataFrame(list(zip(cdate,count1)), 
                           columns =['date', 'count'])
        data = df3.values.tolist()
        data1 = df4.values.tolist()
        return json.dumps({"bar":data,"line":data1})







@app.route('/mitpracnew')
def mitpracnew():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass

    collection = db.audio_track_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)


    x =list(collection.aggregate([
        {"$match":{'USER_ID.USER_NAME':{"$ne": {'$regex' : 'test', '$options' : 'i'}},
                'USER_ID.IS_DISABLED':{"$ne":'Y'},'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'},
                'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}},
                'USER_ID.USER_TYPE':{"$regex":'mit','$options':'i'}, 
                'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}},
                'USER_ID.EMAIL_ID':{"$ne":""},
                'USER_ID.CREATED_DATE':{"$gt":myDatetime},
                'USER_ID.ROLE_ID.ROLE_ID':{"$eq":3}}},
        {"$group":{"_id":{"$dateToString": {"format": "%Y-%m-%d","date":'$CREATED_DATE'}},
                'Count':{"$sum":1}}},
        {"$project":{"_id":1, 'Parents_Practice':'$Count'}}]))
    res = [] 
    for idx, sub in enumerate(x, start = 0): 
        if idx == 0: 
    #         res.append(list(sub.keys())) 
            res.append(list(sub.values())) 
        else: 
            res.append(list(sub.values())) 
    df = pd.DataFrame(res, columns = ['date', 'count'])
    df['date'] = pd.to_datetime(df['date'], errors = 'coerce')
    df['date'] = pd.to_datetime(df['date']) - timedelta(hours=4)
    df2 = df.groupby([df['date'].dt.date]).sum()
    cdate=[]
    for i in df2.index:
        x=i.strftime('%S')
        cdate.append(float(x)*1000)
    count=[]
    for i in df2['count'] :
        count.append(i)
    count1=np.cumsum(count)
    df3 = pd.DataFrame(list(zip(cdate,count)), 
                    columns =['date', 'count']) 
    df4 = pd.DataFrame(list(zip(cdate,count1)), 
                    columns =['date', 'count'])
    data = df3.values.tolist()
    data1 = df4.values.tolist()
    return json.dumps({"bar":data,"line":data1})

# @app.route('/sarasotapracweek')
# def sarasotapracweekZZ():
    
#     db = mysql.connector.connect(
#     host="52.35.73.200",
#     user="ieuser",
#     passwd="mijyBg96wtdDSAB5",
#     database="compass")
#     q1="""select atd.modified_date as sign_up
#         from user_master as um left join user_profile as up on up.USER_ID=um.USER_ID
#         left join school_master as sm on sm.id=up.SCHOOL_ID
#         inner join audio_track_detail as atd on atd.USER_ID=um.USER_ID
#         where  um.ROLE_ID=3  and DATE(um.CREATED_DATE) > '2020-03-17' and um.user_type like "%sarasota%" and um.user_name not like "%test%" AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' AND
#         um.EMAIL_ID NOT LIKE "%TEST%" AND um.EMAIL_ID NOT LIKE "%1gen%" AND um.EMAIL_ID <> ""
#         group by sign_up"""
#     df1=pd.read_sql(q1, con=db)
#     df1=df1.dropna()
#     # print(df1)
#     df1['sign_up'] = pd.to_datetime(df1['sign_up'], errors = 'coerce')
    
#     df1['sign_upn'] = pd.to_datetime(df1['sign_up']) - timedelta(hours=0)
    
    
    
#     from datetime import datetime
#     from pytz import timezone
#     tz = timezone('UTC')
#     date=datetime.now(tz) 
#     today = pd.to_datetime(date) - timedelta(hours=0)
#     todaydate=today.strftime("%Y-%m-%d")
#     print(todaydate)
    
    
#     df2 = df1.groupby([df1['sign_upn'].dt.date]).count()

#     print(df1)
    
    
#     cdate=[]
#     for i in df2.index:
#         x=i.strftime('%s')
#         cdate.append(float(x)*1000)
#     count=[]
#     for i in df2['sign_up'] :
#         count.append(i)
#     count1=np.cumsum(count)
    
    
#     df3 = pd.DataFrame(list(zip(cdate,count)), 
#                        columns =['date', 'count']) 
#     df4 = pd.DataFrame(list(zip(cdate,count1)), 
#                        columns =['date', 'count'])
#     data = df3.values.tolist()
#     data1 = df4.values.tolist()


#     ##### hourly graph

    
#     times = pd.to_datetime(df1.sign_upn)
#     times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
#     timedf=times.groupby(['hour']).size().to_frame('count').reset_index()

#     timedata={"hour":timedf['hour'].tolist(),"count":timedf['count'].tolist()}

#     ###### week data
#     df_data = pd.to_datetime(df1['sign_upn'], format='%Y%m%d')
#     week_df = df_data.groupby(df1['sign_upn'].dt.weekday_name).count()

#     weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],"count":[str(week_df['Monday']),str(week_df['Tuesday']),str(week_df['Wednesday']),str(week_df['Thursday']),str(week_df['Friday']),str(week_df['Saturday']),str(week_df['Sunday'])]}
#     temp={"weekdata":weekdata,"timedata":timedata}
#     return json.dumps(temp)

#     return json.dumps(temp)


@app.route('/parpracweek')
def par_analytics_hourly_and_weekly_prac():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))

    db=client.compass
    collection = db.audio_track_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)


    ############# DAY WISE #####################

    df = DataFrame(list(collection.aggregate([
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$nin":["",' ',None]}},
                 {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
        {"$group":{"_id":{'DayOfWeek':{'$dayOfWeek':'$MODIFIED_DATE'}},
                 'Count':{"$sum":1}}},
        {"$project":{"_id":1, 'Parents_Practice':'$Count'}}])))

    df['DayOfWeek'] = pd.json_normalize(df['_id'])
    del df["_id"]
    weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],"count":[str(df['Parents_Practice'][0]),str(df['Parents_Practice'][2]),
                                                                                                            str(df['Parents_Practice'][4]),str(df['Parents_Practice'][1]),
                                                                                                            str(df['Parents_Practice'][5]),str(df['Parents_Practice'][6]),str(df['Parents_Practice'][3])]}


    ############### HOURLY ########################################



    df_hour = DataFrame(list(collection.aggregate([
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$nin":["",' ',None]}},
                 {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
        {"$group":{"_id":{"hour": {"$hour": "$MODIFIED_DATE"}},'Count':{"$sum":1}}},
        {"$project":{"_id":1, 'Parents_Practice':'$Count'}}])))

    df_hour['hour'] = pd.json_normalize(df_hour['_id'])
    del df_hour["_id"]
    df1_hour=df_hour.sort_values(by = ["hour"])
    timedata={"hour":df1_hour['hour'].tolist(),"count":df1_hour['Parents_Practice'].tolist()}



    temp={"weekdata":weekdata,"timedata":timedata}
    return json.dumps(temp)


#>>>>>>>>>>>>--------------PRACTICE BIFURCATION API---------------------
@app.route('/parpracweek/<charttype>')
def paranalytics__hourly__and__weeklyprac(charttype):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))

    db=client.compass
    collection = db.audio_track_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
    ############# DAY WISE #####################

        df = DataFrame(list(collection.aggregate([
            {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                     {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                     {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                     {'USER_ID.EMAIL_ID':{"$nin":["",' ',None]}},
                     {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                     {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
            {"$group":{"_id":{'DayOfWeek':{'$dayOfWeek':'$MODIFIED_DATE'}},
                     'Count':{"$sum":1}}},
            {"$project":{"_id":1, 'Parents_Practice':'$Count'}}])))

        df['DayOfWeek'] = pd.json_normalize(df['_id'])
        del df["_id"]
        weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],"count":[str(df['Parents_Practice'][0]),str(df['Parents_Practice'][2]),
                                                                                                                str(df['Parents_Practice'][4]),str(df['Parents_Practice'][1]),
                                                                                                                str(df['Parents_Practice'][5]),str(df['Parents_Practice'][6]),str(df['Parents_Practice'][3])]}


        ############### HOURLY ########################################



        df_hour = DataFrame(list(collection.aggregate([
            {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                     {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                     {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                     {'USER_ID.EMAIL_ID':{"$nin":["",' ',None]}},
                     {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                     {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
            {"$group":{"_id":{"hour": {"$hour": "$MODIFIED_DATE"}},'Count':{"$sum":1}}},
            {"$project":{"_id":1, 'Parents_Practice':'$Count'}}])))

        df_hour['hour'] = pd.json_normalize(df_hour['_id'])
        del df_hour["_id"]
        df1_hour=df_hour.sort_values(by = ["hour"])
        timedata={"hour":df1_hour['hour'].tolist(),"count":df1_hour['Parents_Practice'].tolist()}



        temp={"weekdata":weekdata,"timedata":timedata}
        return json.dumps(temp)
    
    else:
        
        df = DataFrame(list(collection.aggregate([
            {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                     {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                     {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                     {'USER_ID.EMAIL_ID':{"$nin":["",' ',None]}},
                     {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                     {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
            {"$group":{"_id":{'DayOfWeek':{'$dayOfWeek':'$MODIFIED_DATE'}},
                     'Count':{"$sum":1}}},
            {"$project":{"_id":1, 'Parents_Practice':'$Count'}}])))

        df['DayOfWeek'] = pd.json_normalize(df['_id'])
        del df["_id"]
        weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],"count":[str(df['Parents_Practice'][0]),str(df['Parents_Practice'][2]),
                                                                                                                str(df['Parents_Practice'][4]),str(df['Parents_Practice'][1]),
                                                                                                                str(df['Parents_Practice'][5]),str(df['Parents_Practice'][6]),str(df['Parents_Practice'][3])]}


        ############### HOURLY ########################################



        df_hour = DataFrame(list(collection.aggregate([
            {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                     {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                     {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                     {'USER_ID.EMAIL_ID':{"$nin":["",' ',None]}},
                     {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                     {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
            {"$group":{"_id":{"hour": {"$hour": "$MODIFIED_DATE"}},'Count':{"$sum":1}}},
            {"$project":{"_id":1, 'Parents_Practice':'$Count'}}])))

        df_hour['hour'] = pd.json_normalize(df_hour['_id'])
        del df_hour["_id"]
        df1_hour=df_hour.sort_values(by = ["hour"])
        timedata={"hour":df1_hour['hour'].tolist(),"count":df1_hour['Parents_Practice'].tolist()}



        temp={"weekdata":weekdata,"timedata":timedata}
        return json.dumps(temp)






@app.route('/mitpracweek')
def mitpracweek():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass

    collection = db.audio_track_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)


    ############# DAY WISE #####################

    df = DataFrame(list(collection.aggregate([
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$nin":["",' ',None]}},
                 {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
        {"$group":{"_id":{'DayOfWeek':{'$dayOfWeek':'$MODIFIED_DATE'}},
                 'Count':{"$sum":1}}},
        {"$project":{"_id":1, 'Parents_Practice':'$Count'}}])))

    df['DayOfWeek'] = pd.json_normalize(df['_id'])
    del df["_id"]
    weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],"count":[str(df['Parents_Practice'][0]),str(df['Parents_Practice'][2]),
                                                                                                            str(df['Parents_Practice'][4]),str(df['Parents_Practice'][1]),
                                                                                                            str(df['Parents_Practice'][5]),str(df['Parents_Practice'][6]),str(df['Parents_Practice'][3])]}


    ############### HOURLY ########################################



    df_hour = DataFrame(list(collection.aggregate([
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$nin":["",' ',None]}},
                 {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
        {"$group":{"_id":{"hour": {"$hour": "$MODIFIED_DATE"}},'Count':{"$sum":1}}},
        {"$project":{"_id":1, 'Parents_Practice':'$Count'}}])))

    df_hour['hour'] = pd.json_normalize(df_hour['_id'])
    del df_hour["_id"]
    df1_hour=df_hour.sort_values(by = ["hour"])
    timedata={"hour":df1_hour['hour'].tolist(),"count":df1_hour['Parents_Practice'].tolist()}



    temp={"weekdata":weekdata,"timedata":timedata}
    return json.dumps(temp)




# @app.route('/famprogprac')
# def famprogprac():
#     db = mysql.connector.connect(
#     host="52.35.73.200",
#     user="ieuser",
#     passwd="mijyBg96wtdDSAB5",
#     database="compass")
#     prog="""
#     SELECT pm.PROGRAM_ID, pm.PROGRAM_NAME,pa.AUDIO_ID,pa.AUDIO_NAME,count(um.USER_ID)
#      FROM audio_track_detail atd inner join user_master um on um.USER_ID=atd.USER_ID inner join
#      programs_audio pa on atd.PROGRAM_AUDIO_ID=pa.AUDIO_ID
#      inner join program_master pm on pm.PROGRAM_ID=pa.PROGRAM_ID
#      where um.ROLE_ID=3 and date(um.created_date)>'2020-03-17'  AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.EMAIL_ID not like '%1gen%' 
#     and um.EMAIL_ID not like '%test%' and um.USER_NAME not like '%test%' and um.IS_DISABLED!='Y' and um.INCOMPLETE_SIGNUP!='Y' 
#     group by pa.AUDIO_ID 
#     order by  AUDIO_ID ASC,PROGRAM_AUDIO_ID ASC
#     """
#     df=pd.read_sql(prog, con=db)
#     progcount="""select pa.PROGRAM_ID as 'Program ID',pm.PROGRAM_NAME as 'Program Name', count(um.user_id) as 'Practice Count'
#     from user_master um
#     inner join audio_track_detail atd on atd.user_id=um.user_id
#     inner join programs_audio pa on pa.AUDIO_ID=atd.PROGRAM_AUDIO_ID
#     inner join program_master pm on pm.PROGRAM_ID=pa.PROGRAM_ID
#     where um.ROLE_ID=3 and date(um.created_date)>'2020-03-17'  AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.EMAIL_ID not like '%1gen%' 
#     and um.EMAIL_ID not like '%test%' and um.USER_NAME not like '%test%' and um.IS_DISABLED!='Y' and um.INCOMPLETE_SIGNUP!='Y' 
#     group by PROGRAM_NAME"""
#     df2=pd.read_sql(progcount, con=db)
#     soun=df[df['PROGRAM_ID']==8]
#     hig=df[df['PROGRAM_ID']==4]
#     prek=df[df['PROGRAM_ID']==1]
#     elem=df[df['PROGRAM_ID']==2]
#     mid=df[df['PROGRAM_ID']==3]
#     progname=['PRE-K','ELEMENTARY','MIDDLE','HIGH','SOUND PRACTICE']
#     progcount=[str(df2['Practice Count'][0]),str(df2['Practice Count'][1]),str(df2['Practice Count'][2]),str(df2['Practice Count'][3]),str(df2['Practice Count'][4])]
#     data={"progname":progname,
#         "progcount":progcount,
#     "prek":prek[['AUDIO_NAME','count(um.USER_ID)']].values.tolist(),
#     "elementary":elem[['AUDIO_NAME','count(um.USER_ID)']].values.tolist(),
#     "middle":mid[['AUDIO_NAME','count(um.USER_ID)']].values.tolist(),
#     "high":hig[['AUDIO_NAME','count(um.USER_ID)']].values.tolist(),
#     "sound":soun[['AUDIO_NAME','count(um.USER_ID)']].values.tolist()}
#     return json.dumps(data)

# @app.route('/famprog')
# def famprog():
#     db = mysql.connector.connect(
#     host="52.35.73.200",
#     user="ieuser",
#     passwd="mijyBg96wtdDSAB5",
#     database="compass")
#     prog="""
#     SELECT pm.PROGRAM_ID, pm.PROGRAM_NAME,pa.AUDIO_ID,pa.AUDIO_NAME,count(distinct(um.USER_ID))
#      FROM audio_track_detail atd inner join user_master um on um.USER_ID=atd.USER_ID inner join
#      programs_audio pa on atd.PROGRAM_AUDIO_ID=pa.AUDIO_ID
#      inner join program_master pm on pm.PROGRAM_ID=pa.PROGRAM_ID
#      where um.ROLE_ID=3 and date(um.created_date)>'2020-03-17'  AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.EMAIL_ID not like '%1gen%' 
#     and um.EMAIL_ID not like '%test%' and um.USER_NAME not like '%test%' and um.IS_DISABLED!='Y' and um.INCOMPLETE_SIGNUP!='Y' 
#     group by pa.AUDIO_ID 
#     order by  AUDIO_ID ASC,PROGRAM_AUDIO_ID ASC
#     """
#     df=pd.read_sql(prog, con=db)
#     progcount="""select pa.PROGRAM_ID as 'Program ID',pm.PROGRAM_NAME as 'Program Name', count(distinct(um.user_id)) as 'Practice Count'
#     from user_master um
#     inner join audio_track_detail atd on atd.user_id=um.user_id
#     inner join programs_audio pa on pa.AUDIO_ID=atd.PROGRAM_AUDIO_ID
#     inner join program_master pm on pm.PROGRAM_ID=pa.PROGRAM_ID
#     where um.ROLE_ID=3 and date(um.created_date)>'2020-03-17'  AND um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.EMAIL_ID not like '%1gen%' 
#     and um.EMAIL_ID not like '%test%' and um.USER_NAME not like '%test%' and um.IS_DISABLED!='Y' and um.INCOMPLETE_SIGNUP!='Y' 
#     group by PROGRAM_NAME"""
#     df2=pd.read_sql(progcount, con=db)
#     soun=df[df['PROGRAM_ID']==8]
#     hig=df[df['PROGRAM_ID']==4]
#     prek=df[df['PROGRAM_ID']==1]
#     elem=df[df['PROGRAM_ID']==2]
#     mid=df[df['PROGRAM_ID']==3]
#     progname=['PRE-K','ELEMENTARY','MIDDLE','HIGH','SOUND PRACTICE']
#     progcount=[str(df2['Practice Count'][0]),str(df2['Practice Count'][1]),str(df2['Practice Count'][2]),str(df2['Practice Count'][3]),str(df2['Practice Count'][4])]
#     data={"progname":progname,
#         "progcount":progcount,
#     "prek":prek[['AUDIO_NAME','count(distinct(um.USER_ID))']].values.tolist(),
#     "elementary":elem[['AUDIO_NAME','count(distinct(um.USER_ID))']].values.tolist(),
#     "middle":mid[['AUDIO_NAME','count(distinct(um.USER_ID))']].values.tolist(),
#     "high":hig[['AUDIO_NAME','count(distinct(um.USER_ID))']].values.tolist(),
#     "sound":soun[['AUDIO_NAME','count(distinct(um.USER_ID))']].values.tolist()}
#     return json.dumps(data)


# @app.route('/sarasotasignupweek')

# def sarasotasignupweek():
    
#     db = mysql.connector.connect(
#     host="52.35.73.200",
#     user="ieuser",
#     passwd="mijyBg96wtdDSAB5",
#     database="compass")
#     q1="""select um.created_date as sign_up
#         from user_master as um left join user_profile as up on up.USER_ID=um.USER_ID
#         left join school_master as sm on sm.id=up.SCHOOL_ID
#         left join audio_track_detail as atd on atd.USER_ID=um.USER_ID
#         where  um.ROLE_ID=3  and DATE(um.CREATED_DATE) > '2020-03-17' AND um.user_type like "%sarasota%" and um.IS_DISABLED !='Y' and um.INCOMPLETE_SIGNUP !='Y' and um.user_name not like "%test%"  AND
#         um.EMAIL_ID NOT LIKE "%TEST%" AND um.EMAIL_ID NOT LIKE "%1gen%" AND um.EMAIL_ID <> ""
#         group by um.user_id"""
#     df1=pd.read_sql(q1, con=db)
#     df1['sign_upn'] = pd.to_datetime(df1['sign_up']) - timedelta(hours=4)
#     df2 = df1.groupby([df1['sign_upn'].dt.date]).count()

#     cdate=[]
#     for i in df2.index:
#         x=i.strftime('%s')
#         cdate.append(float(x)*1000)
#     count=[]
#     for i in df2['sign_up'] :
#         count.append(i)
#     count1=np.cumsum(count)
#     df3 = pd.DataFrame(list(zip(cdate,count)), 
#                        columns =['date', 'count']) 
#     df4 = pd.DataFrame(list(zip(cdate,count1)), 
#                        columns =['date', 'count'])
#     data = df3.values.tolist()
#     data1 = df4.values.tolist()


#     ##### hourly graph

#     times = pd.to_datetime(df1.sign_upn)
#     times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
#     timedf=times.groupby(['hour']).size().to_frame('count').reset_index()

#     timedata={"hour":timedf['hour'].tolist(),"count":timedf['count'].tolist()}

#     ###### week data
#     df_data = pd.to_datetime(df1['sign_upn'], format='%Y%m%d')
#     week_df = df_data.groupby(df1['sign_upn'].dt.weekday_name).count()

#     weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],"count":[str(week_df['Monday']),str(week_df['Tuesday']),str(week_df['Wednesday']),str(week_df['Thursday']),str(week_df['Friday']),str(week_df['Saturday']),str(week_df['Sunday'])]}
#     temp={"weekdata":weekdata,"timedata":timedata}
#     return json.dumps(temp)

@app.route('/parsignupweek')
def Par_analytics_signup_daywise_and_hourly_():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass


    collection = db.user_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    ##### HOURLY #################

    df_hour = DataFrame(list(collection.aggregate([{"$match":{'$and':[{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                                                                 
                  {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  
            {"CREATED_DATE":{"$gte":myDatetime}}]}}, 
        {"$group":{"_id":{"hour": {"$hour": "$CREATED_DATE"}}, 'distinct':{"$addToSet":'$_id'}}},
        {"$project":{"_id":1, 'Total_parents':{'$size':'$distinct'}}}])))

    df_hour['hour'] = pd.json_normalize(df_hour['_id'])
    del df_hour["_id"]
    df1_hour=df_hour.sort_values(by = ["hour"])

    timedata={"hour":df1_hour['hour'].tolist(),"count":df1_hour['Total_parents'].tolist()}


    ##### WEEKLY #################

    df = DataFrame(list(collection.aggregate([{"$match":{'$and':[{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                                                                 
                  {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  
            {"CREATED_DATE":{"$gte":myDatetime}}]}}, 
        {"$group":{"_id":{"day": {"$dayOfWeek": "$CREATED_DATE"}}, 'distinct':{"$addToSet":'$_id'}}},
        {"$project":{"_id":1, 'Total_parents':{'$size':'$distinct'}}}])))

    df['day'] = pd.json_normalize(df['_id'])
    del df["_id"]
    weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],"count":[str(df['Total_parents'][0]),str(df['Total_parents'][5]),
                                                                                                       str(df['Total_parents'][3]),str(df['Total_parents'][6]),
                                                                                                       str(df['Total_parents'][4]),str(df['Total_parents'][1]),str(df['Total_parents'][2])]}
    temp={"weekdata":weekdata,"timedata":timedata}
    return json.dumps(temp)


@app.route('/mitsignupweek')

def mitsignupweek():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    ##### HOURLY #################

    df1 = DataFrame(list(collection.aggregate([
        {"$match":{'ROLE_ID.ROLE_ID' :3, 
                "IS_DISABLED":{"$ne":"Y"},
                "INCOMPLETE_SIGNUP":{"$ne":"Y"},
                "EMAIL_ID":{'$not':{'$regex':'test', '$options':'i'}},
                'USER_TYPE':{"$regex":'mit','$options':'i'}, 
                "EMAIL_ID":{"$ne": ""},
                "EMAIL_ID":{'$not':{'$regex':'1gen', '$options':'i'}},
                "USER_NAME":{'$not':{'$regex':'test', '$options':'i'}},
                "CREATED_DATE":{"$gt": myDatetime}}},
        {"$group":{"_id":{"DATE": "$CREATED_DATE"}, 'distinct':{"$addToSet":'$_id'}}},
        {"$project":{"_id":0,"sign_up":"$_id.DATE"}}])))
    df1['sign_upn'] = pd.to_datetime(df1['sign_up']) - timedelta(hours=4)
    df2 = df1.groupby([df1['sign_upn'].dt.date]).count()

    cdate=[]
    for i in df2.index:
        x=i.strftime('%S')
        cdate.append(float(x)*1000)
    count=[]
    for i in df2['sign_up'] :
        count.append(i)
    count1=np.cumsum(count)
    df3 = pd.DataFrame(list(zip(cdate,count)), 
                        columns =['date', 'count']) 
    df4 = pd.DataFrame(list(zip(cdate,count1)), 
                        columns =['date', 'count'])
    data = df3.values.tolist()
    data1 = df4.values.tolist()


    ##### hourly graph

    times = pd.to_datetime(df1.sign_upn)
    times['hour'] = times.map( lambda x: pd.to_datetime(x).hour )
    timedf=times.groupby(['hour']).size().to_frame('count').reset_index()

    timedata0={"hour":timedf['hour'].tolist(),"count":timedf['count'].tolist()}
    timedata1=pd.DataFrame(timedata0)
    hour=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]
    df10 = pd.DataFrame(hour,columns =['hour'])
    timedata2 = pd.merge(timedata1 , df10,how='right', on='hour').fillna(0)
    timedata3=timedata2.sort_values('hour')
    timedata={"hour":timedata3['hour'].tolist(),"count":timedata3['count'].tolist()}

    ###### week data
    df_data = pd.to_datetime(df1['sign_upn'], format='%Y%m%d')
    day=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday']
    week_df= df_data.groupby(df1['sign_upn'].dt.day_name()).count().reindex(day).fillna(0) 


    weekdata={"day":['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday', 'Sunday'],"count":[str(week_df['Monday']),str(week_df['Tuesday']),str(week_df['Wednesday']),str(week_df['Thursday']),str(week_df['Friday']),str(week_df['Saturday']),str(week_df['Sunday'])]}
    temp={"weekdata":weekdata,"timedata":timedata}
    return json.dumps(temp)

@app.route('/parentsmapmexico')

def parentsmapmexico():
    statesshort = {'alaska': 'ak',
    'alabama': 'al',
    'arkansas': 'ar',
    'american samoa': 'as',
    'arizona': 'az',
    'california': 'ca',
    'colorado': 'co',
    'connecticut': 'ct',
    'district of columbia': 'dc',
    'delaware': 'de',
    'florida': 'fl',
    'georgia': 'ga',
    'guam': 'gu',
    'hawaii': 'hi',
    'iowa': 'ia',
    'idaho': 'id',
    'illinois': 'il',
    'indiana': 'in',
    'kansas': 'ks',
    'kentucky': 'ky',
    'louisiana': 'la',
    'massachusetts': 'ma',
    'maryland': 'md',
    'maine': 'me',
    'michigan': 'mi',
    'minnesota': 'mn',
    'missouri': 'mo',
    'northern mariana islands': 'mp',
    'mississippi': 'ms',
    'montana': 'mt',
    'national': 'na',
    'north carolina': 'nc',
    'north dakota': 'nd',
    'nebraska': 'ne',
    'new hampshire': 'nh',
    'new jersey': 'nj',
    'new mexico': 'nm',
    'nevada': 'nv',
    'new york': 'ny',
    'ohio': 'oh',
    'oklahoma': 'ok',
    'oregon': 'or',
    'pennsylvania': 'pa',
    'puerto rico': 'pr',
    'rhode island': 'ri',
    'south carolina': 'sc',
    'south dakota': 'sd',
    'tennessee': 'tn',
    'texas': 'tx',
    'utah': 'ut',
    'virginia': 'va',
    'virgin islands': 'vi',
    'vermont': 'vt',
    'washington': 'wa',
    'wisconsin': 'wi',
    'west virginia': 'wv',
    'wyoming': 'wy'}

    reader = geolite2.reader()

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass


    collection2= db.audio_track_master
    qrB= [{"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}


    ]}},
    {'$group':{'_id':'$USER_ID._id','PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
    {'$project':{'_id':1,'PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE': '$practice_date'
    # 'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}       
              }}
    ]


    collection3= db.user_master
    qrC=[
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},

    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}
    ]}},

    {'$project':{'_id':1, 'SCHOOL_NAME':'$schoolId.NAME', 'PARENTS_NAME':'$USER_NAME', 'PARENTS_EMAIL':'$EMAIL_ID',
      'state':'$schoolId.STATE', 'CITY':'$schoolId.CITY', 'country':'$schoolId.COUNTRY', 
         'USER_TYPE':'$USER_TYPE','ip_address':'$IP_ADDRESS', 'CONTACT_NUMBER':'$CONTACT_NUMBER',
        'SIGNUP_DATE':"$CREATED_DATE"
        }}
    ]


    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join_final1= pd.merge(df_um, df_atma, how='left', on='_id')
    join_final1['PARENTS_NAME'].fillna('NO USER NAME FOUND', inplace=True)
    join_final1['PARENTS_EMAIL'].fillna('NO USER EMAIL FOUND', inplace=True)
    join_final1['SCHOOL_NAME'].fillna('NO SCHOOL NAME FOUND', inplace=True)
    join_final1['USER_TYPE'].fillna('NO USER TYPE FOUND', inplace=True)
    join_final1['state'].fillna('NO STATE FOUND', inplace=True)
    join_final1['CITY'].fillna('NO CITY FOUND', inplace=True)
    join_final1['country'].fillna('NO COUNTRY FOUND', inplace=True)
    join_final1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    join_final1['PRACTICE_COUNT'].fillna(0, inplace=True)
    # join_final1['ip_address'].fillna('NO IP ADDRESS FOUND', inplace=True)

    join_final1=join_final1.replace("UNITED STATES","United States")
    join_final1=join_final1.replace("US","United States")
    join_final1=join_final1.replace("us","United States")
    join_final1=join_final1.replace("USA","United States")
    join_final1=join_final1.replace("Usa","United States")
    join_final1=join_final1.replace("U.S.A","United States")

    def country1(i):
        location =reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location =reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=join_final1['ip_address'].tolist()
    phone_number=join_final1['CONTACT_NUMBER'].tolist()
    Parents_Name=join_final1['PARENTS_NAME'].tolist()
    Parents_Email=join_final1['PARENTS_EMAIL'].tolist()
    state=join_final1['state'].tolist()
    country=join_final1['country'].tolist()
    CITY=join_final1['CITY'].tolist()
    SCHOOL_NAME=join_final1['SCHOOL_NAME'].to_list()
    sign_up_date=join_final1['SIGNUP_DATE'].tolist()
    last_prac_date=join_final1['LAST_PRACTICE_DATE'].tolist()
    practice_count=join_final1['PRACTICE_COUNT'].tolist()
    # mindful_minutes=join_final1['MINDFUL_MINUTES'].tolist()

    for i in range(len(ip)):

        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if state[i] != 'NO STATE FOUND':

            try:
                state[i]=state1(ip[i])
            except:
                pass
        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] == 'NO COUNTRY FOUND':
            country[i]=''
        if state[i] == 'NO COUNTRY FOUND':
            state[i]=''

        if  last_prac_date[i] != 'NO PRACTICE' :

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:

            last_prac_date[i]="NO PRACTICE"

        if sign_up_date[i] is not None:
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')

    state12 =  [each_string.lower() for each_string in state]
    stateshortnew=list(map(statesshort.get, state12))
    cv={'pn':Parents_Name,'pe':Parents_Email,'ut':join_final1['USER_TYPE'].tolist(),'ss':stateshortnew,
                               'st':state,'co':country,'sp':sign_up_date, 'ph':phone_number, 'sn':SCHOOL_NAME,
        'ct':CITY,
                               'lp':last_prac_date,'pc':practice_count}

    dftry = pd.DataFrame.from_dict(cv)
    dfus=dftry[dftry['co']=='United States']
    canada_df= dftry[dftry['co']=='Canada']
    Mexico_df= dftry[dftry['co']=='Mexico']
    India_df= dftry[dftry['co']=='India']
    dfother=dftry[~dftry['co'].isin(['United States', 'Mexico','India','Canada'])]
    # # dfrus=dftry[dftry['co']=='Russia']
    # dfmex=India_df[India_df['country']=='India']
    # dfind=Mexico_df[Mexico_df['country']=='Mexico']
    # dfcan=canada_df[canada_df['country']=='Canada']
    # dfrukr=Ukraine_df[Ukraine_df['country']=='Ukraine']
    totalparents=len(dftry)
    usa=len(dfus)
    india=len(India_df)
    mexico=len(Mexico_df)
    canada=len(canada_df)
    other=len(dfother)


    usaper=round(((usa/totalparents)*100),2)
    #     ukraineper=round(((ukraine/totalparents)*100),2)
    indiaper=round(((india/totalparents)*100),2)
    mexicoper=round(((mexico/totalparents)*100),2)
    canadaper=round(((canada/totalparents)*100),2)
    otherper=round(((other/totalparents)*100),2)

    Mexico_df= Mexico_df[['pn', 'pe', 'ph','sn', 'ct','st','co', 'sp','lp','pc']]
    try1=dftry.to_numpy().tolist()
    Mexico_df = Mexico_df.drop("co", axis=1)

    temp={"data":Mexico_df.values.tolist()}
    return json.dumps(temp)



@app.route('/parentsmapcanada')

def parentsmapcanada():
    statesshort = {'alaska': 'ak',
    'alabama': 'al',
    'arkansas': 'ar',
    'american samoa': 'as',
    'arizona': 'az',
    'california': 'ca',
    'colorado': 'co',
    'connecticut': 'ct',
    'district of columbia': 'dc',
    'delaware': 'de',
    'florida': 'fl',
    'georgia': 'ga',
    'guam': 'gu',
    'hawaii': 'hi',
    'iowa': 'ia',
    'idaho': 'id',
    'illinois': 'il',
    'indiana': 'in',
    'kansas': 'ks',
    'kentucky': 'ky',
    'louisiana': 'la',
    'massachusetts': 'ma',
    'maryland': 'md',
    'maine': 'me',
    'michigan': 'mi',
    'minnesota': 'mn',
    'missouri': 'mo',
    'northern mariana islands': 'mp',
    'mississippi': 'ms',
    'montana': 'mt',
    'national': 'na',
    'north carolina': 'nc',
    'north dakota': 'nd',
    'nebraska': 'ne',
    'new hampshire': 'nh',
    'new jersey': 'nj',
    'new mexico': 'nm',
    'nevada': 'nv',
    'new york': 'ny',
    'ohio': 'oh',
    'oklahoma': 'ok',
    'oregon': 'or',
    'pennsylvania': 'pa',
    'puerto rico': 'pr',
    'rhode island': 'ri',
    'south carolina': 'sc',
    'south dakota': 'sd',
    'tennessee': 'tn',
    'texas': 'tx',
    'utah': 'ut',
    'virginia': 'va',
    'virgin islands': 'vi',
    'vermont': 'vt',
    'washington': 'wa',
    'wisconsin': 'wi',
    'west virginia': 'wv',
    'wyoming': 'wy'}

    reader = geolite2.reader()

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass


    collection2= db.audio_track_master
    qrB= [{"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}


    ]}},
    {'$group':{'_id':'$USER_ID._id','PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
    {'$project':{'_id':1,'PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE': '$practice_date'
    # 'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}       
              }}
    ]


    collection3= db.user_master
    qrC=[
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},

    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}
    ]}},

    {'$project':{'_id':1, 'SCHOOL_NAME':'$schoolId.NAME', 'PARENTS_NAME':'$USER_NAME', 'PARENTS_EMAIL':'$EMAIL_ID',
      'state':'$schoolId.STATE', 'CITY':'$schoolId.CITY', 'country':'$schoolId.COUNTRY', 
         'USER_TYPE':'$USER_TYPE','ip_address':'$IP_ADDRESS', 'CONTACT_NUMBER':'$CONTACT_NUMBER',
        'SIGNUP_DATE':"$CREATED_DATE"
        }}
    ]


    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join_final1= pd.merge(df_um, df_atma, how='left', on='_id')
    join_final1['PARENTS_NAME'].fillna('NO USER NAME FOUND', inplace=True)
    join_final1['PARENTS_EMAIL'].fillna('NO USER EMAIL FOUND', inplace=True)
    join_final1['SCHOOL_NAME'].fillna('NO SCHOOL NAME FOUND', inplace=True)
    join_final1['USER_TYPE'].fillna('NO USER TYPE FOUND', inplace=True)
    join_final1['state'].fillna('NO STATE FOUND', inplace=True)
    join_final1['CITY'].fillna('NO CITY FOUND', inplace=True)
    join_final1['country'].fillna('NO COUNTRY FOUND', inplace=True)
    join_final1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    join_final1['PRACTICE_COUNT'].fillna(0, inplace=True)
    # join_final1['ip_address'].fillna('NO IP ADDRESS FOUND', inplace=True)

    join_final1=join_final1.replace("UNITED STATES","United States")
    join_final1=join_final1.replace("US","United States")
    join_final1=join_final1.replace("us","United States")
    join_final1=join_final1.replace("USA","United States")
    join_final1=join_final1.replace("Usa","United States")
    join_final1=join_final1.replace("U.S.A","United States")

    def country1(i):
        location =reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location =reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=join_final1['ip_address'].tolist()
    phone_number=join_final1['CONTACT_NUMBER'].tolist()
    Parents_Name=join_final1['PARENTS_NAME'].tolist()
    Parents_Email=join_final1['PARENTS_EMAIL'].tolist()
    state=join_final1['state'].tolist()
    country=join_final1['country'].tolist()
    CITY=join_final1['CITY'].tolist()
    SCHOOL_NAME=join_final1['SCHOOL_NAME'].to_list()
    sign_up_date=join_final1['SIGNUP_DATE'].tolist()
    last_prac_date=join_final1['LAST_PRACTICE_DATE'].tolist()
    practice_count=join_final1['PRACTICE_COUNT'].tolist()
    # mindful_minutes=join_final1['MINDFUL_MINUTES'].tolist()

    for i in range(len(ip)):

        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if state[i] != 'NO STATE FOUND':

            try:
                state[i]=state1(ip[i])
            except:
                pass
        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] == 'NO COUNTRY FOUND':
            country[i]=''
        if state[i] == 'NO COUNTRY FOUND':
            state[i]=''

        if  last_prac_date[i] != 'NO PRACTICE' :

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:

            last_prac_date[i]="NO PRACTICE"

        if sign_up_date[i] is not None:
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')

    state12 =  [each_string.lower() for each_string in state]
    stateshortnew=list(map(statesshort.get, state12))
    cv={'pn':Parents_Name,'pe':Parents_Email,'ut':join_final1['USER_TYPE'].tolist(),'ss':stateshortnew,
                               'st':state,'co':country,'sp':sign_up_date, 'ph':phone_number, 'sn':SCHOOL_NAME,
        'ct':CITY,
                               'lp':last_prac_date,'pc':practice_count}

    dftry = pd.DataFrame.from_dict(cv)
    dfus=dftry[dftry['co']=='United States']
    canada_df= dftry[dftry['co']=='Canada']
    Mexico_df= dftry[dftry['co']=='Mexico']
    India_df= dftry[dftry['co']=='India']
    dfother=dftry[~dftry['co'].isin(['United States', 'Mexico','India','Canada'])]
    # # dfrus=dftry[dftry['co']=='Russia']
    # dfmex=India_df[India_df['country']=='India']
    # dfind=Mexico_df[Mexico_df['country']=='Mexico']
    # dfcan=canada_df[canada_df['country']=='Canada']
    # dfrukr=Ukraine_df[Ukraine_df['country']=='Ukraine']
    totalparents=len(dftry)
    usa=len(dfus)
    india=len(India_df)
    mexico=len(Mexico_df)
    canada=len(canada_df)
    other=len(dfother)


    usaper=round(((usa/totalparents)*100),2)
    #     ukraineper=round(((ukraine/totalparents)*100),2)
    indiaper=round(((india/totalparents)*100),2)
    mexicoper=round(((mexico/totalparents)*100),2)
    canadaper=round(((canada/totalparents)*100),2)
    otherper=round(((other/totalparents)*100),2)

    canada_df= canada_df[['pn', 'pe', 'ph','sn', 'ct','st','co', 'sp','lp','pc']]
    try1=dftry.to_numpy().tolist()
    canada_df = canada_df.drop("co", axis=1)

    temp={"data":canada_df.values.tolist()}
    return json.dumps(temp)
# parentsmapcanada()



# =========fast============
@app.route('/fastcards')
def fast_cards():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection2 = db.FAST_APP_CLICKS

    df=DataFrame(list(collection2.aggregate([
        {'$match':{'$and':[
#             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'USER_ID.EMAIL_ID':{'$ne':''}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},]}},
        
    {'$group':{'_id':'$TYPE','uc':{'$addToSet':'$USER_ID._id'}}}
    ,{'$project':{'_id':1,'usercount':{'$size':'$uc'}}}
    ,{'$sort':{'_id':1}}])))
    df.T
    
    fastclick=df['usercount'][2]
    wt=df['usercount'][3]
    bs=df['usercount'][1]
    data={'Fast_clicks':str(fastclick),'weekly_tips_signup':str(wt), 'book_session':str(bs)}
    return json.dumps(data)


@app.route('/fastaskedquestion')
def asked_question():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection2 = db.asked_question

    df=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [{'QUESTION':{"$not":{"$regex":"test",'$options':'i'}}},
                  
                   {"USER.IS_DISABLED":{"$ne":"Y"}},
                  {"USER.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'USER.EMAIL_ID':{'$ne':''}},
         {'USER.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  ]}},

         {'$group':{'_id':'$QUESTION','uc':{'$addToSet':'$USER._id'}}}
    ,{'$project':{'_id':1,'usercount':{'$size':'$uc'}}}])))

    ques=df['_id'].tolist()
    uc=df['usercount'].tolist()
    data={'asked_questions':ques, 'usercount':uc}
    return json.dumps(data)




# ============================




@app.route('/schoolgraph/<sch>')
def schgraph_table(sch):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection1= db.user_master
    query1=[
    {"$match":
        {"$and":[
        {'IS_DISABLED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
                           {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},{'EMAIL_ID':{'$ne':None}},
            {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, {'EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':'$_id', 'name':{'$first':'$schoolId.NAME'} ,'Parents_Name':{'$first':'$USER_NAME'}, 'Sign_Up_Date':{'$first':{"$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" }}},
     'Parents_Email':{'$first':'$EMAIL_ID'}, 'contact_number':{'$first':'$CONTACT_NUMBER'},
        'city':{'$first':'$schoolId.CITY'},'state':{'$first':'$schoolId.STATE'}, 'address':{'$first':'$schoolId.ADDRESS'},
        'country':{'$first':'$schoolId.COUNTRY'}, 'user_type':{'$first':'$USER_TYPE'}, 'ip_address':{'$first':'$IP_ADDRESS'}
        }}         
            ]
    collection2= db.audio_track_master
    query2=[
    {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
         {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},{'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},{'USER_ID.EMAIL_ID':{'$ne':None}},
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},
        ]}},
        {'$group':{'_id':'$USER_ID._id',  'Practice_Count':{'$sum':1},
            'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}},
        'Last_Practice_Date':{'$max':'$MODIFIED_DATE'}
        }}, 
        {'$project':{'_id':1,'Practice_Count':1,
            'mindful_minutes':1, 'Last_Practice_Date':"$Last_Practice_Date" 
        }}
        ]
    list1=list(collection1.aggregate(query1))
    df_1=DataFrame(list1)
    list2=list(collection2.aggregate(query2))
    df_2=DataFrame(list2)
    # df_1['school_name'].fillna("NO SCHOOL FOUND", inplace=True)
    # df_3['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    # df_1['COUNTRY'].fillna("NO COUNTRY FOUND", inplace=True)
    # df_1['STATE'].fillna("NO STATE FOUND", inplace=True)
    # df_1['city'].fillna("NO CITY FOUND", inplace=True)
    # df_1['ADDRESS'].fillna("NO ADDRESS FOUND", inplace=True)
    df= pd.merge(df_1, df_2,how='left', on='_id')
    df.mindful_minutes=df.mindful_minutes.fillna(0)
    df.mindful_minutes=df.mindful_minutes.astype('int64')
    

    df['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    
    df['name'].fillna("NO NAME", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
    df['address'].fillna("NO address", inplace=True)
   
    df['Sign_Up_Date']=pd.to_datetime(df['Sign_Up_Date'])
    
    df= df.groupby(df['name'])
    df= df.get_group(''+sch+'')
    
    
    # print(df)
    def country1(i):
        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con

    ip=df['ip_address'].tolist()
    phone_number=df['contact_number'].tolist()
    
    schname=df['name'].tolist()
    schadd=df['address'].tolist()
    phone_number=df['contact_number'].tolist()
    city=df['city'].tolist()
    Parents_Name=df['Parents_Name'].tolist()
    Parents_Email=df.Parents_Email.tolist()
    state=df['state'].tolist()
    country=df['country'].tolist()
    sign_up_date=df['Sign_Up_Date'].tolist()
    last_prac_date=df['Last_Practice_Date'].tolist()

    practice_count=df['Practice_Count'].tolist()
    mindful_minutes=df['mindful_minutes'].tolist()

    for i in range(len(ip)):
        
        if city[i] is None:
            try:
                city[i]=city1(ip[i])
            except:
                pass

        if country[i] is None:
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if state[i] is None:

            try:
                state[i]=state1(ip[i])
            except:
                pass
        if country[i] is None:
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] is None:
            country[i]=''
        if state[i] is None:
            state[i]=''

        if  last_prac_date[i] != 'NO PRACTICE' :

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:

            last_prac_date[i]="NO PRACTICE"



        if sign_up_date[i] is not None:
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')

    data=[]    
    for i,k,l,m,o,p,q,s,z in zip(Parents_Name,Parents_Email,phone_number,schname,
                               city,state,sign_up_date,
                             last_prac_date,practice_count):

        data.append([i,k,l,m,o,p,q,s,z])
        
        
    return json.dumps({"data":data})


@app.route('/schoolgraph')
def schgraph():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    df = DataFrame(list(collection.aggregate([
     {"$match":{'ROLE_ID.ROLE_ID' :3,
    "IS_DISABLED":{"$ne":"Y"},
     "INCOMPLETE_SIGNUP":{"$ne":"Y"},
       "EMAIL_ID":{"$ne": None},
             "schoolId.NAME":{"$ne": None},
     "$and":[{"EMAIL_ID":{"$not":{"$regex" : 'test','$options':'i'}}},
           {"USER_NAME":{"$not":{"$regex" : 'test','$options':'i'}}},
               {"EMAIL_ID":{"$not":{"$regex" : '1gen','$options':'i'}}}],
      "CREATED_DATE":{"$gt": datetime.datetime(2020,3,17)}
     }},
    {"$group":{'_id':'$schoolId.NAME', 'distinct':{'$addToSet':'$_id'}}},
    {"$project":{'_id':1, 'parcount':{'$size':'$distinct'}}},
    { "$sort":{'parcount' : -1 }}])))
    
    df.dropna()
    df.rename(columns = { '_id': 'schname'}, inplace = True)
    parcount=df['parcount'].tolist()
    schname=df['schname'].tolist()
#     print(df)
    for i in range(len(schname)):
            schname[i] = schname[i]
    data={'parcount':parcount[0:25],'schname':schname[0:25]}
    return json.dumps(data)






@app.route('/paroveralltest')
def parents_tabletest():
    reader = geolite2.reader()
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus("I#L@teST^m0NGO_2o20!")
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.audio_track_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    df = DataFrame(list(collection.aggregate([
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$nin":["",' ',None]}},
                 {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
        {"$project":{"USER_ID":1,"USER_NAME":1,"EMAIL_ID":1,"CONTACT_NUMBER":1,"schoolId.CITY":1,
                     "schoolId.STATE":1,"schoolId.COUNTRY":1,
                     "schoolId.NAME":1,"schoolId.ADDRESS":1,"CREATED_DATE":1}}])))
    df1=df[['_id','schoolId']]
    df2 = df1.dropna()
    schoolId = list(df2['_id'])
    df2 = pd.json_normalize(df2['schoolId'])
    df2['schoolId'] = schoolId
    merge=pd.merge(df, df2, how='left', left_on=['_id'], right_on=['schoolId'])
    del merge['schoolId_x'], merge['schoolId_y']
    merge['CREATED_DATE'] = pd.to_datetime(merge['CREATED_DATE'])
    df_audio = DataFrame(list(collection2.aggregate([
                {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$nin":["",' ',None]}},
                 {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
                {"$group":{"_id":"$USER_ID._id","Last_Practice_Date":{"$max":"$MODIFIED_DATE"},'Count':{"$sum":1}, 
                           "EMAIL":{"$first":"USER_ID.EMAIL_ID"}}},
                {"$project":{"_id":1, 'Practice_Count':'$Count',"Last_Practice_Date":1}}])))
    final = pd.merge(merge, df_audio, how='left', left_on=['_id'], right_on=['_id'])
    del final['_id']
    final['Last_Practice_Date'] = pd.to_datetime(final['Last_Practice_Date'])
    final['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    #df['Last_Login_Date']=pd.to_datetime(df['Last_Login_Date'])
    #df['Last_Login_Date'].fillna("NO LOGIN", inplace=True)
    final['Practice_Count'].fillna("NO PRACTICE", inplace=True)
    final['CREATED_DATE']=pd.to_datetime(final['CREATED_DATE'])
    final['NAME'].fillna("NO SCHOOL INFO", inplace=True)
    final['ADDRESS'].fillna("NO ADDRESS INFO", inplace=True)
    final['COUNTRY'].fillna("NO COUNTRY INFO", inplace=True)
    final['STATE'].fillna("NO STATE INFO", inplace=True)
    final['CITY'].fillna("NO CITY INFO", inplace=True)
    def country1(i):
        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    #ip=df['ip_address'].tolist()
    phone_number=final['CONTACT_NUMBER'].tolist()
    Parents_Name=final['USER_NAME'].tolist()
    Parents_Email=final['EMAIL_ID'].tolist()
    School_Name=final['NAME'].tolist()
    state=final['STATE'].tolist()
    country=final['COUNTRY'].tolist()
    city=final['CITY'].tolist()
    sign_up_date=final['CREATED_DATE'].tolist()
    last_prac_date=final['Last_Practice_Date'].tolist()
    #last_login_date=final['Last_Login_Date'].tolist()
    practice_count=final['Practice_Count'].tolist()
    #mindful_minutes=final['mindful_minutes'].tolist()
    state12 =  [each_string.lower() for each_string in state]
    cv={'pnn':Parents_Name,'pe':Parents_Email,'co':country,'pn':phone_number,'sn':School_Name,'ct':city,
                               'st':state12,'sp':sign_up_date,'lp':last_prac_date,'pc':practice_count}
    dftry = pd.DataFrame.from_dict(cv)
    dftry= dftry.drop("co", axis=1)
    return json.dumps({"data":dftry.values.tolist()})


@app.route('/schoolmap')
def schoolanalyticscards():
    statesshort = {'alaska': 'ak',
    'alabama': 'al',
    'arkansas': 'ar',
    'american samoa': 'as',
    'arizona': 'az',
    'california': 'ca',
    'colorado': 'co',
    'connecticut': 'ct',
    'district of columbia': 'dc',
    'delaware': 'de',
    'florida': 'fl',
    'georgia': 'ga',
    'guam': 'gu',
    'hawaii': 'hi',
    'iowa': 'ia',
    'idaho': 'id',
    'illinois': 'il',
    'indiana': 'in',
    'kansas': 'ks',
    'kentucky': 'ky',
    'louisiana': 'la',
    'massachusetts': 'ma',
    'maryland': 'md',
    'maine': 'me',
    'michigan': 'mi',
    'minnesota': 'mn',
    'missouri': 'mo',
    'northern mariana islands': 'mp',
    'mississippi': 'ms',
    'montana': 'mt',
    'national': 'na',
    'north carolina': 'nc',
    'north dakota': 'nd',
    'nebraska': 'ne',
    'new hampshire': 'nh',
    'new jersey': 'nj',
    'new mexico': 'nm',
    'nevada': 'nv',
    'new york': 'ny',
    'ohio': 'oh',
    'oklahoma': 'ok',
    'oregon': 'or',
    'pennsylvania': 'pa',
    'puerto rico': 'pr',
    'rhode island': 'ri',
    'south carolina': 'sc',
    'south dakota': 'sd',
    'tennessee': 'tn',
    'texas': 'tx',
    'utah': 'ut',
    'virginia': 'va',
    'virgin islands': 'vi',
    'vermont': 'vt',
    'washington': 'wa',
    'wisconsin': 'wi',
    'west virginia': 'wv',
    'wyoming': 'wy'}

    reader = geolite2.reader()

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass


    collection2= db.audio_track_master
    qrB= [{'$match':{'USER_ID.schoolId':{'$exists':1}}},
        {"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
#      {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},

    {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},


    ]}},
    {'$group':{'_id':'$USER_ID.schoolId._id','PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
    {'$project':{'_id':1,'PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE': '$practice_date'
#     'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}       
              }}
    ]


    collection3= db.user_master
    qrC=[{'$match':{'schoolId':{'$exists':1}}},
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
          {'IS_BLOCKED':{"$ne":'Y'}}, 
      {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
          {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},

         {'$group':{'_id':'$schoolId._id', 'SCHOOL_NAME':{'$first':'$schoolId.NAME'},'PARENTS_NAME':{'$first':'$USER_NAME'},
        'PARENTS_EMAIL':{'$first':'$EMAIL_ID'},
      'state':{'$first':'$schoolId.STATE'}, 'CITY':{'$first':'$schoolId.CITY'}, 'country':{'$first':'$schoolId.COUNTRY'}, 
         'USER_TYPE':{'$first':'$USER_TYPE'},'ip_address':{'$first':'$IP_ADDRESS'}, 
       'CONTACT_NUMBER':{'$first':'$CONTACT_NUMBER'},'SIGNUP_DATE':{'$first':"$CREATED_DATE" }
         }}

    ]


    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join_final1= pd.merge(df_um, df_atma, how='left', on='_id')
    join_final1['PARENTS_NAME'].fillna('NO USER NAME FOUND', inplace=True)
    join_final1['PARENTS_EMAIL'].fillna('NO USER EMAIL FOUND', inplace=True)
    join_final1['SCHOOL_NAME'].fillna('NO SCHOOL NAME FOUND', inplace=True)
    join_final1['USER_TYPE'].fillna('NO USER TYPE FOUND', inplace=True)
    join_final1['state'].fillna('NO STATE FOUND', inplace=True)
    join_final1['CITY'].fillna('NO CITY FOUND', inplace=True)
    join_final1['country'].fillna('NO COUNTRY FOUND', inplace=True)
    join_final1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    join_final1['PRACTICE_COUNT'].fillna(0, inplace=True)
    # join_final1['ip_address'].fillna('NO IP ADDRESS FOUND', inplace=True)

    join_final1=join_final1.replace("UNITED STATES","United States")
    join_final1=join_final1.replace("US","United States")
    join_final1=join_final1.replace("us","United States")
    join_final1=join_final1.replace("USA","United States")
    join_final1=join_final1.replace("Usa","United States")
    join_final1=join_final1.replace("U.S.A","United States")

    def country1(i):
        location =reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location =reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=join_final1['ip_address'].tolist()
    phone_number=join_final1['CONTACT_NUMBER'].tolist()
    Parents_Name=join_final1['PARENTS_NAME'].tolist()
    Parents_Email=join_final1['PARENTS_EMAIL'].tolist()
    state=join_final1['state'].tolist()
    country=join_final1['country'].tolist()
    sign_up_date=join_final1['SIGNUP_DATE'].tolist()
    last_prac_date=join_final1['LAST_PRACTICE_DATE'].tolist()
    practice_count=join_final1['PRACTICE_COUNT'].tolist()
    # mindful_minutes=join_final1['MINDFUL_MINUTES'].tolist()

    for i in range(len(ip)):

        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if state[i] != 'NO STATE FOUND':

            try:
                state[i]=state1(ip[i])
            except:
                pass
        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] == 'NO COUNTRY FOUND':
            country[i]=''
        if state[i] == 'NO COUNTRY FOUND':
            state[i]=''

        if  last_prac_date[i] != 'NO PRACTICE' :

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:

            last_prac_date[i]="NO PRACTICE"

        if sign_up_date[i] is not None:
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')

    state12 =  [each_string.lower() for each_string in state]
    stateshortnew=list(map(statesshort.get, state12))
    cv={'pn':Parents_Name,'pe':Parents_Email,'ut':join_final1['USER_TYPE'].tolist(),'ss':stateshortnew,
                               'st':state,'co':country,'sp':sign_up_date,
                               'lp':last_prac_date,'pc':practice_count}

    dftry = pd.DataFrame.from_dict(cv)
    dfus=dftry[dftry['co']=='United States']
    canada_df= dftry[dftry['co']=='Canada']
    Mexico_df= dftry[dftry['co']=='Mexico']
    India_df= dftry[dftry['co']=='India']
    dfother=dftry[~dftry['co'].isin(['United States', 'Mexico','India','Canada'])]
   
    totalparents=len(dftry)
    usa=len(dfus)
    india=len(India_df)
    mexico=len(Mexico_df)
    canada=len(canada_df)
    other=len(dfother)


    usaper=round(((usa/totalparents)*100),2)
    indiaper=round(((india/totalparents)*100),2)
    mexicoper=round(((mexico/totalparents)*100),2)
    canadaper=round(((canada/totalparents)*100),2)
    otherper=round(((other/totalparents)*100),2)

    statesdf=dfus['ss'].dropna()
    count=statesdf.value_counts()

    return json.dumps({"india":india,"mexico":mexico,"canada":canada,"totalparents":totalparents,"usa":usa,"other":other})

@app.route('/parentsmapother')

def parentsmapother():
    statesshort = {'alaska': 'ak',
    'alabama': 'al',
    'arkansas': 'ar',
    'american samoa': 'as',
    'arizona': 'az',
    'california': 'ca',
    'colorado': 'co',
    'connecticut': 'ct',
    'district of columbia': 'dc',
    'delaware': 'de',
    'florida': 'fl',
    'georgia': 'ga',
    'guam': 'gu',
    'hawaii': 'hi',
    'iowa': 'ia',
    'idaho': 'id',
    'illinois': 'il',
    'indiana': 'in',
    'kansas': 'ks',
    'kentucky': 'ky',
    'louisiana': 'la',
    'massachusetts': 'ma',
    'maryland': 'md',
    'maine': 'me',
    'michigan': 'mi',
    'minnesota': 'mn',
    'missouri': 'mo',
    'northern mariana islands': 'mp',
    'mississippi': 'ms',
    'montana': 'mt',
    'national': 'na',
    'north carolina': 'nc',
    'north dakota': 'nd',
    'nebraska': 'ne',
    'new hampshire': 'nh',
    'new jersey': 'nj',
    'new mexico': 'nm',
    'nevada': 'nv',
    'new york': 'ny',
    'ohio': 'oh',
    'oklahoma': 'ok',
    'oregon': 'or',
    'pennsylvania': 'pa',
    'puerto rico': 'pr',
    'rhode island': 'ri',
    'south carolina': 'sc',
    'south dakota': 'sd',
    'tennessee': 'tn',
    'texas': 'tx',
    'utah': 'ut',
    'virginia': 'va',
    'virgin islands': 'vi',
    'vermont': 'vt',
    'washington': 'wa',
    'wisconsin': 'wi',
    'west virginia': 'wv',
    'wyoming': 'wy'}

    reader = geolite2.reader()

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass


    collection2= db.audio_track_master
    qrB= [{"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}


    ]}},
    {'$group':{'_id':'$USER_ID._id','PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
    {'$project':{'_id':1,'PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE': '$practice_date'
    # 'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}       
              }}
    ]


    collection3= db.user_master
    qrC=[
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},

    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}
    ]}},

    {'$project':{'_id':1, 'SCHOOL_NAME':'$schoolId.NAME', 'PARENTS_NAME':'$USER_NAME', 'PARENTS_EMAIL':'$EMAIL_ID',
      'state':'$schoolId.STATE', 'CITY':'$schoolId.CITY', 'country':'$schoolId.COUNTRY', 
         'USER_TYPE':'$USER_TYPE','ip_address':'$IP_ADDRESS', 'CONTACT_NUMBER':'$CONTACT_NUMBER',
        'SIGNUP_DATE':"$CREATED_DATE"
        }}
    ]


    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join_final1= pd.merge(df_um, df_atma, how='left', on='_id')
    join_final1['PARENTS_NAME'].fillna('NO USER NAME FOUND', inplace=True)
    join_final1['PARENTS_EMAIL'].fillna('NO USER EMAIL FOUND', inplace=True)
    join_final1['SCHOOL_NAME'].fillna('NO SCHOOL NAME FOUND', inplace=True)
    join_final1['USER_TYPE'].fillna('NO USER TYPE FOUND', inplace=True)
    join_final1['state'].fillna('NO STATE FOUND', inplace=True)
    join_final1['CITY'].fillna('NO CITY FOUND', inplace=True)
    join_final1['country'].fillna('NO COUNTRY FOUND', inplace=True)
    join_final1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    join_final1['PRACTICE_COUNT'].fillna(0, inplace=True)
    # join_final1['ip_address'].fillna('NO IP ADDRESS FOUND', inplace=True)

    join_final1=join_final1.replace("UNITED STATES","United States")
    join_final1=join_final1.replace("US","United States")
    join_final1=join_final1.replace("us","United States")
    join_final1=join_final1.replace("USA","United States")
    join_final1=join_final1.replace("Usa","United States")
    join_final1=join_final1.replace("U.S.A","United States")

    def country1(i):
        location =reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location =reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=join_final1['ip_address'].tolist()
    phone_number=join_final1['CONTACT_NUMBER'].tolist()
    Parents_Name=join_final1['PARENTS_NAME'].tolist()
    Parents_Email=join_final1['PARENTS_EMAIL'].tolist()
    state=join_final1['state'].tolist()
    country=join_final1['country'].tolist()
    CITY=join_final1['CITY'].tolist()
    SCHOOL_NAME=join_final1['SCHOOL_NAME'].to_list()
    sign_up_date=join_final1['SIGNUP_DATE'].tolist()
    last_prac_date=join_final1['LAST_PRACTICE_DATE'].tolist()
    practice_count=join_final1['PRACTICE_COUNT'].tolist()
    # mindful_minutes=join_final1['MINDFUL_MINUTES'].tolist()

    for i in range(len(ip)):

        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if state[i] != 'NO STATE FOUND':

            try:
                state[i]=state1(ip[i])
            except:
                pass
        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] == 'NO COUNTRY FOUND':
            country[i]=''
        if state[i] == 'NO COUNTRY FOUND':
            state[i]=''

        if  last_prac_date[i] != 'NO PRACTICE' :

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:

            last_prac_date[i]="NO PRACTICE"

        if sign_up_date[i] is not None:
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')

    state12 =  [each_string.lower() for each_string in state]
    stateshortnew=list(map(statesshort.get, state12))
    cv={'pn':Parents_Name,'pe':Parents_Email,'ut':join_final1['USER_TYPE'].tolist(),'ss':stateshortnew,
                               'st':state,'co':country,'sp':sign_up_date, 'ph':phone_number, 'sn':SCHOOL_NAME,
        'ct':CITY,
                               'lp':last_prac_date,'pc':practice_count}

    dftry = pd.DataFrame.from_dict(cv)
    dfus=dftry[dftry['co']=='United States']
    canada_df= dftry[dftry['co']=='Canada']
    Mexico_df= dftry[dftry['co']=='Mexico']
    India_df= dftry[dftry['co']=='India']
    dfother=dftry[~dftry['co'].isin(['United States', 'Mexico','India','Canada'])]
    # # dfrus=dftry[dftry['co']=='Russia']
    # dfmex=India_df[India_df['country']=='India']
    # dfind=Mexico_df[Mexico_df['country']=='Mexico']
    # dfcan=canada_df[canada_df['country']=='Canada']
    # dfrukr=Ukraine_df[Ukraine_df['country']=='Ukraine']
    totalparents=len(dftry)
    usa=len(dfus)
    india=len(India_df)
    mexico=len(Mexico_df)
    canada=len(canada_df)
    other=len(dfother)


    usaper=round(((usa/totalparents)*100),2)
    #     ukraineper=round(((ukraine/totalparents)*100),2)
    indiaper=round(((india/totalparents)*100),2)
    mexicoper=round(((mexico/totalparents)*100),2)
    canadaper=round(((canada/totalparents)*100),2)
    otherper=round(((other/totalparents)*100),2)

    dfother= dfother[['pn', 'pe', 'ph','sn', 'ct','st','co', 'sp','lp','pc']]
    try1=dftry.to_numpy().tolist()
    dfother = dfother.drop("co", axis=1)

    temp={"data":dfother.values.tolist()}
    return json.dumps(temp)


@app.route('/parentsmapukraine')

def parentsmapukraine():
    reader = geolite2.reader()
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username,password))
    db=client.compass


    collection2= db.audio_track_master
    qrB= [{"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'USER_ID.BLOCKED_BY_CAP':{'$ne':'Y'}}
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.CREATED_DATE':{'$gt':datetime.datetime(2020,3,17)}}
    ]}},
    {'$group':{'_id':'$USER_ID._id','PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
    {'$project':{'_id':1,'PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date": "$practice_date" }},
    'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}       
                      }}
    ]
    
    
    collection3= db.user_master
    qrC=[{'$match':{"schoolId":{'$exists':True}}},
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
   {'BLOCKED_BY_CAP':{'$ne':'Y'}}
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, {'schoolId._id':{'$not':{'$regex':'null'}}},
    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'CREATED_DATE':{'$gt':datetime.datetime(2020,3,17)}}
    ]}},
    {'$group':{'_id':'$_id', 
     'SCHOOL_NAME':{'$first':'$schoolId.NAME'}, 'PARENTS_EMAIL':{'$first':'$EMAIL_ID'} ,
     'PARENTS_NAME':{'$first':'$USER_NAME'}, 'ip_address':{'$first':'$ip_address'},
               'CONTACT_NUMBER':{'$first':'$CONTACT_NUMBER'},
       'state':{'$first':'$schoolId.STATE'}, 'city':{'$first':'$schoolId.CITY'},'country':{'$first':'$schoolId.COUNTRY'},   
               'USER_TYPE':{'$first':'USER_TYPE'}, 'SIGNUP_DATE':{'$first':'$CREATED_DATE'}
              }},
    {'$project':{'_id':1, 'SCHOOL_NAME':1, 'PARENTS_NAME':1, 'PARENTS_EMAIL':1,
              'state':1, 'city':1, 'country':1, 'USER_TYPE':1,'ip_address':1, 'CONTACT_NUMBER':1,
                'SIGNUP_DATE':{"$dateToString": { "format": "%Y-%m-%d", "date": "$SIGNUP_DATE" }}
                }}
     ]
    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join_final1= pd.merge(df_um, df_atma, how='left', on='_id')
    

    join_final1=join_final1.replace("UNITED STATES","United States")
    join_final1=join_final1.replace("US","United States")
    join_final1=join_final1.replace("us","United States")
    join_final1=join_final1.replace("USA","United States")
    join_final1=join_final1.replace("Usa","United States")
    join_final1=join_final1.replace("U.S.A","United States")
    join_final1=join_final1[join_final1['country']=='United States']
    join_final1.mindful_minutes=join_final1.MINDFUL_MINUTES.fillna(0)
    join_final1['LAST_PRACTICE_DATE']=pd.to_datetime(join_final1['LAST_PRACTICE_DATE'])
    join_final1['LAST_PRACTICE_DATE'].fillna("NO PRACTICE", inplace=True)
    join_final1['SCHOOL_NAME'].fillna("NO SCHOOL INFO", inplace=True)
    join_final1['SIGNUP_DATE']=pd.to_datetime(join_final1['SIGNUP_DATE'])
    def country1(i):
        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con

    ip=join_final1['ip_address'].tolist()
    phone_number=join_final1['CONTACT_NUMBER'].tolist()
    Parents_Name=join_final1['PARENTS_NAME'].tolist()
    Parents_Email=join_final1['PARENTS_EMAIL'].tolist()
    School_Name=join_final1['SCHOOL_NAME'].tolist()
    state=join_final1['state'].tolist()
    country=join_final1['country'].tolist()
    city=join_final1['city'].tolist()
    sign_up_date=join_final1['SIGNUP_DATE'].tolist()
    last_prac_date=join_final1['LAST_PRACTICE_DATE'].tolist()
    practice_count=join_final1['PRACTICE_COUNT'].tolist()
    mindful_minutes=join_final1['MINDFUL_MINUTES'].tolist()

    for i in range(len(ip)):

        if country[i] is None:
            try:
                country[i]=country1(ip[i])
            except:
                pass
        elif country[i]=='null':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if city[i] is None:
            try:
                city[i]=city1(ip[i])
            except:
                pass
        elif city[i]=='null':
            try:
                city[i]=city1(ip[i])
            except:
                pass
        if state[i] is None:

            try:
                state[i]=state1(ip[i])
            except:
                pass
        elif state[i] =='NO state info':

            try:
                state[i]=state1(ip[i])
            except:
                pass    
        if country[i] is None:
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] is None:
            country[i]=''
        if state[i] is None:
            state[i]=''

        if  last_prac_date[i] != 'NO PRACTICE' :

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:

            last_prac_date[i]="NO PRACTICE"

        
        if sign_up_date[i] is not None:
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')
    state12 =  [each_string.lower() for each_string in state]
    cv={'pnn':Parents_Name,'pe':Parents_Email,'co':country,'pn':phone_number,'sn':School_Name,'ct':city,
                               'st':state12,'sp':sign_up_date,
                               'lp':last_prac_date,'pc':practice_count}
    dftry = pd.DataFrame.from_dict(cv)
    
    dfrus=dftry[dftry['co']=='Ukraine']
    dfrus = dfrus.drop("co", axis=1)

    temp={"data":dfrus.values.tolist()}
    return json.dumps(temp)
# parentsmapukraine()

@app.route('/parentsmapindia')

def parentsmapindia():
    statesshort = {'alaska': 'ak',
    'alabama': 'al',
    'arkansas': 'ar',
    'american samoa': 'as',
    'arizona': 'az',
    'california': 'ca',
    'colorado': 'co',
    'connecticut': 'ct',
    'district of columbia': 'dc',
    'delaware': 'de',
    'florida': 'fl',
    'georgia': 'ga',
    'guam': 'gu',
    'hawaii': 'hi',
    'iowa': 'ia',
    'idaho': 'id',
    'illinois': 'il',
    'indiana': 'in',
    'kansas': 'ks',
    'kentucky': 'ky',
    'louisiana': 'la',
    'massachusetts': 'ma',
    'maryland': 'md',
    'maine': 'me',
    'michigan': 'mi',
    'minnesota': 'mn',
    'missouri': 'mo',
    'northern mariana islands': 'mp',
    'mississippi': 'ms',
    'montana': 'mt',
    'national': 'na',
    'north carolina': 'nc',
    'north dakota': 'nd',
    'nebraska': 'ne',
    'new hampshire': 'nh',
    'new jersey': 'nj',
    'new mexico': 'nm',
    'nevada': 'nv',
    'new york': 'ny',
    'ohio': 'oh',
    'oklahoma': 'ok',
    'oregon': 'or',
    'pennsylvania': 'pa',
    'puerto rico': 'pr',
    'rhode island': 'ri',
    'south carolina': 'sc',
    'south dakota': 'sd',
    'tennessee': 'tn',
    'texas': 'tx',
    'utah': 'ut',
    'virginia': 'va',
    'virgin islands': 'vi',
    'vermont': 'vt',
    'washington': 'wa',
    'wisconsin': 'wi',
    'west virginia': 'wv',
    'wyoming': 'wy'}

    reader = geolite2.reader()

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass


    collection2= db.audio_track_master
    qrB= [{"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}


    ]}},
    {'$group':{'_id':'$USER_ID._id','PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
    {'$project':{'_id':1,'PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE': '$practice_date'
    # 'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}       
              }}
    ]


    collection3= db.user_master
    qrC=[
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},

    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}
    ]}},

    {'$project':{'_id':1, 'SCHOOL_NAME':'$schoolId.NAME', 'PARENTS_NAME':'$USER_NAME', 'PARENTS_EMAIL':'$EMAIL_ID',
      'state':'$schoolId.STATE', 'CITY':'$schoolId.CITY', 'country':'$schoolId.COUNTRY', 
         'USER_TYPE':'$USER_TYPE','ip_address':'$IP_ADDRESS', 'CONTACT_NUMBER':'$CONTACT_NUMBER',
        'SIGNUP_DATE':"$CREATED_DATE"
        }}
    ]


    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join_final1= pd.merge(df_um, df_atma, how='left', on='_id')
    join_final1['PARENTS_NAME'].fillna('NO USER NAME FOUND', inplace=True)
    join_final1['PARENTS_EMAIL'].fillna('NO USER EMAIL FOUND', inplace=True)
    join_final1['SCHOOL_NAME'].fillna('NO SCHOOL NAME FOUND', inplace=True)
    join_final1['USER_TYPE'].fillna('NO USER TYPE FOUND', inplace=True)
    join_final1['state'].fillna('NO STATE FOUND', inplace=True)
    join_final1['CITY'].fillna('NO CITY FOUND', inplace=True)
    join_final1['country'].fillna('NO COUNTRY FOUND', inplace=True)
    join_final1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    join_final1['PRACTICE_COUNT'].fillna(0, inplace=True)
    # join_final1['ip_address'].fillna('NO IP ADDRESS FOUND', inplace=True)

    join_final1=join_final1.replace("UNITED STATES","United States")
    join_final1=join_final1.replace("US","United States")
    join_final1=join_final1.replace("us","United States")
    join_final1=join_final1.replace("USA","United States")
    join_final1=join_final1.replace("Usa","United States")
    join_final1=join_final1.replace("U.S.A","United States")

    def country1(i):
        location =reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location =reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=join_final1['ip_address'].tolist()
    phone_number=join_final1['CONTACT_NUMBER'].tolist()
    Parents_Name=join_final1['PARENTS_NAME'].tolist()
    Parents_Email=join_final1['PARENTS_EMAIL'].tolist()
    state=join_final1['state'].tolist()
    country=join_final1['country'].tolist()
    CITY=join_final1['CITY'].tolist()
    SCHOOL_NAME=join_final1['SCHOOL_NAME'].to_list()
    sign_up_date=join_final1['SIGNUP_DATE'].tolist()
    last_prac_date=join_final1['LAST_PRACTICE_DATE'].tolist()
    practice_count=join_final1['PRACTICE_COUNT'].tolist()
    # mindful_minutes=join_final1['MINDFUL_MINUTES'].tolist()

    for i in range(len(ip)):

        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if state[i] != 'NO STATE FOUND':

            try:
                state[i]=state1(ip[i])
            except:
                pass
        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] == 'NO COUNTRY FOUND':
            country[i]=''
        if state[i] == 'NO COUNTRY FOUND':
            state[i]=''

        if  last_prac_date[i] != 'NO PRACTICE' :

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:

            last_prac_date[i]="NO PRACTICE"

        if sign_up_date[i] is not None:
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')

    state12 =  [each_string.lower() for each_string in state]
    stateshortnew=list(map(statesshort.get, state12))
    cv={'pn':Parents_Name,'pe':Parents_Email,'ut':join_final1['USER_TYPE'].tolist(),'ss':stateshortnew,
                               'st':state,'co':country,'sp':sign_up_date, 'ph':phone_number, 'sn':SCHOOL_NAME,
        'ct':CITY,
                               'lp':last_prac_date,'pc':practice_count}

    dftry = pd.DataFrame.from_dict(cv)
    dfus=dftry[dftry['co']=='United States']
    canada_df= dftry[dftry['co']=='Canada']
    Mexico_df= dftry[dftry['co']=='Mexico']
    India_df= dftry[dftry['co']=='India']
    dfother=dftry[~dftry['co'].isin(['United States', 'Mexico','India','Canada'])]
    # # dfrus=dftry[dftry['co']=='Russia']
    # dfmex=India_df[India_df['country']=='India']
    # dfind=Mexico_df[Mexico_df['country']=='Mexico']
    # dfcan=canada_df[canada_df['country']=='Canada']
    # dfrukr=Ukraine_df[Ukraine_df['country']=='Ukraine']
    totalparents=len(dftry)
    usa=len(dfus)
    india=len(India_df)
    mexico=len(Mexico_df)
    canada=len(canada_df)
    other=len(dfother)


    usaper=round(((usa/totalparents)*100),2)
    #     ukraineper=round(((ukraine/totalparents)*100),2)
    indiaper=round(((india/totalparents)*100),2)
    mexicoper=round(((mexico/totalparents)*100),2)
    canadaper=round(((canada/totalparents)*100),2)
    otherper=round(((other/totalparents)*100),2)

    India_df= India_df[['pn', 'pe', 'ph','sn', 'ct','st','co', 'sp','lp','pc']]
    try1=dftry.to_numpy().tolist()
    dfus = India_df.drop("co", axis=1)

    temp={"data":India_df.values.tolist()}
    return json.dumps(temp)
# parentsmapindia()



@app.route('/parentsmapusa')

def parentsmapusa():
    statesshort = {'alaska': 'ak',
    'alabama': 'al',
    'arkansas': 'ar',
    'american samoa': 'as',
    'arizona': 'az',
    'california': 'ca',
    'colorado': 'co',
    'connecticut': 'ct',
    'district of columbia': 'dc',
    'delaware': 'de',
    'florida': 'fl',
    'georgia': 'ga',
    'guam': 'gu',
    'hawaii': 'hi',
    'iowa': 'ia',
    'idaho': 'id',
    'illinois': 'il',
    'indiana': 'in',
    'kansas': 'ks',
    'kentucky': 'ky',
    'louisiana': 'la',
    'massachusetts': 'ma',
    'maryland': 'md',
    'maine': 'me',
    'michigan': 'mi',
    'minnesota': 'mn',
    'missouri': 'mo',
    'northern mariana islands': 'mp',
    'mississippi': 'ms',
    'montana': 'mt',
    'national': 'na',
    'north carolina': 'nc',
    'north dakota': 'nd',
    'nebraska': 'ne',
    'new hampshire': 'nh',
    'new jersey': 'nj',
    'new mexico': 'nm',
    'nevada': 'nv',
    'new york': 'ny',
    'ohio': 'oh',
    'oklahoma': 'ok',
    'oregon': 'or',
    'pennsylvania': 'pa',
    'puerto rico': 'pr',
    'rhode island': 'ri',
    'south carolina': 'sc',
    'south dakota': 'sd',
    'tennessee': 'tn',
    'texas': 'tx',
    'utah': 'ut',
    'virginia': 'va',
    'virgin islands': 'vi',
    'vermont': 'vt',
    'washington': 'wa',
    'wisconsin': 'wi',
    'west virginia': 'wv',
    'wyoming': 'wy'}

    reader = geolite2.reader()

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass


    collection2= db.audio_track_master
    qrB= [{"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}


    ]}},
    {'$group':{'_id':'$USER_ID._id','PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
    {'$project':{'_id':1,'PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE': '$practice_date'
    # 'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}       
              }}
    ]


    collection3= db.user_master
    qrC=[
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},

    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}
    ]}},

    {'$project':{'_id':1, 'SCHOOL_NAME':'$schoolId.NAME', 'PARENTS_NAME':'$USER_NAME', 'PARENTS_EMAIL':'$EMAIL_ID',
      'state':'$schoolId.STATE', 'CITY':'$schoolId.CITY', 'country':'$schoolId.COUNTRY', 
         'USER_TYPE':'$USER_TYPE','ip_address':'$IP_ADDRESS', 'CONTACT_NUMBER':'$CONTACT_NUMBER',
        'SIGNUP_DATE':"$CREATED_DATE"
        }}
    ]


    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join_final1= pd.merge(df_um, df_atma, how='left', on='_id')
    join_final1['PARENTS_NAME'].fillna('NO USER NAME FOUND', inplace=True)
    join_final1['PARENTS_EMAIL'].fillna('NO USER EMAIL FOUND', inplace=True)
    join_final1['SCHOOL_NAME'].fillna('NO SCHOOL NAME FOUND', inplace=True)
    join_final1['USER_TYPE'].fillna('NO USER TYPE FOUND', inplace=True)
    join_final1['state'].fillna('NO STATE FOUND', inplace=True)
    join_final1['CITY'].fillna('NO CITY FOUND', inplace=True)
    join_final1['country'].fillna('NO COUNTRY FOUND', inplace=True)
    join_final1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    join_final1['PRACTICE_COUNT'].fillna(0, inplace=True)
    # join_final1['ip_address'].fillna('NO IP ADDRESS FOUND', inplace=True)

    join_final1=join_final1.replace("UNITED STATES","United States")
    join_final1=join_final1.replace("US","United States")
    join_final1=join_final1.replace("us","United States")
    join_final1=join_final1.replace("USA","United States")
    join_final1=join_final1.replace("Usa","United States")
    join_final1=join_final1.replace("U.S.A","United States")

    def country1(i):
        location =reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location =reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=join_final1['ip_address'].tolist()
    phone_number=join_final1['CONTACT_NUMBER'].tolist()
    Parents_Name=join_final1['PARENTS_NAME'].tolist()
    Parents_Email=join_final1['PARENTS_EMAIL'].tolist()
    state=join_final1['state'].tolist()
    country=join_final1['country'].tolist()
    CITY=join_final1['CITY'].tolist()
    SCHOOL_NAME=join_final1['SCHOOL_NAME'].to_list()
    sign_up_date=join_final1['SIGNUP_DATE'].tolist()
    last_prac_date=join_final1['LAST_PRACTICE_DATE'].tolist()
    practice_count=join_final1['PRACTICE_COUNT'].tolist()
    # mindful_minutes=join_final1['MINDFUL_MINUTES'].tolist()

    for i in range(len(ip)):

        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if state[i] != 'NO STATE FOUND':

            try:
                state[i]=state1(ip[i])
            except:
                pass
        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] == 'NO COUNTRY FOUND':
            country[i]=''
        if state[i] == 'NO COUNTRY FOUND':
            state[i]=''

        if  last_prac_date[i] != 'NO PRACTICE' :

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:

            last_prac_date[i]="NO PRACTICE"

        if sign_up_date[i] is not None:
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')

    state12 =  [each_string.lower() for each_string in state]
    stateshortnew=list(map(statesshort.get, state12))
    cv={'pn':Parents_Name,'pe':Parents_Email,'ut':join_final1['USER_TYPE'].tolist(),'ss':stateshortnew,
                               'st':state,'co':country,'sp':sign_up_date, 'ph':phone_number, 'sn':SCHOOL_NAME,
        'ct':CITY,
                               'lp':last_prac_date,'pc':practice_count}

    dftry = pd.DataFrame.from_dict(cv)
    dfus=dftry[dftry['co']=='United States']
    canada_df= dftry[dftry['co']=='Canada']
    Mexico_df= dftry[dftry['co']=='Mexico']
    India_df= dftry[dftry['co']=='India']
    dfother=dftry[~dftry['co'].isin(['United States', 'Mexico','India','Canada'])]
    # # dfrus=dftry[dftry['co']=='Russia']
    # dfmex=India_df[India_df['country']=='India']
    # dfind=Mexico_df[Mexico_df['country']=='Mexico']
    # dfcan=canada_df[canada_df['country']=='Canada']
    # dfrukr=Ukraine_df[Ukraine_df['country']=='Ukraine']
    totalparents=len(dftry)
    usa=len(dfus)
    india=len(India_df)
    mexico=len(Mexico_df)
    canada=len(canada_df)
    other=len(dfother)


    usaper=round(((usa/totalparents)*100),2)
    #     ukraineper=round(((ukraine/totalparents)*100),2)
    indiaper=round(((india/totalparents)*100),2)
    mexicoper=round(((mexico/totalparents)*100),2)
    canadaper=round(((canada/totalparents)*100),2)
    otherper=round(((other/totalparents)*100),2)

    dfus= dfus[['pn', 'pe', 'ph','sn', 'ct','st','co', 'sp','lp','pc']]
    try1=dftry.to_numpy().tolist()
    dfus = dfus.drop("co", axis=1)

    temp={"data":dfus.values.tolist()}
    return json.dumps(temp)
# parentsmapusa()






@app.route('/parentsmap')
def parentsmaps():
    statesshort = {'alaska': 'ak',
    'alabama': 'al',
    'arkansas': 'ar',
    'american samoa': 'as',
    'arizona': 'az',
    'california': 'ca',
    'colorado': 'co',
    'connecticut': 'ct',
    'district of columbia': 'dc',
    'delaware': 'de',
    'florida': 'fl',
    'georgia': 'ga',
    'guam': 'gu',
    'hawaii': 'hi',
    'iowa': 'ia',
    'idaho': 'id',
    'illinois': 'il',
    'indiana': 'in',
    'kansas': 'ks',
    'kentucky': 'ky',
    'louisiana': 'la',
    'massachusetts': 'ma',
    'maryland': 'md',
    'maine': 'me',
    'michigan': 'mi',
    'minnesota': 'mn',
    'missouri': 'mo',
    'northern mariana islands': 'mp',
    'mississippi': 'ms',
    'montana': 'mt',
    'national': 'na',
    'north carolina': 'nc',
    'north dakota': 'nd',
    'nebraska': 'ne',
    'new hampshire': 'nh',
    'new jersey': 'nj',
    'new mexico': 'nm',
    'nevada': 'nv',
    'new york': 'ny',
    'ohio': 'oh',
    'oklahoma': 'ok',
    'oregon': 'or',
    'pennsylvania': 'pa',
    'puerto rico': 'pr',
    'rhode island': 'ri',
    'south carolina': 'sc',
    'south dakota': 'sd',
    'tennessee': 'tn',
    'texas': 'tx',
    'utah': 'ut',
    'virginia': 'va',
    'virgin islands': 'vi',
    'vermont': 'vt',
    'washington': 'wa',
    'wisconsin': 'wi',
    'west virginia': 'wv',
    'wyoming': 'wy'}

    reader = geolite2.reader()

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass


    collection2= db.audio_track_master
    qrB= [{"$match":
    {"$and":[
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}


    ]}},
    {'$group':{'_id':'$USER_ID._id','PRACTICE_COUNT':{'$sum':1}, 'practice_date':{'$max':'$MODIFIED_DATE'}
    }},
    {'$project':{'_id':1,'PRACTICE_COUNT':1, 'LAST_PRACTICE_DATE': '$practice_date'
    # 'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}       
              }}
    ]


    collection3= db.user_master
    qrC=[
    {"$match":
    {"$and":[
    {'IS_DISABLED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    ]}},
    {"$match": {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}, 
    {'EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}}, {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}},

    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}}
    ]}},

    {'$project':{'_id':1, 'SCHOOL_NAME':'$schoolId.NAME', 'PARENTS_NAME':'$USER_NAME', 'PARENTS_EMAIL':'$EMAIL_ID',
      'state':'$schoolId.STATE', 'CITY':'$schoolId.CITY', 'country':'$schoolId.COUNTRY', 
         'USER_TYPE':'$USER_TYPE','ip_address':'$IP_ADDRESS', 'CONTACT_NUMBER':'$CONTACT_NUMBER',
        'SIGNUP_DATE':"$CREATED_DATE"
        }}
    ]


    list2=list(collection2.aggregate(qrB))
    df_atma= DataFrame(list2)
    list3= list(collection3.aggregate(qrC))
    df_um= DataFrame(list3)
    join_final1= pd.merge(df_um, df_atma, how='left', on='_id')
    join_final1['PARENTS_NAME'].fillna('NO USER NAME FOUND', inplace=True)
    join_final1['PARENTS_EMAIL'].fillna('NO USER EMAIL FOUND', inplace=True)
    join_final1['SCHOOL_NAME'].fillna('NO SCHOOL NAME FOUND', inplace=True)
    join_final1['USER_TYPE'].fillna('NO USER TYPE FOUND', inplace=True)
    join_final1['state'].fillna('NO STATE FOUND', inplace=True)
    join_final1['CITY'].fillna('NO CITY FOUND', inplace=True)
    join_final1['country'].fillna('NO COUNTRY FOUND', inplace=True)
    join_final1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    join_final1['PRACTICE_COUNT'].fillna(0, inplace=True)
    # join_final1['ip_address'].fillna('NO IP ADDRESS FOUND', inplace=True)

    join_final1=join_final1.replace("UNITED STATES","United States")
    join_final1=join_final1.replace("US","United States")
    join_final1=join_final1.replace("us","United States")
    join_final1=join_final1.replace("USA","United States")
    join_final1=join_final1.replace("Usa","United States")
    join_final1=join_final1.replace("U.S.A","United States")

    def country1(i):
        location =reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location =reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=join_final1['ip_address'].tolist()
    phone_number=join_final1['CONTACT_NUMBER'].tolist()
    Parents_Name=join_final1['PARENTS_NAME'].tolist()
    Parents_Email=join_final1['PARENTS_EMAIL'].tolist()
    state=join_final1['state'].tolist()
    country=join_final1['country'].tolist()
    sign_up_date=join_final1['SIGNUP_DATE'].tolist()
    last_prac_date=join_final1['LAST_PRACTICE_DATE'].tolist()
    practice_count=join_final1['PRACTICE_COUNT'].tolist()
    # mindful_minutes=join_final1['MINDFUL_MINUTES'].tolist()

    for i in range(len(ip)):

        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if state[i] != 'NO STATE FOUND':

            try:
                state[i]=state1(ip[i])
            except:
                pass
        if country[i] != 'NO COUNTRY FOUND':
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] == 'NO COUNTRY FOUND':
            country[i]=''
        if state[i] == 'NO COUNTRY FOUND':
            state[i]=''

        if  last_prac_date[i] != 'NO PRACTICE' :

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:

            last_prac_date[i]="NO PRACTICE"

        if sign_up_date[i] is not None:
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')

    state12 =  [each_string.lower() for each_string in state]
    stateshortnew=list(map(statesshort.get, state12))
    cv={'pn':Parents_Name,'pe':Parents_Email,'ut':join_final1['USER_TYPE'].tolist(),'ss':stateshortnew,
                               'st':state,'co':country,'sp':sign_up_date,
                               'lp':last_prac_date,'pc':practice_count}

    dftry = pd.DataFrame.from_dict(cv)
    dfus=dftry[dftry['co']=='United States']
    canada_df= dftry[dftry['co']=='Canada']
    Mexico_df= dftry[dftry['co']=='Mexico']
    India_df= dftry[dftry['co']=='India']
    dfother=dftry[~dftry['co'].isin(['United States', 'Mexico','India','Canada'])]
    # # dfrus=dftry[dftry['co']=='Russia']
    # dfmex=India_df[India_df['country']=='India']
    # dfind=Mexico_df[Mexico_df['country']=='Mexico']
    # dfcan=canada_df[canada_df['country']=='Canada']
    # dfrukr=Ukraine_df[Ukraine_df['country']=='Ukraine']
    totalparents=len(dftry)
    usa=len(dfus)
    india=len(India_df)
    mexico=len(Mexico_df)
    canada=len(canada_df)
    other=len(dfother)


    usaper=round(((usa/totalparents)*100),2)
#     ukraineper=round(((ukraine/totalparents)*100),2)
    indiaper=round(((india/totalparents)*100),2)
    mexicoper=round(((mexico/totalparents)*100),2)
    canadaper=round(((canada/totalparents)*100),2)
    otherper=round(((other/totalparents)*100),2)

    statesdf=dfus['ss'].dropna()
    count=statesdf.value_counts()


    data=[]
    for i,k in zip(count.index,count.values):

        try:
            data.append({"code":i,"value":int(k),'hc-key':"us-"+i})
        except:
            pass
#     print(json.dumps({"india":india,"mexico":mexico,"canada":canada,"totalparents":totalparents,"data":data,"usa":usa,"ukraine":ukraine,"usaper":usaper,"ukraineper":ukraineper,"other":other }))
    return json.dumps({"india":india,"mexico":mexico,"canada":canada,"totalparents":totalparents,"data":data,"usa":usa,"other":other,"usaper":usaper,"otherper":otherper})
parentsmaps()    





@app.route('/userparents/<usertype>')
def userparents_table(usertype):


    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass


    collection1= db.user_master
    query1=[

    {"$match":
        {"$and":[
        {'IS_DISABLED':{"$ne":'Y'}}, {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
                           {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},{'EMAIL_ID':{'$ne':None}},
           
            {'EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, {'EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},

        ]}},

        {'$group':{'_id':'$_id', 'name':{'$first':'$schoolId.NAME'} ,'Parents_Name':{'$first':'$USER_NAME'}, 'Sign_Up_Date':{'$first':{"$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" }}},
     'Parents_Email':{'$first':'$EMAIL_ID'}, 'contact_number':{'$first':'$CONTACT_NUMBER'},
        'city':{'$first':'$schoolId.CITY'},'state':{'$first':'$schoolId.STATE'}, 
        'country':{'$first':'$schoolId.COUNTRY'}, 'user_type':{'$first':'$USER_TYPE'}, 'ip_address':{'$first':'$IP_ADDRESS'}

        }}         
            ]



    collection2= db.audio_track_master
    query2=[

    {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},

        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
         {'USER_ID.schoolId._id':{'$not':{'$regex':'null'}}},{'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},{'USER_ID.EMAIL_ID':{'$ne':None}},
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
            {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},

        ]}},
        {'$group':{'_id':'$USER_ID._id',  'Practice_Count':{'$sum':1},
            'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}},
        'Last_Practice_Date':{'$max':'$MODIFIED_DATE'}
        }}, 
        {'$project':{'_id':1,'Practice_Count':1,
            'mindful_minutes':1, 'Last_Practice_Date':"$Last_Practice_Date" 
        }}
        ]


    list1=list(collection1.aggregate(query1))
    df_1=DataFrame(list1)
    list2=list(collection2.aggregate(query2))
    df_2=DataFrame(list2)
    # df_1['school_name'].fillna("NO SCHOOL FOUND", inplace=True)
    # df_3['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    # df_1['COUNTRY'].fillna("NO COUNTRY FOUND", inplace=True)
    # df_1['STATE'].fillna("NO STATE FOUND", inplace=True)
    # df_1['city'].fillna("NO CITY FOUND", inplace=True)
    # df_1['ADDRESS'].fillna("NO ADDRESS FOUND", inplace=True)


    df= pd.merge(df_1, df_2,how='left', on='_id')


    df.mindful_minutes=df.mindful_minutes.fillna(0)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.mindful_minutes=df.mindful_minutes.astype('int64')

    # df['Last_Practice_Date']=pd.to_datetime(df['Last_Practice_Date'])
    df['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    df['Sign_Up_Date']=pd.to_datetime(df['Sign_Up_Date'])
    df['name'].fillna("NO SCHOOL INFO", inplace=True)

    df.Practice_Count=df.Practice_Count.astype('int64')
    
    
    df= df.groupby(df['user_type'])
    df= df.get_group(''+usertype+'')
    
   
    
    # print(df)

    def country1(i):
            location = reader.get(i)
            c=(location['country']['names']['en'])
            return c
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con

    ip=df['ip_address'].tolist()
    phone_number=df['contact_number'].tolist()
    Parents_Name=df['Parents_Name'].tolist()
    Parents_Email=df['Parents_Email'].tolist()
    School_Name=df['name'].tolist()
    state=df['state'].tolist()
    country=df['country'].tolist()
    city=df['city'].tolist()
    sign_up_date=df['Sign_Up_Date'].tolist()
    last_prac_date=df['Last_Practice_Date'].tolist()

    practice_count=df['Practice_Count'].tolist()
    mindful_minutes=df['mindful_minutes'].tolist()

    for i in range(len(ip)):

        if country[i] is None:
            try:
                country[i]=country1(ip[i])
            except:
                pass
        elif country[i]=='null':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if city[i] is None:
            try:
                city[i]=city1(ip[i])
            except:
                pass
        elif city[i]=='null':
            try:
                city[i]=city1(ip[i])
            except:
                pass
        if state[i] is None:

            try:
                state[i]=state1(ip[i])
            except:
                pass
        elif state[i] =='NO state info':

            try:
                state[i]=state1(ip[i])
            except:
                pass    
        if country[i] is None:
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] is None:
            country[i]=''
        if state[i] is None:
            state[i]=''

        if  last_prac_date[i] != 'NO PRACTICE' :

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')

        if sign_up_date[i] is not None:
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')

    state12 =  [each_string.lower() for each_string in state]
    cv={'pnn':Parents_Name,'pe':Parents_Email,'co':country,'pn':phone_number,'sn':School_Name,'ct':city,
                               'st':state12,'sp':sign_up_date,
                             'lp':last_prac_date,'pc':practice_count}
    dftry = pd.DataFrame.from_dict(cv)
    dftry= dftry.drop("co", axis=1)
    # print(dftry)
    return json.dumps({"data":dftry.values.tolist()})



@app.route('/graph1parents/<daate>')
def graph1_table(daate):
    reader = geolite2.reader()
    daate1=int(daate)/1000
    DATE1 =time.strftime('%y/%m/%d 00:00:00', time.localtime(daate1))
    print(DATE1,"SELECTED DATE")
    datetime_object = datetime.datetime.strptime(DATE1, '%y/%m/%d %H:%M:%S')
    minus=datetime_object
    minus1 = minus.strftime("%d-%b-%Y").replace('-', ' ')
    mongo_uri = "mongodb://admin:" + urllib.parse.quote('I#L@teST^m0NGO_2o20!') + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.user_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    qr1=[{"$match":{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b"), 
        "IS_DISABLED":{"$ne":"Y"},
        "INCOMPLETE_SIGNUP":{"$ne":"Y"},
        "EMAIL_ID":{'$not':{'$regex':'test', '$options':'i'}},
        "EMAIL_ID":{"$ne": ""},
        "EMAIL_ID":{'$not':{'$regex':'1gen', '$options':'i'}},
        "USER_NAME":{'$not':{'$regex':'test', '$options':'i'}},
        "CREATED_DATE":{"$gt":myDatetime}}}, 
    {'$group':{'_id':'$_id','Parents_Id':{'$first':'$_id'},'name':{'$first':'$schoolId.NAME'},'city':{'$first':'$schoolId.CITY'},'state':{'$first':'$schoolId.STATE'},
    'country':{'$first':'$schoolId.COUNTRY'},
    'ip_address':{'$first':'$IP_ADDRESS'}, 'Parents_Name':{'$first':'$USER_NAME'}, 'Parents_Email':{'$first':'$EMAIL_ID'}, 
    'contact_number':{'$first':'$CONTACT_NUMBER'}, 'user_type':{'$first':'$USER_TYPE'}, 'Sign_Up_Date':{'$first':'$CREATED_DATE'}
    }}
    ]
    collection2= db.audio_track_master
    qr2= [
        {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}, 
    {'USER_ID.CREATED_DATE':{'$gt':myDatetime}}, 
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}}
    ]}},
    {"$match":
    {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}
    ]
    }}, 
    {'$group':{'_id':'$USER_ID._id', 
    'Practice_Count':{'$sum':1},'Last_Practice_Date':{'$max':'$MODIFIED_DATE'},'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}
    }} 
        ]
    collection3= db.login_logs
    qr3=[
        {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}, 
    {'USER_ID.CREATED_DATE':{'$gt':myDatetime}}, {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}}
    ]}},
    {"$match":
    {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}
    ]
    }}, 
    {'$group':{'_id':'$USER_ID._id', 'Last_Login_Date':{'$max':'$LAST_LOGGED_IN'},
    }}     
        ]
    um= list(collection.aggregate(qr1))
    df_um= pd.DataFrame(um)
    atd= list(collection2.aggregate(qr2))
    df_atd= pd.DataFrame(atd)
    ll= list(collection3.aggregate(qr3))
    df_ll=pd.DataFrame(ll)
    join=pd.merge(df_um, df_atd, how='left', on='_id')
    df= pd.merge(join, df_ll, how='left', on='_id')
    df.mindful_minutes=df.mindful_minutes.fillna(0)
    df.mindful_minutes=df.mindful_minutes.astype('int64')
    df['Last_Practice_Date']=pd.to_datetime(df['Last_Practice_Date'])
    df['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    df['Last_Login_Date']=pd.to_datetime(df['Last_Login_Date'])
    df['Last_Login_Date'].fillna("NO LOGIN", inplace=True)
    df['Sign_Up_Date']=pd.to_datetime(df['Sign_Up_Date'])
    df['name'].fillna("NO SCHOOL INFO", inplace=True)
    def country1(i):
        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=df['ip_address'].tolist()
    phone_number=df['contact_number'].tolist()
    Parents_Name=df['Parents_Name'].tolist()
    Parents_Email=df.Parents_Email.tolist()
    School_Name=df['name'].tolist()
    state=df['state'].tolist()
    country=df['country'].tolist()
    city=df['city'].tolist()
    sign_up_date=df['Sign_Up_Date'].tolist()
    last_prac_date=df['Last_Practice_Date'].tolist()
    last_login_date=df['Last_Login_Date'].tolist()
    practice_count=df['Practice_Count'].tolist()
    mindful_minutes=df['mindful_minutes'].tolist()
    for i in range(len(ip)):
        if country[i] is None:
            try:
                country[i]=country1(ip[i])
            except:
                pass
        elif country[i]=='null':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if city[i] is None:
            try:
                city[i]=city1(ip[i])
            except:
                pass
        elif city[i]=='null':
            try:
                city[i]=city1(ip[i])
            except:
                pass
        if state[i] is None:
            try:
                state[i]=state1(ip[i])
            except:
                pass
        elif state[i] =='NO state info':
            try:
                state[i]=state1(ip[i])
            except:
                pass    
        if country[i] is None:
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] is None:
            country[i]=''
        if state[i] is None:
            state[i]=''
        if  last_prac_date[i] != 'NO PRACTICE' :
            last_prac_date[i]=(last_prac_date[i]- timedelta(hours=4)).strftime('%d %b %Y')
        else:
            last_prac_date[i]="NO PRACTICE"
        if  last_login_date[i] != 'NO LOGIN' :
            last_login_date[i]=(last_login_date[i]- timedelta(hours=4)).strftime('%d %b %Y')

        else:
            last_login_date[i]="NO LOGIN"
        if sign_up_date[i] is not None:

            sign_up_date[i]=(sign_up_date[i]- timedelta(hours=4)).strftime('%d %b %Y')
    #             print(sign_up_date[i])
    state12 =  [each_string.lower() for each_string in state]
    cv={'pnn':Parents_Name,'pe':Parents_Email,'co':country,'pn':phone_number,'sn':School_Name,'ct':city,
                            'st':state12,'sp':sign_up_date,
                            'll':last_login_date,'lp':last_prac_date,'pc':practice_count}
    dftry = pd.DataFrame.from_dict(cv).fillna(0)
    dftry= dftry.drop("co", axis=1) 
    dftry1=dftry[dftry["sp"].str.contains(minus1, na=False)]
    return json.dumps({"data":dftry1.values.tolist()})



@app.route('/logparents')
def logparents_table():
    
    reader = geolite2.reader()
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus("I#L@teST^m0NGO_2o20!")
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.audio_track_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    df = DataFrame(list(collection.aggregate([
        {"$match":{"$and":[{'ROLE_ID.ROLE_ID' :3}, 
                   {"IS_DISTABLED":{"$ne":"Y"}},
                   {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                   {"EMAIL_ID":{"$ne": ""}}]}},
        {"$match":{"$and":[{"EMAIL_ID":{"$not":{"$regex":'1gen','$options':'i'}}},
                           {"USER_NAME":{"$not":{"$regex":'test','$options':'i'}}},
                          {"EMAIL_ID":{"$not":{"$regex":'test','$options':'i'}}}]}},
        {"$match":{"$and":[{"CREATED_DATE":{"$gt": myDatetime}}]}},
        {"$project":{"USER_ID":1,"USER_NAME":1,"EMAIL_ID":1,"CONTACT_NUMBER":1,"schoolId.CITY":1,
                     "schoolId.STATE":1,"schoolId.COUNTRY":1,'IP_ADDRESS':1,
                     "schoolId.NAME":1,"CREATED_DATE":1}}])))

    df1=df[['_id','schoolId']]
    df2 = df1.dropna()
    schoolId = list(df2['_id'])
    df2 = pd.json_normalize(df2['schoolId'])
    df2['schoolId'] = schoolId

    merge=pd.merge(df, df2, how='left', left_on=['_id'], right_on=['schoolId'])
    del merge['schoolId_x'], merge['schoolId_y']
    merge['CREATED_DATE'] = pd.to_datetime(merge['CREATED_DATE'])

    df_audio = DataFrame(list(collection2.aggregate([
                {"$match":{'USER_ID.IS_DISABLED':{"$ne":'Y'},
                'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'},
                'USER_ID.EMAIL_ID':{"$ne":""},
                'USER_ID.CREATED_DATE':{"$gt":myDatetime},
                'USER_ID.ROLE_ID.ROLE_ID':{"$eq":3}}},
                {"$match":{"$and":[
                {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}}]}},
                {"$group":{"_id":"$USER_ID._id","Last_Practice_Date":{"$max":"$MODIFIED_DATE"},'Count':{"$sum":1}, 
                           "EMAIL":{"$first":"USER_ID.EMAIL_ID"},
                           'mindful_minutes':{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                {"$project":{"_id":1, 'Practice_Count':'$Count',"Last_Practice_Date":1,'mindful_minutes':1}}])))


    final = pd.merge(merge, df_audio, how='left', left_on=['_id'], right_on=['_id'])

    del final['_id']
    final['Last_Practice_Date'] = pd.to_datetime(final['Last_Practice_Date'])

    final.mindful_minutes=final.mindful_minutes.fillna(0)
    final.mindful_minutes=final.mindful_minutes.astype('int64')
    final['Last_Practice_Date']=pd.to_datetime(final['Last_Practice_Date'])
    final['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    #df['Last_Login_Date']=pd.to_datetime(df['Last_Login_Date'])
    #df['Last_Login_Date'].fillna("NO LOGIN", inplace=True)
    final['CREATED_DATE']=pd.to_datetime(final['CREATED_DATE'])
    final['NAME'].fillna("NO SCHOOL INFO", inplace=True)
    final['STATE'].fillna('NO STATE INFO', inplace = True)

    def country1(i):
        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=final['IP_ADDRESS'].tolist()
    phone_number=final['CONTACT_NUMBER'].tolist()
    Parents_Name=final['USER_NAME'].tolist()
    Parents_Email=final['EMAIL_ID'].tolist()
    School_Name=final['NAME'].tolist()
    state=final['STATE'].tolist()
    country=final['COUNTRY'].tolist()
    city=final['CITY'].tolist()
    sign_up_date=final['CREATED_DATE'].tolist()
    last_prac_date=final['Last_Practice_Date'].tolist()
    practice_count=final['Practice_Count'].tolist()
    mindful_minutes=final['mindful_minutes'].tolist()

    for i in range(len(ip)):

        if country[i] is None:
            try:
                country[i]=country1(ip[i])
            except:
                pass
        elif country[i]=='null':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if city[i] is None:
            try:
                city[i]=city1(ip[i])
            except:
                pass
        elif city[i]=='null':
            try:
                city[i]=city1(ip[i])
            except:
                pass
        if state[i] is None:

            try:
                state[i]=state1(ip[i])
            except:
                pass
        elif state[i] =='NO state info':

            try:
                state[i]=state1(ip[i])
            except:
                pass    
        if country[i] is None:
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] is None:
            country[i]=''
        if state[i] is None:
            state[i]=''

        if  last_prac_date[i] != 'NO PRACTICE' :

            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:

            last_prac_date[i]="NO PRACTICE"

    if sign_up_date[i] is not None:
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')

    state12 =  [each_string.lower() for each_string in state]
    cv={'pnn':Parents_Name,'pe':Parents_Email,'co':country,'pn':phone_number,'sn':School_Name,'ct':city,
                               'st':state12,'sp':sign_up_date,'lp':last_prac_date,'pc':practice_count}
    dftry = pd.DataFrame.from_dict(cv)
    dftry= dftry.drop("co", axis=1)

    return json.dumps({"data":dftry.values.tolist()})
@app.route('/pracparents')
def pracparents_table():
    reader = geolite2.reader()

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus("I#L@teST^m0NGO_2o20!")
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.audio_track_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    df = DataFrame(list(collection.aggregate([
        {"$match":{'$and':[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                 {'USER_ID.EMAIL_ID':{"$nin":["",' ',None]}},
                 {'USER_ID.CREATED_DATE':{"$gt":myDatetime}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
        {"$project":{"USER_ID":1,"USER_NAME":1,"EMAIL_ID":1,"CONTACT_NUMBER":1,"schoolId.CITY":1,
                     "schoolId.STATE":1,"schoolId.COUNTRY":1,
                     "schoolId.NAME":1,"schoolId.ADDRESS":1,"CREATED_DATE":1}}])))

    df1=df[['_id','schoolId']]
    df2 = df1.dropna()
    schoolId = list(df2['_id'])
    df2 = pd.json_normalize(df2['schoolId'])
    df2['schoolId'] = schoolId

    merge=pd.merge(df, df2, how='left', left_on=['_id'], right_on=['schoolId'])
    del merge['schoolId_x'], merge['schoolId_y']
    merge['CREATED_DATE'] = pd.to_datetime(merge['CREATED_DATE'])

    df_audio = DataFrame(list(collection2.aggregate([
                {"$match":{'USER_ID.IS_DISABLED':{"$ne":'Y'},
                'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'},
                'USER_ID.EMAIL_ID':{"$ne":""},
                'USER_ID.CREATED_DATE':{"$gt":myDatetime},
                'USER_ID.ROLE_ID.ROLE_ID':{"$eq":3}}},
                {"$match":{"$and":[
                {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}}]}},
                {"$group":{"_id":"$USER_ID._id","Last_Practice_Date":{"$max":"$MODIFIED_DATE"},'Count':{"$sum":1}, 
                           "EMAIL":{"$first":"USER_ID.EMAIL_ID"}}},
                {"$project":{"_id":1, 'Practice_Count':'$Count',"Last_Practice_Date":1}}])))


    final = pd.merge(merge, df_audio, how='left', left_on=['_id'], right_on=['_id'])

    del final['_id']

    final['Last_Practice_Date'] = pd.to_datetime(final['Last_Practice_Date'])


    final['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    #df['Last_Login_Date']=pd.to_datetime(df['Last_Login_Date'])
    #df['Last_Login_Date'].fillna("NO LOGIN", inplace=True)
    final['Practice_Count'].fillna("NO PRACTICE", inplace=True)
    final['CREATED_DATE']=pd.to_datetime(final['CREATED_DATE'])
    final['NAME'].fillna("NO SCHOOL INFO", inplace=True)
    final['ADDRESS'].fillna("NO ADDRESS INFO", inplace=True)
    final['COUNTRY'].fillna("NO COUNTRY INFO", inplace=True)
    final['STATE'].fillna("NO STATE INFO", inplace=True)
    final['CITY'].fillna("NO CITY INFO", inplace=True)

    def country1(i):
        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con

    #ip=df['ip_address'].tolist()
    phone_number=final['CONTACT_NUMBER'].tolist()
    Parents_Name=final['USER_NAME'].tolist()
    Parents_Email=final['EMAIL_ID'].tolist()
    School_Name=final['NAME'].tolist()
    state=final['STATE'].tolist()
    country=final['COUNTRY'].tolist()
    city=final['CITY'].tolist()
    sign_up_date=final['CREATED_DATE'].tolist()
    last_prac_date=final['Last_Practice_Date'].tolist()
    #last_login_date=final['Last_Login_Date'].tolist()
    practice_count=final['Practice_Count'].tolist()
    #mindful_minutes=final['mindful_minutes'].tolist()

    state12 =  [each_string.lower() for each_string in state]
    cv={'pnn':Parents_Name,'pe':Parents_Email,'co':country,'pn':phone_number,'sn':School_Name,'ct':city,
                               'st':state12,'sp':sign_up_date,'lp':last_prac_date,'pc':practice_count}
    dftry = pd.DataFrame.from_dict(cv)
    dftry= dftry.drop("co", axis=1)
    return json.dumps({"data":dftry.values.tolist()})

@app.route('/paroverall')
def parents_table():

    reader = geolite2.reader()
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus("I#L@teST^m0NGO_2o20!")
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.audio_track_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    qr1=[{"$match":{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b"), 
        "IS_DISABLED":{"$ne":"Y"},
        "INCOMPLETE_SIGNUP":{"$ne":"Y"},
        "EMAIL_ID":{'$not':{'$regex':'test', '$options':'i'}},
        "EMAIL_ID":{"$ne": ""},
        "EMAIL_ID":{'$not':{'$regex':'1gen', '$options':'i'}},
        "USER_NAME":{'$not':{'$regex':'test', '$options':'i'}},
        "CREATED_DATE":{"$gt":myDatetime}}}, 
    {'$group':{'_id':'$_id','Parents_Id':{'$first':'$_id'},'name':{'$first':'$schoolId.NAME'},'city':{'$first':'$schoolId.CITY'},'state':{'$first':'$schoolId.STATE'},
    'country':{'$first':'$schoolId.COUNTRY'},
    'ip_address':{'$first':'$IP_ADDRESS'}, 'Parents_Name':{'$first':'$USER_NAME'}, 'Parents_Email':{'$first':'$EMAIL_ID'}, 
    'contact_number':{'$first':'$CONTACT_NUMBER'}, 'user_type':{'$first':'$USER_TYPE'}, 'Sign_Up_Date':{'$first':'$CREATED_DATE'}
    }}
    ]
    collection2= db.audio_track_master
    qr2= [
        {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}, 
    {'USER_ID.CREATED_DATE':{'$gt':myDatetime}}, 
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}}
    ]}},
    {"$match":
    {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}
    ]
    }}, 
    {'$group':{'_id':'$USER_ID._id', 
    'Practice_Count':{'$sum':1},'Last_Practice_Date':{'$max':'$MODIFIED_DATE'},'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}
    }} 
        ]
    collection3= db.login_logs
    qr3=[
        {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}, 
    {'USER_ID.CREATED_DATE':{'$gt':myDatetime}}, {'USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}, 
    {'USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}}
    ]}},
    {"$match":
    {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}},
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}
    ]
    }}, 
    {'$group':{'_id':'$USER_ID._id', 'Last_Login_Date':{'$max':'$LAST_LOGGED_IN'},
    }}     
        ]
    um= list(collection.aggregate(qr1))
    df_um= pd.DataFrame(um)
    atd= list(collection2.aggregate(qr2))
    df_atd= pd.DataFrame(atd)
    ll= list(collection3.aggregate(qr3))
    df_ll=pd.DataFrame(ll)
    join=pd.merge(df_um, df_atd, how='left', on='_id')
    df= pd.merge(join, df_ll, how='left', on='_id')
    df.mindful_minutes=df.mindful_minutes.fillna(0)
    df.mindful_minutes=df.mindful_minutes.astype('int64')
    df['Last_Practice_Date']=pd.to_datetime(df['Last_Practice_Date'])
    df['Last_Practice_Date'].fillna("NO PRACTICE", inplace=True)
    df['Last_Login_Date']=pd.to_datetime(df['Last_Login_Date'])
    df['Last_Login_Date'].fillna("NO LOGIN", inplace=True)
    df['Sign_Up_Date']=pd.to_datetime(df['Sign_Up_Date'])
    df['name'].fillna("NO SCHOOL INFO", inplace=True)
    df['city'].fillna("NO CITY INFO", inplace=True)
    df['state'].fillna("NO STATE INFO", inplace=True)
    df['country'].fillna("NO COUNTRY INFO", inplace=True)
    df['Parents_Email'].fillna("NO EMAIL INFO", inplace=True)
    df['Parents_Name'].fillna("NO USERNAME INFO", inplace=True)
    def country1(i):
        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=df['ip_address'].tolist()
    phone_number=df['contact_number'].tolist()
    Parents_Name=df['Parents_Name'].tolist()
    Parents_Email=df.Parents_Email.tolist()
    School_Name=df['name'].tolist()
    state=df['state'].tolist()
    country=df['country'].tolist()
    city=df['city'].tolist()
    sign_up_date=df['Sign_Up_Date'].tolist()
    last_prac_date=df['Last_Practice_Date'].tolist()
    last_login_date=df['Last_Login_Date'].tolist()
    practice_count=df['Practice_Count'].tolist()
    mindful_minutes=df['mindful_minutes'].tolist()
    for i in range(len(ip)):
        if country[i] is None:
            try:
                country[i]=country1(ip[i])
            except:
                pass
        elif country[i]=='null':
            try:
                country[i]=country1(ip[i])
            except:
                pass
        if city[i] is None:
            try:
                city[i]=city1(ip[i])
            except:
                pass
        elif city[i]=='null':
            try:
                city[i]=city1(ip[i])
            except:
                pass
        if state[i] is None:
            try:
                state[i]=state1(ip[i])
            except:
                pass
        elif state[i] =='NO state info':
            try:
                state[i]=state1(ip[i])
            except:
                pass    
        if country[i] is None:
            try:
                country[i]=pn_country(phone_number[i])
            except:
                pass
        if country[i] is None:
            country[i]=''
        if state[i] is None:
            state[i]=''
        if  last_prac_date[i] != 'NO PRACTICE' :
            last_prac_date[i]=(last_prac_date[i]- timedelta(hours=4)).strftime('%d %b %Y')
        else:
            last_prac_date[i]="NO PRACTICE"
        if  last_login_date[i] != 'NO LOGIN' :
            last_login_date[i]=(last_login_date[i]- timedelta(hours=4)).strftime('%d %b %Y')

        else:
            last_login_date[i]="NO LOGIN"
        if sign_up_date[i] is not None:

            sign_up_date[i]=(sign_up_date[i]- timedelta(hours=4)).strftime('%d %b %Y')
    #             print(sign_up_date[i])
    state12 =  [each_string.lower() for each_string in state]
    cv={'pnn':Parents_Name,'pe':Parents_Email,'co':country,'pn':phone_number,'sn':School_Name,'ct':city,
                            'st':state12,'sp':sign_up_date,
                            'll':last_login_date,'lp':last_prac_date,'pc':practice_count}
    dftry = pd.DataFrame.from_dict(cv).fillna(0)
    dftry= dftry.drop("co", axis=1)
    return json.dumps({"data":dftry.values.tolist()})



@app.route('/parcount')
def parcount__():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass

    collection = db.user_master
    collection2 = db.audio_track_detail_backup
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    df = DataFrame(list(collection.aggregate([
        {"$match":{'$and':[{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                  {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"CREATED_DATE":{"$gte":myDatetime}}]}}, 
                                              
        {'$group':{'_id':'$_id','Parents_Id':{'$first':'$_id'},'name':{'$first':'$schoolId.NAME'},
                   'city':{'$first':'$schoolId.CITY'},'state':{'$first':'$schoolId.STATE'},
        'country':{'$first':'$schoolId.COUNTRY'},
        'ip_address':{'$first':'$IP_ADDRESS'}, 'Parents_Name':{'$first':'$USER_NAME'},
                   'Parents_Email':{'$first':'$EMAIL_ID'}, 
        'contact_number':{'$first':'$CONTACT_NUMBER'}, 'user_type':{'$first':'$USER_TYPE'}, 
                   'Sign_Up_Date':{'$first':'$CREATED_DATE'}
        }}
        ])))
# ========================================= FROM --/presentios for IOS downloads =======================================
  
    total_parents = df.shape[0]
    total_downloads=round(total_parents*.95)
    downloadper=round((total_downloads/total_parents)*100)
#     ios=round(total_downloads*0.60)
    android=round(total_downloads*0.40)
    
    googleSheetId = '1UrhNlOkyAhboHYQwNQJHpEiJ-NfeCDX5MS3DPh8Na50'
    worksheetName = 'impressions'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    #product page views
    googleSheetId1 = '1UrhNlOkyAhboHYQwNQJHpEiJ-NfeCDX5MS3DPh8Na50'
    worksheetName1 = 'product_page_views'
    URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId1,
    worksheetName1
    )
    df1 = pd.read_csv(URL1)
    #conversion_rate
    googleSheetId2 = '1UrhNlOkyAhboHYQwNQJHpEiJ-NfeCDX5MS3DPh8Na50'
    worksheetName2 = 'conversion_rate'
    URL2 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId2,
    worksheetName2
    )
    df2 = pd.read_csv(URL2)
    dfs = [df, df1, df2]
    df_final = reduce(lambda left,right: pd.merge(left,right,on='Date'), dfs)
    df_final['Date'] = pd.to_datetime(df_final['Date'])
    newdf=df_final[(df_final.Date> '2020-03-16')]
    newdf['Date'] = newdf['Date'].astype(np.int64) / int(1e6)
    df3=newdf[['Date','Impressions']]

    df6=newdf[['Date','App Units']]
    #APP UNIT ---- INSTALL
    App_Units= df6.values.tolist()
    appunit=list(df6['App Units'])

    ios=str(sum(appunit))

    temp={"download":[str(total_downloads)],"downloadper":[str(downloadper)],"android":[str(android)],
          "ios":[str(ios)],'totalparents':[str(total_parents)]}
    return json.dumps(temp)

@app.route('/mitcount')
def mitcount():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass

    collection = db.user_master
    collection2 = db.audio_track_master

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)


    df = DataFrame(list(collection.aggregate([
       {"$match":{'$and':[{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                                                                 
                  {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  
            {"CREATED_DATE":{"$gte":myDatetime}}]}}, 
        {"$group":{"_id":{}, 'distinct':{"$addToSet":'$_id'}}},
        {"$project":{"_id":0, 'Total_parents':{'$size':'$distinct'}}}])))




    total_parents = df['Total_parents'][0]
    total_downloads=round(total_parents*.95)
    downloadper=round((total_downloads/total_parents)*100)
    ios=round(total_downloads*0.60)
    android=round(total_downloads*0.40)

    temp={"download":[str(total_downloads)],"downloadper":[str(downloadper)],"android":[str(android)],"ios":[str(ios)],'totalparents':[str(total_parents)]}
    return json.dumps(temp)

@app.route('/parsignups')
def parsignup():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus("I#L@teST^m0NGO_2o20!")
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
        
        
    df_sign = DataFrame(list(collection.aggregate([
           {"$match":{'$and':[{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                                                                 
                  {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  
            {"CREATED_DATE":{"$gte":myDatetime}}]}}, 
            {'$group':{'_id':'$_id',
                       'date':{'$first':'$CREATED_DATE'} }},
#             {"$project":{"_id":0, 'sign_up':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}},'practice_count':{'$size':'$distinct'}}},
#             { '$sort': { '_id': 1 }}
    ])))
    df_sign1 = df_sign.rename(columns={"date": "sign_up"})
#     df_prac1 = df_prac.sort_values(by = ['sign_up']).reset_index(drop = True)
    
    
#     final['practice_count'] = final['practice_count'].fillna(0)
    # print(df1)
    
    df_sign1['sign_upn'] = pd.to_datetime(df_sign1['sign_up']) - timedelta(hours=4)
    df2 = df_sign1.groupby([df_sign1['sign_upn'].dt.date]).count()
    cdate=[]
    for i in df2.index:
        x=i.strftime('%s')
        cdate.append(float(x)*1000)
    count=[]
    for i in df2['sign_up'] :
        count.append(i)
    df3 = pd.DataFrame(list(zip(cdate,count)), 
                       columns =['date', 'count']) 
    data = df3.values.tolist()
    return json.dumps(data)

# parsignup()    






@app.route('/mitsignupsnew')
def miitsignupnew():
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    
    collection = db.user_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    query=[
    {"$match":{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b"), 
        "IS_DISABLED":{"$ne":"Y"},
        "INCOMPLETE_SIGNUP":{"$ne":"Y"},
        "EMAIL_ID":{'$not':{'$regex':'test', '$options':'i'}},
        'USER_TYPE':{"$regex":'mit','$options':'i'}, 
        "EMAIL_ID":{"$ne": ""},
        "EMAIL_ID":{'$not':{'$regex':'1gen', '$options':'i'}},
        "USER_NAME":{'$not':{'$regex':'test', '$options':'i'}},
        "CREATED_DATE":{"$gt":myDatetime}}},
        {"$group":{"_id":"$_id","CREATED_DATE":{"$first": "$CREATED_DATE"}}},
    {"$project":{"_id":0,'sign_up':{"$dateToString":{"format": "%Y-%m-%d","date":'$CREATED_DATE'}}}}
    ]
    df1=pd.DataFrame(list(collection.aggregate(query)))
    df1['sign_upn'] = pd.to_datetime(df1['sign_up']) 
    df2 = df1.groupby([df1['sign_upn'].dt.date]).count()

    cdate=[]
    for i in df2.index:
        x=i.strftime('%S')
        cdate.append(float(x)*1000)
    count=[]
    for i in df2['sign_up'] :
        count.append(i)
    count1=np.cumsum(count)
    df3 = pd.DataFrame(list(zip(cdate,count)), 
                    columns =['date', 'count']) 
    df4 = pd.DataFrame(list(zip(cdate,count1)), 
                    columns =['date', 'count'])
    data = df3.values.tolist()
    data1 = df4.values.tolist()
    return json.dumps({"bar":data,"line":data1})

@app.route('/parsignupsnew')
def parentsanalytics_chart1():
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.user_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    query=[{"$match":{'$and':[{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                                                                 
                  {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  
            {"CREATED_DATE":{"$gte":myDatetime}}]}}, 
     {"$group":{"_id":{"$dateToString": {"format": "%Y-%m-%d","date":'$CREATED_DATE'}}, 'distinct':{"$addToSet":'$_id'}}},
     {"$project":{"_id":1, 'Total_parents':{'$size':'$distinct'}}},
     { '$sort': { '_id': 1 }}
    ]
    x=list(collection.aggregate(query))
    res = [] 
    for idx, sub in enumerate(x, start = 0): 
        if idx == 0: 
    #         res.append(list(sub.keys())) 
            res.append(list(sub.values())) 
        else: 
            res.append(list(sub.values())) 
    df = pd.DataFrame(res, columns = ['date', 'count'])
    df['date'] = pd.to_datetime(df['date'], errors = 'coerce')
    df['date'] = pd.to_datetime(df['date']) - timedelta(hours=4)
    df2 = df.groupby([df['date'].dt.date]).sum()
    cdate=[]
    for i in df2.index:
        x=i.strftime('%s')
        cdate.append(float(x)*1000)
    count=[]
    for i in df2['count'] :
        count.append(i)
    count1=np.cumsum(count)
    df3 = pd.DataFrame(list(zip(cdate,count)), 
                       columns =['date', 'count']) 
    df4 = pd.DataFrame(list(zip(cdate,count1)), 
                       columns =['date', 'count'])
    data = df3.values.tolist()
    data1 = df4.values.tolist()
    return json.dumps({"bar":data,"line":data1})




@app.route('/psignupu')
def psignu():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username,       password))
    db=client.compass
    collection = db.user_master
    df = DataFrame(list(collection.aggregate([{"$match":
                                           {"$and":[{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                                                     {"IS_DISABLED":{"$ne":"Y"}},
                                                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                                                    { "EMAIL_ID":{"$ne": None}},
                                                  {"USER_TYPE":{"$not":{"$regex" : 'NULL','$options':'i'}}},
                                                    {"USER_TYPE":{"$ne":None}},
                                                      { "CREATED_DATE":{"$gt": datetime.datetime(2020,3,17)}},
                                                    {"USER_TYPE":{"$not":{"$regex" : 'FAMILY IAMPRESENT'}}},
                                                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                                     {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},

                                                             {"USER_TYPE":{"$not":{"$regex" : 'LG'}}},
                                                             {"USER_TYPE":{"$not":{"$regex" : 'OTP BASED'}}},
                                                             {"USER_TYPE":{"$not":{"$regex" : 'Added BY CAP'}}},
                                                             {"EMAIL_ID":{"$not":{"$regex" : 'test','$options':'i'}}},
                                                             {"USER_NAME":{"$not":{"$regex" : 'test','$options':'i'}}},
                                                             {"EMAIL_ID":{"$not":{"$regex" : 'gen.io','$options':'i'}}}]
                                                  }},
                                              {"$group":{'_id':'$USER_TYPE', 'distinct':{'$addToSet':'$_id'}}},
                                              {"$project":{'_id':1, 'parents_count':{'$size':'$distinct'}}},{ "$sort":{'parents_count' : 1 }} ])))
    
    df.rename(columns = { '_id': 'USER_TYPE'}, inplace = True)
    parents_count=df['parents_count'].tolist()
    user_type=df['USER_TYPE'].tolist()
    # print(df)
    for i in range(len(user_type)):
        user_type[i] = user_type[i]
    data={'parents_count':parents_count,'user_type':user_type}
    return json.dumps(data)

@app.route('/psignupw')
def psignw():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus("I#L@teST^m0NGO_2o20!")
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.audio_track_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    df = DataFrame(list(collection.aggregate([
            {"$match":{'$and':[{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                                                                 
                  {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  
            {"CREATED_DATE":{"$gt":myDatetime}}]}}, 
                                              
            {'$group':{'_id':{'day':{'$dayOfMonth':'$CREATED_DATE'},
                              'month':{'$month':'$CREATED_DATE'}, 
                              'year':{'$year':'$CREATED_DATE'} },
                       'date':{'$first':'$CREATED_DATE'}, 'distinct':{"$addToSet":'$_id'}}},
            {"$project":{"_id":0, 'date':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}},'parents_count':{'$size':'$distinct'}}},
            { '$sort': { '_id': 1 }}])))
    df1 = df.sort_values(by = ['date']).reset_index(drop = True)
    df1 = df1.rename(columns={"date": "sign_up"})
    df_prac = DataFrame(list(collection2.aggregate([
            {"$match":{'$and':[{'USER_ID.ROLE_ID.ROLE_ID':{'$eq':3}}, 
                       {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                       {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                       {"USER_ID.EMAIL_ID":{"$not":{"$regex" : 'test','$options':'i'}}},
                       {"USER_ID.EMAIL_ID":{"$nin": ["",None]}},
                       {"USER_ID.EMAIL_ID":{"$not":{"$regex" : '1gen','$options':'i'}}},
                       {"USER_ID.USER_NAME":{"$not":{"$regex" : 'test','$options':'i'}}},
                       {'USER_ID.USER_NAME':{'$ne':{'$regex':'1gen','$options':'i'}}},
                       {"USER_ID.CREATED_DATE":{"$gt": myDatetime}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'},
                              'month':{'$month':'$MODIFIED_DATE'}, 
                              'year':{'$year':'$MODIFIED_DATE'} },
                       'date':{'$first':'$MODIFIED_DATE'}, 'distinct':{"$addToSet":'$_id'}}},
            {"$project":{"_id":0, 'sign_up':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}},'practice_count':{'$size':'$distinct'}}},
            { '$sort': { '_id': 1 }}])))
    df_prac1 = df_prac.sort_values(by = ['sign_up']).reset_index(drop = True)
    final = pd.merge(df1,df_prac1,on='sign_up',how='outer')
    final['practice_count'] = final['practice_count'].fillna(0)
    final['sign_up'] = pd.to_datetime(final['sign_up'], errors = 'coerce')
    parents_count=final['parents_count'].tolist()
    practice_count=final['practice_count'].tolist()
    sign_up=[]
    for i in final['sign_up']:
        sign_up.append(i.strftime("%d %b %Y "))
    data={'parents_count':parents_count,'practice_count':practice_count,'sign_up':sign_up}
    return json.dumps(data)

@app.route('/psignups')
def psigns():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus("I#L@teST^m0NGO_2o20!")
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.audio_track_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    df = DataFrame(list(collection.aggregate([
           {"$match":{'$and':[{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                                                                 
                  {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  
            {"CREATED_DATE":{"$gt":myDatetime}}]}}, 
                                              
            {'$group':{'_id':{'day':{'$dayOfMonth':'$CREATED_DATE'},
                              'month':{'$month':'$CREATED_DATE'}, 
                              'year':{'$year':'$CREATED_DATE'} },
                       'date':{'$first':'$CREATED_DATE'}, 'distinct':{"$addToSet":'$_id'}}},
            {"$project":{"_id":0, 'date':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}},'parents_count':{'$size':'$distinct'}}},
            { '$sort': { '_id': 1 }}])))
    df1 = df.sort_values(by = ['date']).reset_index(drop = True)
    df1 = df1.rename(columns={"date": "sign_up"})
    df_prac = DataFrame(list(collection2.aggregate([
          {"$match":{'$and':[{'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                                                                 
                  {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  
            {"USER_ID.CREATED_DATE":{"$gt":myDatetime}}]}}, 
                                              
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'},
                              'month':{'$month':'$MODIFIED_DATE'}, 
                              'year':{'$year':'$MODIFIED_DATE'} },
                       'date':{'$first':'$MODIFIED_DATE'}, 'distinct':{"$addToSet":'$_id'}}},
            {"$project":{"_id":0, 'sign_up':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}},'practice_count':{'$size':'$distinct'}}},
            { '$sort': { '_id': 1 }}])))
    df_prac1 = df_prac.sort_values(by = ['sign_up']).reset_index(drop = True)
    final = pd.merge(df1,df_prac1,on='sign_up',how='outer')
    final['practice_count'] = final['practice_count'].fillna(0)
    final['sign_up'] = pd.to_datetime(final['sign_up'], errors = 'coerce')
    parents_count=final['parents_count'].tolist()
    practice_count=final['practice_count'].tolist()
    sign_up=[]
    for i in final['sign_up']:
        sign_up.append(i.strftime("%d %b %Y "))
    data={'parents_count':parents_count,'practice_count':practice_count,'sign_up':sign_up}
    return json.dumps(data)



@app.route('/psignup')
def psign():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus("I#L@teST^m0NGO_2o20!")
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.audio_track_master
    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    df = DataFrame(list(collection.aggregate([
           {"$match":{'$and':[{'ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                                                                 
                  {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  
            {"CREATED_DATE":{"$gt":myDatetime}}]}}, 
                                              
            {'$group':{'_id':{'day':{'$dayOfMonth':'$CREATED_DATE'},
                              'month':{'$month':'$CREATED_DATE'}, 
                              'year':{'$year':'$CREATED_DATE'} },
                       'date':{'$first':'$CREATED_DATE'}, 'distinct':{"$addToSet":'$_id'}}},
            {"$project":{"_id":0, 'date':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}},'parents_count':{'$size':'$distinct'}}},
            { '$sort': { '_id': 1 }}])))
    df1 = df.sort_values(by = ['date']).reset_index(drop = True)
    df1 = df1.rename(columns={"date": "sign_up"})
    df_prac = DataFrame(list(collection2.aggregate([
            {"$match":{'$and':[{'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
                                                                 
                  {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

    # //               {'IS_ADMIN':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  
            {"USER_ID.CREATED_DATE":{"$gt":myDatetime}}]}}, 
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'},
                              'month':{'$month':'$MODIFIED_DATE'}, 
                              'year':{'$year':'$MODIFIED_DATE'} },
                       'date':{'$first':'$MODIFIED_DATE'}, 'distinct':{"$addToSet":'$_id'}}},
            {"$project":{"_id":0, 'sign_up':{'$dateToString':{'format':"%Y-%m-%d","date":'$date'}},'practice_count':{'$size':'$distinct'}}},
            { '$sort': { '_id': 1 }}])))
    df_prac1 = df_prac.sort_values(by = ['sign_up']).reset_index(drop = True)
    final = pd.merge(df1,df_prac1,on='sign_up',how='outer')
    final['practice_count'] = final['practice_count'].fillna(0)
    final['sign_up'] = pd.to_datetime(final['sign_up'], errors = 'coerce')
    parents_count=final['parents_count'].tolist()
    practice_count=final['practice_count'].tolist()
    sign_up=[]
    for i in final['sign_up']:
        sign_up.append(i.strftime("%d %b %Y "))
    data={'parents_count':parents_count,'practice_count':practice_count,'sign_up':sign_up}
    return json.dumps(data)

@app.route('/feedbackrating_csy')
def schoolrating_csy():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback
    df1=DataFrame(list(db.user_master.aggregate([
        {"$match":
         {
            '$and':[
    # // #             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'EMAIL_ID':{'$ne':''}},
#                 {'schoolId._id':{'$in':school}},
                
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]

         }},
        {'$project':{'_id':'$_id','school':'$schoolId._id' }}
        ])))

    user=df1['_id'].tolist() 

    
    df = DataFrame(list(collection.aggregate([
     {"$match":{'$and':[
         
           {'USER._id':{'$in':user}},
      
        {'RATING':{'$ne':0}},
        {'MODIFIED_DATE':{'$gte':csy_first_date()}}]}},
        
    {'$group':{'_id':'$RATING' ,'count':{'$sum':1}}},
           {'$sort':{'_id':-1}}
        
    ])))
    rating=df['_id'].tolist()
    count=df['count'].tolist()

    temp={'rating':rating,'count':count}
    return json.dumps(temp)


@app.route('/sentimentdonut_csy')
def sentiment_pie():
    clean_list=[]
    news_headlines_senti = []
    news_headlines_dict = {}
    pnews_headlines=0
    nnews_headlines=0
    nenews_headlines = 0
    # date1=startdate
    # date2=enddate
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    # myDatetimestrt = dateutil.parser.parse(date1)
    # myDatetimeend = dateutil.parser.parse(date2)
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback
#     district=disdic[districtid]
#     myDatetime1 = dateutil.parser.parse(startdate)
#     myDatetime2 = dateutil.parser.parse(enddate)

    df1=DataFrame(list(db.user_master.aggregate([
        {"$match":
         {
            '$and':[
#                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'EMAIL_ID':{'$ne':''}},
#                 {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}
            ]

         }},
        {'$project':{'_id':'$_id','school':'$schoolId._id' }}
        ])))

    userid=df1['_id'].tolist() 
    x=['NA','N/A','n.a','.\n',"a\\n","a\n","v\n","v\\n","0-",'na\n','na','Write a feedback (optional)','Na','k,n/l','[pppppppppppsz']
    user=[
    {"$match":{'$and':[ {'USER._id':{'$in':userid}},
                    {'COMMENT':{'$exists':1}},
                       {'COMMENT':{'$ne':''}},
                       {'COMMENT':{'$ne':None}},
                        {'COMMENT':{'$nin':x}},
                       
                       
                       
    #         {'RATING':{'$ne':0}},
         {'MODIFIED_DATE':{"$gte":csy_first_date()}}
                         ,
                        ]}},
    { "$project": { "USER_ID": "$USER._id", "USER_NAME": "$USER.USER_NAME","_id":0, "EMAIL": "$USER.EMAIL_ID", "RATING":1,
    "LAST_COMMENT_DATE": "$MODIFIED_DATE", "AUDIO_NAME": "$AUDIO_ID.AUDIO_NAME", "NARRATOR_NAME": "$AUDIO_ID.NARRATEDBY",
    "COMMENT":1, "PROGRAM_NAME": "$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME"}}
    ]
    update=list(collection.aggregate(user))
    df=pd.DataFrame(update).fillna("no info")
    text=df["COMMENT"].to_list()
    df=df[['COMMENT']]
    df = df.sample(frac=1.0).reset_index(drop=True)
    for i in df['COMMENT'].tolist():
        df = df[df.COMMENT.str.len()!=1] 
    
    import nltk
    nltk.download('vader_lexicon')

    from nltk.sentiment.vader import SentimentIntensityAnalyzer
    sia = SentimentIntensityAnalyzer()
    df['Positivity'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['pos'])
    df['Negativity'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['neg'])
    df['Neutrality'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['neu'])
    df['Compound'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['compound'])
    pd.pandas.set_option('display.max_rows',None)  
    neg=df[df['Compound']<0]
    pos=df[df['Compound']>0]
    neu=df[df['Compound']==0]
    neg_sentiment=round(100*(len(neg)/(len(neu)+len(neg)+len(pos))),2)
    pos_sentiment=round(100*(len(pos)/(len(neu)+len(neg)+len(pos))),2)
    neu_sentiment=round(100*(len(neu)/(len(neu)+len(neg)+len(pos))),2)
    word_chart={'donut':{'pos':pos_sentiment,'neg':neg_sentiment,'neu':neu_sentiment}}

#     print(df)
    
#     word_chart={"donut":{"pos":round(pos, 2),"neg":round(neg, 2)}}
    return json.dumps(word_chart)
#     return df
# dis_sentiment_pie('5ffd8176469a86e28635f512','2021-08-01','2021-12-17')




# @app.route('/sentimentdonut_csy')
# def sentiment_pie():
#     clean_list=[]
#     news_headlines_senti = []
#     news_headlines_dict = {}
#     pnews_headlines=0
#     nnews_headlines=0
#     nenews_headlines = 0
#     # date1=startdate
#     # date2=enddate
#     today = date.today()
#     d1 = today.strftime("%Y-%m-%d")
#     # myDatetimestrt = dateutil.parser.parse(date1)
#     # myDatetimeend = dateutil.parser.parse(date2)
#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
#     db=client.compass
#     collection = db.audio_feedback
#     df1=DataFrame(list(db.user_master.aggregate([
#         {"$match":
#          {
#             '$and':[
#     # // #             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#              {"IS_DISABLED":{"$ne":"Y"}},
#               {"IS_BLOCKED":{"$ne":"Y"}},
#              {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#                 {'EMAIL_ID':{'$ne':''}},
# #                 {'schoolId._id':{'$in':school}},
                
#                  {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#              { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#          { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                            {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                              {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]

#          }},
#         {'$project':{'_id':'$_id','school':'$schoolId._id' }}
#         ])))

#     userid=df1['_id'].tolist() 

#     user=[
#     {"$match":{'$and':[ {'USER._id':{'$in':userid}},
      
# #         {'RATING':{'$ne':0}},
#         {'MODIFIED_DATE':{'$gte':csy_first_date()}}
#                         ]}},
#     { "$project": { "USER_ID": "$USER._id", "USER_NAME": "$USER.USER_NAME","_id":0, "EMAIL": "$USER.EMAIL_ID", "RATING":1,
#     "LAST_COMMENT_DATE": "$MODIFIED_DATE", "AUDIO_NAME": "$AUDIO_ID.AUDIO_NAME", "NARRATOR_NAME": "$AUDIO_ID.NARRATEDBY",
#     "COMMENT":1, "PROGRAM_NAME": "$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME"}}
#     ]
#     update=list(collection.aggregate(user))
#     df=pd.DataFrame(update).fillna("no info")
#     list_of_names=df["USER_ID"].to_list()
#     df

#     # def Average(lst):
#     #     return sum(lst) / len(lst)

#     # # Driver Code
#     # lst =df123["RATING"].to_list()
#     # average = Average(lst)
#     # average

#     #     print(df123["COMMENT"],"lola")
#     xx=df[df["COMMENT"]!="no info"]
#     xxc=xx[xx["COMMENT"]!=""]

#     comment_list=xxc["COMMENT"].to_list()
#     comment_list
#     newtexttoken=[]
#     for i in comment_list:
#         text_tokens = word_tokenize(i)
#         newtexttoken.append(text_tokens)
#     newlist=[]
#     for i in newtexttoken:
#         for z in i:
#             newlist.append(z.lower())
#     st_word=stopwords.words('english')
#     tokens_without_sw= [word for word in newlist if not word in st_word]
#     token5=[]
#     for sentence in tokens_without_sw:
#     #     print(sentence)
#         text3 = sentence.split('ing')
#     #     print(text3,"text3")
#         for i in text3:
#     #         print(i)
#             token5.append(i)
#     words = [w.replace('liked', 'like') for w in token5]
#     words2 = [w.replace('relaxed', 'relax') for w in words]
#     words3 = [w.replace('relaxing', 'relax') for w in words2]
#     words4 = [w.replace('excitinging', 'excited') for w in words3]
#     #     print(words4)
#     zxc=""
#     name=""
#     count=""
#     try:
#         xcvv=[x for x in words4 if len(x)>3]
#         fdist=FreqDist(xcvv)
#         df_fdist = pd.DataFrame.from_dict(fdist, orient='index')
#     #         print(df_fdist)
#         df_fdist.columns = ['Frequency']
#         df_fdist.index.name = 'Term'
#         xc=df_fdist.sort_values(by='Frequency', ascending=False, na_position='first')
#         #     tt=xc.drop(["i","it","we","made","us","the","feeling","some","students"])
#         cc=xc[0:10]
#         name=cc.index.to_list()
#         count=cc["Frequency"].to_list()
#         zxc=' '.join(word for word in xcvv)
#     except:
#         pass
#     for item in comment_list:
#         # trim
#         item = item.strip()
#         # Removing RT
#         item = item.replace('RT', '')
#         # Removing new line character
#         item = item.replace('\\n', '')
#         # Replace #word with word
#         news_headlines = re.sub(r'#([^\s]+)', r'\1', item)
#         # Convert @username to username
#         news_headlines = re.sub(r'@([^\s]+)', r'\1', item)
#         item = " ".join(re.findall("[a-zA-Z]+", item))
#         tmp_var = re.sub(r'^\S*\s', '', item)
#         clean_list.append(tmp_var)
#     for item in clean_list:
#             #print(item)
#             # create TextBlob object of passed news_headlines text
#             analysis = TextBlob(item)
#             # set sentiment
#             if analysis.sentiment.polarity > 0:
#                 # saving sentiment of news_headlines
#                 news_headlines_score = 'positive'
#                 pnews_headlines = pnews_headlines + 1
#                 news_headlines_dict[item] = news_headlines_score
#             elif analysis.sentiment.polarity == 0:
#                 # saving sentiment of news_headlines
#                 news_headlines_score = 'neutral'
#                 nenews_headlines = nenews_headlines + 1
#                 news_headlines_dict[item] = news_headlines_score
#             else:
#                 # saving sentiment of news_headlines
#                 news_headlines_score = 'negative'
#                 nnews_headlines = nnews_headlines + 1
#                 news_headlines_dict[item] = news_headlines_score
#     # print(clean_list)
#     newssentiment=[]
#     # for k, v in news_headlines_dict.items():
#     #     print(k,':',v)
#     for k, v in news_headlines_dict.items():

#         if v == "positive":
#             newssentiment.append({"sentiment":int(1),"text":k})
#         elif v == "negative":
#             newssentiment.append({"sentiment":int(-1),"text":k})
#         else:
#             newssentiment.append({"sentiment":int(0),"text":k})

#     #print(newssentiment)
#     newssentiment_dataframe=pd.DataFrame.from_dict(newssentiment)
#     # newssentiment_dataframe.to_csv("news_headlines_sentiment.csv", encoding='utf-8', index=False)
#     neg = 100 * (nnews_headlines) / ((nnews_headlines) + (pnews_headlines))
#     pos = 100 * (pnews_headlines) / ((nnews_headlines) + (pnews_headlines))

#     word_chart={"donut":{"pos":round(pos, 2),"neg":round(neg, 2)}}
    
#     return json.dumps(word_chart)



@app.route('/topdistrictplayback')
def topdistrict_playback():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass

    from datetime import datetime


    DF1=DataFrame(list(db.school_master.aggregate([
        {"$match":
         {
            '$and':[
            {'CATEGORY' :{'$exists':True}},
               {'CATEGORY' :{'$ne':"Null"}},  
                  {'CATEGORY' :{'$ne':None}}, 
             ]

         }},
    #     {'$group':{'_id':'$DISTRICT_ID.DISTRICT_NAME','pc':{'$sum':1},'uc':{'$addToSet':'$_id'}}},
        {'$project':{'school':'$_id','_id':0,'CATEGORY':'$CATEGORY'}}

        ])))
    school=DF1['school'].tolist()




    DF2=DataFrame(list(db.user_master.aggregate([
        {"$match":
         {
            '$and':[
    # // #             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'EMAIL_ID':{'$ne':''}},
                {'schoolId._id':{'$in':school}},
                 {'schoolId._id':{'$in':db.school_master.distinct('_id', {'CATEGORY':{'$ne':"Null"}})}},

    #              {'EMAIL_ID':{'$nin':['north5special@gmail.com','north4prek@gmail.com',
    #                                         'north1high@gmail.com',
    #                                         'north3ele@gmail.com',
    #                                         'north4prek@gmail.com',
    #                                         'north2middle@gmail.com']}},

                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]

         }},
        {'$project':{'_id':'$_id','school':'$schoolId._id' }}
        ])))

    user=DF2['_id'].tolist() 
    df=pd.merge(DF1,DF2, on='school', how='right')
    DF3=DataFrame(list(db.audio_track_master.aggregate(
    [{"$match":{"$and":[
    # // #              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},

                    {'USER_ID._id':{'$in':user}},
          {"MODIFIED_DATE":{"$gte": csy_first_date()}}

                ]
         }},


                    {'$group':{'_id':'$USER_ID._id','complete practice':{'$sum':1}}}


         ])))
    df2=pd.merge(df,DF3, on='_id', how='left').fillna(0)

    dff=df2.groupby(['CATEGORY']).sum()
    dff=dff.drop('NULL').reset_index()
    dfff=dff.sort_values('complete practice',ascending=False)
    dfff=dfff.head(20)

    District=dfff['CATEGORY'].tolist()
    Playbacks=dfff['complete practice'].tolist()

    data={'District':District,'Playbacks':Playbacks}
    return json.dumps(data)


@app.route('/averagetrend/')
def average_trend_new_():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    from datetime import datetime

    df0 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[

     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": LSYTOLSY_Date(),
                                        "$lt":LSY_Date()}}]}},
       {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
    'TOTAL_USERS_PRACTICING':{'$sum':1},
    'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID._id'}
     }}, 
     {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}}, 
     {'$sort':{'_id':1}},
    { "$project": { "TOTAL_LSYTOLSY": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
    ])))
    df0.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df0['Month'] = df0['Month'].map(d) 


    df1 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[

     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": LSY_Date(),
                                        "$lt":csy_first_date()}}]}},
       {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
    'TOTAL_USERS_PRACTICING':{'$sum':1},
    'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID._id'}
     }}, 
     {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}}, 
     {'$sort':{'_id':1}},
    { "$project": { "TOTAL_LSY": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
    ])))
    df1.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df1['Month'] = df1['Month'].map(d)
    print('LSY:', LSY_Date)
    print('CSY',csy_first_date())
    # print(df1)
    df2 = DataFrame(list(collection.aggregate([
        {"$match":{
     '$and':[
#          {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#              {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#              {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
              { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},  
#                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {"MODIFIED_DATE":{"$gte": csy_first_date(),
#                                         "$lt":datetime.datetime(2021,8,1)
                         }}]}},
       {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
    'TOTAL_USERS_PRACTICING':{'$sum':1},
    'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID._id'}
     }}, 
     {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}}, 
     {'$sort':{'_id':1}},
    { "$project": { "teacher_CSY": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
    ])))
    if df2.empty == True:
        df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'teacher_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
    else:
        df2
    df2.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df2['Month'] = df2['Month'].map(d)
    # df2
#     practice_left= pd.merge(df1, df2,on='Month', how='outer')
#     practice_left=practice_left.fillna(0)
    #print(practice_left)


    
    # df2
    practice_LSY_lsy= pd.merge(df1, df0,on='Month', how='left')
    practice_CSY= pd.merge(practice_LSY_lsy, df2,on='Month', how='left')
#     practice_CSY =pd.merge(practice_LSY, dfschoology, on='Month', how='left')
#     practice_CSY =pd.merge(practice_CSY, dfclever, on='Month', how='left')
#     practice_CSY =pd.merge(practice_CSY, df4, on='Month', how='left').fillna(0)

    mon=pd.DataFrame({'Month':[8,9,10,11,12,1,2,3,4,5,6,7]})
    d = dict(enumerate(calendar.month_abbr))
    mon['Month'] = mon['Month'].map(d)

    data=pd.merge(mon,practice_CSY,on='Month',how='left').fillna(0)
    Month=data['Month'].tolist()
    TOTAL_LSY=data['TOTAL_LSY'].tolist()
    TOTAL_LSYTOLSY=data['TOTAL_LSYTOLSY'].tolist()
    teacher_CSY=data['teacher_CSY'].tolist()
   
    temp=[{'Month':Month,'curve':TOTAL_LSY,'curve_LYTOLY':TOTAL_LSYTOLSY,'bar':teacher_CSY}]

    return json.dumps(temp)



# @app.route('/averagetrend/')
# def average_trend_new_():

#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
#     db=client.compass
#     collection = db.audio_track_master
#     from datetime import datetime

#     df0 = DataFrame(list(collection.aggregate([
#         {"$match":{
#      '$and':[

#      {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#       {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#      {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
#      { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#         {"MODIFIED_DATE":{"$gte": LSYTOLSY_Date(),
#                                         "$lt":LSY_Date()}}]}},
#        {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
#     'TOTAL_USERS_PRACTICING':{'$sum':1},
#     'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID._id'}
#      }}, 
#      {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}}, 
#      {'$sort':{'_id':1}},
#     { "$project": { "TOTAL_LSYTOLSY": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
#     ])))
#     df0.rename(columns = { '_id': 'Month'}, inplace = True)
#     d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
#     df0['Month'] = df0['Month'].map(d) 


#     df1 = DataFrame(list(collection.aggregate([
#         {"$match":{
#      '$and':[

#      {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#       {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#      {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
#      { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#         {"MODIFIED_DATE":{"$gte": LSY_Date(),
#                                         "$lt":csy_first_date()}}]}},
#        {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
#     'TOTAL_USERS_PRACTICING':{'$sum':1},
#     'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID._id'}
#      }}, 
#      {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}}, 
#      {'$sort':{'_id':1}},
#     { "$project": { "TOTAL_LSY": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
#     ])))
#     df1.rename(columns = { '_id': 'Month'}, inplace = True)
#     d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
#     df1['Month'] = df1['Month'].map(d)
#     print('LSY:', LSY_Date)
#     print('CSY',csy_first_date())
#     # print(df1)
#     df2 = DataFrame(list(collection.aggregate([
#         {"$match":{
#      '$and':[
#          {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#              {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#              {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
#      {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#       {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#      {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
#      { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#               { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#           {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#         {'USER_ID.EMAIL_ID':{'$ne':''}},  
# #                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#          {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#         {"MODIFIED_DATE":{"$gte": csy_first_date(),
# #                                         "$lt":datetime.datetime(2021,8,1)
#                          }}]}},
#        {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
#     'TOTAL_USERS_PRACTICING':{'$sum':1},
#     'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID._id'}
#      }}, 
#      {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}}, 
#      {'$sort':{'_id':1}},
#     { "$project": { "teacher_CSY": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
#     ])))
#     if df2.empty == True:
#         df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'teacher_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
#     else:
#         df2
#     df2.rename(columns = { '_id': 'Month'}, inplace = True)
#     d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
#     df2['Month'] = df2['Month'].map(d)
#     # df2
# #     practice_left= pd.merge(df1, df2,on='Month', how='outer')
# #     practice_left=practice_left.fillna(0)
#     #print(practice_left)


#     dfschoology = DataFrame(list(collection.aggregate([
#         {"$match":{
#      '$and':[
# #              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
#             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
#      {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#       {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#      {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
#      { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#               { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#           {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#         {'USER_ID.EMAIL_ID':{'$ne':''}},  
# #                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#          {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#         {"MODIFIED_DATE":{"$gte": csy_first_date(),
# #                                         "$lt":datetime.datetime(2021,8,1)
#                          }}]}},
#        {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
#     'TOTAL_USERS_PRACTICING':{'$sum':1},
#     'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID._id'}
#      }}, 
#      {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}}, 
#      {'$sort':{'_id':1}},
#     { "$project": { "schoology_CSY": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
#     ])))
#     if dfschoology.empty == True:
#         dfschoology=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'schoology_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
#     else:
#         dfschoology
#     dfschoology.rename(columns = { '_id': 'Month'}, inplace = True)
#     d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
#     dfschoology['Month'] = dfschoology['Month'].map(d)
#     dfschoology=dfschoology.fillna(0)


#     dfclever = DataFrame(list(collection.aggregate([
#         {"$match":{
#      '$and':[
# #              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#             {"USER_ID._id":{"$in":db.clever_master.distinct("USER_ID._id")}},
#      {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#       {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#      {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
#      { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#               { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#           {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#         {'USER_ID.EMAIL_ID':{'$ne':''}},  
# #                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#          {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                      {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#         {"MODIFIED_DATE":{"$gte": csy_first_date(),
# #                                         "$lt":datetime.datetime(2021,8,1)
#                          }}]}},
#       {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
#     'TOTAL_USERS_PRACTICING':{'$sum':1},
#     'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID._id'}
#      }}, 
#      {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}}, 
#      {'$sort':{'_id':1}},
#     { "$project": { "clever_CSY": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
#     ])))
#     if dfclever.empty == True:
#         dfclever=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'clever_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
#     else:
#         dfclever
#     dfclever.rename(columns = { '_id': 'Month'}, inplace = True)
#     d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
#     dfclever['Month'] = dfclever['Month'].map(d)
#     dfclever=dfclever.fillna(0)

#     df4 = DataFrame(list(collection.aggregate([
#         {"$match":{
#      '$and':[{'USER_ID.ROLE_ID._id':ObjectId("5f155b8a3b6800007900da2b")},
#              {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
#            {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
#              { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                          {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#               { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#           {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#         {'USER_ID.EMAIL_ID':{'$ne':''}},  
#              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#          {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#               {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#               {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
#               {"USER_ID.CREATED_DATE":{"$gte": datetime(2020,3,17)}},
#         {"MODIFIED_DATE":{"$gte": csy_first_date(),
# #                                         "$lt":datetime.datetime(2021,8,1)
#                          }}]}},
#       {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
#     'TOTAL_USERS_PRACTICING':{'$sum':1},
#     'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID._id'}
#      }}, 
#      {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}}, 
#      {'$sort':{'_id':1}},
#     { "$project": { "parents_CSY": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
#     ])))
#     if df4.empty == True:
#         df4=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents_CSY':[0,0,0,0,0,0,0,0,0,0,0,0]})
#     else:
#         df4
#     df4.rename(columns = { '_id': 'Month'}, inplace = True)
#     d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
#     df4['Month'] = df4['Month'].map(d)
#     # df2
#     practice_LSY_lsy= pd.merge(df1, df0,on='Month', how='left')
#     practice_LSY= pd.merge(practice_LSY_lsy, df2,on='Month', how='left')
#     practice_CSY =pd.merge(practice_LSY, dfschoology, on='Month', how='left')
#     practice_CSY =pd.merge(practice_CSY, dfclever, on='Month', how='left')
#     practice_CSY =pd.merge(practice_CSY, df4, on='Month', how='left').fillna(0)

#     mon=pd.DataFrame({'Month':[8,9,10,11,12,1,2,3,4,5,6,7]})
#     d = dict(enumerate(calendar.month_abbr))
#     mon['Month'] = mon['Month'].map(d)

#     data=pd.merge(mon,practice_CSY,on='Month',how='left')
#     Month=data['Month'].tolist()
#     TOTAL_LSY=data['TOTAL_LSY'].tolist()
#     TOTAL_LSYTOLSY=data['TOTAL_LSYTOLSY'].tolist()
#     teacher_CSY=data['teacher_CSY'].tolist()
#     parents_CSY=data['parents_CSY'].tolist()
#     schoology_CSY=data['schoology_CSY'].tolist()
#     clever_CSY=data['clever_CSY'].tolist()
#     temp=[{'Month':Month,'curve':TOTAL_LSY,'curve_LYTOLY':TOTAL_LSYTOLSY,'bar':teacher_CSY},{'bar2':parents_CSY},{'bars':schoology_CSY},{'barc': clever_CSY}]

#     return json.dumps(temp)

# <<<<<<<<<<<<<<<<<<<<<<<< Practice Bifurcation API >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

@app.route('/averagetrendnew/<charttype>')
def average___trend_____(charttype):
   
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
   
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
   
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        df1 = DataFrame(list(collection.aggregate([
            {'$match':{
        'USER_ID.IS_DISABLED':{'$ne':'Y'},
         'USER_ID.IS_BLOCKED':{"$ne":'Y'},
         'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'},
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],

    #      "MODIFIED_DATE":{"$gt": datetime.datetime(2019,8,1),"$lt":datetime.datetime(2020,8,1)}
        'MODIFIED_DATE':{'$gt':LSY_Date,'$lt': csy_first_date()}
            }},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
        {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
        'TOTAL_USERS_PRACTICING':{'$sum':1},
        'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID._id'}
         }},
         {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}},
        
        {"$match":
            {
                'UNIQUE_USERS_PRACTICING':{'$gt':0}
            }
        },
        {'$sort':{'_id':1}},
        { "$project": { "Practice_count in 2019-2020": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
        ])))
        df1.rename(columns = { '_id': 'Month'}, inplace = True)  
        d = dict(enumerate(calendar.month_name))    # to convert monthnumber of dataframe into monthname
        Month=[8,9,10,11,12,1,2,3,4,5,6,7]
        if df1.empty:
            df1=pd.DataFrame(index=[0,1,2,3,4,5,6,7,8,9,10,11], columns=['Month','Practice_count in 2019-2020'])
            df1["Month"] = Month
            df1.fillna(0,inplace=True)        
        df1['Month'] = df1['Month'].map(d)
        # print(df1)

        df2 = DataFrame(list(collection.aggregate([
        {'$match':{
        'USER_ID.IS_DISABLED':{'$ne':'Y'},
         'USER_ID.IS_BLOCKED':{"$ne":'Y'},
         'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'},
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],
    #      "MODIFIED_DATE":{"$gt": datetime.datetime(2020,8,1),"$lt":datetime.datetime(2021,8,1)}
            'MODIFIED_DATE':{'$gt':csy_first_date()}
        }},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
        {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
        'TOTAL_USERS_PRACTICING':{'$sum':1},
        'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID._id'}
         }},
         {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}},
         {"$match":
            {
                'UNIQUE_USERS_PRACTICING':{'$gt':0}
            }
        },
        {'$sort':{'_id':1}},
        { "$project": { "Practice_count in 2020-2021": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
        ])))
        df2.rename(columns = { '_id': 'Month'}, inplace = True)  
        d = dict(enumerate(calendar.month_name))    # to convert monthnumber of dataframe into monthname
        Month=[8,9,10,11,12,1,2,3,4,5,6,7]
        if df2.empty:
            df2=pd.DataFrame(index=[0,1,2,3,4,5,6,7,8,9,10,11], columns=['Month','Practice_count in 2020-2021'])
            df2["Month"] = Month
            df2.fillna(0,inplace=True)        
        df2['Month'] = df2['Month'].map(d)
        # print(df2)

        practice_left= pd.merge(df1, df2,on='Month', how='outer')

        practice_left=practice_left.fillna(0)
        practice_left

        month=["AUG","SEP","OCT","NOV","DEC","JAN","FEB","MAR","APR","MAY","JUN","JUL"]
        curve=[practice_left[practice_left['Month']=='August']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='September']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='October']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='November']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='December']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='January']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='February']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='March']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='April']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='May']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='June']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='July']['Practice_count in 2019-2020'].item()]
        bar=[practice_left[practice_left['Month']=='August']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='September']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='October']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='November']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='December']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='January']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='February']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='March']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='April']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='May']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='June']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='July']['Practice_count in 2020-2021'].item()]
        averageTREND={'month':month,'curve':curve,'bar':bar}
        averageTREND=[averageTREND]
        return json.dumps(averageTREND)
   
    else:
        df1 = DataFrame(list(collection.aggregate([
            {'$match':{
        'USER_ID.IS_DISABLED':{'$ne':'Y'},
         'USER_ID.IS_BLOCKED':{"$ne":'Y'},
         'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'},
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],

    #      "MODIFIED_DATE":{"$gt": datetime.datetime(2019,8,1),"$lt":datetime.datetime(2020,8,1)}
        'MODIFIED_DATE':{'$gt':LSY_Date,'$lt': csy_first_date()}


        }},
        {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
        'TOTAL_USERS_PRACTICING':{'$sum':1},
        'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID.USER_ID'}
         }},
         {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}},
         {'$sort':{'_id':1}},
        { "$project": { "Practice_count in 2019-2020": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
        ])))
        df1.rename(columns = { '_id': 'Month'}, inplace = True)  
        d = dict(enumerate(calendar.month_name))    # to convert monthnumber of dataframe into monthname
        df1['Month'] = df1['Month'].map(d)
        # print(df1)

        df2 = DataFrame(list(collection.aggregate([
        {'$match':{
        'USER_ID.IS_DISABLED':{'$ne':'Y'},
         'USER_ID.IS_BLOCKED':{"$ne":'Y'},
         'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'},
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}],
    #      "MODIFIED_DATE":{"$gt": datetime.datetime(2020,8,1),"$lt":datetime.datetime(2021,8,1)}
            'MODIFIED_DATE':{'$gt':csy_first_date()}
        }},
        {'$group':{'_id':{'$month':"$MODIFIED_DATE"},
        'TOTAL_USERS_PRACTICING':{'$sum':1},
        'UNIQUE_USERS_PRACTICING':{'$addToSet':'$USER_ID.USER_ID'}
         }},
         {'$project':{'_id':1, 'TOTAL_USERS_PRACTICING':'$TOTAL_USERS_PRACTICING', 'UNIQUE_USERS_PRACTICING':{'$size':'$UNIQUE_USERS_PRACTICING'}}},
         {'$sort':{'_id':1}},
        { "$project": { "Practice_count in 2020-2021": {"$round":[{ "$divide": ["$TOTAL_USERS_PRACTICING", "$UNIQUE_USERS_PRACTICING"] },2 ]} } }
        ])))
        df2.rename(columns = { '_id': 'Month'}, inplace = True)  
        d = dict(enumerate(calendar.month_name))    # to convert monthnumber of dataframe into monthname
        df2['Month'] = df2['Month'].map(d)
        # print(df2)

        practice_left= pd.merge(df1, df2,on='Month', how='outer')

        practice_left=practice_left.fillna(0)
        practice_left

        month=["AUG","SEP","OCT","NOV","DEC","JAN","FEB","MAR","APR","MAY","JUN","JUL"]
        curve=[practice_left[practice_left['Month']=='August']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='September']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='October']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='November']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='December']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='January']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='February']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='March']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='April']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='May']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='June']['Practice_count in 2019-2020'].item(),
               practice_left[practice_left['Month']=='July']['Practice_count in 2019-2020'].item()]
        bar=[practice_left[practice_left['Month']=='August']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='September']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='October']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='November']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='December']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='January']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='February']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='March']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='April']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='May']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='June']['Practice_count in 2020-2021'].item(),
             practice_left[practice_left['Month']=='July']['Practice_count in 2020-2021'].item()]
        averageTREND={'month':month,'curve':curve,'bar':bar}
        averageTREND=[averageTREND]
        return json.dumps(averageTREND)


@app.route('/feedbacktrend/')
def feedback_trend():

    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback
    df = DataFrame(list(collection.aggregate([
        {"$match":{
         '$and':
             [{'USER.ROLE_ID.ROLE_ID' :{'$ne':3}},
            {"USER.IS_DISABLED":{"$ne":"Y"}},
            {"USER.IS_BLOCKED":{"$ne":"Y"}},
            {"USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            {"USER.EMAIL_ID":{"$not":{"$regex" : 'test'}}},
            {"USER.EMAIL_ID":{"$not":{"$regex" : '1gen'}}},

              {"USER.USER_NAME":{"$not":{"$regex" : 'test'}}},
    #            {'RATING':{'$ne':0}},
              {'MODIFIED_DATE':{"$gte": LSY_Date,
                                         "$lte": csy_first_date()}}]
         }},
        {'$group':{'_id':{'$month':'$MODIFIED_DATE'}, 'count':{'$sum':1}}},
    {'$project':{'_id':1, '2019-2020':'$count'}}
        ])))
    df.rename(columns={'_id':'month'},inplace=True)
    # print(df)
    d=dict(enumerate(calendar.month_name))
    df['month']=df['month'].map(d)
    #df
    df1 = DataFrame(list(collection.aggregate([
        {"$match":{
         '$and':
             [{'USER.ROLE_ID.ROLE_ID' :{'$ne':3}},
            {"USER.IS_DISABLED":{"$ne":"Y"}},
            {"USER.IS_BLOCKED":{"$ne":"Y"}},
            {"USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            {"USER.EMAIL_ID":{"$not":{"$regex" : 'test'}}},
            {"USER.EMAIL_ID":{"$not":{"$regex" : '1gen'}}},

              {"USER.USER_NAME":{"$not":{"$regex" : 'test'}}},
    #            {'RATING':{'$ne':0}},
              {'MODIFIED_DATE':{"$gte": csy_first_date(),
#                                          "$lte":datetime.datetime(2021,7,31)
                               }}]
         }},
        {'$group':{'_id':{'$month':'$MODIFIED_DATE'}, 'count':{'$sum':1}}},
    {'$project':{'_id':1, '2020-2021':'$count'}}
        ])))
    df1.rename(columns={'_id':'month'},inplace=True)
    # print(df1)
    d=dict(enumerate(calendar.month_name))
    df1['month']=df1['month'].map(d)

    data=pd.merge(df,df1,on='month',how='outer')
    feedbacktrend=data.fillna(0)
    # print(feedbacktrend)
    month=["AUG","SEP","OCT","NOV","DEC","JAN","FEB","MAR","APR","MAY","JUN","JUL"]
    curve=[feedbacktrend[feedbacktrend['month']=='August']['2019-2020'].item(),
           feedbacktrend[feedbacktrend['month']=='September']['2019-2020'].item(),
           feedbacktrend[feedbacktrend['month']=='October']['2019-2020'].item(),
           feedbacktrend[feedbacktrend['month']=='November']['2019-2020'].item(),
           feedbacktrend[feedbacktrend['month']=='December']['2019-2020'].item(),
           feedbacktrend[feedbacktrend['month']=='January']['2019-2020'].item(),
           feedbacktrend[feedbacktrend['month']=='February']['2019-2020'].item(),
           feedbacktrend[feedbacktrend['month']=='March']['2019-2020'].item(),
           feedbacktrend[feedbacktrend['month']=='April']['2019-2020'].item(),
           feedbacktrend[feedbacktrend['month']=='May']['2019-2020'].item(),
           feedbacktrend[feedbacktrend['month']=='June']['2019-2020'].item(),
           feedbacktrend[feedbacktrend['month']=='July']['2019-2020'].item()]
    bar=[feedbacktrend[feedbacktrend['month']=='August']['2020-2021'].item(),
         feedbacktrend[feedbacktrend['month']=='September']['2020-2021'].item(),
         feedbacktrend[feedbacktrend['month']=='October']['2020-2021'].item(),
         feedbacktrend[feedbacktrend['month']=='November']['2020-2021'].item(),
         feedbacktrend[feedbacktrend['month']=='December']['2020-2021'].item(),
         feedbacktrend[feedbacktrend['month']=='January']['2020-2021'].item(),
         feedbacktrend[feedbacktrend['month']=='February']['2020-2021'].item(),
         feedbacktrend[feedbacktrend['month']=='March']['2020-2021'].item(),
         feedbacktrend[feedbacktrend['month']=='April']['2020-2021'].item(),
         feedbacktrend[feedbacktrend['month']=='May']['2020-2021'].item(),
         feedbacktrend[feedbacktrend['month']=='June']['2020-2021'].item(),
         feedbacktrend[feedbacktrend['month']=='July']['2020-2021'].item()]
    feedbacktrend={'month':month,'curve':curve,'bar':bar}
#     print(feedbacktrend)

    return json.dumps(feedbacktrend)

from functools import reduce
@app.route('/activeprogcharttable/<d>')
def parents_tableprogramnew(d):    
    x=''
    query=''
    if d=='D':        
        reader = geolite2.reader()
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
        client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
        db=client.compass
        collection = db.audio_track_master
        query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                        {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                        {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'bonus','$options':'i'}}},
                        {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                        ]}},

            {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                'Mindful_Minutes':{"$round":[{"$divide":
                    [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                    ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
            {'$match':{'PlayBack_Time_Percent':{'$gte':0.5}}},

            { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'AGE_GROUP':1     
                }},
        {'$group':
                    {'_id':{'user':'$User_ObjectId','agegp':'$AGE_GROUP'},
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'EMAIL_ID':{'$first':'$USER_EMAIL'},
                        'SCHOOL':{'$first':'$SCHOOL_NAME'},
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'CITY':{'$first':'$CITY'},
                        'STATE':{'$first':'$STATE'},
                        'IP':{'$first':'$IP'},
                        'CREATED_DATE':{'$first':'$CREATED_DATE'},
                        'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                        'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                        'PHONE':{'$first':'$PHONE'},
                        }},
        { "$project": { '_id':0,

            'USER_ID':'$_id.user','USER_NAME':1,'EMAIL_ID':1,
                'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                }}]
        
    elif d=='T':
        reader = geolite2.reader()
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
        client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
        db=client.compass
        collection = db.audio_track_master
        query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                        {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                        {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$regex':'bonus','$options':'i'}},
#                         {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                        ]}},

            {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                'Mindful_Minutes':{"$round":[{"$divide":
                    [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                    ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
            {'$match':{'PlayBack_Time_Percent':{'$gte':0.5}}},

            { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'AGE_GROUP':1     
                }},
        {'$group':
                    {'_id':{'user':'$User_ObjectId','agegp':'$AGE_GROUP'},
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'EMAIL_ID':{'$first':'$USER_EMAIL'},
                        'SCHOOL':{'$first':'$SCHOOL_NAME'},
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'CITY':{'$first':'$CITY'},
                        'STATE':{'$first':'$STATE'},
                        'IP':{'$first':'$IP'},
                        'CREATED_DATE':{'$first':'$CREATED_DATE'},
                        'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                        'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                        'PHONE':{'$first':'$PHONE'},
                        }},
        { "$project": { '_id':0,

            'USER_ID':'$_id.user','USER_NAME':1,'EMAIL_ID':1,
                'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                }}]
    elif d=='S':


        reader = geolite2.reader()
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
        client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
        db=client.compass
        collection = db.audio_track_master
        query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{"$eq":ObjectId("5f155b8a3b6800007900da2b")}},                  
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                        {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                        {'USER_ID.CREATED_DATE':{'$gte':datetime.datetime(2020,3,17)}},                
                        {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$regex':'sound','$options':'i'}},
#                         {'PROGRAM_AUDIO_ID.AUDIO_DAY':{'$not':{'$regex':'sound','$options':'i'}}}             
                        ]}},

            {"$project":{'_id':0,'User_ObjectId':'$USER_ID._id',      
                'USER_ID':'$USER_ID.USER_ID','USER_NAME':'$USER_ID.USER_NAME','USER_EMAIL':'$USER_ID.EMAIL_ID',
                'PHONE':'$USER_ID.CONTACT_NUMBER','IP':'$USER_ID.IP_ADDRESS',
                'SCHOOL_NAME':'$USER_ID.schoolId.NAME','CITY':'$USER_ID.schoolId.CITY',
                'STATE':'$USER_ID.schoolId.STATE','CREATED_DATE':'$USER_ID.CREATED_DATE',
                'PRACTICE_DATE':'$MODIFIED_DATE','PROGRAM_AUDIO_ID.AUDIO_ID':1,
                'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                'AUDIO_NAME':1,'AUDIO_LENGTH':1,'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,
                'Mindful_Minutes':{"$round":[{"$divide":
                    [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
                'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
                    ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
            {'$match':{'PlayBack_Time_Percent':{'$gte':0.5}}},

            { "$project": { 'USER_ID':1,'User_ObjectId':1,'USER_NAME':1,'USER_EMAIL':1,
                'PHONE':1,'SCHOOL_NAME':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'AGE_GROUP':1     
                }},
        {'$group':
                    {'_id':'$User_ObjectId',
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'EMAIL_ID':{'$first':'$USER_EMAIL'},
                        'SCHOOL':{'$first':'$SCHOOL_NAME'},
                        'USER_NAME':{'$first':'$USER_NAME'},
                        'CITY':{'$first':'$CITY'},
                        'STATE':{'$first':'$STATE'},
                        'IP':{'$first':'$IP'},
                        'CREATED_DATE':{'$first':'$CREATED_DATE'},
                        'MODIFIED_DATE':{'$max':'$PRACTICE_DATE'},
                        'Mindful_minutes':{'$sum':'$Mindful_Minutes'},
                        'PHONE':{'$first':'$PHONE'},
                        }},
        { "$project": { '_id':0,

            'USER_ID':'$_id','USER_NAME':1,'EMAIL_ID':1,
                'PHONE':1,'SCHOOL':1,'CITY':1,'STATE':1,
                           'CREATED_DATE':1,'PRACTICE_DATE':1,'IS_DONE':1,'Mindful_Minutes':1,
                           'IP':1,'CREATED_DATE':1,'MODIFIED_DATE':1,'Mindful_minutes':1   
                }}]
    else:
        pass  
    daily=list(collection.aggregate(query))
    daily_df=pd.DataFrame(daily)
    daily_df.Mindful_minutes=daily_df.Mindful_minutes.astype('int64')
    daily_df['MODIFIED_DATE']=pd.to_datetime(daily_df['MODIFIED_DATE'])
    daily_df['CREATED_DATE']=pd.to_datetime(daily_df['CREATED_DATE'])
    daily_df['SCHOOL'].fillna("NO SCHOOL INFO", inplace=True)
    daily_df['EMAIL_ID'].fillna("EMAIL_ID NOT AVAILABLE", inplace=True)
    daily_df['EMAIL_ID'].replace("",'EMAIL_ID NOT AVAILABLE', inplace=True)
    daily_df['USER_NAME'].replace("",'USER NAME NOT AVAILABLE', inplace=True)
    daily_df['CITY'].fillna("NO CITY INFO AVAILABLE", inplace=True)
    daily_df['STATE'].fillna("NO STATE INFO AVAILABLE", inplace=True)


    
    def country1(i):

        location = reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location = reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def city1(i):
        location = reader.get(i)
        city=location['city']['names']['en']
        return city
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    ip=daily_df['IP'].tolist()
    phone_number=daily_df['PHONE'].tolist()
    Parents_Name=daily_df['USER_NAME'].tolist()
    Parents_Email=daily_df.EMAIL_ID.tolist()
    School_Name=daily_df['SCHOOL'].tolist()
    state=daily_df['STATE'].tolist()
    city=daily_df['CITY'].tolist()
    sign_up_date=daily_df['CREATED_DATE'].tolist()
    last_prac_date=daily_df['MODIFIED_DATE'].tolist()
    #     practice_count=df['Practice_Count'].tolist()
    mindful_minutes=daily_df['Mindful_minutes'].tolist()

    for i in range(len(ip)):            
        if city[i] is None:
            try:
                city[i]=city1(ip[i])
            except:
                pass
        elif city[i]=='NO CITY INFO AVAILABLE':
            try:
                city[i]=city1(ip[i])
            except:
                pass                        
        
        if state[i] is None:
            try:
                state[i]=state1(ip[i])
            except:
                pass
        elif state[i] =='NO STATE INFO AVAILABLE':
            try:
                state[i]=state1(ip[i])
            except:
                pass    
        if state[i] is None:
            state[i]=''
        if  last_prac_date[i] != 'NO PRACTICE' :
            last_prac_date[i]=last_prac_date[i].strftime('%d %b %Y')
        else:
            last_prac_date[i]="NO PRACTICE"

        if sign_up_date[i] is not None:        
            sign_up_date[i]=sign_up_date[i].strftime('%d %b %Y')


    state12 =  [each_string.upper() for each_string in state]
    city12= [each_string.upper() for each_string in city]
    school= [each_string.upper() for each_string in School_Name]



    cv={'pnn':Parents_Name,'pe':Parents_Email,'pn':phone_number,'sn':school,'ct':city12,
       'st':state12,'sp':sign_up_date,
       'lp':last_prac_date,'mm':mindful_minutes}
    dftry = pd.DataFrame.from_dict(cv)
    print(dftry.shape)

    return json.dumps({"data":dftry.values.tolist()})

@app.route('/activeprogchart')
def parpracticeprogram_unique_active():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                {'USER_ID.EMAIL_ID':{'$nin':['',' ',None]}}

                ]}},

    {"$project":{'USER_ID':'$USER_ID.USER_ID','PROGRAM_AUDIO_ID.AUDIO_ID':1,
        'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':1,
        'AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
        'AUDIO_NAME':1,'AUDIO_LENGTH':1,
        'IS_DONE':1,'PROGRAM_AUDIO_ID.AUDIO_DAY':1,'PROGRAM_AUDIO_ID.AUDIO_LENGTH':1,

        'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
            ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}},
        {"$match":{'PlayBack_Time_Percent':{"$gte":.5}}},


    { "$project": { 'USER_ID':1,'AGE_GROUP':1,

        "status": {
          "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": 'bonus','options': "i"  }}


              , 
          "then": 'Bonus', "else": {
             "$cond": { "if": { "$regexMatch": { 
                                    "input": "$PROGRAM_AUDIO_ID.AUDIO_DAY",
                                    "regex": "sound",'options': "i" }}, 
             "then": 'Sound', "else": 'daily'
             }}}}}}         

             ]

    x=list(collection.aggregate(query))
    df=pd.DataFrame(x)
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])

    practice_count_overall=pd.DataFrame(df.groupby(['AGE_GROUP','status'])['USER_ID'].nunique()).reset_index().rename(columns={'USER_ID':'Count'})
    age_group_df=pd.DataFrame({'AGE_GROUP':list(set(df.AGE_GROUP.tolist()))}).dropna().sort_values(by=['AGE_GROUP'])
    dailydf=practice_count_overall[practice_count_overall.status=='daily']
    dailycompdf=pd.merge(age_group_df,dailydf,on='AGE_GROUP',how='left')
    dailycompdf['status'].fillna('daily',inplace=True)
    dailycompdf['Count'].fillna(0,inplace=True)
    Sounddf=practice_count_overall[practice_count_overall.status=='Sound']
    Soundcompdf=pd.merge(age_group_df,Sounddf,on='AGE_GROUP',how='left')
    Soundcompdf['status'].fillna('Sound',inplace=True)
    Soundcompdf['Count'].fillna(0,inplace=True)
    Bonusdf=practice_count_overall[practice_count_overall.status=='Bonus']
    Bonuscompdf=pd.merge(age_group_df,Bonusdf,on='AGE_GROUP',how='left')
    Bonuscompdf['status'].fillna('Bonus',inplace=True)
    Bonuscompdf['Count'].fillna(0,inplace=True)
    temp={'daily':dailycompdf.Count.tolist(),'dtotal':dailycompdf.Count.sum(),'prog':age_group_df.AGE_GROUP.tolist(),
      'sound':Soundcompdf.Count.tolist(),'soundt':Soundcompdf.Count.sum(),
       'transition':Bonuscompdf.Count.tolist(),'trant':Bonuscompdf.Count.sum()}

    return json.dumps(temp)





@app.route('/presentios')
def presentios():
   #impressions
    googleSheetId = '1UrhNlOkyAhboHYQwNQJHpEiJ-NfeCDX5MS3DPh8Na50'
    worksheetName = 'impressions'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId,
    worksheetName
    )
    df = pd.read_csv(URL)
    #product page views
    googleSheetId1 = '1UrhNlOkyAhboHYQwNQJHpEiJ-NfeCDX5MS3DPh8Na50'
    worksheetName1 = 'product_page_views'
    URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId1,
    worksheetName1
    )
    df1 = pd.read_csv(URL1)
    #conversion_rate
    googleSheetId2 = '1UrhNlOkyAhboHYQwNQJHpEiJ-NfeCDX5MS3DPh8Na50'
    worksheetName2 = 'conversion_rate'
    URL2 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId2,
    worksheetName2
    )
    df2 = pd.read_csv(URL2)
    dfs = [df, df1, df2]
    df_final = reduce(lambda left,right: pd.merge(left,right,on='Date'), dfs)
    df_final['Date'] = pd.to_datetime(df_final['Date'])
    newdf=df_final[(df_final.Date> '2020-03-16')]
    newdf['Date'] = newdf['Date'].astype(np.int64) / int(1e6)
    df3=newdf[['Date','Impressions']]
    
    #IMPRESSION =====NO OF STORE VISIT
    Impressions= df3.values.tolist()
    df4=newdf[['Date','Product Page Views']]
    #PAGE VIEW OPEN AFTER INSTALL
    PViews=sum(list(df4['Product Page Views']))
    Page_Views= df4.values.tolist()
    
    df6=newdf[['Date','App Units']]
    #APP UNIT ---- INSTALL
    App_Units= df6.values.tolist()
    df7=newdf[['Date','Impressions (Unique Devices)']]
    I_Unique_Devices= df7.values.tolist()
    
    newdate=list(newdf['Date'])
    Impressions=list(df3['Impressions'])
    Impressionsnew=[]
#     cumImpressions=np.cumsum(Impressions)
#     print(cuminst)
    for i,j in zip(newdate,Impressions):
        Impressionsnew.append([i,int(j)])
    
#     print(Impressionsnew)
    appunit=list(df6['App Units'])
    cumImpressionsgraph=[]
#     print(newdate)
    cumImpressions=np.cumsum(Impressions)
#     print(cuminst)
    for i,j in zip(newdate,cumImpressions):
        cumImpressionsgraph.append([i,int(j)])
#     print(cuminstgraph)

    cumappunit2=[]
#     print(newdate)
    cumappunit=np.cumsum(appunit)
#     print(cumappunit,"cumappunit")
#     print(cuminst)
    for i,j in zip(newdate,cumappunit):
        cumappunit2.append([i,int(j)])
    
    User_install= df7.values.tolist()
    
    
    
    temp={"Impressionsnew":Impressionsnew,"totalpageview":[str(PViews)],"totalimpression":[str(sum(Impressions))],"totalappunit":[str(sum(appunit))],"cumappunit":cumappunit2,"cumImpressionsgraph":cumImpressionsgraph,"Impressions":Impressions,"Page_Views":Page_Views,"App_Units":App_Units,"Impression_Devices":I_Unique_Devices}
#     print(temp)
    return(json.dumps(temp))


@app.route('/appandroid')
def appandroid():
    googleSheetId = '1-UfcdmB78qk86zuK2fSFqDg-eenyNBzYzu5vI41mDXg'
    worksheetName = 'Installs'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
        googleSheetId,
        worksheetName
    )
    df = pd.read_csv(URL)
    #Active_Users
    googleSheetId1 = '1-UfcdmB78qk86zuK2fSFqDg-eenyNBzYzu5vI41mDXg'
    worksheetName1 = 'Sessions'
    URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
        googleSheetId1,
        worksheetName1
    )
    df1 = pd.read_csv(URL1)

    #User Loss
    googleSheetId2 = '1-UfcdmB78qk86zuK2fSFqDg-eenyNBzYzu5vI41mDXg'
    worksheetName2 = 'User_Loss'
    URL2 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
        googleSheetId2,
        worksheetName2
    )
    df2 = pd.read_csv(URL2)

    #Uninstalls
    googleSheetId3 = '1-UfcdmB78qk86zuK2fSFqDg-eenyNBzYzu5vI41mDXg'
    worksheetName3 = 'Uninstalls'
    URL3 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
        googleSheetId3,
        worksheetName3
    )
    df3 = pd.read_csv(URL3)

    #Ratings
    googleSheetId4 = '1-UfcdmB78qk86zuK2fSFqDg-eenyNBzYzu5vI41mDXg'
    worksheetName4 = 'Ratings'
    URL4 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
        googleSheetId4,
        worksheetName4
    )
    df4 = pd.read_csv(URL4)

    dfs = [df, df1, df2, df3,df4]
    df_final = reduce(lambda left,right: pd.merge(left,right,on='Date'), dfs)
    df_final['Day'] = df_final['Date'].astype(str).str[:2]
    df_final['Month'] =df_final['Date'].astype(str).str[3:5]
    df_final['Year'] = df_final['Date'].astype(str).str[6:10]
    df_final['New_Date']=pd.to_datetime(df_final[['Year', 'Month', 'Day']].rename(columns={'YY': 'year', 'MM': 'month', 'DD': 'day'}))
    newdf=df_final[(df_final.New_Date> '2020-03-16')]
    df6=newdf[['New_Date','Installs','Sessions','User_Lost','User_Uninstalls','Rating']].apply(pd.to_numeric, errors='coerce')
    df6['New_Date'] = df6['New_Date'].astype(np.int64) / int(1e6)
    df6=df6.fillna(0)

    df7=df6[['New_Date','Installs']]
    newdate=list(df7['New_Date'])
    installss=list(df7['Installs'])
    cuminstgraph=[]
    #     print(newdate)
    cuminst=np.cumsum(installss)
    #     print(cuminst)
    for i,j in zip(newdate,cuminst):
        cuminstgraph.append([i,int(j)])
    #     print(cuminstgraph)
    User_install= df7.values.tolist()


    df8=df6[['New_Date','Sessions']]
    User_Active= df8.values.tolist()
    Useractive=list(df8['Sessions'])
    cumUseractive=np.cumsum(Useractive)
    #     print(cuminst)
    cumactivegraph=[]
    for i,j in zip(newdate,cumUseractive):
        cumactivegraph.append([i,int(j)])
    #     print(cuminstgraph)
    User_install= df7.values.tolist()

    df9=df6[['New_Date','User_Lost']]
    User_Lost= df9.values.tolist() 
    df10=df6[['New_Date','User_Uninstalls']]
    User_Uninstall= df10.values.tolist()
    df11=df6[['New_Date','Rating']]
    User_Raiting= df11.values.tolist()
    Dload = df6['Installs'].sum()
    User_Download= Dload.tolist()
    ActiveU = int(df6['Sessions'].sum())
    uninstallsum = int(df10['User_Uninstalls'].sum())
    #     Active_users= ActiveU.tolist()
    temp={'installcard':[str(sum(installss))],'cumactivegraph':cumactivegraph,'cuminstall':cuminstgraph,"install":User_install,"Active":User_Active,"Lost":User_Lost,"Uninstall":User_Uninstall,"Raiting":User_Raiting,"Downloads":User_Download,'uninstallcard':[str(uninstallsum)],"activecard":[str(ActiveU)]}
    return(json.dumps(temp))


@app.route('/presentandroid')

def indexdcsdcds():
    googleSheetId = '1-UfcdmB78qk86zuK2fSFqDg-eenyNBzYzu5vI41mDXg'
    worksheetName = 'Installs'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
        googleSheetId,
        worksheetName
    )
    df = pd.read_csv(URL)
    #Active_Users
    googleSheetId1 = '1-UfcdmB78qk86zuK2fSFqDg-eenyNBzYzu5vI41mDXg'
    worksheetName1 = 'Active_Users'
    URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
        googleSheetId1,
        worksheetName1
    )
    df1 = pd.read_csv(URL1)

    #User Loss
    googleSheetId2 = '1-UfcdmB78qk86zuK2fSFqDg-eenyNBzYzu5vI41mDXg'
    worksheetName2 = 'User_Loss'
    URL2 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
        googleSheetId2,
        worksheetName2
    )
    df2 = pd.read_csv(URL2)

    #Uninstalls
    googleSheetId3 = '1-UfcdmB78qk86zuK2fSFqDg-eenyNBzYzu5vI41mDXg'
    worksheetName3 = 'Uninstalls'
    URL3 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
        googleSheetId3,
        worksheetName3
    )
    df3 = pd.read_csv(URL3)

    #Ratings
    googleSheetId4 = '1-UfcdmB78qk86zuK2fSFqDg-eenyNBzYzu5vI41mDXg'
    worksheetName4 = 'Ratings'
    URL4 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
        googleSheetId4,
        worksheetName4
    )
    df4 = pd.read_csv(URL4)

    dfs = [df, df1, df2, df3,df4]
   
    df_final = reduce(lambda left,right: pd.merge(left,right,on='Date'), dfs)
    df_final['Day'] = df_final['Date'].astype(str).str[:2]
    df_final['Month'] =df_final['Date'].astype(str).str[3:5]
    df_final['Year'] = df_final['Date'].astype(str).str[6:10]
    df_final['New_Date']=pd.to_datetime(df_final[['Year', 'Month', 'Day']].rename(columns={'YY': 'year', 'MM': 'month', 'DD': 'day'}))
    newdf=df_final[(df_final.New_Date> '2020-03-16')]
#     print(newdf.fillna(0))
    df6=newdf[['New_Date','Installs','Active_Users','User_Lost','User_Uninstalls','Rating']].apply(pd.to_numeric, errors='coerce')
    df6['New_Date'] = df6['New_Date'].astype(np.int64) / int(1e6)
    df6=df6.fillna(0)
    df7=df6[['New_Date','Installs']]
    User_install= df7.values.tolist()
    df8=df6[['New_Date','Active_Users']]
    User_Active= df8.values.tolist()
    
    df9=df6[['New_Date','User_Lost']]
    User_Lost= df9.values.tolist() 
    df10=df6[['New_Date','User_Uninstalls']]
    User_Uninstall= df10.values.tolist()
    df11=df6[['New_Date','Rating']]
    User_Raiting= df11.values.tolist()
    Dload = df6['Installs'].sum()
    User_Download= Dload.tolist()
    ActiveU = df6['Active_Users'].sum()
    Active_users= ActiveU.tolist()
    
    temp={"install":User_install,"Active":User_Active,"Lost":User_Lost,"Uninstall":User_Uninstall,"Raiting":User_Raiting,"Downloads":User_Download,"ActiveU":Active_users}
   
    return(json.dumps(temp))


@app.route('/pfeedbackcards')
def familyfeedbackcards():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    query=[
        {"$match":{"$and":[{'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER_ID.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER_ID.IS_DISABLE':{"$ne":'Y'}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                {'USER_ID.EMAIL_ID':{'$nin':['',' ',None]}},
                {"USER_ID.CREATED_DATE":{"$gt": datetime.datetime(2020,3,17)}}
                           
                ]}},
           {"$project":{"_id":0, "USER_ID":'$USER_ID.USER_ID','MODIFIED_DATE':1}}]
    

    query2=[
     {"$match":{"$and":[{'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER.IS_DISABLE':{"$ne":'Y'}},
                {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
                {'RATING':{'$ne':0}},
                {"USER.CREATED_DATE":{"$gt": datetime.datetime(2020,3,17)}}
                ]}},
            {"$project":{'RATING':1,'COMMENT':1,'USER_ID':'$USER.USER','USER_NAME':'$USER.USER_NAME','EMAIL':'$USER.EMAIL_ID'}}]
    practice=list(collection.aggregate(query))
    practice_df=pd.DataFrame(practice)
    feedback=list(collection2.aggregate(query2))
    feedback_df=pd.DataFrame(feedback)
    card_df=pd.DataFrame({'Feedback_Percentage':(len(feedback_df[feedback_df['RATING']!=0])/len(practice_df))*100,
                 'Comment_per_feedback':len(feedback_df[(feedback_df['COMMENT'].notnull()) & (feedback_df['COMMENT']!='') ])/
                 len(feedback_df[feedback_df['RATING']!=0])*100,
                  'Total_Playbacks':len(practice_df),'Average_Rating':feedback_df[feedback_df['RATING']!=0]['RATING'].mean()},
                      index=[0])
    temp={}
    for j in range(len(card_df.columns)):
        key = card_df.columns[j]
        value = [str(card_df[card_df.columns[j]].iloc[0])]
        temp.update({key:value})
#     print(temp)
    return json.dumps(temp)
# familyfeedbackcards()

@app.route('/familyfeedback')
def feedback():


    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback
    df = DataFrame(list(collection.aggregate([
    {"$match":{"$and":[{'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                  
                {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
                {'USER.IS_DISABLE':{"$ne":'Y'}},
                {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
                {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
                {'RATING':{'$ne':0}},
                {"USER.CREATED_DATE":{"$gt": datetime.datetime(2020,3,17)}}
                ]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
    'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
    'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}}
    }},
    {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3', 'rating_2':'$rating_2','rating_1':'$rating_1' }}
    ])))

    df.rename(columns = { '_id': 'Month'}, inplace = True)

    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df['Month'] = df['Month'].map(d)


    df1=Sort_Dataframeby_MonthandNumeric_cols(df = df, monthcolumn='Month',numericcolumn='rating_5')

    df1['Month'] = df1['Month'].astype(str).str[:3]
    # df2f=df1.rename(columns={"_id": "Month"})
    Month= ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
    df2t = pd.DataFrame(Month,columns =['Month'])

    df2 = pd.merge(df2t, df1, on="Month", how='left').fillna(0)

    df3=df2.agg({'rating_5': 'sum', 'rating_4': 'sum','rating_3': 'sum','rating_2': 'sum','rating_1': 'sum'})

    df4 = pd.DataFrame()
    df5=df4.append(df3, ignore_index = True) 

    df6=df5[['rating_5','rating_4','rating_3','rating_2','rating_1']] #arranging rating5 to rating1

    df7=df2[['Month','rating_1']]

    df8=df2[['Month','rating_2']]
    df9=df2[['Month','rating_3']]
    df10=df2[['Month','rating_4']]
    df11=df2[['Month','rating_5']]

    D_1= df7.values.tolist()
    D_2= df8.values.tolist()
    D_3= df9.values.tolist()
    D_4= df10.values.tolist()
    D_5= df11.values.tolist()
    links = df6.rename(columns={'rating_5' : 'S5', 'rating_4' : 'S4','rating_3' : 'S3', 'rating_2' : 'S2', 'rating_1' : 'S1'}).to_dict('r')
    temp={'Total':links,'D5':D_5,'D4':D_4,'D3':D_3,'D2':D_2,'D1':D_1}
    return json.dumps(temp)





@app.route('/familyschoolsearch/<month>/<n>')
def parents_rating_month_info(month,n):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection1 = db.audio_feedback
    collection2 = db.audio_track_master
#     feedback=[n]
    df1 = DataFrame(list(collection1.aggregate([
       {"$match":
        {'$and': [
             {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER.IS_DISABLED":{"$ne":"Y"}},
#               {"USER.IS_BLOCKED":{"$ne":"Y"}},
             {"USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                         {'RATING':{'$ne':0}},
             {'RATING':{"$eq":int(""+n+"")}}
#              {'RATING':{'$in':feedback}}

#             {'MODIFIED_DATE':{'month':{'$in':monthname}}},
            ]}},
        {'$group':{'_id':'$_id','um':{'$first':'$USER.USER_NAME'},'email':{'$first':'$USER.EMAIL_ID'},
                   'COMMENT':{'$first':'$COMMENT'},'an':{'$first':'$AUDIO_ID.AUDIO_NAME'}, 
     'rating':{'$first':'$RATING'},
        'comment_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }}}}},
        {'$project':{'_id':1, 'USER_NAME':'$um','EMAIL_ID':'$email','COMMENT':'$COMMENT','AUDIO_NAME':'$an', 'RATING':'$rating','last_comment_rating_date':'$comment_date'}}
    # //     ,{'$count':'count'}
        ])))
    df1.rename(columns={'_id':'user'},inplace=True)
    # print(df)
    # d=dict(enumerate(calendar.month_name))
    # df['month']=df['month'].map(d)
    # #df
   #'month':{'$first':{'$monthname':'$MODIFIED_DATE'}},
    df2 = DataFrame(list(collection2.aggregate([
       {"$match":{
         '$and':[{'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#           {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    
         { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}
                                            ]}},
           {'$group':{'_id':'$USER_ID._id','sm':{'$first':'$USER_ID.schoolId.NAME'},'pc':{'$sum':1},'email':{'$first':'$USER_ID.EMAIL_ID'},'COUNTRY':{'$first':'$USER_ID.schoolId.COUNTRY'},'STATE':{'$first':'$USER_ID.schoolId.STATE'},
           'CITY':{'$first':'$USER_ID.schoolId.CITY'},'LAST_PRACTICE':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}}}}},
           {'$project':{'_id':1,'school_name':'$sm','country':'$COUNTRY','Practice_Count':'$pc','EMAIL_ID':'$email','State':'$STATE','city':'$CITY','last_practice_date':'$LAST_PRACTICE'}}
    # //        ,{'$count':'count'}
           ])))
    df2.rename(columns={'_id':'user'},inplace=True)
    df=pd.merge(df1,df2,on='EMAIL_ID',how='left')
    # df
   

    
    df['school_name'].fillna("NO INFO", inplace=True)
    df['country'].fillna("NO INFO", inplace=True)
    
    df['USER_NAME'].fillna("NO INFO", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
   
    df['EMAIL_ID'].fillna("NO INFO", inplace=True)
    df['EMAIL_ID'].replace("",'NO INFO', inplace=True)
    df['school_name'].replace("",'NO INFO', inplace=True)
    df['city'].replace("",'NO INFO', inplace=True)
    df['State'].replace("",'NO INFO', inplace=True)
    df['country'].replace("",'NO INFO', inplace=True)
    df['USER_NAME'].replace("",'NO INFO', inplace=True)
    df['city'].fillna("NO INFO", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['State'].fillna("NO INFO", inplace=True)
    df['State'].replace("NULL","NO INFO", inplace=True)


    df['last_comment_rating_date']=df['last_comment_rating_date'].dropna()
    df=df.reset_index(drop=True)
    df['COMMENT']=df['COMMENT'].replace('','NO COMMENT')
    df['COMMENT']=df['COMMENT'].fillna('NO COMMENT')
    df['last_practice_date']=pd.to_datetime(df['last_practice_date'])
    df['last_comment_rating_date']=pd.to_datetime(df['last_comment_rating_date'])
    df['last_practice_date']=df['last_practice_date'].fillna('NO PRACTICE')
#     print(df)
#     df= df.groupby(by=['RATING'])
#     df= df.get_group((''+n+'') )
#     df= df.groupby(df['RATING'])
#     df= df.get_group(''+rating+'')
    df=df.groupby(df['last_comment_rating_date'].dt.strftime('%b'))
    df=df.get_group(''+month+'')
    LAST_PRACTICE_DATE=[]
    for i in df['last_practice_date']:
        if  i != 'NO PRACTICE' :
            LAST_PRACTICE_DATE.append(i.strftime("%d %b %Y "))
        else:
            LAST_PRACTICE_DATE.append("NO PRACTICE")
    last_comment_rating_date=[]
    for i in df['last_comment_rating_date']:
        if  i != ' ' :
            last_comment_rating_date.append(i.strftime("%d %b %Y "))
        else:
            last_comment_rating_date.append(" ")
        # print(last_comment_rating_date)
#     df=df.groupby(df['last_practice_date'].dt.strftime('%b'))
#     df=df.get_group(''+month+'')
    data=[]
    for i,j,k,l,m,n,o,p,q,r in zip(df['school_name'].tolist(),df['State'].tolist(),df['city'].tolist(),df['Practice_Count'].tolist(),df['USER_NAME'].tolist(),df['EMAIL_ID'].tolist(),df['AUDIO_NAME'].tolist(),df['COMMENT'].tolist(),last_comment_rating_date,LAST_PRACTICE_DATE):
        data.append([i,j,k,l,m,n,o,p,q,r])
    temp={"data":data}
    return json.dumps(temp)
# rating_month_info('Aug','4')



@app.route('/card/<district>')
def card(district):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master.aggregate([
    {"$match":{"schoolId":{"$exists":1}}},
    {"$match":
        {"$and":[
        {"DISTRICT_ID._id":ObjectId(""+district+"")},
        {"schoolId._id":{"$in":db.school_master.distinct( "_id",  {"IS_PORTAL":"Y"} )}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME",
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME"}}

    ])
    df1= DataFrame(list(collection)).fillna(0)
    user_list=df1["USER_ID"].tolist()
    collection1=db.login_logs.aggregate([{"$match":{"USER_ID._id":{
                        "$in":user_list

                    }    ,"USER_ID.schoolId":{"$exists":1}}},
    {"$group":{"_id":"$USER_ID._id",
            "count":{"$sum":1},
            }},
    {"$project":{"_id":0,"USER_ID":"$_id","count(last_logged_in)":"$count"}}
            ])
    df2= DataFrame(list(collection1)).fillna(0)
    collection2 = db.audio_track_master.aggregate([
    {"$match":{"USER_ID._id":{
                        "$in":user_list

                    }    ,"USER_ID.schoolId":{"$exists":1}}},
    {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'MODIFIED_DATE':{"$gt":datetime.datetime(2019,7,31)}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$group":{"_id":{"USER_ID":"$USER_ID._id"},
            "NEW":{"$addToSet":"$USER_ID._id"},
            "count":{"$sum":1},
            "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
            }},
        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","practice_count12":"$count"}}

    ])
    df3= DataFrame(list(collection2)).fillna(0)
    #####################CLEVER#######################
    collection3 = db.user_master.aggregate([
    {"$match":{"schoolId":{"$exists":1}}},
    {"$match":
        {"$and":[
            {"_id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                {"DISTRICT_ID._id":ObjectId(""+district+"")},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME",
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME"}}

    ])
    dfclever= DataFrame(list(collection3)).fillna(0)
    if dfclever.empty == True:
        column_names1 = ["ID","USER_ID","school_name","email_id","district_name","count(last_logged_in)","practice_count12","role_type"]
        final1clever = pd.DataFrame(columns = column_names1)
    else:
        user_list1=dfclever["USER_ID"].tolist()
        collection4=db.login_logs.aggregate([{"$match":{"USER_ID._id":{
                            "$in":user_list1

                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$group":{"_id":"$USER_ID._id",
                "count":{"$sum":1},
                }},
        {"$project":{"_id":0,"USER_ID":"$_id","count(last_logged_in)":"$count"}}
                ])
        dfcleverlog= DataFrame(list(collection4)).fillna(0)
        collection5 = db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list1

                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$match":
            {"$and":[
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":datetime.datetime(2019,7,31)}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
        {"$match":
        {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        {"$group":{"_id":{"USER_ID":"$USER_ID._id"},
                "NEW":{"$addToSet":"$USER_ID._id"},
                "count":{"$sum":1},
                "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
                }},
            {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","practice_count12":"$count"}}

        ])
        dfcleverprac= DataFrame(list(collection5)).fillna(0)
        finalclever=pd.merge(dfclever, dfcleverlog, on='USER_ID',how='left').fillna(0)
        final1clever=pd.merge(finalclever, dfcleverprac, on='USER_ID',how='left').fillna(0)
        final1clever["role_type"]="CLEVER"
    ######################################################################################

    #####################schoology#######################
    collection6 = db.user_master.aggregate([
    {"$match":{"schoolId":{"$exists":1}}},
    {"$match":
        {"$and":[ 
            {"_id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                {"DISTRICT_ID._id":ObjectId(""+district+"")},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME",
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME"}}
    ])
    dfschoology= DataFrame(list(collection6)).fillna(0)
    if dfschoology.empty == True:
        column_names = ["ID","USER_ID","school_name","email_id","district_name","count(last_logged_in)","practice_count12","role_type"]
        final1schoology = pd.DataFrame(columns = column_names)
    else:
        user_list2=dfschoology["USER_ID"].tolist()
        collection7=db.login_logs.aggregate([{"$match":{"USER_ID._id":{
                            "$in":user_list2

                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$group":{"_id":"$USER_ID._id",
                "count":{"$sum":1},
                }},
        {"$project":{"_id":0,"USER_ID":"$_id","count(last_logged_in)":"$count"}}
                ])
        dfschoologylog= DataFrame(list(collection7)).fillna(0)
        collection8 = db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list2

                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$match":
            {"$and":[
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":datetime.datetime(2019,7,31)}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
        {"$match":
        {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        {"$group":{"_id":{"USER_ID":"$USER_ID._id"},
                "NEW":{"$addToSet":"$USER_ID._id"},
                "count":{"$sum":1},
                "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
                }},
            {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","practice_count12":"$count"}}

        ])
        dfschoologyprac= DataFrame(list(collection8)).fillna(0)
        finalschoology=pd.merge(dfschoology, dfschoologylog, on='USER_ID',how='left').fillna(0)
        final1schoology=pd.merge(finalschoology, dfschoologyprac, on='USER_ID',how='left').fillna(0)
        final1schoology["role_type"]="SCHOOLOGY"
    ######################################################################################
    final=pd.merge(df1, df2, on='USER_ID',how='left').fillna(0)
    final1=pd.merge(final, df3, on='USER_ID',how='left').fillna(0)
    final1["role_type"]="IE"
    final2 = pd.concat([final1, final1clever], ignore_index=True, sort=False)
    final3 = pd.concat([final2, final1schoology], ignore_index=True, sort=False)
    df=final3[["ID","USER_ID","school_name","email_id","district_name","count(last_logged_in)","practice_count12","role_type"]]
    Dormant=df[(df["practice_count12"]==0) & (df["role_type"]=="IE")].count()["practice_count12"]
    Passive=df[(df['practice_count12'] > 0) & (df['practice_count12'] <= 6) & (df["role_type"]=="IE")].count()["practice_count12"]
    Active=df[(df['practice_count12'] > 6) & (df['practice_count12'] <= 50)& (df["role_type"]=="IE")].count()["practice_count12"]
    Power=df[(df['practice_count12'] > 50) & (df["role_type"]=="IE")].count()["practice_count12"]
    schoology=df[df["role_type"]=="SCHOOLOGY"].count()["USER_ID"]
    print(schoology)
    clever=df[df["role_type"]=="CLEVER"].count()["USER_ID"]
    User_count=Active+Passive+Dormant+Power
    school_count=df['ID'].nunique()
    Onboarding0 = df.groupby('ID')['USER_ID'].nunique().to_frame(name = 'user_count').reset_index()
    Onboarding=Onboarding0[Onboarding0["user_count"]==1].count()["user_count"]
    Engaged01=df[(df['practice_count12'] > 0)]
    Engaged0 = Engaged01.groupby('ID')['practice_count12'].count().reset_index()
    Engaged1=pd.merge(Engaged0, Onboarding0, on='ID',how='left')
    Engaged1['percentage']=Engaged1['practice_count12']*100/Engaged1['user_count']
    Engaged2=Engaged1[(Engaged1['user_count'] > 1)]
    Engaged=Engaged2[(Engaged2['percentage'] > 20)].count()["percentage"]
    Intervention=school_count-(Engaged+Onboarding)
    temp={'dormant':int(Dormant) ,'passive':int(Passive) ,'active':int(Active), 'power':int(Power) ,'usercount':int(User_count),'onboarding':int(Onboarding),'engaged':int(Engaged),'intervention':int(Intervention),'totalschool':int(school_count)
        ,'schoology':int(schoology),'clever':int(clever)}
    return(json.dumps(temp))

@app.route('/parusmap')
def state_Infop():
    statesshort = {'alaska': 'ak',
        'alabama': 'al',
        'arkansas': 'ar',
        'american samoa': 'as',
        'arizona': 'az',
        'california': 'ca',
        'colorado': 'co',
        'connecticut': 'ct',
        'district of columbia': 'dc',
        'delaware': 'de',
        'florida': 'fl',
        'georgia': 'ga',
        'guam': 'gu',
        'hawaii': 'hi',
        'iowa': 'ia',
        'idaho': 'id',
        'illinois': 'il',
        'indiana': 'in',
        'kansas': 'ks',
        'kentucky': 'ky',
        'louisiana': 'la',
        'massachusetts': 'ma',
        'maryland': 'md',
        'maine': 'me',
        'michigan': 'mi',
        'minnesota': 'mn',
        'missouri': 'mo',
        'northern mariana islands': 'mp',
        'mississippi': 'ms',
        'montana': 'mt',
        'national': 'na',
        'north carolina': 'nc',
        'north dakota': 'nd',
        'nebraska': 'ne',
        'new hampshire': 'nh',
        'new jersey': 'nj',
        'new mexico': 'nm',
        'nevada': 'nv',
        'new york': 'ny',
        'ohio': 'oh',
        'oklahoma': 'ok',
        'oregon': 'or',
        'pennsylvania': 'pa',
        'puerto rico': 'pr',
        'rhode island': 'ri',
        'south carolina': 'sc',
        'south dakota': 'sd',
        'tennessee': 'tn',
        'texas': 'tx',
        'utah': 'ut',
        'virginia': 'va',
        'virgin islands': 'vi',
        'vermont': 'vt',
        'washington': 'wa',
        'wisconsin': 'wi',
        'west virginia': 'wv',
        'wyoming': 'wy'}
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collectionMap=db.user_master
    querymap=[{"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    #//             {'schoolId._id':{"$nin":db.audio_track_master.distinct("USER_ID.schoolId._id")}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #//               {'IS_ADMIN':'Y'},
    #//             {'CAP_PROGRAM':{'$exists':true}},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$_id','ID':{'$addToSet':'$_id'},'country':{'$first':'$schoolId.COUNTRY'},'state':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'},
            'IP':{'$first':'$IP_ADDRESS'},'CONTACT_NUMBER':{'$first':'$CONTACT_NUMBER'}}},
                  {'$project':{'_id':1,'USER_ID':'$ID','country':'$country','state':'$state','CITY':'$city','IP_address':'$IP','CONTACT_NUMBER':'$CONTACT_NUMBER'}}
                  #{'$count':'count'}]
             ]
    map_list= list(collectionMap.aggregate(querymap))
    df_map= DataFrame(map_list)
    df_map['state'].fillna('NO STATE FOUND', inplace=True)
    df_map['CITY'].fillna('NO CITY FOUND', inplace=True)
    df_map['country'].fillna('NO COUNTRY FOUND', inplace=True)
    df_map['CONTACT_NUMBER'].fillna('NO CONTACT FOUND', inplace=True)
    df_map=df_map.replace("UNITED STATES","United States")
    df_map=df_map.replace("US","United States")
    df_map=df_map.replace("us","United States")
    df_map=df_map.replace("USA","United States")
    df_map=df_map.replace("Usa","United States")
    df_map=df_map.replace("U.S.A","United States")
    reader = geolite2.reader()
    def country1(i):
        location =reader.get(i)
        c=(location['country']['names']['en'])
        return c
    def state1(i):
        location =reader.get(i)
        s=(location['subdivisions'][0]['names']['en'])
        return s
    def pn_country(i):
        import phonenumbers
        import pycountry
        from phonenumbers.phonenumberutil import (
        region_code_for_country_code,
        region_code_for_number,)
        pn = phonenumbers.parse('+'+i)   
        country = pycountry.countries.get(alpha_2=region_code_for_number(pn))
        con=country.name
        return con
    state=df_map['state'].tolist()
    country=df_map['country'].tolist()
    CITY=df_map['CITY'].tolist()
    ip=df_map['IP_address'].tolist()
    phone_number=df_map['CONTACT_NUMBER'].tolist()
    for i in range(len(ip)):
        if state[i] == 'NO STATE FOUND':
            try:
                state[i]=state1(ip[i])
            except:
                pass
    state12 =[each_string.lower() for each_string in state]
    stateshortnew=list(map(statesshort.get, state12))
    cv={'ss':stateshortnew,'st':state,'co':country, 'ph':phone_number,'ct':CITY}
    dftry = pd.DataFrame.from_dict(cv)
    dftry2=dftry['ss'].value_counts().reset_index()
    dftry2
    # dftry2['ss'].sum()
    data=[]
    for i, j in zip(dftry2['index'], dftry2['ss']):
        try:
            data.append({"code":i, "value":j,'hc-key':'us-'+i})
        except:
            pass
    return json.dumps(data)

@app.route('/dashcount')
def dashcount():
    totalschool=3864

    aftercsy=293
    beforecsy=1522
    expcsy=385
    upexcsy=1664
    totalstudents=1016064
    totalclassroom=36288
    totaluserbase=40630
    power=2225
    dormant=32612
    passive=2848
    active=2945
    neverlogged=23790
    mindmin=8128512
    activeschool=2945
    
    passiveper=(round((passive/totaluserbase)*100))
    activeper=(round((active/totaluserbase)*100))
    powerper=(round((power/totaluserbase)*100))
    dormantper=(round((dormant/totaluserbase)*100))
    year=(round(((mindmin/60)/24)/365))
    temp={'activeschool':[str(activeschool)],'passiveper':passiveper,'year':year,'dormantper':dormantper,'activeper':[str(activeper)],'powerper':[str(powerper)],'totalschool':[str(totalschool)],'aftercsy':[str(aftercsy)],'beforecsy':[str(beforecsy)],
          'expcsy':[str(expcsy)],"upexcsy":[str(upexcsy)],'totalstudents':[str(totalstudents)],
          'totalclassroom':[str(totalclassroom)],'totaluserbase':[str(totaluserbase)],
          'power':[str(power)],'neverlogged':[str(neverlogged)],'mindmin':[str(mindmin)],"usa":["3600"],'other':["163"],'india':["9"],'mexico':["31"],'canada':["61"],'dormant':[str(dormant)],'passive':[str(passive)],'active':[str(active)]}
    return json.dumps(temp)



@app.route('/mongo/<district>')   
def mongo_spider(district):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.user_master.aggregate([
    {"$match":{"schoolId":{"$exists":1}}},
    {"$match":
        {"$and":[
        {"DISTRICT_ID._id":ObjectId(""+district+"")},
         {"schoolId._id":{"$in":db.school_master.distinct( "_id",  {"IS_PORTAL":"Y"} )}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME",
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME"}}

    ])
    df1= DataFrame(list(collection)).fillna(0)
    user_list=df1["USER_ID"].tolist()
    collection1=db.login_logs.aggregate([{"$match":{"USER_ID._id":{
                        "$in":user_list

                    }    ,"USER_ID.schoolId":{"$exists":1}}},
    {"$group":{"_id":"$USER_ID._id",
            "count":{"$sum":1},
            }},
    {"$project":{"_id":0,"USER_ID":"$_id","count(last_logged_in)":"$count"}}
            ])
    df2= DataFrame(list(collection1)).fillna(0)
    collection2 = db.audio_track_master.aggregate([
    {"$match":{"USER_ID._id":{
                        "$in":user_list

                    }    ,"USER_ID.schoolId":{"$exists":1}}},
    {"$match":
        {"$and":[
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'MODIFIED_DATE':{"$gt":datetime.datetime(2019,7,31)}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$group":{"_id":{"USER_ID":"$USER_ID._id"},
            "NEW":{"$addToSet":"$USER_ID._id"},
            "count":{"$sum":1},
            "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
            }},
        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","practice_count12":"$count"}}

    ])
    df3= DataFrame(list(collection2)).fillna(0)
    #####################CLEVER#######################
    collection3 = db.user_master.aggregate([
    {"$match":{"schoolId":{"$exists":1}}},
    {"$match":
        {"$and":[ 
            {"_id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                  {"DISTRICT_ID._id":ObjectId(""+district+"")},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME",
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME"}}

    ])
    dfclever= DataFrame(list(collection3)).fillna(0)
    if dfclever.empty == True:
        column_names1 = ["ID","USER_ID","school_name","email_id","district_name","count(last_logged_in)","practice_count12","role_type"]
        final1clever = pd.DataFrame(columns = column_names1)
    else:
        user_list1=dfclever["USER_ID"].tolist()
        collection4=db.login_logs.aggregate([{"$match":{"USER_ID._id":{
                            "$in":user_list1

                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$group":{"_id":"$USER_ID._id",
                "count":{"$sum":1},
                }},
        {"$project":{"_id":0,"USER_ID":"$_id","count(last_logged_in)":"$count"}}
                ])
        dfcleverlog= DataFrame(list(collection4)).fillna(0)
        collection5 = db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list1

                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$match":
            {"$and":[
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":datetime.datetime(2019,7,31)}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
        {"$match":
        {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        {"$group":{"_id":{"USER_ID":"$USER_ID._id"},
                "NEW":{"$addToSet":"$USER_ID._id"},
                "count":{"$sum":1},
                "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
                }},
            {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","practice_count12":"$count"}}

        ])
        dfcleverprac= DataFrame(list(collection5)).fillna(0)
        finalclever=pd.merge(dfclever, dfcleverlog, on='USER_ID',how='left').fillna(0)
        final1clever=pd.merge(finalclever, dfcleverprac, on='USER_ID',how='left').fillna(0)
        final1clever["role_type"]="CLEVER"
    ######################################################################################

    #####################schoology#######################
    collection6 = db.user_master.aggregate([
    {"$match":{"schoolId":{"$exists":1}}},
    {"$match":
        {"$and":[
            {"_id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                  {"DISTRICT_ID._id":ObjectId(""+district+"")},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME",
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME"}}
    ])
    dfschoology= DataFrame(list(collection6)).fillna(0)
    if dfschoology.empty == True:
        column_names = ["ID","USER_ID","school_name","email_id","district_name","count(last_logged_in)","practice_count12","role_type"]
        final1schoology = pd.DataFrame(columns = column_names)
    else:
        user_list2=dfschoology["USER_ID"].tolist()
        collection7=db.login_logs.aggregate([{"$match":{"USER_ID._id":{
                            "$in":user_list2

                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$group":{"_id":"$USER_ID._id",
                "count":{"$sum":1},
                }},
        {"$project":{"_id":0,"USER_ID":"$_id","count(last_logged_in)":"$count"}}
                ])
        dfschoologylog= DataFrame(list(collection7)).fillna(0)
        collection8 = db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list2

                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$match":
            {"$and":[
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":datetime.datetime(2019,7,31)}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
        {"$match":
        {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        {"$group":{"_id":{"USER_ID":"$USER_ID._id"},
                "NEW":{"$addToSet":"$USER_ID._id"},
                "count":{"$sum":1},
                "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
                }},
            {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","practice_count12":"$count"}}

        ])
        dfschoologyprac= DataFrame(list(collection8)).fillna(0)
        finalschoology=pd.merge(dfschoology, dfschoologylog, on='USER_ID',how='left').fillna(0)
        final1schoology=pd.merge(finalschoology, dfschoologyprac, on='USER_ID',how='left').fillna(0)
        final1schoology["role_type"]="SCHOOLOGY"
    ######################################################################################
    final=pd.merge(df1, df2, on='USER_ID',how='left').fillna(0)
    final1=pd.merge(final, df3, on='USER_ID',how='left').fillna(0)
    final1["role_type"]="IE"
    final2 = pd.concat([final1, final1clever], ignore_index=True, sort=False)
    final3 = pd.concat([final2, final1schoology], ignore_index=True, sort=False)
    df=final3[["ID","USER_ID","school_name","email_id","district_name","count(last_logged_in)","practice_count12","role_type"]]
    df['practice_count12'].fillna(0, inplace = True)
    df['practice_count12'] = df['practice_count12'].apply(np.int64)
    df['district_name'] = df['district_name'].str.capitalize() 
    dfdd=df[['district_name','practice_count12']]
    dfdd1=dfdd.groupby(['district_name'])['practice_count12'].sum().reset_index()
    links0 = dfdd1.rename(columns={'district_name' : 'name', 'practice_count12' : 'Practice Count'}).to_dict('r')
    df1=df[['email_id','practice_count12','count(last_logged_in)','role_type']]
    df1.rename(columns = {'count(ll.last_logged_in)':'login'}, inplace = True) 
    df1.loc[(df1['practice_count12'] > 50) , 'hex'] = '#006400' #Power
    df1.loc[(df1['practice_count12'] > 6) & (df1['practice_count12'] <= 50), 'hex'] = '#00a651'  #ACTIVE
    df1.loc[(df1['practice_count12'] > 0) & (df1['practice_count12'] <= 6), 'hex'] = '#fff44f'  #PASSIVE
    df1.loc[(df1['practice_count12'] == 0) & (df1['practice_count12'] == 0), 'hex'] = '#ff8300' #DROMANT
    if dfclever.empty == True:
        print("HELLO")
    else:
        df1.loc[(df1['role_type'] == "CLEVER") & (df1['role_type'] == "CLEVER"), 'hex'] = '#0023FF' #CLEVER
    if dfschoology.empty == True:
        print("HELLO1")
    else:
        df1.loc[(df1['role_type'] == "SCHOOLOGY") & (df1['role_type'] == "SCHOOLOGY"), 'hex'] = '#00FFEC' #SCHOOLOGY
    df2=df1[['email_id','hex']]
    links = df2.rename(columns={'email_id' : 'name', 'hex' : 'hex'}).to_dict('r')
    dfdatas=df[['school_name','practice_count12','ID']]
    dfdata2=dfdatas.groupby(['ID','school_name'])['practice_count12'].sum().reset_index()
    dfdata3=dfdata2[['school_name','practice_count12']]
    links1 = dfdata3.rename(columns={'school_name' : 'name', 'practice_count12' : 'Practice Count'}).to_dict('r')
    dfdatae=df[['email_id','practice_count12']]
    links2 = dfdatae.rename(columns={'email_id' : 'name', 'practice_count12' : 'Practice Count'}).to_dict('r')
    links0.extend(links1)
    links0.extend(links2)
    dfst=df[['school_name','email_id']]
    links3 = dfst.rename(columns={'school_name' : 'source', 'email_id' : 'target'}).to_dict('r')
    df4=df[['district_name','school_name','ID']]
    df5 = df4.drop_duplicates(subset='ID', keep="first")
    df6=df5[['district_name','school_name']]
    links4 = df6.rename(columns={'district_name' : 'source', 'school_name' : 'target'}).to_dict('r')
    results = []
    for n in links3:
        for m in links4:
            if m['target']==n['source']:
                results.append(m)
    res_list = [i for n, i in enumerate(results) if i not in results[n + 1:]] 

    for n in links3:
        for m in res_list:
            if m['target']==n['source']:
                res_list.append(n)
    temp={"nodes":links0,"links":res_list,"attributes":links}
    return(json.dumps(temp))


@app.route('/sfeedbackcards')
def schoolfeedbackcards():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    query=[{"$match":{'$and':[{'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
          {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
          {'USER_ID.IS_DISABLED':{"$ne":'Y'}}
         ]}},
                              
         {"$project":{"_id":0, "USER_ID":'$USER_ID.USER_ID','MODIFIED_DATE':1}}]
    query2=[
     {"$match":{'$and':[{'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER.IS_DISABLED":{"$ne":"Y"}},
         { "USER.IS_BLOCKED":{"$ne":"Y"}},
        { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'RATING':{'$ne':0}}]}},
        
            {"$project":{'RATING':1,'COMMENT':1,'USER_ID':'$USER.USER','USER_NAME':'$USER.USER_NAME','EMAIL':'$USER.EMAIL_ID'}}]
    practice=list(collection.aggregate(query))
    practice_df=pd.DataFrame(practice)
    feedback=list(collection2.aggregate(query2))
    feedback_df=pd.DataFrame(feedback)
    card_df=pd.DataFrame({'Feedback_Percentage':(len(feedback_df[feedback_df['RATING']!=0])/len(practice_df))*100,
                 'Comment_per_feedback':len(feedback_df[(feedback_df['COMMENT'].notnull()) & (feedback_df['COMMENT']!='') ])/
                 len(feedback_df[feedback_df['RATING']!=0])*100,
                  'Total_Playbacks':len(practice_df),'Average_Rating':feedback_df[feedback_df['RATING']!=0]['RATING'].mean()},
                  index=[0])
    temp={}
    for j in range(len(card_df.columns)):
        key = card_df.columns[j]
        value = [str(card_df[card_df.columns[j]].iloc[0])]
        temp.update({key:value})
#     print(temp)
    return json.dumps(temp)
# schoolfeedbackcards()


@app.route('/schoolfeedbackrating')
def schoolrating():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback
    df = DataFrame(list(collection.aggregate([
     {"$match":{'$and':[{'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER.IS_DISABLED":{"$ne":"Y"}},
         { "USER.IS_BLOCKED":{"$ne":"Y"}},
        { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'RATING':{'$ne':0}}]}},
        
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
    'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
    'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}}
    }},
    {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3', 'rating_2':'$rating_2','rating_1':'$rating_1' }}
    ])))
    df.rename(columns = { '_id': 'Month'}, inplace = True)
    d = dict(enumerate(calendar.month_abbr))    # to convert monthnumber of dataframe into monthname
    df['Month'] = df['Month'].map(d)
    df1=Sort_Dataframeby_MonthandNumeric_cols(df = df, monthcolumn='Month',numericcolumn='rating_5')
    df1['Month'] = df1['Month'].astype(str).str[:3]
    # df2f=df1.rename(columns={"_id": "Month"})
    Month= ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
    df2t = pd.DataFrame(Month,columns =['Month'])
    df2 = pd.merge(df2t, df1, on="Month", how='left').fillna(0)
    df3=df2.agg({'rating_5': 'sum', 'rating_4': 'sum','rating_3': 'sum','rating_2': 'sum','rating_1': 'sum'})
    df4 = pd.DataFrame()
    df5=df4.append(df3, ignore_index = True) 
    df6=df5[['rating_5','rating_4','rating_3','rating_2','rating_1']] #arranging rating5 to rating1
    df7=df2[['Month','rating_1']]
    df8=df2[['Month','rating_2']]
    df9=df2[['Month','rating_3']]
    df10=df2[['Month','rating_4']]
    df11=df2[['Month','rating_5']]
    D_1= df7.values.tolist()
    D_2= df8.values.tolist()
    D_3= df9.values.tolist()
    D_4= df10.values.tolist()
    D_5= df11.values.tolist()
    links = df6.rename(columns={'rating_5' : 'S5', 'rating_4' : 'S4','rating_3' : 'S3', 'rating_2' : 'S2', 'rating_1' : 'S1'}).to_dict('r')
    temp={'Total':links,'D5':D_5,'D4':D_4,'D3':D_3,'D2':D_2,'D1':D_1}
    return json.dumps(temp)
    #print(temp)

@app.route('/dailychart')
def daily_survey():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.survey_questions

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    df = DataFrame(list(collection.aggregate([{
        '$lookup':{'from':'survey_answers', 'localField':'QUESTION_ID', 
                   'foreignField':'QUESTION_ID.QUESTION_ID', 'as':'sa'}},
        {'$unwind':'$sa'},
        {'$match':{'sa.USER_ID.USER_NAME':{'$not':{'$regex':'test', '$options':'i'}}, 
                   'sa.USER_ID.IS_DISABLED':{'$ne':'Y'},
                   'sa.USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}, 
                   'sa.USER_ID.CREATED_DATE':{'$gt':myDatetime},
                   'sa.USER_ID.INCOMPLETE_SIGNUP':{'$ne':'Y'}, 
                   'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}}},
        {"$match":
         {"$and":[
             {'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}]}},
        {"$group":{"_id":{'day':{'$dayOfMonth':'$sa.CREATED_DATE'}, 
                      'month':{'$month':'$sa.CREATED_DATE'}, 
                      'year':{'$year':'$sa.CREATED_DATE'}},
                 'date':{"$first":'$sa.CREATED_DATE'}, 'Count':{"$addToSet":'$sa.USER_ID.USER_ID'}}},
        {"$project":{"_id":0, 'Date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}},
                     'Count':{"$size":'$Count'}}},
        {"$sort":{'Date':1}}])))

    df.Date=pd.to_datetime(df.Date)
    dates=pd.date_range('2020-04-26',date.today(),freq='d')
    datedf=pd.DataFrame(dates,columns=['Date'])
    df1=datedf.merge(df,how='left',on='Date').fillna(0)
    df1.Date=df1.Date.astype(np.int64)/int(1e6)
    df1['Cumulative']=df1['Count'].cumsum()
    df_count=df1[['Date','Count']]
    df_cum=df1[['Date','Cumulative']]
    temp={'data':{'Survey_Count':df_count.values.tolist(),'Cumulative':df_cum.values.tolist()}}
    return json.dumps(temp)

@app.route('/hourchart')
def hourly_survey():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.survey_questions

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    df = DataFrame(list(collection.aggregate([{
        '$lookup':{'from':'survey_answers', 'localField':'QUESTION_ID', 'foreignField':'QUESTION_ID.QUESTION_ID', 'as':'sa'}}, 
        {'$unwind':'$sa'},
        {'$match':{'sa.USER_ID.USER_NAME':{'$not':{'$regex':'test', '$options':'i'}}, 
                   'sa.USER_ID.IS_DISABLED':{'$ne':'Y'},
                   'sa.USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}, 
                   'sa.USER_ID.CREATED_DATE':{'$gt':myDatetime},
                   'sa.USER_ID.INCOMPLETE_SIGNUP':{'$ne':'Y'}, 
                   'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}}},
        {"$match":
         {"$and":[{'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}]}},
        {"$group":{"_id":{'hour':{'$hour':'$sa.CREATED_DATE'}},
                 'date':{"$first":'$sa.CREATED_DATE'}, 'Count':{"$addToSet":'$sa.USER_ID.USER_ID'}}},
        {"$project":{"_id":0, 'Hour':{"$dateToString":{"format":"%H","date":'$date'}},'Count':{"$size":'$Count'}}},
        {"$sort":{'Hour':1}}])))

    for i in range(len(df)):
        df['Hour'][i] = int(df['Hour'][i])

    hour=np.arange(0,24,1).tolist()
    hourdf=pd.DataFrame(hour,columns=['Hour'])
    df1=hourdf.merge(df,how='left',on='Hour').fillna(0)
    temp={'data':{'Hour':df1.Hour.tolist(),'Survey_Count':df1.Count.tolist()}}
    return json.dumps(temp)

@app.route('/queschart')
def question_analysis():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.survey_questions

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    df = DataFrame(list(collection.aggregate([{
        '$lookup':{'from':'survey_answers', 'localField':'QUESTION_ID', 'foreignField':'QUESTION_ID.QUESTION_ID', 'as':'sa'}}, 
        {'$unwind':'$sa'},
        {'$match':{'sa.USER_ID.IS_DISABLED':{'$ne':'Y'},
                   'sa.USER_ID.ROLE_ID.ROLE_ID':{'$eq':3}, 
                   'sa.USER_ID.CREATED_DATE':{'$gt':myDatetime},
                   'sa.USER_ID.INCOMPLETE_SIGNUP':{'$ne':'Y'}}},
        {"$match":
         {"$and":[{'sa.USER_ID.USER_NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                  {'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}}},
                  {'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}]}},
        {"$unwind":'$PROGRAM_ID'},
        {'$replaceRoot':{"newRoot":{"$mergeObjects":["$$ROOT", "$PROGRAM_ID"] }}},
        {"$project":{'QUESTION_ID':1,'QUESTION':1, 'ANSWER_COUNT':1, 'PROGRAM_ID':1, 
                   'PROGRAM_NAME':1, 'sa.ANSWER':1, 'sa.USER_ID.USER_ID':1}}, {"$sort":{'QUESTION_ID':1}}])))

    df_1 = df['sa']
    df_1 = pd.json_normalize(df['sa'])
    df_final = pd.concat([df,df_1], axis =  1)

    del df_final['_id'], df_final['sa']


    df_2 = DataFrame(list(collection.aggregate([
        {"$group":{"_id":{'PROGRAM_ID':'$PROGRAM_ID.PROGRAM_ID', 'PROGRAM_NAME':'$PROGRAM_ID.PROGRAM_NAME'}, 
                 'Total_Question':{"$addToSet":'$QUESTION_ID'}}},
        {"$project":{"_id":1,'Total_Question':{"$size":'$Total_Question'}}},
        {"$sort":{'_id':1}}])))

    df_1_2 = df_2['_id']
    df_1_2 = pd.json_normalize(df_2['_id'])
    df_final_2 = pd.concat([df_2,df_1_2], axis =  1)

    del df_final_2['_id']


    df_final["ANSWER"] = df_final["ANSWER"].astype(str).astype('int64')
    ques_no_Prek=list(range(1,13))
    ques_no_mid=list(range(1,15))

    df2=df_final.groupby(['QUESTION_ID','PROGRAM_ID']).aggregate(['mean','median'])['ANSWER'].reset_index()
    df3=df2.loc[(df2['PROGRAM_ID'] == 1)]
    df4=df2.loc[(df2['PROGRAM_ID'] == 3)]

    #df3["median"] = df3["median"]
    #df4["median"] = df4["median"]

    prek_mean=df3['mean'].round(2).tolist()
    prek_median=df3['median'].round(2).tolist()
    prek_tolal_ques=df3['QUESTION_ID'].count().tolist()
    mdl_mean=df4['mean'].round(2).tolist()
    mdl_median=df4['median'].round(2).tolist()
    middle_tolal_ques=df4['QUESTION_ID'].count().tolist()
    temp={'Pre_K':{'Question_No':ques_no_Prek,'Mean':prek_mean,'Median':prek_median,
                   'Total_Question':prek_tolal_ques},'Middle':{'Question_No':ques_no_mid,'Mean':mdl_mean,
                                                               'Median':mdl_median,'Total_Question':middle_tolal_ques}}
    return json.dumps({'Question_Data':temp})

@app.route('/quesattempt')
def ques_count():


    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.survey_questions

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    df = DataFrame(list(collection.aggregate([{
        '$lookup':{'from':'survey_answers', 'localField':'QUESTION_ID', 'foreignField':'QUESTION_ID.QUESTION_ID', 'as':'sa'}}, 
        {'$unwind':'$sa'},
        {'$match':{'sa.USER_ID.USER_NAME':{'$not':{'$regex':'test', '$options':'i'}}, 
                   'sa.USER_ID.IS_DISABLED':{'$ne':'Y'},
                   'sa.USER_ID.ROLE_ID.ROLE_ID':{'$eq':3}, 
                   'sa.USER_ID.CREATED_DATE':{'$gt':myDatetime},
                   'sa.USER_ID.INCOMPLETE_SIGNUP':{'$ne':'Y'}, 
                   'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}},
                   'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}},
        {'$unwind':"$PROGRAM_ID"},{'$replaceRoot':{"newRoot":{"$mergeObjects":["$$ROOT", "$PROGRAM_ID"] }}},
        {'$project':{'QUESTION':1, 'PROGRAM_ID':1, 'PROGRAM_NAME':1, 'sa.USER_ID.USER_ID':1}}, 
        {'$group':{'_id':{'QUESTION':'$QUESTION', 'PROGRAM_ID':'$PROGRAM_ID', 'PROGRAM_NAME':'$PROGRAM_NAME'},
                   'Count':{'$addToSet':'$sa.USER_ID.USER_ID'}}},
        {'$project':{'_id':1, 'QUESTION':1, 'PROGRAM_ID':1, 'PROGRAM_NAME':1, 'Count':{'$size':'$Count'}}}, 
        {"$sort":{'PROGRAM_ID':1}}])))

    df1 = df['_id']
    df1 = pd.json_normalize(df['_id'])
    df_final = pd.concat([df1,df], axis =  1)
    del df_final['_id']

    df2=df_final.loc[(df_final['PROGRAM_ID'] == 1)]
    df3=df_final.loc[(df_final['PROGRAM_ID'] == 3)]
    ques_no_prek=list(range(1,13))
    prek_ques=list(df2.QUESTION)
    prek_attempt_count=list(df2.Count)
    ques_no_mid=list(range(1,15))
    midl_ques=list(df3.QUESTION)
    midl_attempt_count=list(df3.Count)
    temp={'PreK':{'Q_No_Prek':ques_no_prek,'Ques_Attempt_Prek':prek_attempt_count},'Middle':{
        'Q_No_Midl':ques_no_mid,'Ques_Attempt_Midl':midl_attempt_count}}
    return json.dumps({'data':temp})

@app.route('/responseanalysis')
def response_analysis():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.survey_questions

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    df = DataFrame(list(collection.aggregate([{
        '$lookup':{'from':'survey_answers', 'localField':'QUESTION_ID', 'foreignField':'QUESTION_ID.QUESTION_ID', 'as':'sa'}}, 
        {'$unwind':'$sa'},
        {'$match':{'sa.USER_ID.USER_NAME':{'$not':{'$regex':'test', '$options':'i'}}, 
                   'sa.USER_ID.IS_DISABLED':{'$ne':'Y'},
                   'sa.USER_ID.ROLE_ID.ROLE_ID':{'$eq':3}, 
                   'sa.USER_ID.CREATED_DATE':{'$gt':myDatetime},
                   'sa.USER_ID.INCOMPLETE_SIGNUP':{'$ne':'Y'}, 
                   'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}},
                   'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}},
        {"$unwind":'$PROGRAM_ID'},
        {'$replaceRoot':{"newRoot":{"$mergeObjects":["$$ROOT", "$PROGRAM_ID"] }}},
        {"$project":{'QUESTION_ID':1,'QUESTION':1, 'ANSWER_COUNT':1, 'PROGRAM_ID':1, 'PROGRAM_NAME':1, 
                   'sa.ANSWER':1, 'sa.USER_ID.USER_ID':1   }}, {"$sort":{'QUESTION_ID':1}}])))
    df_1 = df['sa']
    df_1 = pd.json_normalize(df['sa'])
    df_final = pd.concat([df,df_1], axis =  1)

    del df_final['_id'], df_final['sa']
    df_final.rename({"USER_ID.USER_ID" : "USER_ID"})

    googleSheetId = '1kPoj_0p_03-k3dOvUlRkHjJRJ0PgpNNv9yIEW-dCWIw'
    worksheetName = 'Survey_positive'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    positivedf = pd.read_csv(URL)


    df1=df_final.merge(positivedf,how='left',on='QUESTION_ID')
    df1.ANSWER=df_final.ANSWER.astype('int64')
    df1['Positive_Proportion']=np.where(df1.Positive_Value>df1.ANSWER,df1.ANSWER/df1.Positive_Value,df1.Positive_Value/df1.ANSWER)
    df1['Response_Type']=np.where(df1.Positive_Proportion<=.4,'Negative',np.where(df1.Positive_Proportion>=.6,'Positive','Neutral'))
    Percent=[len(df1[df1['Response_Type']=='Negative'])/len(df1.Response_Type)*100,len(df1[df1['Response_Type']=='Neutral'])/len(df1.Response_Type)*100, len(df1[df1['Response_Type']=='Positive'])/len(df1.Response_Type)*100]
    Percent1=list(np.around(np.array(Percent),3))
    Response_Type=['Negative','Neutral','Positive']
    temp={'data':{'Response_Type':Response_Type,'Proportion':Percent1}}
    return json.dumps({'data':{'Response_Type':Response_Type,'Proportion':Percent1}})

@app.route('/surveycard')
def cards_data():

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    collection = db.survey_questions

    dateStr = "2020-03-17T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)

    df = DataFrame(list(collection.aggregate([
        {'$lookup':{'from':'survey_answers', 'localField':'QUESTION_ID', 'foreignField':'QUESTION_ID.QUESTION_ID', 'as':'sa'}},
        {'$unwind':'$sa'},
        {'$match':{'sa.USER_ID.USER_NAME':{'$not':{'$regex':'test', '$options':'i'}}, 
                   'sa.USER_ID.IS_DISABLED':{'$ne':'Y'},
                   'sa.USER_ID.ROLE_ID.ROLE_ID':{'$eq':3}, 
                   'sa.USER_ID.CREATED_DATE':{'$gt':myDatetime},
                   'sa.USER_ID.INCOMPLETE_SIGNUP':{'$ne':'Y'}, 
                   'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'test', '$options':'i'}},
                   'sa.USER_ID.EMAIL_ID':{'$not':{'$regex':'1gen', '$options':'i'}}}},
        {'$project':{'Created_date': {'$dateToString': { 'format': "%Y-%m-%d", 'date': "$sa.CREATED_DATE" } }, 
                     'sa.USER_ID.USER_ID':1, 
                     'sa.USER_ID.USER_NAME':1,
                     'sa.USER_ID.EMAIL_ID':1, 'sa.USER_ID.CONTACT_NUMBER':1, 
                     'QUESTION_ID':1, 'sa.CREATED_DATE':1, 'PROGRAM_ID.PROGRAM_ID':1, 'PROGRAM_ID.PROGRAM_NAME':1,
                     'sa.schoolId.NAME':1, 'sa.CREATED_DATE':1}},
        {'$group':{'_id':{'user_id':'$sa.USER_ID.USER_ID','PROGRAM_ID':'$PROGRAM_ID.PROGRAM_ID', 'Created_date':'$Created_date'}, 
                   'Attempted_Questions':{'$addToSet':'$QUESTION_ID'},
                   'Survey_End':{'$max':'$sa.CREATED_DATE'}, 'Survey_Start':{'$min':'$sa.CREATED_DATE'}}},
        {'$project':{'_id':1, 'Attempted_Questions':{'$size':'$Attempted_Questions'}, 
                     'Survey_End':'$Survey_End', 'Survey_Start':'$Survey_Start', 
                     "survey_time": {'$divide':[{"$subtract": ["$Survey_End","$Survey_Start" ]}, 1000]}}},
        {'$group':{'_id':0, 'Total_Survey_Taken':{'$sum':1}, 'Total_Parents_Surveyed':{'$addToSet':'$_id.user_id'}, 
                   'PreK_Parents_Surveyed':{'$sum':{'$cond':[{'$eq': ["$_id.PROGRAM_ID", 1]},1,0]}}, 
                   'Middle_Parents_Surveyed':{'$sum':{'$cond':[{'$eq': ["$_id.PROGRAM_ID", 3]},1,0]}}}}, 
        {'$project':{'_id':0, 'Total_Survey_Taken':'$Total_Survey_Taken', 
                     'Total_Parents_Surveyed':{'$size':'$Total_Parents_Surveyed'}, 
                     'PreK_Parents_Surveyed':'$PreK_Parents_Surveyed', 
                     'Middle_Parents_Surveyed':'$Middle_Parents_Surveyed'}}])))

    data=[]
    for i,j in zip(df.columns.tolist(),df.iloc[0].tolist()):
        data.append([i,j])

    temp={"data":data}
    return json.dumps(temp)

@app.route('/modetype/<startdate>/<enddate>')
# @app.route('/modetype/<startdate>/<enddate>')
def Payment_Mode(startdate,enddate):
    date1=startdate
    date2=enddate
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    if(len(date1) == 0): 
        startdate1='2020-07-01'
    else : 
        startdate1=date1
    if(len(date2) == 0):
        enddate1=d1
    else : 
        enddate1=date2
    googleSheetId = '1ydZC5Q5cNBlPb2rI_lzcdL0lh7r7rvuSzDYxCDNseyw'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection1 = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection1))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc = db.subscription_master.aggregate([
    {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
        {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
                     {'USER_ID':{'$exists':1}}  ,  
            {"LAST_PAYMENT_DATE":{"$gte":myDatetime}},
            {"IS_PAYMENT_SUCCESS" : "Y"},
            {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
    }},
    {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
    "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},"Payment_Amount":"$LAST_PAYMENT_AMOUNT",
    "EMAIL_ID":"$USER_ID.EMAIL_ID"}}
    ,{"$unwind":"$Last_Payment_Date"}
    ])
    payment_df1= DataFrame(list(mydoc))
#     payment_df1= payment_df1.fillna('NO INFO')
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1['DEVICE_USED']= payment_df1['DEVICE_USED'].fillna('NO INFO')
    payment_df1['MODE_OF_PAYMENT']= payment_df1['MODE_OF_PAYMENT'].fillna('NO INFO')
    payment_df1['SCHOOL']= payment_df1['SCHOOL'].fillna('NO INFO')
    payment_df1['USER_NAME']= payment_df1['USER_NAME'].fillna('NO INFO')
    payment_df1['EMAIL_ID']= payment_df1['EMAIL_ID'].fillna('NO INFO')
#     payment_df1= payment_df1.fillna('NO INFO')
#     payment_df1= payment_df1.fillna('')
    payment_df1.replace(to_replace="NULL",value="NO INFO",inplace=True)
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
        'MONTGOMERY UPPER MIDDLE SCHOOL',
        'RIVER VALLEY ELEMENTARY',
        'ALTURA PREPARATORY SCHOOL',
        'TWO BUNCH PALMS ELEMENTARY',
        'MELISSA MIDDLE SCHOOL',
        'MONTGOMERY LOWER MID SCH',
        'HATTIE DYER ELEMENTARY SCHOOL',
        'STOCKDALE JUNIOR HIGH',
        'INYO COUNTY COMMUNITY SCHOOL',
        'DESERT HOT SPRINGS HIGH',
        'SEMINOLE HIGH SCHOOL',
        'FRANKLIN WOODS INTERMEDIATE SCHOOL',
        'MARY B. LEWIS ELEMENTARY',
        'MCMILLIN (CORKY) ELEMENTARY',
        'ELGIN MIDDLE',
        'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
        'ODYSSEY ELEMENTARY',
        'FORT MEADOW ECC',
        'NO INFO',
        'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
        'BRIGHTON HIGH',
        'MARY M WALSH',
        'THE CAPITOL SCHOOL',
        'DR. DANIEL BRIGHT SCHOOL',
        'ROCK POINT COMMUNITY SCHOOL',
        'MURNIN ES',
        'SUNNY SANDS ELEMENTARY',
        'THOMAS JEFFERSON MIDDLE SCHOOL',
        'BENJAMIN FRANKLIN MIDDLE SCHOOL',
        'FAIRMONT CHARTER ELEMENTARY',
        'BLAIR ELEMENTARY SCHOOL',
        'L.A. MORGAN ELEMENTARY',
        'KRUM EARLY EDUCATION CENTER',
        'AMANDA HOPE RAINBOW ANGLES(NPO)',
        'STONY BROOK ELEMENTARY',
        'ROSE SPRINGS ELEMENTARY',
        'MT. BALDY JOINT ELEMENTARY',
        'LIBERTY HILLS ELEMENTARY',
        'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df3=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df1=payment_df3.append(dfd1)
    payment_df=payment_df1.append(payment_df2)

    # payment_df.Payment_Amount = payment_df.Payment_Amount.round()
    payment_df['DEVICE_USED'] = payment_df['DEVICE_USED'].str.upper() 
    payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.upper()
    payment_df['DEVICE_USED'] = payment_df['DEVICE_USED'].str.upper()
    payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("POMOCODE", "PROMOCODE")
    payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("SQUAREPAYMENT", "SQUARE PAYMENT")
    payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("INVITED_USER", "INVITED USER")
    payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("INVITEDUSER", "INVITED USER")
    payment_df['Last_Payment_Date'] =  pd.to_datetime(payment_df['Last_Payment_Date'])
    newdf1=payment_df[(payment_df.Last_Payment_Date >= startdate1) & (payment_df.Last_Payment_Date <= enddate1)]
    dm=pd.DataFrame({"TYPE_OF_PAYMENT": ["FOUNDATION", "DISTRICT", "SCHOOL", "DONATION", "MOBILE"]})
    df1web=newdf1[['USER_NAME',"EMAIL_ID",'DEVICE_USED','MODE_OF_PAYMENT','TYPE_OF_PAYMENT','Last_Payment_Date','Payment_Amount']]
    df1web['Last_Payment_Date'] = pd.to_datetime(df1web['Last_Payment_Date'])
    df1web=pd.merge(dm,df1web, on='TYPE_OF_PAYMENT',how='left').fillna(0)
    df1web=df1web.fillna(0)
    dm=pd.DataFrame({"TYPE_OF_PAYMENT": ["FOUNDATION", "DISTRICT", "SCHOOL", "DONATION", "MOBILE"]})
    df2web= df1web.groupby(['TYPE_OF_PAYMENT'])['Payment_Amount'].sum().reset_index()
    df2web=pd.merge(dm,df2web, on='TYPE_OF_PAYMENT',how='left').fillna(0)
    df3web= df1web.groupby(['TYPE_OF_PAYMENT'])['Payment_Amount'].count().reset_index()
    df3web=pd.merge(dm,df3web, on='TYPE_OF_PAYMENT',how='left').fillna(0)
    df4web= df1web.groupby(['TYPE_OF_PAYMENT'])
    df1web.to_csv("revenaue.csv",index=False)
    donation=df4web.get_group('DONATION')
    donation.to_csv("donation.csv",index=False)
    school=df4web.get_group('SCHOOL')
    school.to_csv("school.csv",index=False)
    foundation=df4web.get_group('FOUNDATION')
    foundation.to_csv("foundation.csv",index=False)
    district=df4web.get_group('DISTRICT')
    district.to_csv("district.csv",index=False)
    mobile=df4web.get_group('MOBILE')
    mobile.to_csv("mobile.csv",index=False)
    df3web.sort_values(by=['Payment_Amount'], inplace=True, ascending=False)
    df2web.sort_values(by=['Payment_Amount'], inplace=True, ascending=False)
    df2web.Payment_Amount = df2web.Payment_Amount.round()
    Payment_Mode_amount=df2web['TYPE_OF_PAYMENT'].values.tolist()
    Payment_Mode_user=df3web['TYPE_OF_PAYMENT'].values.tolist()
    Payment_Mode_Amount=df2web['Payment_Amount'].values.tolist()
    Payment_Mode_User=df3web['Payment_Amount'].values.tolist()
    temp={"amount":{"Payment_Mode":Payment_Mode_amount,"Payment_Mode_Amount":Payment_Mode_Amount},"user": {"Payment_Mode":Payment_Mode_user,"Payment_Mode_User":Payment_Mode_User}}
    return (json.dumps(temp))





@app.route('/revenauetable/<type>')
def revenue_table(type):
    df2=pd.read_csv(""+type+".csv")
    df2.sort_values(by=['Last_Payment_Date'], inplace=True, ascending=False)
    if "export" in request.args:
        try:
            df1=df2[['school_name','country','State','city','Practice_Count',
                    'Practice_Count_csy','Practice_Count_lsy','usercount',
                    'Created_date','last_practice_date','Subscription_expire_date','label']]
            csv = df1.to_csv(index=False)
            return Response(
                csv,
                mimetype="text/csv",
                headers={"Content-disposition":
                        "attachment; filename=SchoolData.csv"})
        except:
            return jsonify("Unauthorized Access")   
    else:
        temp={"data":df2.values.tolist()}
    return json.dumps(temp)



@app.route('/revenaueyearly')
def revenue_yearly():
    from datetime import date

    today = date.today()

# dd/mm/YY
    d1 = today.strftime("%Y-%m-%d")
    print("d1 =", d1)

    Payment_Mode('2017-07-01',d1)
    df=pd.read_csv("revenaue.csv")
#     df = df[df.TYPE_OF_PAYMENT != 'MOBILE']
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])
    df['Payment_Amount'] = (df['Payment_Amount']).round()


    df['label'] = np.where(df['Last_Payment_Date']>= '2021-07-01', '2021-2022', '2020-2021')
    df.loc[(df['Last_Payment_Date']>='2019-07-01') & (df['Last_Payment_Date']< '2020-07-01'), 'label']='2019-2020'
    df.loc[(df['Last_Payment_Date']>='2018-07-01') & (df['Last_Payment_Date']< '2019-07-01'), 'label']='2018-2019'
    df.loc[(df['Last_Payment_Date']>='2017-07-01') & (df['Last_Payment_Date']< '2018-07-01'), 'label']='2017-2018'

    df2=df.groupby(['label',"TYPE_OF_PAYMENT"])['Payment_Amount'].sum().reset_index()
    # df2=df1.groupby(["TYPE_OF_PAYMENT"])['Payment_Amount','label'].sum().reset_index()
    donation=df2.loc[(df2["TYPE_OF_PAYMENT"]=='DONATION')]
    donation.columns=['label','TYPE_OF_PAYMENT_do','donation_amount']
    mobile=df2.loc[(df2["TYPE_OF_PAYMENT"]=='MOBILE')]
    mobile.columns=['label','TYPE_OF_PAYMENT_do','mobile_amount']
    foundation = df2.loc[(df2["TYPE_OF_PAYMENT"]=='FOUNDATION')] 
    foundation.columns=['label','TYPE_OF_PAYMENT_fo','foundation_amount']
    school =df2.loc[(df2["TYPE_OF_PAYMENT"]=='SCHOOL')] 
    school.columns=['label','TYPE_OF_PAYMENT_sc','school_amount']
    district=df2.loc[(df2["TYPE_OF_PAYMENT"]=='DISTRICT')]
    district.columns=['label','TYPE_OF_PAYMENT_di','district_amount']
    df1=pd.merge(donation,foundation, on='label', how='outer')
    dff=pd.merge(df1,school, on='label', how='outer')
    dfff=pd.merge(dff,district, on='label', how='outer')
    dfff=pd.merge(dfff,mobile, on='label', how='outer')
    df11=dfff[['label','donation_amount','foundation_amount','school_amount','district_amount','mobile_amount']]
    df11=df11.fillna(0)
    label=df11.label.tolist()
    donation=df11.donation_amount.tolist()
    foundation=df11.foundation_amount.tolist()
    school=df11.school_amount.tolist()
    mobile=df11.mobile_amount.tolist()
    district=df11.district_amount.tolist()
    data={'year':label,'donation':donation,'school':school,'district':district,'foundation':foundation,'mobile':mobile}
    return json.dumps({'data': data})


@app.route('/hpayment/<startdate>/<enddate>')
def Payment_History(startdate,enddate):
    date1=startdate
    date2=enddate
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    if(len(date1) == 0): 
        startdate1='2020-07-01'
    else : 
        startdate1=date1
    if(len(date2) == 0):
        enddate1=d1
    else : 
        enddate1=date2
    googleSheetId = '1X8nlhWRKFE6jO221SP1hrpBi9RSHZJ8_Q7oij1IU14Q'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection1 = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}

            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection1))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]

    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc = db.subscription_master.aggregate([
    {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
        {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"LAST_PAYMENT_DATE":{"$gte":myDatetime}},
            {"IS_PAYMENT_SUCCESS" : "Y"},
                        {'USER_ID':{'$exists':1}}  ,  
            {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
    }},
    {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
    "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},"Payment_Amount":"$LAST_PAYMENT_AMOUNT",
    "EMAIL_ID":"$USER_ID.EMAIL_ID"}}
    ,{"$unwind":"$Last_Payment_Date"}
    ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
        'MONTGOMERY UPPER MIDDLE SCHOOL',
        'RIVER VALLEY ELEMENTARY',
        'ALTURA PREPARATORY SCHOOL',
        'TWO BUNCH PALMS ELEMENTARY',
        'MELISSA MIDDLE SCHOOL',
        'MONTGOMERY LOWER MID SCH',
        'HATTIE DYER ELEMENTARY SCHOOL',
        'STOCKDALE JUNIOR HIGH',
        'INYO COUNTY COMMUNITY SCHOOL',
        'DESERT HOT SPRINGS HIGH',
        'SEMINOLE HIGH SCHOOL',
        'FRANKLIN WOODS INTERMEDIATE SCHOOL',
        'MARY B. LEWIS ELEMENTARY',
        'MCMILLIN (CORKY) ELEMENTARY',
        'ELGIN MIDDLE',
        'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
        'ODYSSEY ELEMENTARY',
        'FORT MEADOW ECC',
        'NO INFO',
        'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
        'BRIGHTON HIGH',
        'MARY M WALSH',
        'THE CAPITOL SCHOOL',
        'DR. DANIEL BRIGHT SCHOOL',
        'ROCK POINT COMMUNITY SCHOOL',
        'MURNIN ES',
        'SUNNY SANDS ELEMENTARY',
        'THOMAS JEFFERSON MIDDLE SCHOOL',
        'BENJAMIN FRANKLIN MIDDLE SCHOOL',
        'FAIRMONT CHARTER ELEMENTARY',
        'BLAIR ELEMENTARY SCHOOL',
        'L.A. MORGAN ELEMENTARY',
        'KRUM EARLY EDUCATION CENTER',
        'AMANDA HOPE RAINBOW ANGLES(NPO)',
        'STONY BROOK ELEMENTARY',
        'ROSE SPRINGS ELEMENTARY',
        'MT. BALDY JOINT ELEMENTARY',
        'LIBERTY HILLS ELEMENTARY',
        'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df3=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df1=payment_df3.append(dfd1)
    payment_df=payment_df1.append(payment_df2)
    dfweb = payment_df  
    # payment_df.Payment_Amount = payment_df.Payment_Amount.round()
    #webapp History Payment
    list1 =['ios', 'android']
    devices = '|'.join(list1)


    dfmob = payment_df[payment_df.DEVICE_USED.str.contains(devices,case=False)]

    dfweb = payment_df  
    df1web=dfweb[['Last_Payment_Date','Payment_Amount']]
    df1web['Last_Payment_Date'] = pd.to_datetime(df1web['Last_Payment_Date'])
    df1web=df1web[(df1web.Last_Payment_Date>=startdate1) & (df1web.Last_Payment_Date<=enddate1)]
    df2web= df1web.groupby(df1web['Last_Payment_Date'].dt.date)['Payment_Amount'].sum().reset_index()

    df2web['Last_Payment_Date'] = pd.to_datetime(df2web['Last_Payment_Date'])

    df2web['Last_Payment_Date'] = df2web['Last_Payment_Date'].astype(np.int64) / int(1e6)
    df2web['Cumulative_Amount'] = df2web['Payment_Amount'].cumsum()
    df3web=df2web[['Last_Payment_Date','Payment_Amount']]
    df3web.Payment_Amount = df3web.Payment_Amount.round()
    WebHistory=df3web.values.tolist()
    df4web=df2web[['Last_Payment_Date','Cumulative_Amount']]
    df4web.Cumulative_Amount = df4web.Cumulative_Amount.round()
    CumWebHistory=df4web.values.tolist()

    #Mobile History Payment

    df1mob=dfmob[['Last_Payment_Date','Payment_Amount']]
    df1mob['Last_Payment_Date'] = pd.to_datetime(df1mob['Last_Payment_Date'])
    df1mob=df1mob[(df1mob.Last_Payment_Date>=startdate1) & (df1mob.Last_Payment_Date<=enddate1)]
    df2mob= df1mob.groupby(df1mob['Last_Payment_Date'].dt.date).sum().reset_index()
    df2mob.Payment_Amount = df2mob.Payment_Amount.round()
    df2mob['Last_Payment_Date'] = pd.to_datetime(df2mob['Last_Payment_Date'])
    df2mob['Last_Payment_Date'] = df2mob['Last_Payment_Date'].astype(np.int64) / int(1e6)
    df2mob['Cumulative_Amount'] = df2mob['Payment_Amount'].cumsum()
    df3mob=df2mob[['Last_Payment_Date','Payment_Amount']]
    mobHistory=df3mob.values.tolist()
    df4mob=df2mob[['Last_Payment_Date','Cumulative_Amount']]
    CummobHistory=df4mob.values.tolist()
    temp={"WebHistory":WebHistory,"CumWebHistory":CumWebHistory,"mobHistory":mobHistory,"CummobHistory":CummobHistory}
    return(json.dumps(temp))

@app.route('/submonth/<month>')
def subtable(month):
    googleSheetId = '1ydZC5Q5cNBlPb2rI_lzcdL0lh7r7rvuSzDYxCDNseyw'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection1 = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection1))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc = db.subscription_master.aggregate([
    {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
        {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
             {'USER_ID':{'$exists':1}}  ,  
            {"IS_PAYMENT_SUCCESS" : "Y"},
            {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
    }},
    {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
    "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},"Payment_Amount":"$LAST_PAYMENT_AMOUNT",
    "EMAIL_ID":"$USER_ID.EMAIL_ID"}}
    ,{"$unwind":"$Last_Payment_Date"}
    ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
    'MONTGOMERY UPPER MIDDLE SCHOOL',
    'RIVER VALLEY ELEMENTARY',
    'ALTURA PREPARATORY SCHOOL',
    'TWO BUNCH PALMS ELEMENTARY',
    'MELISSA MIDDLE SCHOOL',
    'MONTGOMERY LOWER MID SCH',
    'HATTIE DYER ELEMENTARY SCHOOL',
    'STOCKDALE JUNIOR HIGH',
    'INYO COUNTY COMMUNITY SCHOOL',
    'DESERT HOT SPRINGS HIGH',
    'SEMINOLE HIGH SCHOOL',
    'FRANKLIN WOODS INTERMEDIATE SCHOOL',
    'MARY B. LEWIS ELEMENTARY',
    'MCMILLIN (CORKY) ELEMENTARY',
    'ELGIN MIDDLE',
    'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
    'ODYSSEY ELEMENTARY',
    'FORT MEADOW ECC',
    'NO INFO',
    'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
    'BRIGHTON HIGH',
    'MARY M WALSH',
    'THE CAPITOL SCHOOL',
    'DR. DANIEL BRIGHT SCHOOL',
    'ROCK POINT COMMUNITY SCHOOL',
    'MURNIN ES',
    'SUNNY SANDS ELEMENTARY',
    'THOMAS JEFFERSON MIDDLE SCHOOL',
    'BENJAMIN FRANKLIN MIDDLE SCHOOL',
    'FAIRMONT CHARTER ELEMENTARY',
    'BLAIR ELEMENTARY SCHOOL',
    'L.A. MORGAN ELEMENTARY',
    'KRUM EARLY EDUCATION CENTER',
    'AMANDA HOPE RAINBOW ANGLES(NPO)',
    'STONY BROOK ELEMENTARY',
    'ROSE SPRINGS ELEMENTARY',
    'MT. BALDY JOINT ELEMENTARY',
    'LIBERTY HILLS ELEMENTARY',
    'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df3=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df1=payment_df3.append(dfd1)
    payment_df=payment_df1.append(payment_df2)
    payment_df.Payment_Amount = payment_df.Payment_Amount.round()
    newdf=payment_df[(payment_df.Last_Payment_Date>= '2019-07-01')]
    df1=newdf[['USER_NAME',"EMAIL_ID",'DEVICE_USED','MODE_OF_PAYMENT','TYPE_OF_PAYMENT','Last_Payment_Date','Payment_Amount']]
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    df1=df1.groupby(df1['Last_Payment_Date'].dt.strftime('%b'))
    df2=df1.get_group(''+month+'')
    df2['Last_Payment_Date'] = df2['Last_Payment_Date'].astype('str')
    df3=df2.values.tolist()
    temp={'data':df3}

    return(json.dumps(temp))


@app.route('/submonth')
def submonth():
    googleSheetId = '1ydZC5Q5cNBlPb2rI_lzcdL0lh7r7rvuSzDYxCDNseyw'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection1 = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection1))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc = db.subscription_master.aggregate([
    {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
        {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
            {'USER_ID':{'$exists':1}}  ,  
            {"IS_PAYMENT_SUCCESS" : "Y"},
            {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
    }},
    {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
    "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},"Payment_Amount":"$LAST_PAYMENT_AMOUNT",
    "EMAIL_ID":"$USER_ID.EMAIL_ID"}}
    ,{"$unwind":"$Last_Payment_Date"}
    ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
    'MONTGOMERY UPPER MIDDLE SCHOOL',
    'RIVER VALLEY ELEMENTARY',
    'ALTURA PREPARATORY SCHOOL',
    'TWO BUNCH PALMS ELEMENTARY',
    'MELISSA MIDDLE SCHOOL',
    'MONTGOMERY LOWER MID SCH',
    'HATTIE DYER ELEMENTARY SCHOOL',
    'STOCKDALE JUNIOR HIGH',
    'INYO COUNTY COMMUNITY SCHOOL',
    'DESERT HOT SPRINGS HIGH',
    'SEMINOLE HIGH SCHOOL',
    'FRANKLIN WOODS INTERMEDIATE SCHOOL',
    'MARY B. LEWIS ELEMENTARY',
    'MCMILLIN (CORKY) ELEMENTARY',
    'ELGIN MIDDLE',
    'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
    'ODYSSEY ELEMENTARY',
    'FORT MEADOW ECC',
    'NO INFO',
    'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
    'BRIGHTON HIGH',
    'MARY M WALSH',
    'THE CAPITOL SCHOOL',
    'DR. DANIEL BRIGHT SCHOOL',
    'ROCK POINT COMMUNITY SCHOOL',
    'MURNIN ES',
    'SUNNY SANDS ELEMENTARY',
    'THOMAS JEFFERSON MIDDLE SCHOOL',
    'BENJAMIN FRANKLIN MIDDLE SCHOOL',
    'FAIRMONT CHARTER ELEMENTARY',
    'BLAIR ELEMENTARY SCHOOL',
    'L.A. MORGAN ELEMENTARY',
    'KRUM EARLY EDUCATION CENTER',
    'AMANDA HOPE RAINBOW ANGLES(NPO)',
    'STONY BROOK ELEMENTARY',
    'ROSE SPRINGS ELEMENTARY',
    'MT. BALDY JOINT ELEMENTARY',
    'LIBERTY HILLS ELEMENTARY',
    'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df3=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df1=payment_df3.append(dfd1)
    payment_df=payment_df2.append(payment_df1)
    #########################2020#########################
    newdf=payment_df[(payment_df.Last_Payment_Date>= '2021-07-01')]
    df1web=newdf[['MODE_OF_PAYMENT','Last_Payment_Date','Payment_Amount']]
    df1web['Last_Payment_Date'] = pd.to_datetime(df1web['Last_Payment_Date'])
    df1=df1web.groupby(df1web['Last_Payment_Date'].dt.strftime('%b'))['Payment_Amount'].sum().reset_index()
    df1.Payment_Amount = df1.Payment_Amount.round()
    df2=pd.DataFrame(df1)
    df2['Last_Payment_Date'] = df2['Last_Payment_Date'].str.upper() 
    Last_Payment_Date= ['JUL','AUG','SEP','OCT','NOV','DEC','JAN','FEB','MAR','APR','MAY','JUN']
    df10 = pd.DataFrame(Last_Payment_Date,columns =['Last_Payment_Date'])
    final = pd.merge(df10, df2, on="Last_Payment_Date", how='left').fillna(0)
    #########################2019##############################
    newdf2019=payment_df[(payment_df.Last_Payment_Date>= '2020-07-01') &(payment_df.Last_Payment_Date< '2021-07-01')]
    df1web2019=newdf2019[['MODE_OF_PAYMENT','Last_Payment_Date','Payment_Amount']]
    df1web2019['Last_Payment_Date'] = pd.to_datetime(df1web2019['Last_Payment_Date'])
    df12019=df1web2019.groupby(df1web2019['Last_Payment_Date'].dt.strftime('%b'))['Payment_Amount'].sum().reset_index()
    df12019.Payment_Amount = df12019.Payment_Amount.round()
    df22019=pd.DataFrame(df12019)
    df22019['Last_Payment_Date'] = df22019['Last_Payment_Date'].str.upper() 
    Last_Payment_Date2019= ['JUL','AUG','SEP','OCT','NOV','DEC','JAN','FEB','MAR','APR','MAY','JUN']
    df102019= pd.DataFrame(Last_Payment_Date2019,columns =['Last_Payment_Date'])
    final2019 = pd.merge(df102019, df22019, on="Last_Payment_Date", how='left').fillna(0)
    # ##########################2018########################################
    # newdf2018=payment_df[(payment_df.Last_Payment_Date> '2018-07-01') &(payment_df.Last_Payment_Date< '2019-07-01')]
    # df1web2018=newdf2018[['MODE_OF_PAYMENT','Last_Payment_Date','Payment_Amount']]
    # df1web2018['Last_Payment_Date'] = pd.to_datetime(df1web2018['Last_Payment_Date'])
    # df12018=df1web2018.groupby(df1web2018['Last_Payment_Date'].dt.strftime('%b'))['Payment_Amount'].sum().reset_index()
    # df22018=pd.DataFrame(df12018)
    # df22018['Last_Payment_Date'] = df22018['Last_Payment_Date'].str.upper() 
    # Last_Payment_Date2018= ['JUL','AUG','SEP','OCT','NOV','DEC','JAN','FEB','MAR','APR','MAY','JUN']
    # df102018= pd.DataFrame(Last_Payment_Date2018,columns =['Last_Payment_Date'])
    # final2018 = pd.merge(df102018, df22018, on="Last_Payment_Date", how='left').fillna(0)
    temp={"month":final['Last_Payment_Date'].tolist(),"amount":final['Payment_Amount'].tolist(),"amount2020":final2019['Payment_Amount'].tolist()}
    new = pd.DataFrame.from_dict(temp)
    new["amountlsy"]=new["amount2020"]
    new["amount2020"].iloc[0:2]=0
    new["projection"]=new["amount"]+new["amount2020"]
    projection2021=new["projection"].cumsum().tolist()
    cumlsy=new["amountlsy"].cumsum().tolist()
    temp={"month":final['Last_Payment_Date'].tolist(),"amount":final['Payment_Amount'].tolist(),"amount2020":final2019['Payment_Amount'].tolist(),"projection2021":projection2021,
        "cumlsy":cumlsy}
    return(json.dumps(temp))







@app.route('/web/history/<date>')
def web_history_table(date):
    googleSheetId = '1ydZC5Q5cNBlPb2rI_lzcdL0lh7r7rvuSzDYxCDNseyw'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection1 = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection1))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc = db.subscription_master.aggregate([
    {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
        {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
            {"IS_PAYMENT_SUCCESS" : "Y"},
           {'USER_ID':{'$exists':1}}  ,  
            {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
    }},
    {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
    "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},"Payment_Amount":"$LAST_PAYMENT_AMOUNT",
    "EMAIL_ID":"$USER_ID.EMAIL_ID"}}
    ,{"$unwind":"$Last_Payment_Date"}
    ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
    'MONTGOMERY UPPER MIDDLE SCHOOL',
    'RIVER VALLEY ELEMENTARY',
    'ALTURA PREPARATORY SCHOOL',
    'TWO BUNCH PALMS ELEMENTARY',
    'MELISSA MIDDLE SCHOOL',
    'MONTGOMERY LOWER MID SCH',
    'HATTIE DYER ELEMENTARY SCHOOL',
    'STOCKDALE JUNIOR HIGH',
    'INYO COUNTY COMMUNITY SCHOOL',
    'DESERT HOT SPRINGS HIGH',
    'SEMINOLE HIGH SCHOOL',
    'FRANKLIN WOODS INTERMEDIATE SCHOOL',
    'MARY B. LEWIS ELEMENTARY',
    'MCMILLIN (CORKY) ELEMENTARY',
    'ELGIN MIDDLE',
    'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
    'ODYSSEY ELEMENTARY',
    'FORT MEADOW ECC',
    'NO INFO',
    'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
    'BRIGHTON HIGH',
    'MARY M WALSH',
    'THE CAPITOL SCHOOL',
    'DR. DANIEL BRIGHT SCHOOL',
    'ROCK POINT COMMUNITY SCHOOL',
    'MURNIN ES',
    'SUNNY SANDS ELEMENTARY',
    'THOMAS JEFFERSON MIDDLE SCHOOL',
    'BENJAMIN FRANKLIN MIDDLE SCHOOL',
    'FAIRMONT CHARTER ELEMENTARY',
    'BLAIR ELEMENTARY SCHOOL',
    'L.A. MORGAN ELEMENTARY',
    'KRUM EARLY EDUCATION CENTER',
    'AMANDA HOPE RAINBOW ANGLES(NPO)',
    'STONY BROOK ELEMENTARY',
    'ROSE SPRINGS ELEMENTARY',
    'MT. BALDY JOINT ELEMENTARY',
    'LIBERTY HILLS ELEMENTARY',
    'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df3=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df1=payment_df3.append(dfd1)
    payment_df=payment_df1.append(payment_df2) 
    payment_df.Payment_Amount = payment_df.Payment_Amount.round()
    dfweb = payment_df
    df=dfweb[['USER_NAME',"EMAIL_ID",'DEVICE_USED','MODE_OF_PAYMENT','TYPE_OF_PAYMENT','Last_Payment_Date','Payment_Amount']]
    df2 = df[df.Last_Payment_Date.str.contains("" + date + "",case=False)] 
    df2['Last_Payment_Date'] = df2['Last_Payment_Date'].astype('str')
    df3=df2.values.tolist()
    temp={'data':df3}

    return json.dumps(temp)

@app.route('/mobile/history/<date>')
def mobile_history_table(date):
    googleSheetId = '1ydZC5Q5cNBlPb2rI_lzcdL0lh7r7rvuSzDYxCDNseyw'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection1 = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection1))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc = db.subscription_master.aggregate([
    {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
        {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
            {"IS_PAYMENT_SUCCESS" : "Y"},
            {'USER_ID':{'$exists':1}}  ,  
            {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
    }},
    {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
    "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},"Payment_Amount":"$LAST_PAYMENT_AMOUNT",
    "EMAIL_ID":"$USER_ID.EMAIL_ID"}}
    ,{"$unwind":"$Last_Payment_Date"}
    ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
    'MONTGOMERY UPPER MIDDLE SCHOOL',
    'RIVER VALLEY ELEMENTARY',
    'ALTURA PREPARATORY SCHOOL',
    'TWO BUNCH PALMS ELEMENTARY',
    'MELISSA MIDDLE SCHOOL',
    'MONTGOMERY LOWER MID SCH',
    'HATTIE DYER ELEMENTARY SCHOOL',
    'STOCKDALE JUNIOR HIGH',
    'INYO COUNTY COMMUNITY SCHOOL',
    'DESERT HOT SPRINGS HIGH',
    'SEMINOLE HIGH SCHOOL',
    'FRANKLIN WOODS INTERMEDIATE SCHOOL',
    'MARY B. LEWIS ELEMENTARY',
    'MCMILLIN (CORKY) ELEMENTARY',
    'ELGIN MIDDLE',
    'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
    'ODYSSEY ELEMENTARY',
    'FORT MEADOW ECC',
    'NO INFO',
    'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
    'BRIGHTON HIGH',
    'MARY M WALSH',
    'THE CAPITOL SCHOOL',
    'DR. DANIEL BRIGHT SCHOOL',
    'ROCK POINT COMMUNITY SCHOOL',
    'MURNIN ES',
    'SUNNY SANDS ELEMENTARY',
    'THOMAS JEFFERSON MIDDLE SCHOOL',
    'BENJAMIN FRANKLIN MIDDLE SCHOOL',
    'FAIRMONT CHARTER ELEMENTARY',
    'BLAIR ELEMENTARY SCHOOL',
    'L.A. MORGAN ELEMENTARY',
    'KRUM EARLY EDUCATION CENTER',
    'AMANDA HOPE RAINBOW ANGLES(NPO)',
    'STONY BROOK ELEMENTARY',
    'ROSE SPRINGS ELEMENTARY',
    'MT. BALDY JOINT ELEMENTARY',
    'LIBERTY HILLS ELEMENTARY',
    'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df3=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df1=payment_df3.append(dfd1)
    payment_df=payment_df1.append(payment_df2)
    payment_df.Payment_Amount = payment_df.Payment_Amount.round()
    list1 =['ios', 'android']
    devices = '|'.join(list1)
    dfweb = payment_df[payment_df.DEVICE_USED.str.contains(devices,case=False)] 
    df=dfweb[['USER_NAME',"EMAIL_ID",'DEVICE_USED','MODE_OF_PAYMENT','TYPE_OF_PAYMENT','Last_Payment_Date','Payment_Amount']]
    df2 = df[df.Last_Payment_Date.str.contains("" + date + "",case=False)] 
    df2['Last_Payment_Date'] = df2['Last_Payment_Date'].astype('str')
    df3=df2.values.tolist()
    temp={'data':df3}
    return json.dumps(temp)

# @app.route('/pmode/<name>')
# def pmodename(name):
#     googleSheetId = '1X8nlhWRKFE6jO221SP1hrpBi9RSHZJ8_Q7oij1IU14Q'
#     worksheetName = 'Payment'
#     URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
#     payment_df2=pd.read_csv(URL)
#     mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
#     client = pymongo.MongoClient(mongo_uri)
#     db = client.compass
#     collection1 = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
#             {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
#             {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
#                 {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
#                 {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
#                 {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
#                 { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}

#             ]
#         }}
#     ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,"Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
#     ] )
#     dfd= DataFrame(list(collection1))
#     dfd["TYPE_OF_PAYMENT"]="DONATION"
#     dfd["DEVICE_USED"]="COMPASS"
#     dfd["MODE_OF_PAYMENT"]="ONLINE"
#     dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
#     IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
#     # IP_ADDRESS="100.15.128.147"
#     STATE1=[]

#     for i in IP_ADDRESS:
#         url = 'http://ipinfo.io/'+i+'/json'
#         response = urlopen(url)
#         data = json.load(response)

#         IP=data['ip']
#         org=data['org']
#         city = data['city']
#         country=data['country']
#         region=data['region']
#         # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
#         STATE1.append(region)

#     dfd["STATE"]=STATE1
#     us_state_shot = {
#         'Alabama': 'AL',
#         'Alaska': 'AK',
#         'American Samoa': 'AS',
#         'Arizona': 'AZ',
#         'Arkansas': 'AR',
#         'California': 'CA',
#         'Colorado': 'CO',
#         'Connecticut': 'CT',
#         'Delaware': 'DE',
#         'District of Columbia': 'DC',
#         'Florida': 'FL',
#         'Georgia': 'GA',
#         'Guam': 'GU',
#         'Hawaii': 'HI',
#         'Idaho': 'ID',
#         'Illinois': 'IL',
#         'Indiana': 'IN',
#         'Iowa': 'IA',
#         'Kansas': 'KS',
#         'Kentucky': 'KY',
#         'Louisiana': 'LA',
#         'Maine': 'ME',
#         'Maryland': 'MD',
#         'Massachusetts': 'MA',
#         'Michigan': 'MI',
#         'Minnesota': 'MN',
#         'Mississippi': 'MS',
#         'Missouri': 'MO',
#         'Montana': 'MT',
#         'Nebraska': 'NE',
#         'Nevada': 'NV',
#         'New Hampshire': 'NH',
#         'New Jersey': 'NJ',
#         'New Mexico': 'NM',
#         'New York': 'NY',
#         'North Carolina': 'NC',
#         'North Dakota': 'ND',
#         'Northern Mariana Islands':'MP',
#         'Ohio': 'OH',
#         'Oklahoma': 'OK',
#         'Oregon': 'OR',
#         'Pennsylvania': 'PA',
#         'Puerto Rico': 'PR',
#         'Rhode Island': 'RI',
#         'South Carolina': 'SC',
#         'South Dakota': 'SD',
#         'Tennessee': 'TN',
#         'Texas': 'TX',
#         'Utah': 'UT',
#         'Vermont': 'VT',
#         'Virgin Islands': 'VI',
#         'Virginia': 'VA',
#         'Washington': 'WA',
#         'West Virginia': 'WV',
#         'Wisconsin': 'WI',
#         'Wyoming': 'WY'
#     }
#     dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
#     dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
#     dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
#     dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
#     dateStr = "2020-07-01T00:00:00.000Z"
#     myDatetime = dateutil.parser.parse(dateStr)
#     mydoc = db.subscription_master.aggregate([
#     {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
#         {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
#             {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
#             {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
#             {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
#             {"IS_PAYMENT_SUCCESS" : "Y"},
#             {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
#     }},
#     {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED",
#     "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},"Payment_Amount":"$LAST_PAYMENT_AMOUNT",
#     "EMAIL_ID":"$USER_ID.EMAIL_ID"}}
#     ,{"$unwind":"$Last_Payment_Date"}
#     ])
#     payment_df1= DataFrame(list(mydoc)).fillna("OTHERS")
#     payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
#     payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
#     payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
#     payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
#     payment_df3=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
#     payment_df1=payment_df3 #.append(dfd1)
#     payment_df=payment_df1.append(payment_df2)
#     payment_df.Payment_Amount = payment_df.Payment_Amount.round()
#     payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.upper()
#     payment_df['DEVICE_USED'] = payment_df['DEVICE_USED'].str.upper()
#     payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("POMOCODE", "PROMOCODE")
#     payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("SQUAREPAYMENT", "SQUARE PAYMENT")
#     payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("INVITED_USER", "INVITED USER")
#     payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("INVITEDUSER", "INVITED USER")
#     payment_df['Last_Payment_Date'] =  pd.to_datetime(payment_df['Last_Payment_Date'])
#     newdf=payment_df[(payment_df.Last_Payment_Date>= '2020-07-01')]
#     df=newdf[['USER_NAME',"EMAIL_ID",'DEVICE_USED','MODE_OF_PAYMENT','TYPE_OF_PAYMENT','Last_Payment_Date','Payment_Amount']]
#     df2 = df[df.TYPE_OF_PAYMENT.str.contains("" + name + "",na=False)]
#     df2['Last_Payment_Date'] = df2['Last_Payment_Date'].astype('str') 
#     df3=df2.values.tolist()
#     temp={'data':df3}
#     return json.dumps(temp)


# @app.route('/toptrans/<name>')
# def toptrans(name):
#     googleSheetId = '1X8nlhWRKFE6jO221SP1hrpBi9RSHZJ8_Q7oij1IU14Q'
#     worksheetName = 'Payment'
#     URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
#     payment_df2=pd.read_csv(URL)
#     mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
#     client = pymongo.MongoClient(mongo_uri)
#     db = client.compass
#     dateStr = "2020-07-01T00:00:00.000Z"
#     myDatetime = dateutil.parser.parse(dateStr)
#     mydoc = db.subscription_master.aggregate([
#     {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
#         {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
#             {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
#             {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
#             {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
#             {"USER_ID.DEVICE_USED":{ "$regex":"webApp",'$options':'i'}},
#             {"IS_PAYMENT_SUCCESS" : "Y"},
#             {"LAST_PAYMENT_AMOUNT" :{"$gt":100}},
#             {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
#     }},
#     {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED",
#     "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},"Payment_Amount":"$LAST_PAYMENT_AMOUNT",
#     "EMAIL_ID":"$USER_ID.EMAIL_ID"}}
#     ,{"$unwind":"$Last_Payment_Date"}
#     ])
#     payment_df1= DataFrame(list(mydoc)).fillna("OTHERS")
#     payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
#     payment_df=payment_df1.append(payment_df2) 
#     payment_df.Payment_Amount = payment_df.Payment_Amount.round()
#     df=dfweb[['USER_NAME',"EMAIL_ID",'DEVICE_USED','MODE_OF_PAYMENT','TYPE_OF_PAYMENT','Last_Payment_Date','Payment_Amount']]
#     df2 = df[df.USER_NAME.str.contains("" + name + "",case=False)] 
#     df2['Last_Payment_Date'] = df2['Last_Payment_Date'].astype('str')
#     df3=df2.values.tolist()
#     temp={'data':df3}
#     return json.dumps(temp)

@app.route('/chartdesc')
def chartdexc():
    googleSheetId = '1dHQKU0UO3IXYTIMNLeuzHsTi50NlhgiaH8nPl2tS8aw'
    worksheetName = 'Sheet1'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    df=pd.read_csv(URL)
    df1 = df[['Chart_name','Description']]
    df1['Description'] = df1['Description'].apply(str)
    temp={}
    for i,j in zip(df1['Chart_name'].tolist(), df1['Description'].tolist()):
        temp.update({i:j})
    return json.dumps(temp)


# @app.route('/donationmap')
# def Donation_map():
#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
#     db=client.compass
#     datestr7 = "2021-01-31T20:12:46.000Z"
#     myDatetim0 = dateutil.parser.parse(datestr7)
#     collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
#             {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
#             {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
#                 {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
#                 {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
#                 {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
#                 {"CREATED_DATE":{"$gt":myDatetim0}},
#                 { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
#             ]
#         }}
#     ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
#         "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
#     ] )
#     dfd= DataFrame(list(collection))
#     dfd["TYPE_OF_PAYMENT"]="DONATION"
#     dfd["DEVICE_USED"]="COMPASS"
#     dfd["MODE_OF_PAYMENT"]="ONLINE"
#     # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
#     dfd.Payment_Amount = dfd.Payment_Amount.round()
#     dfd.Total_Amount = dfd.Total_Amount.round()
#     # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
#     # IP_ADDRESS="100.15.128.147"
#     STATE1=[]

#     for i in IP_ADDRESS:
#         url = 'http://ipinfo.io/'+i+'/json'
#         response = urllib.request.urlopen(url)
#         data = json.load(response)

#         IP=data['ip']
#         org=data['org']
#         city = data['city']
#         country=data['country']
#         region=data['region']
#         # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
#         STATE1.append(region)
        
#     dfd["STATE"]=STATE1
#     us_state_shot = {
#         'Alabama': 'AL',
#         'Alaska': 'AK',
#         'American Samoa': 'AS',
#         'Arizona': 'AZ',
#         'Arkansas': 'AR',
#         'California': 'CA',
#         'Colorado': 'CO',
#         'Connecticut': 'CT',
#         'Delaware': 'DE',
#         'District of Columbia': 'DC',
#         'Florida': 'FL',
#         'Georgia': 'GA',
#         'Guam': 'GU',
#         'Hawaii': 'HI',
#         'Idaho': 'ID',
#         'Illinois': 'IL',
#         'Indiana': 'IN',
#         'Iowa': 'IA',
#         'Kansas': 'KS',
#         'Kentucky': 'KY',
#         'Louisiana': 'LA',
#         'Maine': 'ME',
#         'Maryland': 'MD',
#         'Massachusetts': 'MA',
#         'Michigan': 'MI',
#         'Minnesota': 'MN',
#         'Mississippi': 'MS',
#         'Missouri': 'MO',
#         'Montana': 'MT',
#         'Nebraska': 'NE',
#         'Nevada': 'NV',
#         'New Hampshire': 'NH',
#         'New Jersey': 'NJ',
#         'New Mexico': 'NM',
#         'New York': 'NY',
#         'North Carolina': 'NC',
#         'North Dakota': 'ND',
#         'Northern Mariana Islands':'MP',
#         'Ohio': 'OH',
#         'Oklahoma': 'OK',
#         'Oregon': 'OR',
#         'Pennsylvania': 'PA',
#         'Puerto Rico': 'PR',
#         'Rhode Island': 'RI',
#         'South Carolina': 'SC',
#         'South Dakota': 'SD',
#         'Tennessee': 'TN',
#         'Texas': 'TX',
#         'Utah': 'UT',
#         'Vermont': 'VT',
#         'Virgin Islands': 'VI',
#         'Virginia': 'VA',
#         'Washington': 'WA',
#         'West Virginia': 'WV',
#         'Wisconsin': 'WI',
#         'Wyoming': 'WY'
#     }
#     dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
#     dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
#     dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
#     dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
#     googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
#     worksheetName = 'Payment'
#     URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
#     dff=pd.read_csv(URL).fillna("NO INFO.")
#     df=dff.append(dfd1)
#     df["Last_Payment_Date"]=pd.to_datetime(df["Last_Payment_Date"])
#     df1=df[(df.Last_Payment_Date>= '2020-07-01')]
#     df2=df1[["STATE_SHOT","STATE","Payment_Amount","Total_Amount"]]
#     df2['Payment_Amount'] = pd.to_numeric(df2['Payment_Amount'],errors='coerce')
#     df3= df2.groupby(['STATE_SHOT',"STATE"])['Payment_Amount','Total_Amount'].sum().reset_index()
#     df4= df3.rename(columns={'STATE_SHOT' : 'code', 'Payment_Amount' : 'value','STATE':'name',"Total_Amount":'value1'}).to_dict('r')
#     temp={"data":df4}

#     return json.dumps(temp)

@app.route('/donationmaptable/<name>')
def Donation_table_map(name):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    STATE1=[]

    for i in IP_ADDRESS:
        url = 'http://ipinfo.io/'+i+'/json'
        response = urllib.request.urlopen(url)
        data = json.load(response)

        IP=data['ip']
        org=data['org']
        city = data['city']
        country=data['country']
        region=data['region']
        # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
        STATE1.append(region)
        
    dfd["STATE"]=STATE1
    us_state_shot = {
        'Alabama': 'AL',
        'Alaska': 'AK',
        'American Samoa': 'AS',
        'Arizona': 'AZ',
        'Arkansas': 'AR',
        'California': 'CA',
        'Colorado': 'CO',
        'Connecticut': 'CT',
        'Delaware': 'DE',
        'District of Columbia': 'DC',
        'Florida': 'FL',
        'Georgia': 'GA',
        'Guam': 'GU',
        'Hawaii': 'HI',
        'Idaho': 'ID',
        'Illinois': 'IL',
        'Indiana': 'IN',
        'Iowa': 'IA',
        'Kansas': 'KS',
        'Kentucky': 'KY',
        'Louisiana': 'LA',
        'Maine': 'ME',
        'Maryland': 'MD',
        'Massachusetts': 'MA',
        'Michigan': 'MI',
        'Minnesota': 'MN',
        'Mississippi': 'MS',
        'Missouri': 'MO',
        'Montana': 'MT',
        'Nebraska': 'NE',
        'Nevada': 'NV',
        'New Hampshire': 'NH',
        'New Jersey': 'NJ',
        'New Mexico': 'NM',
        'New York': 'NY',
        'North Carolina': 'NC',
        'North Dakota': 'ND',
        'Northern Mariana Islands':'MP',
        'Ohio': 'OH',
        'Oklahoma': 'OK',
        'Oregon': 'OR',
        'Pennsylvania': 'PA',
        'Puerto Rico': 'PR',
        'Rhode Island': 'RI',
        'South Carolina': 'SC',
        'South Dakota': 'SD',
        'Tennessee': 'TN',
        'Texas': 'TX',
        'Utah': 'UT',
        'Vermont': 'VT',
        'Virgin Islands': 'VI',
        'Virginia': 'VA',
        'Washington': 'WA',
        'West Virginia': 'WV',
        'Wisconsin': 'WI',
        'Wyoming': 'WY'
    }
    dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1)
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])
    df1=df[(df.Last_Payment_Date>= '2020-07-01')]
    df2=df1[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]]
    df3= df2[df2.STATE.str.contains("" + name + "",case=False)] 
    df3['Last_Payment_Date'] = df3['Last_Payment_Date'].astype('str')
    temp={"data":df3.values.tolist()}
    return json.dumps(temp)
     
@app.route('/donationcsy')
def Donation_csy():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1)
    df1=df[["Last_Payment_Date","Payment_Amount"]]
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    df1=df1[(df1.Last_Payment_Date>= '2021-07-01')]
    df2= df1.groupby(df1['Last_Payment_Date'].dt.date)['Payment_Amount'].sum().reset_index()
    df2['Last_Payment_Date'] = pd.to_datetime(df2['Last_Payment_Date'])
    dfrange1=pd.date_range(start='2021-07-01', end=d1)
    dfrange2 = pd.DataFrame(dfrange1,columns = ["Last_Payment_Date"])
    dfrange2['Payment_Amount'] = 0
    dff2= df2.merge(dfrange2, on="Last_Payment_Date", how='right').fillna(0).sort_values(by='Last_Payment_Date')
    dff2['Last_Payment_Date'] = dff2['Last_Payment_Date'].astype(np.int64) / int(1e6)
    dff2['Cumulative_Amount'] = dff2['Payment_Amount_x'].cumsum()
    df3=dff2[['Last_Payment_Date','Payment_Amount_x']]
    DonationHistory=df3.values.tolist()
    df4=dff2[['Last_Payment_Date','Cumulative_Amount']]
    CumDonationHistory=df4.values.tolist()
    temp={"DonationHistory":DonationHistory,"CumDonationHistory":CumDonationHistory}
    return json.dumps(temp)


@app.route('/donationcsytable/<date>')
def Donation_table_csy(date):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1)
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])
    df1=df[(df.Last_Payment_Date>= '2021-07-01')]
    df2=df1[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]].astype(str)
    df3= df2[df2.Last_Payment_Date.str.contains("" + date + "",case=False)] 
    df3['Last_Payment_Date'] = df3['Last_Payment_Date'].astype('str')
    temp={"data":df3.values.tolist()}
    return json.dumps(temp)

@app.route('/donationCrowdfundingcsy')
def Donation_Crowdfunding_csy():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                { "CAMPAIGN_ID._id":{"$eq":ObjectId("5f5933f122a9de32555fceb4")}}

            ]
        }},{"$project":{"_id":1,"FIRST_NAME":1,"EMAIL_ID":"$EMAIL","Payment_Amount":"$AMOUNT",
                    "Last_Payment_Date":{"$dateToString":{"format":"%Y-%m-%d","date":"$CREATED_DATE"} }}}] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="CAMPAIGN"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    dfd['FIRST_NAME'] = dfd['FIRST_NAME'].str.upper()
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd1=dfd[["FIRST_NAME","EMAIL_ID","DEVICE_USED","TYPE_OF_PAYMENT","MODE_OF_PAYMENT","Last_Payment_Date","Payment_Amount"]]
    df=dfd1
    df1=df[["Last_Payment_Date","Payment_Amount"]]
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    df1=df1[(df1.Last_Payment_Date>= '2021-07-01')]
    df2= df1.groupby(df1['Last_Payment_Date'].dt.date)['Payment_Amount'].sum().reset_index()
    df2['Last_Payment_Date'] = pd.to_datetime(df2['Last_Payment_Date'])
    df2['Last_Payment_Date'] = df2['Last_Payment_Date'].astype(np.int64) / int(1e6)
    df2['Cumulative_Amount'] = df2['Payment_Amount'].cumsum()
    df3=df2[['Last_Payment_Date','Payment_Amount']]
    DonationHistory=df3.values.tolist()
    df4=df2[['Last_Payment_Date','Cumulative_Amount']]
    CumDonationHistory=df4.values.tolist()
    temp={"DonationHistory":DonationHistory,"CumDonationHistory":CumDonationHistory}
    return json.dumps(temp)

@app.route('/donationCrowdfundingcsytable/<date>')
def Donation_table_Crowdfunding_csy(date):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                { "CAMPAIGN_ID._id":{"$eq":ObjectId("5f5933f122a9de32555fceb4")}}

            ]
        }},{"$project":{"_id":1,"FIRST_NAME":1,"EMAIL_ID":"$EMAIL","Payment_Amount":"$AMOUNT",
                    "Last_Payment_Date":{"$dateToString":{"format":"%Y-%m-%d","date":"$CREATED_DATE"} }}}] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="CAMPAIGN"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    dfd['FIRST_NAME'] = dfd['FIRST_NAME'].str.upper()
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd1=dfd[["FIRST_NAME","EMAIL_ID","DEVICE_USED","TYPE_OF_PAYMENT","MODE_OF_PAYMENT","Last_Payment_Date","Payment_Amount"]].astype(str)
    df3= dfd1[dfd1.Last_Payment_Date.str.contains("" + date + "",case=False)] 
    df3['Last_Payment_Date'] = df3['Last_Payment_Date'].astype('str')
    temp={"data":df3.values.tolist()}
    return json.dumps(temp)

@app.route('/donationhistory/<startdate>/<enddate>')
def Donation_history(startdate,enddate):
    date1=startdate
    date2=enddate
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    if(len(date1) == 0): 
        startdate1='2020-07-01'
    else : 
        startdate1=date1
    if(len(date2) == 0):
        enddate1=d1
    else : 
        enddate1=date2
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1)
    df1=df[["Last_Payment_Date","Payment_Amount"]]
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    df1=df1[(df1.Last_Payment_Date >= startdate1) & (df1.Last_Payment_Date <= enddate1)]
    df2= df1.groupby(df1['Last_Payment_Date'].dt.date)['Payment_Amount'].sum().reset_index()
    df2['Last_Payment_Date'] = pd.to_datetime(df2['Last_Payment_Date'])
    df2['Last_Payment_Date'] = df2['Last_Payment_Date'].astype(np.int64) / int(1e6)
    df2['Cumulative_Amount'] = df2['Payment_Amount'].cumsum()
    df3=df2[['Last_Payment_Date','Payment_Amount']]
    DonationHistory=df3.values.tolist()
    df4=df2[['Last_Payment_Date','Cumulative_Amount']]
    CumDonationHistory=df4.values.tolist()
    temp={"DonationHistory":DonationHistory,"CumDonationHistory":CumDonationHistory}
    return json.dumps(temp)

@app.route('/donationhistorytable/<date>')
def Donation_table_history(date):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1)
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])
    df2=df[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]].astype(str)
    df3= df2[df2.Last_Payment_Date.str.contains("" + date + "",case=False)] 
    df3['Last_Payment_Date'] = df3['Last_Payment_Date'].astype('str')
    temp={"data":df3.values.tolist()}
    return json.dumps(temp)

@app.route('/weeklydonation/<startdate>/<enddate>')
def Weekly_donation(startdate,enddate):
    date1=startdate
    date2=enddate
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    if(len(date1) == 0): 
        startdate1='2020-07-01'
    else : 
        startdate1=date1
    if(len(date2) == 0):
        enddate1=d1
    else : 
        enddate1=date2
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}

            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()

    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]

    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1)
    df1=df[["Last_Payment_Date","Payment_Amount"]]
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    df1=df1[(df1.Last_Payment_Date >= startdate1) & (df1.Last_Payment_Date <= enddate1)]
    df1=df1.groupby(df1['Last_Payment_Date'].dt.day_name())['Payment_Amount'].sum().reset_index()
    weeek= ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']
    df2 = pd.DataFrame(weeek,columns =['Last_Payment_Date'])
    final = pd.merge(df2, df1, on="Last_Payment_Date", how='left').fillna(0)
    temp={"month":final['Last_Payment_Date'].tolist(),"amount":final['Payment_Amount'].tolist()}
    return json.dumps(temp)



@app.route('/donationcards')
def Donation_cards():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1)
    df1=df[["Last_Payment_Date","Payment_Amount","Total_Amount"]]
    liftimedonation=df1["Total_Amount"].sum().tolist()
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    df2=df1[(df1.Last_Payment_Date>= '2021-07-01')]
    csydonation=df2["Payment_Amount"].sum().tolist()
    csydonor=df2["Payment_Amount"].count().tolist()
    df3=df1[(df1.Last_Payment_Date>= '2020-07-01') &(df1.Last_Payment_Date< '2021-07-01')]
    lsydonation=df3["Payment_Amount"].sum().tolist()
    lsydonor=df3["Payment_Amount"].count().tolist()
    temp={"liftimedonation":liftimedonation,"csydonation":csydonation,"lsydonation":lsydonation,"totaldonor":csydonor,"lsydonor":lsydonor}
    return json.dumps(temp)


@app.route('/donationcalandercardtable/<startdate>/<enddate>')

def calander_Donation_table(startdate,enddate):
    date1=startdate
    date2=enddate
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    if(len(date1) == 0): 
        startdate1='2020-07-01'
    else : 
        startdate1=date1
    if(len(date2) == 0):
        enddate1=d1
    else : 
        enddate1=date2
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1).fillna('NO INFO')
    df1=df[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]]
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    df2=df1[(df1.Last_Payment_Date >= startdate1) & (df1.Last_Payment_Date <= enddate1)]
    data=df2[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]].astype(str)
    print(len(data))
#     csydonation=df2["Payment_Amount"].sum().tolist()
#     csydonor=df2["Payment_Amount"].count().tolist()
#     temp={"csydonation":csydonation,"totaldonor":csydonor}
    temp={"data":data.values.tolist()}
    return json.dumps(temp)





@app.route('/donationcalandercard/<startdate>/<enddate>')
def calander_Donation_cards(startdate,enddate):
    date1=startdate
    date2=enddate
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    if(len(date1) == 0): 
        startdate1='2020-07-01'
    else : 
        startdate1=date1
    if(len(date2) == 0):
        enddate1=d1
    else : 
        enddate1=date2
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1)
    df1=df[["Last_Payment_Date","Payment_Amount","Total_Amount"]]
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    df2=df1[(df1.Last_Payment_Date >= startdate1) & (df1.Last_Payment_Date <= enddate1)]
    csydonation=df2["Payment_Amount"].sum().tolist()
    csydonor=df2["Payment_Amount"].count().tolist()
    temp={"csydonation":csydonation,"totaldonor":csydonor}
    return json.dumps(temp)

@app.route('/donationjourney/<email>')
def donation_journey(email):   
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}

            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]

    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1).fillna("NO INFO")
    user= df[df.EMAIL_ID.str.contains(""+email+"",case=False)] 
    donor_name=str(user["USER_NAME"].iloc[0])
    donor_email=str(user["EMAIL_ID"].iloc[0])
    donor_state=str(user["STATE"].iloc[0])
    donor_last_date=max(user["Last_Payment_Date"])
    donor_Total_amount=sum(user["Payment_Amount"])
    donor_donation_count=user["Payment_Amount"].count()
    modechart= user.groupby(['DEVICE_USED'])['Payment_Amount'].sum().reset_index()
    chart1names=modechart["DEVICE_USED"].tolist()
    chart1count=modechart["Payment_Amount"].tolist()
    user['Last_Payment_Date'] = pd.to_datetime(user['Last_Payment_Date'])
    user['Last_Payment_Date'] = user['Last_Payment_Date'].astype(np.int64) / int(1e6)
    user['Cumulative_Amount'] = user['Payment_Amount'].cumsum()
    df3=user[['Last_Payment_Date','Payment_Amount']]
    DonationHistory=df3.values.tolist()
    df4=user[['Last_Payment_Date','Cumulative_Amount']]
    CumDonationHistory=df4.values.tolist()
    historychart={"DonationHistory":DonationHistory,"CumDonationHistory":CumDonationHistory}
    temp={"info":{"donor_name":donor_name,"donor_email":donor_email,"donor_state":donor_state,"donor_last_date":donor_last_date,
                },"cards":{"donor_Total_amount":int(donor_Total_amount),"donor_donation_count":int(donor_donation_count)},
                 "typechart":{"name":chart1names,"count":chart1count},"historychart":historychart}
    return json.dumps(temp)

@app.route('/donationcardstablecsy')
def Donation_cards_Table():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]

    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1)
    df1=df[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]]
    liftimedonation=df1["Total_Amount"].sum().tolist()
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    df2=df1[(df1.Last_Payment_Date>= '2021-07-01')].fillna("NO INFO.")
    csy=df2[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]].astype(str)
    df3=df1[(df1.Last_Payment_Date>= '2020-07-01') &(df1.Last_Payment_Date< '2021-07-01')]
    lsy=df3[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]].astype(str)
    temp={"data":csy.values.tolist()}
    return json.dumps(temp)

@app.route('/donationcardstablelsy')
def Donation_cards_Table2():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]

    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff.append(dfd1)
    df1=df[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]]
    liftimedonation=df1["Total_Amount"].sum().tolist()
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    df2=df1[(df1.Last_Payment_Date>= '2021-07-01')]
    csy=df2[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]].astype(str)
    df3=df1[(df1.Last_Payment_Date>= '2020-07-01') &(df1.Last_Payment_Date< '2021-07-01')]
    lsy=df3[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]].astype(str)
    temp={"data":lsy.values.tolist()}
    return json.dumps(temp)

@app.route('/donationmapcard')
def Donation_map_card():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    dfd.Payment_Amount = dfd.Payment_Amount.round()
    dfd.Total_Amount = dfd.Total_Amount.round()
    IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    STATE1=[]

    for i in IP_ADDRESS:
        url = 'http://ipinfo.io/'+i+'/json'
        response = urllib.request.urlopen(url)
        data = json.load(response)

        IP=data['ip']
        org=data['org']
        city = data['city']
        country=data['country']
        region=data['region']
        # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
        STATE1.append(region)
        
    dfd["STATE"]=STATE1
    us_state_shot = {
        'Alabama': 'AL',
        'Alaska': 'AK',
        'American Samoa': 'AS',
        'Arizona': 'AZ',
        'Arkansas': 'AR',
        'California': 'CA',
        'Colorado': 'CO',
        'Connecticut': 'CT',
        'Delaware': 'DE',
        'District of Columbia': 'DC',
        'Florida': 'FL',
        'Georgia': 'GA',
        'Guam': 'GU',
        'Hawaii': 'HI',
        'Idaho': 'ID',
        'Illinois': 'IL',
        'Indiana': 'IN',
        'Iowa': 'IA',
        'Kansas': 'KS',
        'Kentucky': 'KY',
        'Louisiana': 'LA',
        'Maine': 'ME',
        'Maryland': 'MD',
        'Massachusetts': 'MA',
        'Michigan': 'MI',
        'Minnesota': 'MN',
        'Mississippi': 'MS',
        'Missouri': 'MO',
        'Montana': 'MT',
        'Nebraska': 'NE',
        'Nevada': 'NV',
        'New Hampshire': 'NH',
        'New Jersey': 'NJ',
        'New Mexico': 'NM',
        'New York': 'NY',
        'North Carolina': 'NC',
        'North Dakota': 'ND',
        'Northern Mariana Islands':'MP',
        'Ohio': 'OH',
        'Oklahoma': 'OK',
        'Oregon': 'OR',
        'Pennsylvania': 'PA',
        'Puerto Rico': 'PR',
        'Rhode Island': 'RI',
        'South Carolina': 'SC',
        'South Dakota': 'SD',
        'Tennessee': 'TN',
        'Texas': 'TX',
        'Utah': 'UT',
        'Vermont': 'VT',
        'Virgin Islands': 'VI',
        'Virginia': 'VA',
        'Washington': 'WA',
        'West Virginia': 'WV',
        'Wisconsin': 'WI',
        'Wyoming': 'WY'
    }
    dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff #.append(dfd1)
    df1=df[(df.Last_Payment_Date>= '2021-07-01')]
    df2=df1[["STATE_SHOT","STATE","Payment_Amount","Total_Amount"]]
    df2['Payment_Amount'] = pd.to_numeric(df2['Payment_Amount'],errors='coerce')
    df3= df2.groupby(['STATE_SHOT',"STATE"])['Payment_Amount','Total_Amount'].sum().reset_index()
    df4=df3.sort_values(by=['Payment_Amount'],ascending=False)
    df5=df4.head(5)
    temp={"data":df5[["STATE","Payment_Amount"]].values.tolist()}
    return json.dumps(temp)


@app.route('/schoolpaymentcsy')
def school_payment_csy():
    googleSheetId = '1X8nlhWRKFE6jO221SP1hrpBi9RSHZJ8_Q7oij1IU14Q'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc =  db.subscription_master.aggregate([
        {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
            {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
                {"IS_PAYMENT_SUCCESS" : "Y"},
                            {'USER_ID':{'$exists':1}}  ,  
                {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
        }},
        {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
        "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},
        "Payment_Amount":"$LAST_PAYMENT_AMOUNT",
        "EMAIL_ID":"$USER_ID.EMAIL_ID","SCHOOL_NAME":"$USER_ID.schoolId.NAME",
        "STATE":"$USER_ID.schoolId.STATE","STATE_SHOT":"$USER_ID.schoolId.STATE_SHORT"}}
        ,{"$unwind":"$Last_Payment_Date"}
        ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
    'MONTGOMERY UPPER MIDDLE SCHOOL',
    'RIVER VALLEY ELEMENTARY',
    'ALTURA PREPARATORY SCHOOL',
    'TWO BUNCH PALMS ELEMENTARY',
    'MELISSA MIDDLE SCHOOL',
    'MONTGOMERY LOWER MID SCH',
    'HATTIE DYER ELEMENTARY SCHOOL',
    'STOCKDALE JUNIOR HIGH',
    'INYO COUNTY COMMUNITY SCHOOL',
    'DESERT HOT SPRINGS HIGH',
    'SEMINOLE HIGH SCHOOL',
    'FRANKLIN WOODS INTERMEDIATE SCHOOL',
    'MARY B. LEWIS ELEMENTARY',
    'MCMILLIN (CORKY) ELEMENTARY',
    'ELGIN MIDDLE',
    'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
    'ODYSSEY ELEMENTARY',
    'FORT MEADOW ECC',
    'NO INFO',
    'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
    'BRIGHTON HIGH',
    'MARY M WALSH',
    'THE CAPITOL SCHOOL',
    'DR. DANIEL BRIGHT SCHOOL',
    'ROCK POINT COMMUNITY SCHOOL',
    'MURNIN ES',
    'SUNNY SANDS ELEMENTARY',
    'THOMAS JEFFERSON MIDDLE SCHOOL',
    'BENJAMIN FRANKLIN MIDDLE SCHOOL',
    'FAIRMONT CHARTER ELEMENTARY',
    'BLAIR ELEMENTARY SCHOOL',
    'L.A. MORGAN ELEMENTARY',
    'KRUM EARLY EDUCATION CENTER',
    'AMANDA HOPE RAINBOW ANGLES(NPO)',
    'STONY BROOK ELEMENTARY',
    'ROSE SPRINGS ELEMENTARY',
    'MT. BALDY JOINT ELEMENTARY',
    'LIBERTY HILLS ELEMENTARY',
    'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df1=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df=payment_df1.append(payment_df2) 
    
    #webapp History Payment
    dfweb = payment_df[payment_df.TYPE_OF_PAYMENT.str.contains("SCHOOL",case=False)]
    df1web=dfweb[['Last_Payment_Date','Payment_Amount']]
    df1web['Last_Payment_Date'] = pd.to_datetime(df1web['Last_Payment_Date'])
    df1web=df1web[(df1web.Last_Payment_Date>= '2021-07-01')]
    df2web= df1web.groupby(df1web['Last_Payment_Date'].dt.date)['Payment_Amount'].sum().reset_index()
    df2web.Payment_Amount = df2web.Payment_Amount.round()
    df2web['Last_Payment_Date'] = pd.to_datetime(df2web['Last_Payment_Date'])
    df2web['Last_Payment_Date'] = df2web['Last_Payment_Date'].astype(np.int64) / int(1e6)
    df2web['Cumulative_Amount'] = df2web['Payment_Amount'].cumsum()
    df2web.Cumulative_Amount = df2web.Cumulative_Amount.round()
    df3web=df2web[['Last_Payment_Date','Payment_Amount']]
    WebHistory=df3web.values.tolist()
    df4web=df2web[['Last_Payment_Date','Cumulative_Amount']]
    CumWebHistory=df4web.values.tolist()
    temp={"WebHistory":WebHistory,"CumWebHistory":CumWebHistory}
    return json.dumps(temp)


@app.route('/schoolpaymentcsytable/<date>')
def school_payment_csy_table(date):
    googleSheetId = '1X8nlhWRKFE6jO221SP1hrpBi9RSHZJ8_Q7oij1IU14Q'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc =  db.subscription_master.aggregate([
        {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
            {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
                {"IS_PAYMENT_SUCCESS" : "Y"},
                            {'USER_ID':{'$exists':1}}  ,  
                {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
        }},
        {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
        "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},
        "Payment_Amount":"$LAST_PAYMENT_AMOUNT",
        "EMAIL_ID":"$USER_ID.EMAIL_ID","SCHOOL_NAME":"$USER_ID.schoolId.NAME",
        "STATE":"$USER_ID.schoolId.STATE","STATE_SHOT":"$USER_ID.schoolId.STATE_SHORT"}}
        ,{"$unwind":"$Last_Payment_Date"}
        ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
    'MONTGOMERY UPPER MIDDLE SCHOOL',
    'RIVER VALLEY ELEMENTARY',
    'ALTURA PREPARATORY SCHOOL',
    'TWO BUNCH PALMS ELEMENTARY',
    'MELISSA MIDDLE SCHOOL',
    'MONTGOMERY LOWER MID SCH',
    'HATTIE DYER ELEMENTARY SCHOOL',
    'STOCKDALE JUNIOR HIGH',
    'INYO COUNTY COMMUNITY SCHOOL',
    'DESERT HOT SPRINGS HIGH',
    'SEMINOLE HIGH SCHOOL',
    'FRANKLIN WOODS INTERMEDIATE SCHOOL',
    'MARY B. LEWIS ELEMENTARY',
    'MCMILLIN (CORKY) ELEMENTARY',
    'ELGIN MIDDLE',
    'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
    'ODYSSEY ELEMENTARY',
    'FORT MEADOW ECC',
    'NO INFO',
    'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
    'BRIGHTON HIGH',
    'MARY M WALSH',
    'THE CAPITOL SCHOOL',
    'DR. DANIEL BRIGHT SCHOOL',
    'ROCK POINT COMMUNITY SCHOOL',
    'MURNIN ES',
    'SUNNY SANDS ELEMENTARY',
    'THOMAS JEFFERSON MIDDLE SCHOOL',
    'BENJAMIN FRANKLIN MIDDLE SCHOOL',
    'FAIRMONT CHARTER ELEMENTARY',
    'BLAIR ELEMENTARY SCHOOL',
    'L.A. MORGAN ELEMENTARY',
    'KRUM EARLY EDUCATION CENTER',
    'AMANDA HOPE RAINBOW ANGLES(NPO)',
    'STONY BROOK ELEMENTARY',
    'ROSE SPRINGS ELEMENTARY',
    'MT. BALDY JOINT ELEMENTARY',
    'LIBERTY HILLS ELEMENTARY',
    'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df1=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df=payment_df1.append(payment_df2)
    payment_df['STATE'] = payment_df['STATE'].str.upper() 
    payment_df['STATE_SHOT'] = payment_df['STATE_SHOT'].str.upper() 
    payment_df.Payment_Amount = payment_df.Payment_Amount.round()
    df = payment_df[payment_df.TYPE_OF_PAYMENT.str.contains("SCHOOL",case=False)]
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])
    df1=df[(df.Last_Payment_Date>= '2020-07-01')]
    df2=df1[["USER_NAME","EMAIL_ID","SCHOOL_NAME","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount"]].astype(str)
    df3= df2[df2.Last_Payment_Date.str.contains(""+ date +"",case=False)] 
    df3['Last_Payment_Date'] = df3['Last_Payment_Date'].astype('str')
    temp={"data":df3.values.tolist()}
    return json.dumps(temp)

@app.route('/schoolpaymentmap')
def school_payment_map():
    googleSheetId = '1X8nlhWRKFE6jO221SP1hrpBi9RSHZJ8_Q7oij1IU14Q'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc =  db.subscription_master.aggregate([
        {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
            {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
                            {'USER_ID':{'$exists':1}}  ,  
                {"IS_PAYMENT_SUCCESS" : "Y"},
                {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
        }},
        {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
        "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},
        "Payment_Amount":"$LAST_PAYMENT_AMOUNT",
        "EMAIL_ID":"$USER_ID.EMAIL_ID","SCHOOL_NAME":"$USER_ID.schoolId.NAME",
        "STATE":"$USER_ID.schoolId.STATE","STATE_SHOT":"$USER_ID.schoolId.STATE_SHORT"}}
        ,{"$unwind":"$Last_Payment_Date"}
        ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
    'MONTGOMERY UPPER MIDDLE SCHOOL',
    'RIVER VALLEY ELEMENTARY',
    'ALTURA PREPARATORY SCHOOL',
    'TWO BUNCH PALMS ELEMENTARY',
    'MELISSA MIDDLE SCHOOL',
    'MONTGOMERY LOWER MID SCH',
    'HATTIE DYER ELEMENTARY SCHOOL',
    'STOCKDALE JUNIOR HIGH',
    'INYO COUNTY COMMUNITY SCHOOL',
    'DESERT HOT SPRINGS HIGH',
    'SEMINOLE HIGH SCHOOL',
    'FRANKLIN WOODS INTERMEDIATE SCHOOL',
    'MARY B. LEWIS ELEMENTARY',
    'MCMILLIN (CORKY) ELEMENTARY',
    'ELGIN MIDDLE',
    'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
    'ODYSSEY ELEMENTARY',
    'FORT MEADOW ECC',
    'NO INFO',
    'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
    'BRIGHTON HIGH',
    'MARY M WALSH',
    'THE CAPITOL SCHOOL',
    'DR. DANIEL BRIGHT SCHOOL',
    'ROCK POINT COMMUNITY SCHOOL',
    'MURNIN ES',
    'SUNNY SANDS ELEMENTARY',
    'THOMAS JEFFERSON MIDDLE SCHOOL',
    'BENJAMIN FRANKLIN MIDDLE SCHOOL',
    'FAIRMONT CHARTER ELEMENTARY',
    'BLAIR ELEMENTARY SCHOOL',
    'L.A. MORGAN ELEMENTARY',
    'KRUM EARLY EDUCATION CENTER',
    'AMANDA HOPE RAINBOW ANGLES(NPO)',
    'STONY BROOK ELEMENTARY',
    'ROSE SPRINGS ELEMENTARY',
    'MT. BALDY JOINT ELEMENTARY',
    'LIBERTY HILLS ELEMENTARY',
    'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df1=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df=payment_df1.append(payment_df2)
    payment_df['STATE'] = payment_df['STATE'].str.upper() 
    payment_df['STATE_SHOT'] = payment_df['STATE_SHOT'].str.upper() 
    
    df = payment_df[payment_df.TYPE_OF_PAYMENT.str.contains("SCHOOL",case=False)]
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])
    df1=df[(df.Last_Payment_Date>= '2021-07-01')]
    df2=df1[["STATE_SHOT","STATE","Payment_Amount"]]
    df2['Payment_Amount'] = pd.to_numeric(df2['Payment_Amount'],errors='coerce')
    df3= df2.groupby(['STATE_SHOT',"STATE"])['Payment_Amount'].sum().reset_index()
    df3.Payment_Amount = df3.Payment_Amount.round()
    df4= df3.rename(columns={'STATE_SHOT' : 'code', 'Payment_Amount' : 'value','STATE':'name'}).to_dict('r')
    temp={"data":df4}
    return json.dumps(temp)

@app.route('/schoolpaymentmaptable/<name>')
def school_payment_map_table(name):
    googleSheetId = '1X8nlhWRKFE6jO221SP1hrpBi9RSHZJ8_Q7oij1IU14Q'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc =  db.subscription_master.aggregate([
        {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
            {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
                {"IS_PAYMENT_SUCCESS" : "Y"},
                            {'USER_ID':{'$exists':1}}  ,  
                {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
        }},
        {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
        "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},
        "Payment_Amount":"$LAST_PAYMENT_AMOUNT",
        "EMAIL_ID":"$USER_ID.EMAIL_ID","SCHOOL_NAME":"$USER_ID.schoolId.NAME",
        "STATE":"$USER_ID.schoolId.STATE","STATE_SHOT":"$USER_ID.schoolId.STATE_SHORT"}}
        ,{"$unwind":"$Last_Payment_Date"}
        ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
    'MONTGOMERY UPPER MIDDLE SCHOOL',
    'RIVER VALLEY ELEMENTARY',
    'ALTURA PREPARATORY SCHOOL',
    'TWO BUNCH PALMS ELEMENTARY',
    'MELISSA MIDDLE SCHOOL',
    'MONTGOMERY LOWER MID SCH',
    'HATTIE DYER ELEMENTARY SCHOOL',
    'STOCKDALE JUNIOR HIGH',
    'INYO COUNTY COMMUNITY SCHOOL',
    'DESERT HOT SPRINGS HIGH',
    'SEMINOLE HIGH SCHOOL',
    'FRANKLIN WOODS INTERMEDIATE SCHOOL',
    'MARY B. LEWIS ELEMENTARY',
    'MCMILLIN (CORKY) ELEMENTARY',
    'ELGIN MIDDLE',
    'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
    'ODYSSEY ELEMENTARY',
    'FORT MEADOW ECC',
    'NO INFO',
    'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
    'BRIGHTON HIGH',
    'MARY M WALSH',
    'THE CAPITOL SCHOOL',
    'DR. DANIEL BRIGHT SCHOOL',
    'ROCK POINT COMMUNITY SCHOOL',
    'MURNIN ES',
    'SUNNY SANDS ELEMENTARY',
    'THOMAS JEFFERSON MIDDLE SCHOOL',
    'BENJAMIN FRANKLIN MIDDLE SCHOOL',
    'FAIRMONT CHARTER ELEMENTARY',
    'BLAIR ELEMENTARY SCHOOL',
    'L.A. MORGAN ELEMENTARY',
    'KRUM EARLY EDUCATION CENTER',
    'AMANDA HOPE RAINBOW ANGLES(NPO)',
    'STONY BROOK ELEMENTARY',
    'ROSE SPRINGS ELEMENTARY',
    'MT. BALDY JOINT ELEMENTARY',
    'LIBERTY HILLS ELEMENTARY',
    'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df1=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df=payment_df1.append(payment_df2)
    payment_df['STATE'] = payment_df['STATE'].str.upper() 
    payment_df['STATE_SHOT'] = payment_df['STATE_SHOT'].str.upper() 
    payment_df.Payment_Amount = payment_df.Payment_Amount.round()
    df = payment_df[payment_df.TYPE_OF_PAYMENT.str.contains("SCHOOL",case=False)]
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])
    df1=df[(df.Last_Payment_Date>= '2021-07-01')]
    df2=df1[["USER_NAME","EMAIL_ID","SCHOOL_NAME","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount"]]
    df3= df2[df2.STATE.str.contains("" + name + "",case=False)] 
    df3['Last_Payment_Date'] = df3['Last_Payment_Date'].astype('str')
    temp={"data":df3.values.tolist()}
    return json.dumps(temp)

@app.route('/schoolpaymentweekly')
def school_payment_weekly():
    googleSheetId = '1X8nlhWRKFE6jO221SP1hrpBi9RSHZJ8_Q7oij1IU14Q'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc =  db.subscription_master.aggregate([
        {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
            {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
                {"IS_PAYMENT_SUCCESS" : "Y"},
                            {'USER_ID':{'$exists':1}}  ,  
                {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
        }},
        {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
        "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},
        "Payment_Amount":"$LAST_PAYMENT_AMOUNT",
        "EMAIL_ID":"$USER_ID.EMAIL_ID","SCHOOL_NAME":"$USER_ID.schoolId.NAME",
        "STATE":"$USER_ID.schoolId.STATE","STATE_SHOT":"$USER_ID.schoolId.STATE_SHORT"}}
        ,{"$unwind":"$Last_Payment_Date"}
        ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
    'MONTGOMERY UPPER MIDDLE SCHOOL',
    'RIVER VALLEY ELEMENTARY',
    'ALTURA PREPARATORY SCHOOL',
    'TWO BUNCH PALMS ELEMENTARY',
    'MELISSA MIDDLE SCHOOL',
    'MONTGOMERY LOWER MID SCH',
    'HATTIE DYER ELEMENTARY SCHOOL',
    'STOCKDALE JUNIOR HIGH',
    'INYO COUNTY COMMUNITY SCHOOL',
    'DESERT HOT SPRINGS HIGH',
    'SEMINOLE HIGH SCHOOL',
    'FRANKLIN WOODS INTERMEDIATE SCHOOL',
    'MARY B. LEWIS ELEMENTARY',
    'MCMILLIN (CORKY) ELEMENTARY',
    'ELGIN MIDDLE',
    'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
    'ODYSSEY ELEMENTARY',
    'FORT MEADOW ECC',
    'NO INFO',
    'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
    'BRIGHTON HIGH',
    'MARY M WALSH',
    'THE CAPITOL SCHOOL',
    'DR. DANIEL BRIGHT SCHOOL',
    'ROCK POINT COMMUNITY SCHOOL',
    'MURNIN ES',
    'SUNNY SANDS ELEMENTARY',
    'THOMAS JEFFERSON MIDDLE SCHOOL',
    'BENJAMIN FRANKLIN MIDDLE SCHOOL',
    'FAIRMONT CHARTER ELEMENTARY',
    'BLAIR ELEMENTARY SCHOOL',
    'L.A. MORGAN ELEMENTARY',
    'KRUM EARLY EDUCATION CENTER',
    'AMANDA HOPE RAINBOW ANGLES(NPO)',
    'STONY BROOK ELEMENTARY',
    'ROSE SPRINGS ELEMENTARY',
    'MT. BALDY JOINT ELEMENTARY',
    'LIBERTY HILLS ELEMENTARY',
    'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df1=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df=payment_df1.append(payment_df2)
    payment_df['STATE'] = payment_df['STATE'].str.upper() 
    payment_df['STATE_SHOT'] = payment_df['STATE_SHOT'].str.upper() 
    
    df = payment_df[payment_df.TYPE_OF_PAYMENT.str.contains("SCHOOL",case=False)]
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])
    df1=df[(df.Last_Payment_Date>= '2021-07-01')]
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    df1=df1.groupby(df1['Last_Payment_Date'].dt.day_name())['Payment_Amount'].sum().reset_index()
    df1.Payment_Amount = df1.Payment_Amount.round()
    weeek= ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']
    df2 = pd.DataFrame(weeek,columns =['Last_Payment_Date'])
    final = pd.merge(df2, df1, on="Last_Payment_Date", how='left').fillna(0)
    temp={"month":final['Last_Payment_Date'].tolist(),"amount":final['Payment_Amount'].tolist()}
    return json.dumps(temp)








import plotly.express as px
@app.route('/bubble')
def bubblee():
    import plotly.express as px
    df2=pd.read_csv("/bubbledata124.csv")
    fig = px.scatter(df2.query("year==2007"), x="user enagement", y="family engagement",
            size="overall practice", color="school count",
                     hover_name="DISTRICT NAME", log_x=True, size_max=60)
    return(fig.show())

@app.route('/schoolpaymentcard')
def school_payment_card():
    googleSheetId = '1X8nlhWRKFE6jO221SP1hrpBi9RSHZJ8_Q7oij1IU14Q'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc =  db.subscription_master.aggregate([
        {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
            {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
                {"IS_PAYMENT_SUCCESS" : "Y"},
                {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
        }},
        {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
        "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},
        "Payment_Amount":"$LAST_PAYMENT_AMOUNT",
        "EMAIL_ID":"$USER_ID.EMAIL_ID","SCHOOL_NAME":"$USER_ID.schoolId.NAME",
        "STATE":"$USER_ID.schoolId.STATE","STATE_SHOT":"$USER_ID.schoolId.STATE_SHORT"}}
        ,{"$unwind":"$Last_Payment_Date"}
        ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
    'MONTGOMERY UPPER MIDDLE SCHOOL',
    'RIVER VALLEY ELEMENTARY',
    'ALTURA PREPARATORY SCHOOL',
    'TWO BUNCH PALMS ELEMENTARY',
    'MELISSA MIDDLE SCHOOL',
    'MONTGOMERY LOWER MID SCH',
    'HATTIE DYER ELEMENTARY SCHOOL',
    'STOCKDALE JUNIOR HIGH',
    'INYO COUNTY COMMUNITY SCHOOL',
    'DESERT HOT SPRINGS HIGH',
    'SEMINOLE HIGH SCHOOL',
    'FRANKLIN WOODS INTERMEDIATE SCHOOL',
    'MARY B. LEWIS ELEMENTARY',
    'MCMILLIN (CORKY) ELEMENTARY',
    'ELGIN MIDDLE',
    'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
    'ODYSSEY ELEMENTARY',
    'FORT MEADOW ECC',
    'NO INFO',
    'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
    'BRIGHTON HIGH',
    'MARY M WALSH',
    'THE CAPITOL SCHOOL',
    'DR. DANIEL BRIGHT SCHOOL',
    'ROCK POINT COMMUNITY SCHOOL',
    'MURNIN ES',
    'SUNNY SANDS ELEMENTARY',
    'THOMAS JEFFERSON MIDDLE SCHOOL',
    'BENJAMIN FRANKLIN MIDDLE SCHOOL',
    'FAIRMONT CHARTER ELEMENTARY',
    'BLAIR ELEMENTARY SCHOOL',
    'L.A. MORGAN ELEMENTARY',
    'KRUM EARLY EDUCATION CENTER',
    'AMANDA HOPE RAINBOW ANGLES(NPO)',
    'STONY BROOK ELEMENTARY',
    'ROSE SPRINGS ELEMENTARY',
    'MT. BALDY JOINT ELEMENTARY',
    'LIBERTY HILLS ELEMENTARY',
    'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df1=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df=payment_df1.append(payment_df2)
    payment_df['STATE'] = payment_df['STATE'].str.upper() 
    payment_df['STATE_SHOT'] = payment_df['STATE_SHOT'].str.upper() 
    
    df = payment_df[payment_df.TYPE_OF_PAYMENT.str.contains("SCHOOL",case=False)]
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])
    df1=df[(df.Last_Payment_Date>= '2021-07-01')]
    df1['Last_Payment_Date'] = pd.to_datetime(df1['Last_Payment_Date'])
    amount=df1['Payment_Amount'].sum()
    amount = amount.round()
    count=df1['Payment_Amount'].count()
    temp={"amount":int(amount),"count":int(count)}
    return json.dumps(temp)

@app.route('/schoolmapcard')
def school_map_card():
    googleSheetId = '1X8nlhWRKFE6jO221SP1hrpBi9RSHZJ8_Q7oij1IU14Q'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc =  db.subscription_master.aggregate([
        {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
            {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"LAST_PAYMENT_DATE":{"$gt":myDatetime}},
                {"IS_PAYMENT_SUCCESS" : "Y"},
                {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
        }},
        {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
        "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},
        "Payment_Amount":"$LAST_PAYMENT_AMOUNT",
        "EMAIL_ID":"$USER_ID.EMAIL_ID","SCHOOL_NAME":"$USER_ID.schoolId.NAME",
        "STATE":"$USER_ID.schoolId.STATE","STATE_SHOT":"$USER_ID.schoolId.STATE_SHORT"}}
        ,{"$unwind":"$Last_Payment_Date"}
        ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
    'MONTGOMERY UPPER MIDDLE SCHOOL',
    'RIVER VALLEY ELEMENTARY',
    'ALTURA PREPARATORY SCHOOL',
    'TWO BUNCH PALMS ELEMENTARY',
    'MELISSA MIDDLE SCHOOL',
    'MONTGOMERY LOWER MID SCH',
    'HATTIE DYER ELEMENTARY SCHOOL',
    'STOCKDALE JUNIOR HIGH',
    'INYO COUNTY COMMUNITY SCHOOL',
    'DESERT HOT SPRINGS HIGH',
    'SEMINOLE HIGH SCHOOL',
    'FRANKLIN WOODS INTERMEDIATE SCHOOL',
    'MARY B. LEWIS ELEMENTARY',
    'MCMILLIN (CORKY) ELEMENTARY',
    'ELGIN MIDDLE',
    'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
    'ODYSSEY ELEMENTARY',
    'FORT MEADOW ECC',
    'NO INFO',
    'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
    'BRIGHTON HIGH',
    'MARY M WALSH',
    'THE CAPITOL SCHOOL',
    'DR. DANIEL BRIGHT SCHOOL',
    'ROCK POINT COMMUNITY SCHOOL',
    'MURNIN ES',
    'SUNNY SANDS ELEMENTARY',
    'THOMAS JEFFERSON MIDDLE SCHOOL',
    'BENJAMIN FRANKLIN MIDDLE SCHOOL',
    'FAIRMONT CHARTER ELEMENTARY',
    'BLAIR ELEMENTARY SCHOOL',
    'L.A. MORGAN ELEMENTARY',
    'KRUM EARLY EDUCATION CENTER',
    'AMANDA HOPE RAINBOW ANGLES(NPO)',
    'STONY BROOK ELEMENTARY',
    'ROSE SPRINGS ELEMENTARY',
    'MT. BALDY JOINT ELEMENTARY',
    'LIBERTY HILLS ELEMENTARY',
    'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df1=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df=payment_df1.append(payment_df2)
    payment_df['STATE'] = payment_df['STATE'].str.upper() 
    payment_df['STATE_SHOT'] = payment_df['STATE_SHOT'].str.upper() 
    
    df = payment_df[payment_df.TYPE_OF_PAYMENT.str.contains("SCHOOL",case=False)]
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])
    df1=df[(df.Last_Payment_Date>= '2021-07-01')]
    df2=df1[["STATE_SHOT","STATE","Payment_Amount"]]
    df2['Payment_Amount'] = pd.to_numeric(df2['Payment_Amount'],errors='coerce')
    df3= df2.groupby(['STATE_SHOT',"STATE"])['Payment_Amount'].sum().reset_index()
    df3.Payment_Amount = df3.Payment_Amount.round()
    df4=df3.sort_values(by=['Payment_Amount'],ascending=False)
    df5=df4.head(5)
    temp={"data":df5[["STATE","Payment_Amount"]].values.tolist()}
    return json.dumps(temp)

# Code for D3_Renewal Chart active csy and overall expiring schools count and tables.
@app.route('/d3renewalchart')

def d3_chart():
    #school summary df
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    query=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
    # //       {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          
              {'$group':{
                  '_id':'$schoolId._id',
                  'schoolname':{'$first':'$schoolId.NAME'},
                  'CITY':{'$first':'$schoolId.CITY'},
                  'STATE':{'$first':'$schoolId.STATE'},
                  'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                  'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                  'CREATED_DATE':{'$min':'$CREATED_DATE'},
                  'USER_COUNT':{'$addToSet':'$_id'}}},
              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'SCHOOL_NAME':'$schoolname',
                  'CITY':'$CITY',
                  'STATE':'$STATE',
                  'COUNTRY':'$COUNTRY',
                  'ROLE_ID':'$ROLE_ID',
                  'CREATED_DATE':'$CREATED_DATE',
                  'USER_COUNT':{'$size':'$USER_COUNT'}
                  }}]
    school_summary=list(collection.aggregate(query))
    school_summary_df=pd.DataFrame(school_summary)

    #admin summary info

    query2=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
          {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
             {'IS_ADMIN':'Y'},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$schoolId._id',
                  'SCHOOL_NAME':'$schoolId.NAME',
                  'ADMIN_ID':'$_id',
                  'ADMIN_NAME':'$USER_NAME',
                  'ADMIN_EMAIL':'$EMAIL_ID',
                  'DISTRICT_ID':'$DISTRICT_ID._id',
                  'DISTRICT_NAME':'$DISTRICT_ID.DISTRICT_NAME',
                  'ROLE_ID':'$ROLE_ID.ROLE_ID',
                  'D_CATEGORY':'$D_CATEGORY'         
                  }}]
    admin_summary=list(collection.aggregate(query2))
    admin_summary_df=pd.DataFrame(admin_summary)

    #school_Subscription_master summary
    collection2 = db.subscription_master
    query3=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_ID'},
                  }},

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan'
                  }}]
    school_sm_summary=list(collection2.aggregate(query3))
    school_sm_summary_df=pd.DataFrame(school_sm_summary)

    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y'})
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)


    #school summary audio_track_master

    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_summary=list(collection3.aggregate(query5))
    school_prac_summary_df=pd.DataFrame(school_prac_summary)
    query6=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}       


              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_active_csy=list(collection3.aggregate(query6))
    school_prac_active_csy_df=pd.DataFrame(school_prac_active_csy)

            # <<<<<<<<<<<---------------------------------------------------->>>>>>>>>>>>>

    school_with_admin=school_summary_df.merge(admin_summary_df[['SCHOOL_ID',
                                                        'SCHOOL_NAME','ADMIN_ID','ADMIN_NAME','D_CATEGORY',
                                                        'ADMIN_EMAIL','ROLE_ID','DISTRICT_ID','DISTRICT_NAME']],
                                      how='left',on='SCHOOL_ID')
    school_with_admin.loc[school_with_admin['ADMIN_ID'].notnull(), 'SCHOOL_NAME_x'] = school_with_admin['SCHOOL_NAME_y']
    school_with_admin.rename({'SCHOOL_NAME_x': 'SCHOOL_NAME'}, axis=1, inplace=True)
    school_with_admin.drop(['SCHOOL_NAME_y'],axis=1,inplace=True)
    school_with_admin.loc[school_with_admin['ADMIN_ID'].notnull(), 'ROLE_ID_x'] = school_with_admin['ROLE_ID_y']
    school_with_admin.rename({'ROLE_ID_x': 'ROLE_ID'}, axis=1, inplace=True)
    school_with_admin.drop(['ROLE_ID_y'],axis=1,inplace=True)
    school_renewal_info_df=school_with_admin.merge(admin_sm_summary_df[['ADMIN_ID', 'Renewal_Date', 'PLAN_ID', 'PLAN_NAME']]
                                                   ,how='left',on='ADMIN_ID')
    school_renewal_info1=school_renewal_info_df.merge(school_sm_summary_df,how='left',on='SCHOOL_ID')
    school_renewal_info1.loc[school_renewal_info1['ADMIN_ID'].isnull(), 
                             'Renewal_Date'] = school_renewal_info1['MAX_RENEWAL_DATE']
    school_renewal_info1.drop(['MAX_RENEWAL_DATE'],axis=1,inplace=True)
    school_renewal_info1.loc[school_renewal_info1['ADMIN_ID'].isnull(), 'PLAN_ID'] = school_renewal_info1['MAX_PLAN']
    school_renewal_info1.drop(['MAX_PLAN'],axis=1,inplace=True)
    school_complete_info=school_renewal_info1.merge(school_prac_summary_df,how='left',on='SCHOOL_ID')
    school_complete_info1=school_complete_info.merge(school_prac_active_csy_df[['SCHOOL_ID','Last_Practice_Date']],how='left',on='SCHOOL_ID')
    school_complete_info1.loc[school_complete_info1['Last_Practice_Date_y'].notnull(), 'Active_CSY'] = 'Yes'
    school_complete_info1.drop(['Last_Practice_Date_y'],axis=1,inplace=True)
    school_complete_info1.rename({'Last_Practice_Date_x': 'Last_Practice_Date'}, axis=1, inplace=True)
    school_complete_info1.Active_User.fillna(0,inplace=True)
    school_complete_info1.Active_CSY.fillna('No',inplace=True)
    school_complete_info1.Practice_Sessions.fillna(0,inplace=True)
    school_complete_info1.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_info1.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    last_prac_date=school_complete_info1['Last_Practice_Date'].tolist()
    created_date=school_complete_info1['CREATED_DATE'].tolist()
    renewal_date=school_complete_info1['Renewal_Date'].tolist()

    webapp_schools=school_complete_info1[school_complete_info1.PLAN_ID!=16]
    webapp_schools_final=webapp_schools[webapp_schools.ADMIN_ID.notnull() & 
                                                webapp_schools.Renewal_Date.notnull()]
    webapp_schools_final_D3=webapp_schools_final[webapp_schools_final['D_CATEGORY']=='D3']

    webapp_schools_final_D3_csy_active=webapp_schools_final_D3[webapp_schools_final_D3['Active_CSY']=='Yes']

    D3_Schools=webapp_schools_final_D3['Renewal_Date'].groupby([webapp_schools_final_D3.Renewal_Date.dt.year.rename('year'), 
                                       webapp_schools_final_D3.Renewal_Date.dt.month.rename('month')]).agg('count').reset_index().rename({'Renewal_Date':'Total_Schools'},axis=1)
    D3_Schools_active_csy=webapp_schools_final_D3_csy_active['Renewal_Date'].groupby([webapp_schools_final_D3_csy_active.Renewal_Date.dt.year.rename('year'), 
                                       webapp_schools_final_D3_csy_active.Renewal_Date.dt.month.rename('month')]).agg('count').reset_index().rename({'Renewal_Date':'Active_Schools'},axis=1)
    D3_chart_Data=D3_Schools.merge(D3_Schools_active_csy,on=['year','month'],how='left').fillna(0)
    D3_chart_Data['Month_Name'] = pd.to_datetime(D3_chart_Data['month'], format='%m').dt.month_name().str.slice(stop=3)
    Month_Name = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
    month_df=pd.DataFrame({'Month_Name':Month_Name})
    D3_chart_Data_2020=D3_chart_Data[D3_chart_Data['year']==2020]
    D3_chart_Data_2021=D3_chart_Data[D3_chart_Data['year']==2021]
    D3_chart_Data_2022=D3_chart_Data[D3_chart_Data['year']==2022]
    D3_chart_Data_2023=D3_chart_Data[D3_chart_Data['year']==2023]

    D3_chart_Data_2020_mothwise=month_df.merge(D3_chart_Data_2020,on='Month_Name',how='left').fillna(0)
    D3_chart_Data_2021_mothwise=month_df.merge(D3_chart_Data_2021,on='Month_Name',how='left').fillna(0)
    D3_chart_Data_2022_mothwise=month_df.merge(D3_chart_Data_2022,on='Month_Name',how='left').fillna(0)
    D3_chart_Data_2023_mothwise=month_df.merge(D3_chart_Data_2023,on='Month_Name',how='left').fillna(0)

    temp={'Data_2020':{'Month_Name':D3_chart_Data_2020_mothwise.Month_Name.tolist(),
                        'Expiring_Schools':D3_chart_Data_2020_mothwise.Total_Schools.to_list(),
                         'Active_Schools_csy':D3_chart_Data_2020_mothwise.Active_Schools.to_list()
                        },
                        'Data_2021':{
                         'Month_Name':D3_chart_Data_2021_mothwise.Month_Name.tolist(),
                        'Expiring_Schools':D3_chart_Data_2021_mothwise.Total_Schools.to_list(),
                         'Active_Schools_csy':D3_chart_Data_2021_mothwise.Active_Schools.to_list()   
                        },
                        'Data_2022':{
                         'Month_Name':D3_chart_Data_2022_mothwise.Month_Name.tolist(),
                        'Expiring_Schools':D3_chart_Data_2022_mothwise.Total_Schools.to_list(),
                         'Active_Schools_csy':D3_chart_Data_2022_mothwise.Active_Schools.to_list()   
                        },
                        'Data_2023':{
                         'Month_Name':D3_chart_Data_2023_mothwise.Month_Name.tolist(),
                        'Expiring_Schools':D3_chart_Data_2023_mothwise.Total_Schools.to_list(),
                         'Active_Schools_csy':D3_chart_Data_2023_mothwise.Active_Schools.to_list()   
                        }}

    return json.dumps(temp)

@app.route('/d3renewaltable/EXP/<year>/<month>')

def d3_renewal_table(year,month):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    query=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
    # //       {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          
              {'$group':{
                  '_id':'$schoolId._id',
                  'schoolname':{'$first':'$schoolId.NAME'},
                  'CITY':{'$first':'$schoolId.CITY'},
                  'STATE':{'$first':'$schoolId.STATE'},
                  'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                  'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                  'CREATED_DATE':{'$min':'$CREATED_DATE'},
                  'USER_COUNT':{'$addToSet':'$_id'}}},
              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'SCHOOL_NAME':'$schoolname',
                  'CITY':'$CITY',
                  'STATE':'$STATE',
                  'COUNTRY':'$COUNTRY',
                  'ROLE_ID':'$ROLE_ID',
                  'CREATED_DATE':'$CREATED_DATE',
                  'USER_COUNT':{'$size':'$USER_COUNT'}
                  }}]
    school_summary=list(collection.aggregate(query))
    school_summary_df=pd.DataFrame(school_summary)

    #admin summary info

    query2=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
          {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
             {'IS_ADMIN':'Y'},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$schoolId._id',
                  'SCHOOL_NAME':'$schoolId.NAME',
                  'ADMIN_ID':'$_id',
                  'ADMIN_NAME':'$USER_NAME',
                  'ADMIN_EMAIL':'$EMAIL_ID',
                  'DISTRICT_ID':'$DISTRICT_ID._id',
                  'DISTRICT_NAME':'$DISTRICT_ID.DISTRICT_NAME',
                  'ROLE_ID':'$ROLE_ID.ROLE_ID',
                  'D_CATEGORY':'$D_CATEGORY'         
                  }}]
    admin_summary=list(collection.aggregate(query2))
    admin_summary_df=pd.DataFrame(admin_summary)

    #school_Subscription_master summary
    collection2 = db.subscription_master
    query3=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_ID'},
                  }},

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan'
                  }}]
    school_sm_summary=list(collection2.aggregate(query3))
    school_sm_summary_df=pd.DataFrame(school_sm_summary)

    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y'})
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)


    #school summary audio_track_master

    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_summary=list(collection3.aggregate(query5))
    school_prac_summary_df=pd.DataFrame(school_prac_summary)
    query6=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}       


              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_active_csy=list(collection3.aggregate(query6))
    school_prac_active_csy_df=pd.DataFrame(school_prac_active_csy)

            # <<<<<<<<<<<---------------------------------------------------->>>>>>>>>>>>>

    school_with_admin=school_summary_df.merge(admin_summary_df[['SCHOOL_ID',
                                                        'SCHOOL_NAME','ADMIN_ID','ADMIN_NAME','D_CATEGORY',
                                                        'ADMIN_EMAIL','ROLE_ID','DISTRICT_ID','DISTRICT_NAME']],
                                      how='left',on='SCHOOL_ID')
    school_with_admin.loc[school_with_admin['ADMIN_ID'].notnull(), 'SCHOOL_NAME_x'] = school_with_admin['SCHOOL_NAME_y']
    school_with_admin.rename({'SCHOOL_NAME_x': 'SCHOOL_NAME'}, axis=1, inplace=True)
    school_with_admin.drop(['SCHOOL_NAME_y'],axis=1,inplace=True)
    school_with_admin.loc[school_with_admin['ADMIN_ID'].notnull(), 'ROLE_ID_x'] = school_with_admin['ROLE_ID_y']
    school_with_admin.rename({'ROLE_ID_x': 'ROLE_ID'}, axis=1, inplace=True)
    school_with_admin.drop(['ROLE_ID_y'],axis=1,inplace=True)
    school_renewal_info_df=school_with_admin.merge(admin_sm_summary_df[['ADMIN_ID', 'Renewal_Date', 'PLAN_ID', 'PLAN_NAME']]
                                                   ,how='left',on='ADMIN_ID')
    school_renewal_info1=school_renewal_info_df.merge(school_sm_summary_df,how='left',on='SCHOOL_ID')
    school_renewal_info1.loc[school_renewal_info1['ADMIN_ID'].isnull(), 
                             'Renewal_Date'] = school_renewal_info1['MAX_RENEWAL_DATE']
    school_renewal_info1.drop(['MAX_RENEWAL_DATE'],axis=1,inplace=True)
    school_renewal_info1.loc[school_renewal_info1['ADMIN_ID'].isnull(), 'PLAN_ID'] = school_renewal_info1['MAX_PLAN']
    school_renewal_info1.drop(['MAX_PLAN'],axis=1,inplace=True)
    school_complete_info=school_renewal_info1.merge(school_prac_summary_df,how='left',on='SCHOOL_ID')
    school_complete_info1=school_complete_info.merge(school_prac_active_csy_df[['SCHOOL_ID','Last_Practice_Date']],how='left',on='SCHOOL_ID')
    school_complete_info1.loc[school_complete_info1['Last_Practice_Date_y'].notnull(), 'Active_CSY'] = 'Yes'
    school_complete_info1.drop(['Last_Practice_Date_y'],axis=1,inplace=True)
    school_complete_info1.rename({'Last_Practice_Date_x': 'Last_Practice_Date'}, axis=1, inplace=True)
    school_complete_info1.Active_User.fillna(0,inplace=True)
    school_complete_info1.Active_CSY.fillna('No',inplace=True)
    school_complete_info1.Practice_Sessions.fillna(0,inplace=True)
    school_complete_info1.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_info1.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    last_prac_date=school_complete_info1['Last_Practice_Date'].tolist()
    created_date=school_complete_info1['CREATED_DATE'].tolist()
    renewal_date=school_complete_info1['Renewal_Date'].tolist()

    webapp_schools=school_complete_info1[school_complete_info1.PLAN_ID!=16]
    webapp_schools_final=webapp_schools[webapp_schools.ADMIN_ID.notnull() & 
                                                webapp_schools.Renewal_Date.notnull()]
    webapp_schools_final_D3=webapp_schools_final[webapp_schools_final['D_CATEGORY']=='D3']
    webapp_schools_final_D3_table=webapp_schools_final_D3[['SCHOOL_NAME', 'CITY', 'STATE', 'COUNTRY', 'ROLE_ID',
                               'CREATED_DATE', 'USER_COUNT','ADMIN_NAME',
                               'ADMIN_EMAIL','Renewal_Date',
                               'PLAN_NAME','Active_User','Last_Practice_Date',
                               'Practice_Sessions', 'Mindful_Minutes', 'Active_CSY']]
    webapp_schools_final_D3_table=webapp_schools_final_D3[['SCHOOL_NAME', 'CITY', 'STATE', 'COUNTRY', 'ROLE_ID',
                               'CREATED_DATE', 'USER_COUNT','ADMIN_NAME',
                               'ADMIN_EMAIL','Renewal_Date',
                               'PLAN_NAME','Active_User','Last_Practice_Date',
                               'Practice_Sessions', 'Mindful_Minutes', 'Active_CSY']]
    month_name = str(month).title()
    _year=int(year)
    datetime_object = datetime.datetime.strptime(month_name, "%b")
    month_number = datetime_object.month


    required_df_expiring_schools=webapp_schools_final_D3_table[(webapp_schools_final_D3_table['Renewal_Date'].dt.month == month_number) 
                                                               & (webapp_schools_final_D3_table['Renewal_Date'].dt.year == _year)]

    required_df_expiring_schools.CITY.fillna('NO INFO',inplace=True)
    required_df_expiring_schools.STATE.fillna('NO INFO',inplace=True)
    required_df_expiring_schools.COUNTRY.fillna('NO INFO',inplace=True)
    required_df_expiring_schools.SCHOOL_NAME.fillna('NO INFO',inplace=True)
    required_df_expiring_schools.SCHOOL_NAME=required_df_expiring_schools.SCHOOL_NAME.str.upper()
    required_df_expiring_schools.CITY=required_df_expiring_schools.CITY.str.upper()
    required_df_expiring_schools.STATE=required_df_expiring_schools.STATE.str.upper()
    required_df_expiring_schools.COUNTRY=required_df_expiring_schools.COUNTRY.str.upper()
    
    created_date=required_df_expiring_schools['CREATED_DATE'].tolist()
    renewal_date=required_df_expiring_schools['Renewal_Date'].tolist()
    prac_date=required_df_expiring_schools['Last_Practice_Date'].tolist()
    

    created_date_1=[]
    renewal_date_1=[]
    prac_date_1=[]

    for i in range(len(created_date)):
        if created_date[i]!='':
            created_date_1.append(created_date[i].strftime("%d %b %Y "))
        else:
            created_date_1.append('NO CREATED DATE')

        if renewal_date[i] is not None:
            renewal_date_1.append(renewal_date[i].strftime("%d %b %Y "))
        else:
            renewal_date_1.append('NO RENEWAL DATE')    

        if prac_date[i]!='NO PRACTICE':
            prac_date_1.append(prac_date[i].strftime("%d %b %Y "))
        else:
            prac_date_1.append(prac_date[i])

    new_df=pd.DataFrame({'SCHOOL':required_df_expiring_schools.SCHOOL_NAME.tolist(),
      'CITY':required_df_expiring_schools.CITY.tolist(),
      'STATE':required_df_expiring_schools.STATE.tolist(),
      'COUNTRY':required_df_expiring_schools.COUNTRY.tolist(),
      'ADMIN':required_df_expiring_schools.ADMIN_NAME.tolist(),
      'EMAIL':required_df_expiring_schools.ADMIN_EMAIL.tolist(),
      'Plan':required_df_expiring_schools.PLAN_NAME.tolist(),
      'Created_Date':created_date_1,
      'Active_User':required_df_expiring_schools.Active_User.tolist(),
      'Total_Users':required_df_expiring_schools.USER_COUNT.tolist(),                   
      'Renewal_Date':renewal_date_1,
      'Last_Practice_Date':prac_date_1,
      'Mindful_Minutes':required_df_expiring_schools.Mindful_Minutes.tolist(),
      'Practice_Sessions':required_df_expiring_schools.Practice_Sessions.tolist(),
      'Active_CSY':required_df_expiring_schools.Active_CSY.tolist()})
    
    data=[]
    for i,j,k,l,m,n,o,p,q,r,s,t,u,v in zip(
        new_df.SCHOOL.tolist(),new_df.CITY.tolist(),new_df.STATE.tolist(),new_df.COUNTRY.tolist(),
        new_df.ADMIN.tolist(),new_df.EMAIL.tolist(),new_df.Created_Date.tolist(),
        new_df.Renewal_Date.tolist(),new_df.Last_Practice_Date.tolist(),new_df.Mindful_Minutes.tolist(),
        new_df.Practice_Sessions.tolist(),new_df.Total_Users.tolist(),new_df.Active_User.tolist(),new_df.Plan.tolist()
    ) :       
        data.append([i,j,k,l,m,n,o,p,q,r,s,t,u,v])
    temp ={"data":data}
    return json.dumps(temp)

@app.route('/d3renewaltable/ACT/<year>/<month>')

def d3_renewal_active_csy_table(year,month):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    query=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
    # //       {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          
              {'$group':{
                  '_id':'$schoolId._id',
                  'schoolname':{'$first':'$schoolId.NAME'},
                  'CITY':{'$first':'$schoolId.CITY'},
                  'STATE':{'$first':'$schoolId.STATE'},
                  'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                  'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                  'CREATED_DATE':{'$min':'$CREATED_DATE'},
                  'USER_COUNT':{'$addToSet':'$_id'}}},
              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'SCHOOL_NAME':'$schoolname',
                  'CITY':'$CITY',
                  'STATE':'$STATE',
                  'COUNTRY':'$COUNTRY',
                  'ROLE_ID':'$ROLE_ID',
                  'CREATED_DATE':'$CREATED_DATE',
                  'USER_COUNT':{'$size':'$USER_COUNT'}
                  }}]
    school_summary=list(collection.aggregate(query))
    school_summary_df=pd.DataFrame(school_summary)

    #admin summary info

    query2=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
          {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'DEVICE_USED':{"$regex":'webapp','$options':'i'}},
             {'IS_ADMIN':'Y'},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$schoolId._id',
                  'SCHOOL_NAME':'$schoolId.NAME',
                  'ADMIN_ID':'$_id',
                  'ADMIN_NAME':'$USER_NAME',
                  'ADMIN_EMAIL':'$EMAIL_ID',
                  'DISTRICT_ID':'$DISTRICT_ID._id',
                  'DISTRICT_NAME':'$DISTRICT_ID.DISTRICT_NAME',
                  'ROLE_ID':'$ROLE_ID.ROLE_ID',
                  'D_CATEGORY':'$D_CATEGORY'         
                  }}]
    admin_summary=list(collection.aggregate(query2))
    admin_summary_df=pd.DataFrame(admin_summary)

    #school_Subscription_master summary
    collection2 = db.subscription_master
    query3=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_ID'},
                  }},

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan'
                  }}]
    school_sm_summary=list(collection2.aggregate(query3))
    school_sm_summary_df=pd.DataFrame(school_sm_summary)

    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y'})
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)


    #school summary audio_track_master

    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_summary=list(collection3.aggregate(query5))
    school_prac_summary_df=pd.DataFrame(school_prac_summary)
    query6=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}       


              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_active_csy=list(collection3.aggregate(query6))
    school_prac_active_csy_df=pd.DataFrame(school_prac_active_csy)

            # <<<<<<<<<<<---------------------------------------------------->>>>>>>>>>>>>

    school_with_admin=school_summary_df.merge(admin_summary_df[['SCHOOL_ID',
                                                        'SCHOOL_NAME','ADMIN_ID','ADMIN_NAME','D_CATEGORY',
                                                        'ADMIN_EMAIL','ROLE_ID','DISTRICT_ID','DISTRICT_NAME']],
                                      how='left',on='SCHOOL_ID')
    school_with_admin.loc[school_with_admin['ADMIN_ID'].notnull(), 'SCHOOL_NAME_x'] = school_with_admin['SCHOOL_NAME_y']
    school_with_admin.rename({'SCHOOL_NAME_x': 'SCHOOL_NAME'}, axis=1, inplace=True)
    school_with_admin.drop(['SCHOOL_NAME_y'],axis=1,inplace=True)
    school_with_admin.loc[school_with_admin['ADMIN_ID'].notnull(), 'ROLE_ID_x'] = school_with_admin['ROLE_ID_y']
    school_with_admin.rename({'ROLE_ID_x': 'ROLE_ID'}, axis=1, inplace=True)
    school_with_admin.drop(['ROLE_ID_y'],axis=1,inplace=True)
    school_renewal_info_df=school_with_admin.merge(admin_sm_summary_df[['ADMIN_ID', 'Renewal_Date', 'PLAN_ID', 'PLAN_NAME']]
                                                   ,how='left',on='ADMIN_ID')
    school_renewal_info1=school_renewal_info_df.merge(school_sm_summary_df,how='left',on='SCHOOL_ID')
    school_renewal_info1.loc[school_renewal_info1['ADMIN_ID'].isnull(), 
                             'Renewal_Date'] = school_renewal_info1['MAX_RENEWAL_DATE']
    school_renewal_info1.drop(['MAX_RENEWAL_DATE'],axis=1,inplace=True)
    school_renewal_info1.loc[school_renewal_info1['ADMIN_ID'].isnull(), 'PLAN_ID'] = school_renewal_info1['MAX_PLAN']
    school_renewal_info1.drop(['MAX_PLAN'],axis=1,inplace=True)
    school_complete_info=school_renewal_info1.merge(school_prac_summary_df,how='left',on='SCHOOL_ID')
    school_complete_info1=school_complete_info.merge(school_prac_active_csy_df[['SCHOOL_ID','Last_Practice_Date']],how='left',on='SCHOOL_ID')
    school_complete_info1.loc[school_complete_info1['Last_Practice_Date_y'].notnull(), 'Active_CSY'] = 'Yes'
    school_complete_info1.drop(['Last_Practice_Date_y'],axis=1,inplace=True)
    school_complete_info1.rename({'Last_Practice_Date_x': 'Last_Practice_Date'}, axis=1, inplace=True)
    school_complete_info1.Active_User.fillna(0,inplace=True)
    school_complete_info1.Active_CSY.fillna('No',inplace=True)
    school_complete_info1.Practice_Sessions.fillna(0,inplace=True)
    school_complete_info1.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_info1.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    last_prac_date=school_complete_info1['Last_Practice_Date'].tolist()
    created_date=school_complete_info1['CREATED_DATE'].tolist()
    renewal_date=school_complete_info1['Renewal_Date'].tolist()

    webapp_schools=school_complete_info1[school_complete_info1.PLAN_ID!=16]
    webapp_schools_final=webapp_schools[webapp_schools.ADMIN_ID.notnull() & 
                                                webapp_schools.Renewal_Date.notnull()]
    webapp_schools_final_D3=webapp_schools_final[webapp_schools_final['D_CATEGORY']=='D3']
    webapp_schools_final_D3_table=webapp_schools_final_D3[['SCHOOL_NAME', 'CITY', 'STATE', 'COUNTRY', 'ROLE_ID',
                               'CREATED_DATE', 'USER_COUNT','ADMIN_NAME',
                               'ADMIN_EMAIL','Renewal_Date',
                               'PLAN_NAME','Active_User','Last_Practice_Date',
                               'Practice_Sessions', 'Mindful_Minutes', 'Active_CSY']]
    webapp_schools_final_D3_table=webapp_schools_final_D3[['SCHOOL_NAME', 'CITY', 'STATE', 'COUNTRY', 'ROLE_ID',
                               'CREATED_DATE', 'USER_COUNT','ADMIN_NAME',
                               'ADMIN_EMAIL','Renewal_Date',
                               'PLAN_NAME','Active_User','Last_Practice_Date',
                               'Practice_Sessions', 'Mindful_Minutes', 'Active_CSY']]
    month_name = str(month).title()
    _year=int(year)
    datetime_object = datetime.datetime.strptime(month_name, "%b")
    month_number = datetime_object.month


    required_df_expiring_schools=webapp_schools_final_D3_table[(webapp_schools_final_D3_table['Renewal_Date'].dt.month == month_number) 
                                                               & (webapp_schools_final_D3_table['Renewal_Date'].dt.year == _year)]

    required_df_expiring_schools.CITY.fillna('NO INFO',inplace=True)
    required_df_expiring_schools.STATE.fillna('NO INFO',inplace=True)
    required_df_expiring_schools.COUNTRY.fillna('NO INFO',inplace=True)
    required_df_expiring_schools.SCHOOL_NAME.fillna('NO INFO',inplace=True)
    required_df_expiring_schools.SCHOOL_NAME=required_df_expiring_schools.SCHOOL_NAME.str.upper()
    required_df_expiring_schools.CITY=required_df_expiring_schools.CITY.str.upper()
    required_df_expiring_schools.STATE=required_df_expiring_schools.STATE.str.upper()
    required_df_expiring_schools.COUNTRY=required_df_expiring_schools.COUNTRY.str.upper()
    
    created_date=required_df_expiring_schools['CREATED_DATE'].tolist()
    renewal_date=required_df_expiring_schools['Renewal_Date'].tolist()
    prac_date=required_df_expiring_schools['Last_Practice_Date'].tolist()
    

    created_date_1=[]
    renewal_date_1=[]
    prac_date_1=[]

    for i in range(len(created_date)):
        if created_date[i]!='':
            created_date_1.append(created_date[i].strftime("%d %b %Y "))
        else:
            created_date_1.append('NO CREATED DATE')

        if renewal_date[i] is not None:
            renewal_date_1.append(renewal_date[i].strftime("%d %b %Y "))
        else:
            renewal_date_1.append('NO RENEWAL DATE')    

        if prac_date[i]!='NO PRACTICE':
            prac_date_1.append(prac_date[i].strftime("%d %b %Y "))
        else:
            prac_date_1.append(prac_date[i])

    new_df=pd.DataFrame({'SCHOOL':required_df_expiring_schools.SCHOOL_NAME.tolist(),
      'CITY':required_df_expiring_schools.CITY.tolist(),
      'STATE':required_df_expiring_schools.STATE.tolist(),
      'COUNTRY':required_df_expiring_schools.COUNTRY.tolist(),
      'ADMIN':required_df_expiring_schools.ADMIN_NAME.tolist(),
      'EMAIL':required_df_expiring_schools.ADMIN_EMAIL.tolist(),
      'Plan':required_df_expiring_schools.PLAN_NAME.tolist(),
      'Created_Date':created_date_1,
      'Active_User':required_df_expiring_schools.Active_User.tolist(),
      'Total_Users':required_df_expiring_schools.USER_COUNT.tolist(),                   
      'Renewal_Date':renewal_date_1,
      'Last_Practice_Date':prac_date_1,
      'Mindful_Minutes':required_df_expiring_schools.Mindful_Minutes.tolist(),
      'Practice_Sessions':required_df_expiring_schools.Practice_Sessions.tolist(),
      'Active_CSY':required_df_expiring_schools.Active_CSY.tolist()})
    
    new_df_active_csy=new_df[new_df['Active_CSY']=='Yes']
    data=[]
    for i,j,k,l,m,n,o,p,q,r,s,t,u,v in zip(
        new_df_active_csy.SCHOOL.tolist(),new_df_active_csy.CITY.tolist(),new_df_active_csy.STATE.tolist(),new_df_active_csy.COUNTRY.tolist(),
        new_df_active_csy.ADMIN.tolist(),new_df_active_csy.EMAIL.tolist(),new_df_active_csy.Created_Date.tolist(),
        new_df_active_csy.Renewal_Date.tolist(),new_df_active_csy.Last_Practice_Date.tolist(),
        new_df_active_csy.Mindful_Minutes.tolist(),
        new_df_active_csy.Practice_Sessions.tolist(),new_df_active_csy.Total_Users.tolist(),
        new_df_active_csy.Active_User.tolist(),new_df_active_csy.Plan.tolist()
    ):
        
        data.append([i,j,k,l,m,n,o,p,q,r,s,t,u,v])
    temp ={"data":data}
    return json.dumps(temp)

@app.route('/MOBILE_PAID_SCHOOL_TABLE')
def Paid_mobile_subscription_table():
    dflife=pd.read_csv("hom_exec.csv")
    lifelist=list(dflife["0"])

    lifetimelist=[]

    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    ]}},
    {'$group':{  '_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
                      'USER_COUNT':{'$size':'$USER_COUNT'}                              
                      }}]


    home_app_=list(collection.aggregate(query))
    home_app_df=pd.DataFrame(home_app_)

    dflife1=pd.read_csv("sch_exec.csv")


    lifelist1=list(dflife1["0"])

    lifetimelist1=[]

    from bson import ObjectId
    for i in lifelist1:
        lifetimelist1.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query1=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist1
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{'_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]

    IEschool_=list(collection.aggregate(query1))
    IEschool__df=pd.DataFrame(IEschool_)

    mobile_app_df=home_app_df.append(IEschool__df, ignore_index=True)

    schoolids=list(mobile_app_df['SCHOOL_ID'])

    collection22 = db.subscription_master
    query33=[{'$match':{'LAST_PAYMENT_AMOUNT':{'$exists':1}}},
        {"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'LAST_PAYMENT_AMOUNT':{'$ne':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{              
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_NAME'},'LAST_PAYMENT_AMOUNT':{'$max':'$LAST_PAYMENT_AMOUNT'},
                  'MODE_OF_PAYMENT':{'$first':'$MODE_OF_PAYMENT'},
                  'LAST_PAYMENT_DATE':{'$max':'$LAST_PAYMENT_DATE'},
                  'COMMENT_BY_DS_TEAM':{'$first':'$COMMENT_BY_DS_TEAM'}
                  }},
        {'$project':{'_id':0, 'SCHOOL_ID':'$_id','Max_Renewal_Date':'$Max_Renewal_Date',
                   'Max_Plan':'$Max_Plan', 'LAST_PAYMENT_AMOUNT':'$LAST_PAYMENT_AMOUNT',
                    'MODE_OF_PAYMENT':'$MODE_OF_PAYMENT','LAST_PAYMENT_DATE':'$LAST_PAYMENT_DATE',
                   'COMMENT_BY_DS_TEAM':'$COMMENT_BY_DS_TEAM' }}

            ]

    subscription=list(collection22.aggregate(query33))
    subscription_df=pd.DataFrame(subscription)



    collection33 = db.audio_track_master
    query44=[
        {"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{              
                  '_id':'$USER_ID.schoolId._id',
                  'Last_practice_date':{'$max':'$MODIFIED_DATE'},
                  'Practice_count':{'$sum':1}
                }},
            {'$project':{'_id':0,'SCHOOL_ID':'$_id','Last_practice_date':'$Last_practice_date',
                        'Practice_count':'$Practice_count'}}

            ]

    practice=list(collection33.aggregate(query44))
    practice_df=pd.DataFrame(practice)



    collection44 = db.user_master
    query55=[
        {"$match":{
             '$and':[{'schoolId._id':{'$in':schoolids}},
                 { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{              
                  '_id':'$schoolId._id',
                  'EMAIL_ID':{'$first':'$EMAIL_ID'},
#                   'SCHOOL_ID':{'$first':'$schoolId._id'},
                  'SCHOOL_NAME':{'$first':'$schoolId.NAME'},
                  'DEVICE_USED':{'$first':'$DEVICE_USED'},
                  'STATE':{'$first':'$schoolId.STATE'},
                  'CITY':{'$first':'$schoolId.CITY'}
                               }},

    {'$project':{'_id':0, 'SCHOOL_ID':'$_id','EMAIL_ID':'$EMAIL_ID','SCHOOL_NAME':'$SCHOOL_NAME',
               'DEVICE_USED':'$DEVICE_USED','STATE':'$STATE','CITY':'$CITY' }}
            ]

    user_master=list(collection44.aggregate(query55))
    user_master_df=pd.DataFrame(user_master)


    subatm=pd.merge(subscription_df,practice_df, on='SCHOOL_ID',how='left')
    table=pd.merge(subatm,user_master_df, on='SCHOOL_ID',how='left')


    table.Practice_count.fillna(0, inplace=True)
    table.Last_practice_date.fillna('NO PRACTICE', inplace=True)

    table1=table[['SCHOOL_NAME','EMAIL_ID','Max_Renewal_Date','LAST_PAYMENT_AMOUNT','LAST_PAYMENT_DATE','MODE_OF_PAYMENT','Max_Plan',
          'Practice_count','Last_practice_date','DEVICE_USED'
          ]]

    # Last_practice_date=table1.Last_practice_date.tolist()
    # LAST_PAYMENT_DATE=table1.LAST_PAYMENT_DATE.tolist()
    # Max_Renewal_Date=table1.Max_Renewal_Date.tolist()
    # table1['Last_practice_date']=pd.to_datetime(table1['Last_practice_date'])
    # # LAST_PAYMENT_DATE.dt.strftime("%d %b %Y")
    # table['Max_Renewal_Date1'].dt.strftime("%d %b %Y")




    LAST_PRACTICE_DATE=[]
    for i in table1['Last_practice_date']:
        if  i != 'NO PRACTICE' :
            LAST_PRACTICE_DATE.append(i.strftime("%d %b %Y "))
        else:
            LAST_PRACTICE_DATE.append("NO PRACTICE")

    LAST_PAYMENT_DATE1=[]
    for i in table1['LAST_PAYMENT_DATE']:
        if  i != ' ' :
            LAST_PAYMENT_DATE1.append(i.strftime("%d %b %Y "))
        else:
            LAST_PAYMENT_DATE1.append(" ")

    MAX_RENEWAL_DATE=[]
    for i in table1['Max_Renewal_Date']:
        if  i != ' ' :
            MAX_RENEWAL_DATE.append(i.strftime("%d %b %Y "))
        else:
            MAX_RENEWAL_DATE.append(" ")



    new_df=pd.DataFrame({'SCHOOL_NAME':table1.SCHOOL_NAME.tolist(),'EMAIL_ID':table1.EMAIL_ID.tolist(),
            'Max_Renewal_Date':MAX_RENEWAL_DATE, 'LAST_PAYMENT_AMOUNT':table1.LAST_PAYMENT_AMOUNT.tolist(),
               'LAST_PAYMENT_DATE':LAST_PAYMENT_DATE1, 'MODE_OF_PAYMENT':table1.MODE_OF_PAYMENT.tolist(),
               'Max_Plan':table1.Max_Plan.tolist()  ,   'Practice_count':table1.Practice_count.tolist()     ,
                'Last_practice_date':LAST_PRACTICE_DATE ,   'DEVICE_USED':table1.DEVICE_USED.tolist()    

                        })

    data=[]
    for i,j,k,l,m,n,o,p,q,r in zip(
            new_df.SCHOOL_NAME.tolist(),
        new_df.EMAIL_ID.tolist(),new_df.Max_Renewal_Date.tolist(),new_df.LAST_PAYMENT_AMOUNT.tolist(),
        new_df.LAST_PAYMENT_DATE.tolist(),new_df.MODE_OF_PAYMENT.tolist(),new_df.Max_Plan.tolist()
            ,new_df.Practice_count.tolist(),new_df.Last_practice_date.tolist(),new_df.DEVICE_USED.tolist()

        ):
        data.append([i,j,k,l,m,n,o,p,q,r])

    temp ={"data":data}

    return json.dumps(temp)



@app.route('/MOBILE_APP_SUBSCRIPTION_CARDSSSS')
def mobile_subscription_card():
    dflife=pd.read_csv("hom_exec.csv")
    lifelist=list(dflife["0"])

    lifetimelist=[]

    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    ]}},
    {'$group':{  '_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
                      'USER_COUNT':{'$size':'$USER_COUNT'}                              
                      }}]


    home_app_=list(collection.aggregate(query))
    home_app_df=pd.DataFrame(home_app_)

    dflife1=pd.read_csv("sch_exec.csv")


    lifelist1=list(dflife1["0"])

    lifetimelist1=[]

    from bson import ObjectId
    for i in lifelist1:
        lifetimelist1.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query1=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist1
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{'_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]

    IEschool_=list(collection.aggregate(query1))
    IEschool__df=pd.DataFrame(IEschool_)

    mobile_app_df=home_app_df.append(IEschool__df, ignore_index=True)

    schoolids=list(mobile_app_df['SCHOOL_ID'])
    
    collection22 = db.subscription_master
    query10=[
        {"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{              
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_ID'},
                  }},

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan'
                  }}]

    subscription_=list(collection22.aggregate(query10))
    subscription_df_1=pd.DataFrame(subscription_)

    collection22 = db.subscription_master
    query33=[{'$match':{'LAST_PAYMENT_AMOUNT':{'$exists':1}}},
        {"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'LAST_PAYMENT_AMOUNT':{'$ne':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{              
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_ID'},
                  }},

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan'
                  }}]

    subscription=list(collection22.aggregate(query33))
    subscription_df=pd.DataFrame(subscription)


    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    #                  {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}} ,      
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]

    practice=list(collection3.aggregate(query5))
    practice_df=pd.DataFrame(practice)


    subscription_df['month']=subscription_df['MAX_RENEWAL_DATE'].dt.month_name()
    subscription_df['year']=subscription_df['MAX_RENEWAL_DATE'].dt.year

    practice_df['month']=practice_df['Last_Practice_Date'].dt.month_name()
    practice_df['year']=practice_df['Last_Practice_Date'].dt.year
    sbmatm=pd.merge(practice_df,subscription_df_1, on='SCHOOL_ID', how='left')

#     print(sbmatm)

    card_df=pd.DataFrame({
                      'total_mobile_app_schools':len(mobile_app_df),
                        'Total_home_app_schools':len(home_app_df),
                            'Total_classroom_app_schools':len(IEschool__df),
                          'TOTAL_PAID_SCHOOLS':len(subscription_df),
                    'TOTAL_CLASSROOM_PAID_SCHOOLS':len(subscription_df[(subscription_df['MAX_PLAN']== 16)]),
        'TOTAL_HOME_PAID_SCHOOLS':len(subscription_df[(subscription_df['MAX_PLAN']== 17)]),
        
                          'TOTAL_Practicing_mobile_app_schools':len(practice_df),
    'TOTAL_CLASSROOM_PRACTICING_SCHOOLS':len(sbmatm[(sbmatm['MAX_PLAN']== 16)]),
        'TOTAL_HOME_PRACTICING_SCHOOLS':len(sbmatm[(sbmatm['MAX_PLAN']== 17)]),
        
    }, index=[0]

                         )


    data={}
    for j in range(len(card_df.columns)):
        key = card_df.columns[j]
        value = [str(card_df[card_df.columns[j]].iloc[0])]
        data.update({key:value})    
        
    temp ={"data":data}
    return json.dumps(temp)


@app.route('/mobile_app_SCH')
def mobile_app_schoooool():

    dflife=pd.read_csv("hom_exec.csv")
    lifelist=list(dflife["0"])

    lifetimelist=[]

    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{
                      '_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]


    home_app_=list(collection.aggregate(query))
    home_app_df=pd.DataFrame(home_app_)

    dflife1=pd.read_csv("sch_exec.csv")


    lifelist1=list(dflife1["0"])

    lifetimelist1=[]

    from bson import ObjectId
    for i in lifelist1:
        lifetimelist1.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query1=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist1
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{'_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]

    IEschool_=list(collection.aggregate(query1))
    IEschool__df=pd.DataFrame(IEschool_)

    mobile_app_df=home_app_df.append(IEschool__df, ignore_index=True)

    schoolids=list(mobile_app_df['SCHOOL_ID'])

    collection22 = db.subscription_master
    query33=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{              
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_ID'},
                  }},

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan'
                  }}]

    subscription=list(collection22.aggregate(query33))
    subscription_df=pd.DataFrame(subscription)


    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                     {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}} ,      
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]

    practice=list(collection3.aggregate(query5))
    practice_df=pd.DataFrame(practice)


    subscription_df['month']=subscription_df['MAX_RENEWAL_DATE'].dt.month_name()
    subscription_df['year']=subscription_df['MAX_RENEWAL_DATE'].dt.year

    practice_df['month']=practice_df['Last_Practice_Date'].dt.month_name()
    practice_df['year']=practice_df['Last_Practice_Date'].dt.year
    school_complete_info1=subscription_df.merge(practice_df, on='SCHOOL_ID', how='left')


    school_complete_info1.loc[school_complete_info1['Last_Practice_Date'].notnull(), 'Active_CSY'] = 'Yes'
    # school_complete_info1.drop(['Last_Practice_Date'],axis=1,inplace=True)
    # school_complete_info1.rename({'Last_Practice_Date_x': 'Last_Practice_Date'}, axis=1, inplace=True)
    school_complete_info1.Active_CSY.fillna('No',inplace=True)
    school_complete_info1.Practice_Sessions.fillna(0,inplace=True)
    school_complete_info1.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_info1.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    mobile_app_schools_csy_active=school_complete_info1[school_complete_info1['Active_CSY']=='Yes']

    mobile_app_schools=school_complete_info1['MAX_RENEWAL_DATE'].groupby([school_complete_info1.MAX_RENEWAL_DATE.dt.year.rename('year'), 
    school_complete_info1.MAX_RENEWAL_DATE.dt.month.rename('month')]).agg('count').reset_index().rename({'MAX_RENEWAL_DATE':'Total_Schools'},axis=1)


    mobile_app_active_schools=mobile_app_schools_csy_active['MAX_RENEWAL_DATE'].groupby([mobile_app_schools_csy_active.MAX_RENEWAL_DATE.dt.year.rename('year'), 
    mobile_app_schools_csy_active.MAX_RENEWAL_DATE.dt.month.rename('month')]).agg('count').reset_index().rename({'MAX_RENEWAL_DATE':'Active_Schools'},axis=1)


    mobile_app_schools_chart=mobile_app_schools.merge(mobile_app_active_schools,on=['year','month'],how='left').fillna(0)

    mobile_app_schools_chart['Month_Name']= pd.to_datetime(mobile_app_schools_chart['month'], format='%m').dt.month_name().str.slice(stop=3)

    Month_Name = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

    month_df=pd.DataFrame({'Month_Name':Month_Name})


    mobile_app_chart_2020=mobile_app_schools_chart[mobile_app_schools_chart['year']==2020]
    mobile_app_chart_2021=mobile_app_schools_chart[mobile_app_schools_chart['year']==2021]
    mobile_app_chart_2022=mobile_app_schools_chart[mobile_app_schools_chart['year']==2022]
    mobile_app_chart_2026=mobile_app_schools_chart[mobile_app_schools_chart['year']==2026]
    
    mobile_app_chart_2020_mothwise=month_df.merge(mobile_app_chart_2020,on='Month_Name',how='left').fillna(0)
    mobile_app_chart_2021mothwise=month_df.merge(mobile_app_chart_2021,on='Month_Name',how='left').fillna(0)
    mobile_app_chart_2022mothwise=month_df.merge(mobile_app_chart_2022,on='Month_Name',how='left').fillna(0)
    mobile_app_chart_2026mothwise=month_df.merge(mobile_app_chart_2026,on='Month_Name',how='left').fillna(0)
    

    temp={'Data_2020':{'Month_Name':mobile_app_chart_2020_mothwise.Month_Name.tolist(),
                            'Expiring_Schools':mobile_app_chart_2020_mothwise.Total_Schools.to_list(),
                             'Active_Schools_csy':mobile_app_chart_2020_mothwise.Active_Schools.to_list()
                            },
                            'Data_2021':{
                             'Month_Name':mobile_app_chart_2021mothwise.Month_Name.tolist(),
                            'Expiring_Schools':mobile_app_chart_2021mothwise.Total_Schools.to_list(),
                             'Active_Schools_csy':mobile_app_chart_2021mothwise.Active_Schools.to_list()   
                            },
                            'Data_2022':{
                             'Month_Name':mobile_app_chart_2022mothwise.Month_Name.tolist(),
                            'Expiring_Schools':mobile_app_chart_2022mothwise.Total_Schools.to_list(),
                             'Active_Schools_csy':mobile_app_chart_2022mothwise.Active_Schools.to_list()   
                            },
                            'Data_2026':{
                             'Month_Name':mobile_app_chart_2026mothwise.Month_Name.tolist(),
                            'Expiring_Schools':mobile_app_chart_2026mothwise.Total_Schools.to_list(),
                             'Active_Schools_csy':mobile_app_chart_2026mothwise.Active_Schools.to_list()   
                            }}

    return json.dumps(temp)




@app.route('/mobile_app_USERR')
def mobile_app_user():

    dflife=pd.read_csv("hom_exec.csv")
    lifelist=list(dflife["0"])

    lifetimelist=[]

    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{'_id':'$schoolId._id',
    'schoolname':{'$first':'$schoolId.NAME'},
    'CITY':{'$first':'$schoolId.CITY'},
    'STATE':{'$first':'$schoolId.STATE'},
    'COUNTRY':{'$first':'$schoolId.COUNTRY'},
    'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
    'CREATED_DATE':{'$min':'$CREATED_DATE'},
    'USER_COUNT':{'$addToSet':'$_id'}}},
    {'$project':{'_id':0,
    'SCHOOL_ID':'$_id',
    'SCHOOL_NAME':'$schoolname',
    'CITY':'$CITY',
    'STATE':'$STATE',
    'COUNTRY':'$COUNTRY',
    'ROLE_ID':'$ROLE_ID',
    'CREATED_DATE':'$CREATED_DATE',
    'USER_COUNT':{'$size':'$USER_COUNT'}
    }}]


    home_app_=list(collection.aggregate(query))
    home_app_df=pd.DataFrame(home_app_)

    dflife1=pd.read_csv("sch_exec.csv")


    lifelist1=list(dflife1["0"])

    lifetimelist1=[]

    from bson import ObjectId
    for i in lifelist1:
        lifetimelist1.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query1=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist1
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{'_id':'$schoolId._id',
    'schoolname':{'$first':'$schoolId.NAME'},
    'CITY':{'$first':'$schoolId.CITY'},
    'STATE':{'$first':'$schoolId.STATE'},
    'COUNTRY':{'$first':'$schoolId.COUNTRY'},
    'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
    'CREATED_DATE':{'$min':'$CREATED_DATE'},
    'USER_COUNT':{'$addToSet':'$_id'}}},
    {'$project':{'_id':0,
    'SCHOOL_ID':'$_id',
    'SCHOOL_NAME':'$schoolname',
    'CITY':'$CITY',
    'STATE':'$STATE',
    'COUNTRY':'$COUNTRY',
    'ROLE_ID':'$ROLE_ID',
    'CREATED_DATE':'$CREATED_DATE',
    'USER_COUNT':{'$size':'$USER_COUNT'}
    }}]

    IEschool_=list(collection.aggregate(query1))
    IEschool__df=pd.DataFrame(IEschool_)

    mobile_app_df=home_app_df.append(IEschool__df, ignore_index=True)

    schoolids=list(mobile_app_df['SCHOOL_ID'])

    collection22 = db.subscription_master
    query33=[{"$match":{
    '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
    ]}},
    {'$group':{              
    '_id':'$USER_ID._id',
        'SCHOOL_ID':{'$first':'$USER_ID.schoolId._id'},
    'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
    'Max_Plan':{'$max':'$PLAN_ID.PLAN_ID'},
    }},

    {'$project':{'_id':1,
    'SCHOOL_ID':'$SCHOOL_ID',             
    'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
    'MAX_PLAN':'$Max_Plan'
    }}]

    subscription=list(collection22.aggregate(query33))
    subscription_df=pd.DataFrame(subscription)


    collection3 = db.audio_track_master
    query5=[{"$match":{
    '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}} ,      
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
    ]}},

    {'$group':{
    '_id':'$USER_ID._id',
        'SCHOOL_ID':{'$first':'$USER_ID.schoolId._id'},
    'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
    'Active_User':{'$addToSet':'$USER_ID._id'},
    'Practice_Sessions':{'$sum':1},
    'Mindful_Minutes':{'$sum':{'$round':
    [{'$divide':[{'$subtract':
      ['$CURSOR_END','$cursorStart']},60]},0]}}  
    }},

    {'$project':{'_id':1,
    'SCHOOL_ID':'$SCHOOL_ID',
    'Active_User':{'$size':'$Active_User'},
    'Last_Practice_Date':'$Last_Prac_Date',
    'Practice_Sessions':'$Practice_Sessions',
    'Mindful_Minutes':'$Mindful_Minutes'
    }
    }]

    practice=list(collection3.aggregate(query5))
    practice_df=pd.DataFrame(practice)


    subscription_df['month']=subscription_df['MAX_RENEWAL_DATE'].dt.month_name()
    subscription_df['year']=subscription_df['MAX_RENEWAL_DATE'].dt.year

    practice_df['month']=practice_df['Last_Practice_Date'].dt.month_name()
    practice_df['year']=practice_df['Last_Practice_Date'].dt.year
    school_complete_info1=subscription_df.merge(practice_df, on='_id', how='left')


    school_complete_info1.loc[school_complete_info1['Last_Practice_Date'].notnull(), 'Active_CSY'] = 'Yes'
    # school_complete_info1.drop(['Last_Practice_Date'],axis=1,inplace=True)
    # school_complete_info1.rename({'Last_Practice_Date_x': 'Last_Practice_Date'}, axis=1, inplace=True)
    school_complete_info1.Active_CSY.fillna('No',inplace=True)
    school_complete_info1.Practice_Sessions.fillna(0,inplace=True)
    school_complete_info1.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_info1.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    mobile_app_schools_csy_active=school_complete_info1[school_complete_info1['Active_CSY']=='Yes']

    mobile_app_schools=school_complete_info1['MAX_RENEWAL_DATE'].groupby([school_complete_info1.MAX_RENEWAL_DATE.dt.year.rename('year'), 
    school_complete_info1.MAX_RENEWAL_DATE.dt.month.rename('month')]).agg('count').reset_index().rename({'MAX_RENEWAL_DATE':'Total_Users'},axis=1)


    mobile_app_active_schools=mobile_app_schools_csy_active['MAX_RENEWAL_DATE'].groupby([mobile_app_schools_csy_active.MAX_RENEWAL_DATE.dt.year.rename('year'), 
    mobile_app_schools_csy_active.MAX_RENEWAL_DATE.dt.month.rename('month')]).agg('count').reset_index().rename({'MAX_RENEWAL_DATE':'Active_Users'},axis=1)


    mobile_app_schools_chart=mobile_app_schools.merge(mobile_app_active_schools,on=['year','month'],how='left').fillna(0)

    mobile_app_schools_chart['Month_Name']= pd.to_datetime(mobile_app_schools_chart['month'], format='%m').dt.month_name().str.slice(stop=3)

    Month_Name = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

    month_df=pd.DataFrame({'Month_Name':Month_Name})


    mobile_app_chart_2020=mobile_app_schools_chart[mobile_app_schools_chart['year']==2020]
    mobile_app_chart_2021=mobile_app_schools_chart[mobile_app_schools_chart['year']==2021]
    mobile_app_chart_2022=mobile_app_schools_chart[mobile_app_schools_chart['year']==2022]
    mobile_app_chart_2026=mobile_app_schools_chart[mobile_app_schools_chart['year']==2026]

    mobile_app_chart_2020_mothwise=month_df.merge(mobile_app_chart_2020,on='Month_Name',how='left').fillna(0)
    mobile_app_chart_2021mothwise=month_df.merge(mobile_app_chart_2021,on='Month_Name',how='left').fillna(0)
    mobile_app_chart_2022mothwise=month_df.merge(mobile_app_chart_2022,on='Month_Name',how='left').fillna(0)
    mobile_app_chart_2026mothwise=month_df.merge(mobile_app_chart_2026,on='Month_Name',how='left').fillna(0)
    
    
    temp={'Data_2020':{'Month_Name':mobile_app_chart_2020_mothwise.Month_Name.tolist(),
        'Expiring_users':mobile_app_chart_2020_mothwise.Total_Users.to_list(),
         'Active_users_csy':mobile_app_chart_2020_mothwise.Active_Users.to_list()
        },
        'Data_2021':{
         'Month_Name':mobile_app_chart_2021mothwise.Month_Name.tolist(),
        'Expiring_users':mobile_app_chart_2021mothwise.Total_Users.to_list(),
         'Active_users_csy':mobile_app_chart_2021mothwise.Active_Users.to_list()   
        },
        'Data_2022':{
         'Month_Name':mobile_app_chart_2022mothwise.Month_Name.tolist(),
        'Expiring_users':mobile_app_chart_2022mothwise.Total_Users.to_list(),
         'Active_users_csy':mobile_app_chart_2022mothwise.Active_Users.to_list()   
        },
        'Data_2026':{
         'Month_Name':mobile_app_chart_2026mothwise.Month_Name.tolist(),
        'Expiring_users':mobile_app_chart_2026mothwise.Total_Users.to_list(),
         'Active_users_csy':mobile_app_chart_2026mothwise.Active_Users.to_list()   
        }}


    return json.dumps(temp)


@app.route('/mobile_app_USER/<year>/<month>')
def mobile_app_USERS(year,month):
    dflife = pd.read_csv("hom_exec.csv")
    lifelist=list(dflife["0"])
    lifetimelist=[]

    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
        
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{
                      '_id':'$_id',
        'SCHOOL_ID':{'$first':'$schoolId._id'},
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
    #     'District_Name':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                        'USER_ID':'$_id',       
                      'SCHOOL_ID':'$SCHOOL_ID',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
    #                            ,'District_Name':'$District_Name',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]


    home_app_=list(collection.aggregate(query))
    home_app_df=pd.DataFrame(home_app_)

    dflife1=pd.read_csv("sch_exec.csv")


    lifelist1=list(dflife1["0"])

    lifetimelist1=[]

    from bson import ObjectId
    for i in lifelist1:
        lifetimelist1.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query1=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist1
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{'_id':'$_id',
               'SCHOOL_ID':{'$first':'$schoolId._id'},
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
    #                          'District_Name':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                               'USER_ID':'$_id',
                      'SCHOOL_ID':'$SCHOOL_ID',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
    #                            ,'District_Name':'$District_Name',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]

    IEschool_=list(collection.aggregate(query1))
    IEschool__df=pd.DataFrame(IEschool_)

    mobile_app_df=home_app_df.append(IEschool__df, ignore_index=True)

    schoolids=list(mobile_app_df['SCHOOL_ID'])



    collection22 = db.subscription_master
    query33=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{              
                  '_id':'$USER_ID._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_NAME'},
                  'Amount':{'$max':'$PLAN_ID.AMOUNT'}
                  }},

              {'$project':{'_id':0,
                  'USER_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan',
                     'Amount':'$Amount'      
                  }}]

    subscription=list(collection22.aggregate(query33))
    subscription_df=pd.DataFrame(subscription)


    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                     {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}} ,      
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                          'USER_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions_CSY':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]


    collection3 = db.audio_track_master
    query6=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID._id',
                  'Practice_overall':{'$sum':1},
    #               'Mindful_Minutes':{'$sum':{'$round':
    #                   [{'$divide':[{'$subtract':
    #                       ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                          'USER_ID':'$_id',
                 'Practice_overall':'$Practice_overall',
    #              'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]


    collection4 = db.audio_feedback
    query7=[
    {"$match":{
                 '$and':[
     {'USER.schoolId._id':{'$in':schoolids}},
                     { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER.IS_DISABLED':{"$ne":'Y'}},
                  {'USER.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'USER.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
                  ]}},
                  {'$group':{
                      '_id':'$USER._id',
                      'RATING':{'$first':'$RATING'},'COMMENT':{'$first':'$COMMENT'},
                              'PROGRAM_NAME':{'$first':'$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}                     
                      }},
    {'$project':{'_id':0,'USER_ID':'$_id','RATING':'$RATING','COMMENT':'$COMMENT','PROGRAM_NAME':'$PROGRAM_NAME'}}
                     ]



    practice=list(collection3.aggregate(query5))
    practice_csy=pd.DataFrame(practice)

    practice_overall=list(collection3.aggregate(query6))
    practice_df_overall=pd.DataFrame(practice_overall)

    practice_program=list(collection4.aggregate(query7))
    practice_program_df=pd.DataFrame(practice_program)


    practice_=pd.merge(practice_csy,practice_df_overall,on='USER_ID',how='left')
    practice_df=pd.merge(practice_,practice_program_df,on='USER_ID',how='left')

    practice_df['month']=practice_df['Last_Practice_Date'].dt.month_name()
    practice_df['year']=practice_df['Last_Practice_Date'].dt.year




    #     subscription_df['month']=subscription_df['MAX_RENEWAL_DATE'].dt.month_name()
    #     subscription_df['year']=subscription_df['MAX_RENEWAL_DATE'].dt.year


    sub_um_df=pd.merge(subscription_df,mobile_app_df,on='USER_ID',how='left')


    school_complete_=sub_um_df.merge(practice_df, on='USER_ID', how='left')

    school_complete_.loc[school_complete_['Last_Practice_Date'].notnull(), 'Active_CSY'] = 'Yes'
    school_complete_.Active_CSY.fillna('No',inplace=True)
    school_complete_.Practice_overall.fillna(0,inplace=True)
    school_complete_.Practice_Sessions_CSY.fillna(0,inplace=True)
    school_complete_.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    school_complete_table=school_complete_[['SCHOOL_NAME','MAX_PLAN','Amount','MAX_RENEWAL_DATE',
                           'CREATED_DATE','Practice_Sessions_CSY',
    'Practice_overall','Last_Practice_Date', 'PROGRAM_NAME','RATING','COMMENT',
                           'Mindful_Minutes', 'Active_CSY','CITY','STATE','COUNTRY']]



    month_name = str(month).title()
    _year=int(year)
    datetime_object = datetime.datetime.strptime(month_name, "%b")
    month_number = datetime_object.month

    school_complete_info1=school_complete_table[(school_complete_table['MAX_RENEWAL_DATE'].dt.month == month_number) 
                                                               & (school_complete_table['MAX_RENEWAL_DATE'].dt.year == _year)]


    school_complete_table[['SCHOOL_NAME','MAX_PLAN','Amount','MAX_RENEWAL_DATE',
                           'CREATED_DATE','Practice_Sessions_CSY',
    'Practice_overall','Last_Practice_Date', 'PROGRAM_NAME','RATING','COMMENT',
                           'Mindful_Minutes', 'Active_CSY','CITY','STATE','COUNTRY']]


    school_complete_table.CITY.fillna('NO INFO',inplace=True)
    school_complete_table.STATE.fillna('NO INFO',inplace=True)
    school_complete_table.COUNTRY.fillna('NO INFO',inplace=True)
    school_complete_table.SCHOOL_NAME.fillna('NO INFO',inplace=True)
    school_complete_table.SCHOOL_NAME=school_complete_table.SCHOOL_NAME.str.upper()
    school_complete_table.CITY=school_complete_table.CITY.str.upper()
    school_complete_table.STATE=school_complete_table.STATE.str.upper()
    school_complete_table.COUNTRY=school_complete_table.COUNTRY.str.upper()
    school_complete_table.RATING.fillna('NO RATING',inplace=True)
    school_complete_table.COMMENT.fillna('NO COMMENT',inplace=True)
    created_date=school_complete_table['CREATED_DATE'].tolist()
    renewal_date=school_complete_table['MAX_RENEWAL_DATE'].tolist()
    prac_date=school_complete_table['Last_Practice_Date'].tolist()


    created_date_1=[]
    renewal_date_1=[]
    prac_date_1=[]

    for i in range(len(created_date)):
        if created_date[i] !='':
            created_date_1.append(created_date[i].strftime("%d %b %Y"))
        else:
            created_date_1.append('NO CREATED DATE')

        if renewal_date[i] is not None:
            renewal_date_1.append(renewal_date[i].strftime("%d %b %Y"))
        else:
            renewal_date_1.append('NO RENEWAL DATE')

        if prac_date[i] !='NO PRACTICE':
            prac_date_1.append(prac_date[i].strftime("%d %b %Y"))

        else:

            prac_date_1.append(prac_date[i])


    new_df=pd.DataFrame({'SCHOOL':school_complete_table.SCHOOL_NAME.tolist(),
          'CITY':school_complete_table.CITY.tolist(),
          'STATE':school_complete_table.STATE.tolist(),
          'COUNTRY':school_complete_table.COUNTRY.tolist(),
          'Plan_NAME':school_complete_table.MAX_PLAN.tolist(),
           'Plan_Amount':school_complete_table.Amount.tolist(),
          'School_Creation_Date':created_date_1,
#           'Total_Users':school_complete_table.USER_COUNT.tolist(),                   
          'Renewal_Date':renewal_date_1,
          'Last_Practice_Date':prac_date_1,
          'Mindful_Minutes':school_complete_table.Mindful_Minutes.tolist(),
          'Practice_Sessions_CSY':school_complete_table.Practice_Sessions_CSY.tolist(),
          'Practice_Sessions_OVERALL':school_complete_table.Practice_overall.tolist(),
          'Active_in_CSY':school_complete_table.Active_CSY.tolist(),
          'PROGRAM_NAME':school_complete_table.Active_CSY.tolist(),
         'RATING':school_complete_table.Active_CSY.tolist(),
                         'COMMENT':school_complete_table.Active_CSY.tolist(),
                         
                        })
    
    
    data=[]
    for i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x in zip(
            new_df.SCHOOL.tolist(),
        new_df.Plan_NAME.tolist(),new_df.Plan_Amount.tolist(),new_df.Renewal_Date.tolist(),
        new_df.CITY.tolist(),new_df.STATE.tolist(),new_df.COUNTRY.tolist()
            ,new_df.School_Creation_Date.tolist(),new_df.Last_Practice_Date.tolist(),new_df.Mindful_Minutes.tolist(),
            new_df.Practice_Sessions_CSY.tolist(),new_df.Active_in_CSY.tolist(),new_df.Practice_Sessions_OVERALL.tolist(),
        new_df.PROGRAM_NAME.tolist(), new_df.RATING.tolist(),
        new_df.COMMENT.tolist(),
        ):
        data.append([i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x])
        
    temp ={"data":data}

    return json.dumps(temp)

@app.route('/mobile_app_ACTIVEUSER/<year>/<month>')
def mobile_app_activeusersss(year,month):
    dflife = pd.read_csv("hom_exec.csv")
    lifelist=list(dflife["0"])
    lifetimelist=[]

    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
        
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{
                      '_id':'$_id',
        'SCHOOL_ID':{'$first':'$schoolId._id'},
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
    #     'District_Name':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                        'USER_ID':'$_id',       
                      'SCHOOL_ID':'$SCHOOL_ID',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
    #                            ,'District_Name':'$District_Name',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]


    home_app_=list(collection.aggregate(query))
    home_app_df=pd.DataFrame(home_app_)

    dflife1=pd.read_csv("sch_exec.csv")


    lifelist1=list(dflife1["0"])

    lifetimelist1=[]

    from bson import ObjectId
    for i in lifelist1:
        lifetimelist1.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query1=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist1
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{'_id':'$_id',
               'SCHOOL_ID':{'$first':'$schoolId._id'},
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
    #                          'District_Name':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                               'USER_ID':'$_id',
                      'SCHOOL_ID':'$SCHOOL_ID',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
    #                            ,'District_Name':'$District_Name',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]

    IEschool_=list(collection.aggregate(query1))
    IEschool__df=pd.DataFrame(IEschool_)

    mobile_app_df=home_app_df.append(IEschool__df, ignore_index=True)

    schoolids=list(mobile_app_df['SCHOOL_ID'])



    collection22 = db.subscription_master
    query33=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{              
                  '_id':'$USER_ID._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_NAME'},
                  'Amount':{'$max':'$PLAN_ID.AMOUNT'}
                  }},

              {'$project':{'_id':0,
                  'USER_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan',
                     'Amount':'$Amount'      
                  }}]

    subscription=list(collection22.aggregate(query33))
    subscription_df=pd.DataFrame(subscription)


    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                     {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}} ,      
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                          'USER_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions_CSY':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]


    collection3 = db.audio_track_master
    query6=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID._id',
                  'Practice_overall':{'$sum':1},
    #               'Mindful_Minutes':{'$sum':{'$round':
    #                   [{'$divide':[{'$subtract':
    #                       ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                          'USER_ID':'$_id',
                 'Practice_overall':'$Practice_overall',
    #              'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]


    collection4 = db.audio_feedback
    query7=[
    {"$match":{
                 '$and':[
     {'USER.schoolId._id':{'$in':schoolids}},
                     { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER.IS_DISABLED':{"$ne":'Y'}},
                  {'USER.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'USER.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
                  ]}},
                  {'$group':{
                      '_id':'$USER._id',
                      'RATING':{'$first':'$RATING'},'COMMENT':{'$first':'$COMMENT'},
                              'PROGRAM_NAME':{'$first':'$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}                     
                      }},
    {'$project':{'_id':0,'USER_ID':'$_id','RATING':'$RATING','COMMENT':'$COMMENT','PROGRAM_NAME':'$PROGRAM_NAME'}}
                     ]



    practice=list(collection3.aggregate(query5))
    practice_csy=pd.DataFrame(practice)

    practice_overall=list(collection3.aggregate(query6))
    practice_df_overall=pd.DataFrame(practice_overall)

    practice_program=list(collection4.aggregate(query7))
    practice_program_df=pd.DataFrame(practice_program)


    practice_=pd.merge(practice_csy,practice_df_overall,on='USER_ID',how='left')
    practice_df=pd.merge(practice_,practice_program_df,on='USER_ID',how='left')

    practice_df['month']=practice_df['Last_Practice_Date'].dt.month_name()
    practice_df['year']=practice_df['Last_Practice_Date'].dt.year




    #     subscription_df['month']=subscription_df['MAX_RENEWAL_DATE'].dt.month_name()
    #     subscription_df['year']=subscription_df['MAX_RENEWAL_DATE'].dt.year


    sub_um_df=pd.merge(subscription_df,mobile_app_df,on='USER_ID',how='left')


    school_complete_=sub_um_df.merge(practice_df, on='USER_ID', how='left')

    school_complete_.loc[school_complete_['Last_Practice_Date'].notnull(), 'Active_CSY'] = 'Yes'
    school_complete_.Active_CSY.fillna('No',inplace=True)
    school_complete_.Practice_overall.fillna(0,inplace=True)
    school_complete_.Practice_Sessions_CSY.fillna(0,inplace=True)
    school_complete_.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    school_complete_table=school_complete_[['SCHOOL_NAME','MAX_PLAN','Amount','MAX_RENEWAL_DATE',
                           'CREATED_DATE','Practice_Sessions_CSY',
    'Practice_overall','Last_Practice_Date', 'PROGRAM_NAME','RATING','COMMENT',
                           'Mindful_Minutes', 'Active_CSY','CITY','STATE','COUNTRY']]



    month_name = str(month).title()
    _year=int(year)
    datetime_object = datetime.datetime.strptime(month_name, "%b")
    month_number = datetime_object.month

    school_complete_info1=school_complete_table[(school_complete_table['MAX_RENEWAL_DATE'].dt.month == month_number) 
                                                               & (school_complete_table['MAX_RENEWAL_DATE'].dt.year == _year)]


    school_complete_table[['SCHOOL_NAME','MAX_PLAN','Amount','MAX_RENEWAL_DATE',
                           'CREATED_DATE','Practice_Sessions_CSY',
    'Practice_overall','Last_Practice_Date', 'PROGRAM_NAME','RATING','COMMENT',
                           'Mindful_Minutes', 'Active_CSY','CITY','STATE','COUNTRY']]


    school_complete_table.CITY.fillna('NO INFO',inplace=True)
    school_complete_table.STATE.fillna('NO INFO',inplace=True)
    school_complete_table.COUNTRY.fillna('NO INFO',inplace=True)
    school_complete_table.SCHOOL_NAME.fillna('NO INFO',inplace=True)
    school_complete_table.SCHOOL_NAME=school_complete_table.SCHOOL_NAME.str.upper()
    school_complete_table.CITY=school_complete_table.CITY.str.upper()
    school_complete_table.STATE=school_complete_table.STATE.str.upper()
    school_complete_table.COUNTRY=school_complete_table.COUNTRY.str.upper()
    school_complete_table.RATING.fillna('NO RATING',inplace=True)
    school_complete_table.COMMENT.fillna('NO COMMENT',inplace=True)
    created_date=school_complete_table['CREATED_DATE'].tolist()
    renewal_date=school_complete_table['MAX_RENEWAL_DATE'].tolist()
    prac_date=school_complete_table['Last_Practice_Date'].tolist()


    created_date_1=[]
    renewal_date_1=[]
    prac_date_1=[]

    for i in range(len(created_date)):
        if created_date[i] !='':
            created_date_1.append(created_date[i].strftime("%d %b %Y"))
        else:
            created_date_1.append('NO CREATED DATE')

        if renewal_date[i] is not None:
            renewal_date_1.append(renewal_date[i].strftime("%d %b %Y"))
        else:
            renewal_date_1.append('NO RENEWAL DATE')

        if prac_date[i] !='NO PRACTICE':
            prac_date_1.append(prac_date[i].strftime("%d %b %Y"))

        else:

            prac_date_1.append(prac_date[i])


    new_df=pd.DataFrame({'SCHOOL':school_complete_table.SCHOOL_NAME.tolist(),
          'CITY':school_complete_table.CITY.tolist(),
          'STATE':school_complete_table.STATE.tolist(),
          'COUNTRY':school_complete_table.COUNTRY.tolist(),
          'Plan_NAME':school_complete_table.MAX_PLAN.tolist(),
           'Plan_Amount':school_complete_table.Amount.tolist(),
          'School_Creation_Date':created_date_1,
#           'Total_Users':school_complete_table.USER_COUNT.tolist(),                   
          'Renewal_Date':renewal_date_1,
          'Last_Practice_Date':prac_date_1,
          'Mindful_Minutes':school_complete_table.Mindful_Minutes.tolist(),
          'Practice_Sessions_CSY':school_complete_table.Practice_Sessions_CSY.tolist(),
          'Practice_Sessions_OVERALL':school_complete_table.Practice_overall.tolist(),
          'Active_in_CSY':school_complete_table.Active_CSY.tolist(),
          'PROGRAM_NAME':school_complete_table.Active_CSY.tolist(),
         'RATING':school_complete_table.Active_CSY.tolist(),
                         'COMMENT':school_complete_table.Active_CSY.tolist(),
                         
                        })
    
    new_df_active_csy=new_df[new_df['Active_in_CSY']=='Yes']
    data=[]
    for i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x in zip(
            new_df_active_csy.SCHOOL.tolist(),
        new_df_active_csy.Plan_NAME.tolist(),new_df_active_csy.Plan_Amount.tolist(),new_df_active_csy.Renewal_Date.tolist(),
        new_df_active_csy.CITY.tolist(),new_df_active_csy.STATE.tolist(),new_df_active_csy.COUNTRY.tolist()
            ,new_df_active_csy.School_Creation_Date.tolist(),new_df_active_csy.Last_Practice_Date.tolist(),new_df_active_csy.Mindful_Minutes.tolist(),
            new_df_active_csy.Practice_Sessions_CSY.tolist(),new_df_active_csy.Active_in_CSY.tolist(),new_df_active_csy.Practice_Sessions_OVERALL.tolist(),
        new_df_active_csy.PROGRAM_NAME.tolist(), new_df_active_csy.RATING.tolist(),
        new_df_active_csy.COMMENT.tolist(),
        ):
        data.append([i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x])
        
    temp ={"data":data}

    return json.dumps(temp)



@app.route('/mobile_app_ACTIVE_SCHOOL/<year>/<month>')
def mobile_app_actice_schools(year,month):

    dflife = pd.read_csv("hom_exec.csv")
    lifelist=list(dflife["0"])

    lifetimelist=[]

    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{
                      '_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
    #     'District_Name':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
    #                            ,'District_Name':'$District_Name',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]


    home_app_=list(collection.aggregate(query))
    home_app_df=pd.DataFrame(home_app_)

    dflife1=pd.read_csv("sch_exec.csv")


    lifelist1=list(dflife1["0"])

    lifetimelist1=[]

    from bson import ObjectId
    for i in lifelist1:
        lifetimelist1.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query1=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist1
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{'_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
    #                          'District_Name':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
    #                            ,'District_Name':'$District_Name',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]

    IEschool_=list(collection.aggregate(query1))
    IEschool__df=pd.DataFrame(IEschool_)

    mobile_app_df=home_app_df.append(IEschool__df, ignore_index=True)

    schoolids=list(mobile_app_df['SCHOOL_ID'])



    collection22 = db.subscription_master
    query33=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{              
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_NAME'},
                  'Amount':{'$max':'$PLAN_ID.AMOUNT'}
                  }},

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan',
                     'Amount':'$Amount'      
                  }}]

    subscription=list(collection22.aggregate(query33))
    subscription_df=pd.DataFrame(subscription)


    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                     {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}} ,      
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                          'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions_CSY':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]


    collection3 = db.audio_track_master
    query6=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Practice_overall':{'$sum':1},
    #               'Mindful_Minutes':{'$sum':{'$round':
    #                   [{'$divide':[{'$subtract':
    #                       ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                          'SCHOOL_ID':'$_id',
                 'Practice_overall':'$Practice_overall',
    #              'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]



    practice=list(collection3.aggregate(query5))
    practice_csy=pd.DataFrame(practice)

    practice_overall=list(collection3.aggregate(query6))
    practice_df_overall=pd.DataFrame(practice_overall)


    practice_df=pd.merge(practice_csy,practice_df_overall,on='SCHOOL_ID',how='left')
    practice_df['month']=practice_df['Last_Practice_Date'].dt.month_name()
    practice_df['year']=practice_df['Last_Practice_Date'].dt.year




    #     subscription_df['month']=subscription_df['MAX_RENEWAL_DATE'].dt.month_name()
    #     subscription_df['year']=subscription_df['MAX_RENEWAL_DATE'].dt.year


    sub_um_df=pd.merge(subscription_df,mobile_app_df,on='SCHOOL_ID',how='left')


    school_complete_=sub_um_df.merge(practice_df, on='SCHOOL_ID', how='left')

    school_complete_.loc[school_complete_['Last_Practice_Date'].notnull(), 'Active_CSY'] = 'Yes'
    school_complete_.Active_CSY.fillna('No',inplace=True)
    school_complete_.Practice_overall.fillna(0,inplace=True)
    school_complete_.Practice_Sessions_CSY.fillna(0,inplace=True)
    school_complete_.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    school_complete_table=school_complete_[['SCHOOL_NAME','USER_COUNT','MAX_PLAN','Amount','MAX_RENEWAL_DATE',
                           'CREATED_DATE','Practice_Sessions_CSY',
    'Practice_overall','Last_Practice_Date',
                           'Mindful_Minutes', 'Active_CSY','CITY','STATE','COUNTRY']]



    month_name = str(month).title()
    _year=int(year)
    datetime_object = datetime.datetime.strptime(month_name, "%b")
    month_number = datetime_object.month

    school_complete_info1=school_complete_table[(school_complete_table['MAX_RENEWAL_DATE'].dt.month == month_number) 
                                                               & (school_complete_table['MAX_RENEWAL_DATE'].dt.year == _year)]


    school_complete_table[['SCHOOL_NAME','USER_COUNT','MAX_PLAN','Amount','MAX_RENEWAL_DATE',
                           'CREATED_DATE','Practice_Sessions_CSY',
    'Practice_overall','Last_Practice_Date',
                           'Mindful_Minutes', 'Active_CSY','CITY','STATE','COUNTRY']]


    school_complete_table.CITY.fillna('NO INFO',inplace=True)
    school_complete_table.STATE.fillna('NO INFO',inplace=True)
    school_complete_table.COUNTRY.fillna('NO INFO',inplace=True)
    school_complete_table.SCHOOL_NAME.fillna('NO INFO',inplace=True)
    school_complete_table.SCHOOL_NAME=school_complete_table.SCHOOL_NAME.str.upper()
    school_complete_table.CITY=school_complete_table.CITY.str.upper()
    school_complete_table.STATE=school_complete_table.STATE.str.upper()
    school_complete_table.COUNTRY=school_complete_table.COUNTRY.str.upper()

    created_date=school_complete_table['CREATED_DATE'].tolist()
    renewal_date=school_complete_table['MAX_RENEWAL_DATE'].tolist()
    prac_date=school_complete_table['Last_Practice_Date'].tolist()


    created_date_1=[]
    renewal_date_1=[]
    prac_date_1=[]

    for i in range(len(created_date)):
        if created_date[i] !='':
            created_date_1.append(created_date[i].strftime("%d %b %Y"))
        else:
            created_date_1.append('NO CREATED DATE')

        if renewal_date[i] is not None:
            renewal_date_1.append(renewal_date[i].strftime("%d %b %Y"))
        else:
            renewal_date_1.append('NO RENEWAL DATE')

        if prac_date[i] !='NO PRACTICE':
            prac_date_1.append(prac_date[i].strftime("%d %b %Y"))

        else:

            prac_date_1.append(prac_date[i])


    new_df=pd.DataFrame({'SCHOOL':school_complete_table.SCHOOL_NAME.tolist(),
          'CITY':school_complete_table.CITY.tolist(),
          'STATE':school_complete_table.STATE.tolist(),
          'COUNTRY':school_complete_table.COUNTRY.tolist(),
          'Plan_NAME':school_complete_table.MAX_PLAN.tolist(),
           'Plan_Amount':school_complete_table.Amount.tolist(),
          'School_Creation_Date':created_date_1,
          'Total_Users':school_complete_table.USER_COUNT.tolist(),                   
          'Renewal_Date':renewal_date_1,
          'Last_Practice_Date':prac_date_1,
          'Mindful_Minutes':school_complete_table.Mindful_Minutes.tolist(),
          'Practice_Sessions_CSY':school_complete_table.Practice_Sessions_CSY.tolist(),
          'Practice_Sessions_OVERALL':school_complete_table.Practice_overall.tolist(),
          'Active_in_CSY':school_complete_table.Active_CSY.tolist()
                        })
    new_df_active_csy=new_df[new_df['Active_in_CSY']=='Yes']
    data=[]
    for i,j,k,l,m,n,o,p,q,r,s,t,u,v in zip(
            new_df_active_csy.SCHOOL.tolist(),
        new_df_active_csy.Plan_NAME.tolist(),new_df_active_csy.Plan_Amount.tolist(),new_df_active_csy.Renewal_Date.tolist(),
        new_df_active_csy.CITY.tolist(),new_df.STATE.tolist(),new_df_active_csy.COUNTRY.tolist()
            ,new_df_active_csy.School_Creation_Date.tolist(),new_df_active_csy.Last_Practice_Date.tolist(),new_df.Mindful_Minutes.tolist(),
            new_df_active_csy.Practice_Sessions_CSY.tolist(),new_df_active_csy.Total_Users.tolist(),new_df.Active_in_CSY.tolist(),new_df_active_csy.Practice_Sessions_OVERALL.tolist()
        ) :       
            data.append([i,j,k,l,m,n,o,p,q,r,s,t,u,v])
    temp ={"data":data}
    
    return json.dumps(temp)




@app.route('/mobile_app_SCHOOL/<year>/<month>')
def mobile_app_schl(year,month):
    dflife = pd.read_csv("hom_exec.csv")
    lifelist=list(dflife["0"])

    lifetimelist=[]

    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{
                      '_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
    #     'District_Name':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
    #                            ,'District_Name':'$District_Name',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]


    home_app_=list(collection.aggregate(query))
    home_app_df=pd.DataFrame(home_app_)

    dflife1=pd.read_csv("sch_exec.csv")


    lifelist1=list(dflife1["0"])

    lifetimelist1=[]

    from bson import ObjectId
    for i in lifelist1:
        lifetimelist1.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query1=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist1
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{'_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
    #                          'District_Name':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
    #                            ,'District_Name':'$District_Name',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]

    IEschool_=list(collection.aggregate(query1))
    IEschool__df=pd.DataFrame(IEschool_)

    mobile_app_df=home_app_df.append(IEschool__df, ignore_index=True)

    schoolids=list(mobile_app_df['SCHOOL_ID'])



    collection22 = db.subscription_master
    query33=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{              
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_NAME'},
                  'Amount':{'$max':'$PLAN_ID.AMOUNT'}
                  }},

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan',
                     'Amount':'$Amount'      
                  }}]

    subscription=list(collection22.aggregate(query33))
    subscription_df=pd.DataFrame(subscription)


    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                     {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}} ,      
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                          'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions_CSY':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]


    collection3 = db.audio_track_master
    query6=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Practice_overall':{'$sum':1},
    #               'Mindful_Minutes':{'$sum':{'$round':
    #                   [{'$divide':[{'$subtract':
    #                       ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                          'SCHOOL_ID':'$_id',
                 'Practice_overall':'$Practice_overall',
    #              'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]



    practice=list(collection3.aggregate(query5))
    practice_csy=pd.DataFrame(practice)

    practice_overall=list(collection3.aggregate(query6))
    practice_df_overall=pd.DataFrame(practice_overall)


    practice_df=pd.merge(practice_csy,practice_df_overall,on='SCHOOL_ID',how='left')
    practice_df['month']=practice_df['Last_Practice_Date'].dt.month_name()
    practice_df['year']=practice_df['Last_Practice_Date'].dt.year




    #     subscription_df['month']=subscription_df['MAX_RENEWAL_DATE'].dt.month_name()
    #     subscription_df['year']=subscription_df['MAX_RENEWAL_DATE'].dt.year


    sub_um_df=pd.merge(subscription_df,mobile_app_df,on='SCHOOL_ID',how='left')


    school_complete_=sub_um_df.merge(practice_df, on='SCHOOL_ID', how='left')

    school_complete_.loc[school_complete_['Last_Practice_Date'].notnull(), 'Active_CSY'] = 'Yes'
    school_complete_.Active_CSY.fillna('No',inplace=True)
    school_complete_.Practice_overall.fillna(0,inplace=True)
    school_complete_.Practice_Sessions_CSY.fillna(0,inplace=True)
    school_complete_.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    school_complete_table=school_complete_[['SCHOOL_NAME','USER_COUNT','MAX_PLAN','Amount','MAX_RENEWAL_DATE',
                           'CREATED_DATE','Practice_Sessions_CSY',
    'Practice_overall','Last_Practice_Date',
                           'Mindful_Minutes', 'Active_CSY','CITY','STATE','COUNTRY']]



    month_name = str(month).title()
    _year=int(year)
    datetime_object = datetime.datetime.strptime(month_name, "%b")
    month_number = datetime_object.month

    school_complete_info1=school_complete_table[(school_complete_table['MAX_RENEWAL_DATE'].dt.month == month_number) 
                                                               & (school_complete_table['MAX_RENEWAL_DATE'].dt.year == _year)]


    school_complete_table[['SCHOOL_NAME','USER_COUNT','MAX_PLAN','Amount','MAX_RENEWAL_DATE',
                           'CREATED_DATE','Practice_Sessions_CSY',
    'Practice_overall','Last_Practice_Date',
                           'Mindful_Minutes', 'Active_CSY','CITY','STATE','COUNTRY']]


    school_complete_table.CITY.fillna('NO INFO',inplace=True)
    school_complete_table.STATE.fillna('NO INFO',inplace=True)
    school_complete_table.COUNTRY.fillna('NO INFO',inplace=True)
    school_complete_table.SCHOOL_NAME.fillna('NO INFO',inplace=True)
    school_complete_table.SCHOOL_NAME=school_complete_table.SCHOOL_NAME.str.upper()
    school_complete_table.CITY=school_complete_table.CITY.str.upper()
    school_complete_table.STATE=school_complete_table.STATE.str.upper()
    school_complete_table.COUNTRY=school_complete_table.COUNTRY.str.upper()

    created_date=school_complete_table['CREATED_DATE'].tolist()
    renewal_date=school_complete_table['MAX_RENEWAL_DATE'].tolist()
    prac_date=school_complete_table['Last_Practice_Date'].tolist()


    created_date_1=[]
    renewal_date_1=[]
    prac_date_1=[]

    for i in range(len(created_date)):
        if created_date[i] !='':
            created_date_1.append(created_date[i].strftime("%d %b %Y"))
        else:
            created_date_1.append('NO CREATED DATE')

        if renewal_date[i] is not None:
            renewal_date_1.append(renewal_date[i].strftime("%d %b %Y"))
        else:
            renewal_date_1.append('NO RENEWAL DATE')

        if prac_date[i] !='NO PRACTICE':
            prac_date_1.append(prac_date[i].strftime("%d %b %Y"))

        else:

            prac_date_1.append(prac_date[i])


    new_df=pd.DataFrame({'SCHOOL':school_complete_table.SCHOOL_NAME.tolist(),
          'CITY':school_complete_table.CITY.tolist(),
          'STATE':school_complete_table.STATE.tolist(),
          'COUNTRY':school_complete_table.COUNTRY.tolist(),
          'Plan_NAME':school_complete_table.MAX_PLAN.tolist(),
           'Plan_Amount':school_complete_table.Amount.tolist(),
          'School_Creation_Date':created_date_1,
          'Total_Users':school_complete_table.USER_COUNT.tolist(),                   
          'Renewal_Date':renewal_date_1,
          'Last_Practice_Date':prac_date_1,
          'Mindful_Minutes':school_complete_table.Mindful_Minutes.tolist(),
          'Practice_Sessions_CSY':school_complete_table.Practice_Sessions_CSY.tolist(),
          'Practice_Sessions_OVERALL':school_complete_table.Practice_overall.tolist(),
          'Active_in_CSY':school_complete_table.Active_CSY.tolist()
                        })

    data=[]
    for i,j,k,l,m,n,o,p,q,r,s,t,u,v in zip(
            new_df.SCHOOL.tolist(),
        new_df.Plan_NAME.tolist(),new_df.Plan_Amount.tolist(),new_df.Renewal_Date.tolist(),
        new_df.CITY.tolist(),new_df.STATE.tolist(),new_df.COUNTRY.tolist()
            ,new_df.School_Creation_Date.tolist(),new_df.Last_Practice_Date.tolist(),new_df.Mindful_Minutes.tolist(),
            new_df.Practice_Sessions_CSY.tolist(),new_df.Total_Users.tolist(),new_df.Active_in_CSY.tolist(),new_df.Practice_Sessions_OVERALL.tolist()
        ) :       
            data.append([i,j,k,l,m,n,o,p,q,r,s,t,u,v])
    temp ={"data":data}
    
    return json.dumps(temp)

@app.route('/mobile_app_ACTIVE_SCHOOL/<year>/<month>')

def mobile_app_ACTIVE_schools(year,month):
    dflife = pd.read_csv("hom_exec.csv")
    lifelist=list(dflife["0"])

    lifetimelist=[]

    from bson import ObjectId
    for i in lifelist:
        lifetimelist.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{
                      '_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
    #     'District_Name':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
    #                            ,'District_Name':'$District_Name',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]


    home_app_=list(collection.aggregate(query))
    home_app_df=pd.DataFrame(home_app_)

    dflife1=pd.read_csv("sch_exec.csv")


    lifelist1=list(dflife1["0"])

    lifetimelist1=[]

    from bson import ObjectId
    for i in lifelist1:
        lifetimelist1.append(ObjectId(i))
    from bson.objectid import ObjectId
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master

    query1=[{'$match':{'$and':[{
    "schoolId._id": {
    "$in":lifetimelist1
    }},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},

    ]}},
    {'$group':{'_id':'$schoolId._id',
                      'schoolname':{'$first':'$schoolId.NAME'},
                      'CITY':{'$first':'$schoolId.CITY'},
                      'STATE':{'$first':'$schoolId.STATE'},
                      'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                      'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                      'CREATED_DATE':{'$min':'$CREATED_DATE'},
    #                          'District_Name':{'$first':'$DISTRICT_ID.DISTRICT_NAME'},
                      'USER_COUNT':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':0,
                      'SCHOOL_ID':'$_id',
                      'SCHOOL_NAME':'$schoolname',
                      'CITY':'$CITY',
                      'STATE':'$STATE',
                      'COUNTRY':'$COUNTRY',
                      'ROLE_ID':'$ROLE_ID',
                      'CREATED_DATE':'$CREATED_DATE',
    #                            ,'District_Name':'$District_Name',
                      'USER_COUNT':{'$size':'$USER_COUNT'}
                      }}]

    IEschool_=list(collection.aggregate(query1))
    IEschool__df=pd.DataFrame(IEschool_)

    mobile_app_df=home_app_df.append(IEschool__df, ignore_index=True)

    schoolids=list(mobile_app_df['SCHOOL_ID'])



    collection22 = db.subscription_master
    query33=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},
              {'$group':{              
                  '_id':'$USER_ID.schoolId._id',
                  'Max_Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'Max_Plan':{'$max':'$PLAN_ID.PLAN_NAME'},
                  'Amount':{'$max':'$PLAN_ID.AMOUNT'}
                  }},

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'MAX_RENEWAL_DATE':'$Max_Renewal_Date',
                  'MAX_PLAN':'$Max_Plan',
                     'Amount':'$Amount'      
                  }}]

    subscription=list(collection22.aggregate(query33))
    subscription_df=pd.DataFrame(subscription)


    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                     {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}} ,      
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                          'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions_CSY':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]


    collection3 = db.audio_track_master
    query6=[{"$match":{
             '$and':[{'USER_ID.schoolId._id':{'$in':schoolids}},
                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Practice_overall':{'$sum':1},
    #               'Mindful_Minutes':{'$sum':{'$round':
    #                   [{'$divide':[{'$subtract':
    #                       ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                          'SCHOOL_ID':'$_id',
                 'Practice_overall':'$Practice_overall',
    #              'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]



    practice=list(collection3.aggregate(query5))
    practice_csy=pd.DataFrame(practice)

    practice_overall=list(collection3.aggregate(query6))
    practice_df_overall=pd.DataFrame(practice_overall)


    practice_df=pd.merge(practice_csy,practice_df_overall,on='SCHOOL_ID',how='left')
    practice_df['month']=practice_df['Last_Practice_Date'].dt.month_name()
    practice_df['year']=practice_df['Last_Practice_Date'].dt.year




    #     subscription_df['month']=subscription_df['MAX_RENEWAL_DATE'].dt.month_name()
    #     subscription_df['year']=subscription_df['MAX_RENEWAL_DATE'].dt.year


    sub_um_df=pd.merge(subscription_df,mobile_app_df,on='SCHOOL_ID',how='left')


    school_complete_=sub_um_df.merge(practice_df, on='SCHOOL_ID', how='left')

    school_complete_.loc[school_complete_['Last_Practice_Date'].notnull(), 'Active_CSY'] = 'Yes'
    school_complete_.Active_CSY.fillna('No',inplace=True)
    school_complete_.Practice_overall.fillna(0,inplace=True)
    school_complete_.Practice_Sessions_CSY.fillna(0,inplace=True)
    school_complete_.Mindful_Minutes.fillna(0,inplace=True)
    school_complete_.Last_Practice_Date.fillna('NO PRACTICE',inplace=True)

    school_complete_table=school_complete_[['SCHOOL_NAME','USER_COUNT','MAX_PLAN','Amount','MAX_RENEWAL_DATE',
                           'CREATED_DATE','Practice_Sessions_CSY',
    'Practice_overall','Last_Practice_Date',
                           'Mindful_Minutes', 'Active_CSY','CITY','STATE','COUNTRY']]



    month_name = str(month).title()
    _year=int(year)
    datetime_object = datetime.datetime.strptime(month_name, "%b")
    month_number = datetime_object.month

    school_complete_info1=school_complete_table[(school_complete_table['MAX_RENEWAL_DATE'].dt.month == month_number) 
                                                               & (school_complete_table['MAX_RENEWAL_DATE'].dt.year == _year)]


    school_complete_table[['SCHOOL_NAME','USER_COUNT','MAX_PLAN','Amount','MAX_RENEWAL_DATE',
                           'CREATED_DATE','Practice_Sessions_CSY',
    'Practice_overall','Last_Practice_Date',
                           'Mindful_Minutes', 'Active_CSY','CITY','STATE','COUNTRY']]


    school_complete_table.CITY.fillna('NO INFO',inplace=True)
    school_complete_table.STATE.fillna('NO INFO',inplace=True)
    school_complete_table.COUNTRY.fillna('NO INFO',inplace=True)
    school_complete_table.SCHOOL_NAME.fillna('NO INFO',inplace=True)
    school_complete_table.SCHOOL_NAME=school_complete_table.SCHOOL_NAME.str.upper()
    school_complete_table.CITY=school_complete_table.CITY.str.upper()
    school_complete_table.STATE=school_complete_table.STATE.str.upper()
    school_complete_table.COUNTRY=school_complete_table.COUNTRY.str.upper()

    created_date=school_complete_table['CREATED_DATE'].tolist()
    renewal_date=school_complete_table['MAX_RENEWAL_DATE'].tolist()
    prac_date=school_complete_table['Last_Practice_Date'].tolist()


    created_date_1=[]
    renewal_date_1=[]
    prac_date_1=[]

    for i in range(len(created_date)):
        if created_date[i] !='':
            created_date_1.append(created_date[i].strftime("%d %b %Y"))
        else:
            created_date_1.append('NO CREATED DATE')

        if renewal_date[i] is not None:
            renewal_date_1.append(renewal_date[i].strftime("%d %b %Y"))
        else:
            renewal_date_1.append('NO RENEWAL DATE')

        if prac_date[i] !='NO PRACTICE':
            prac_date_1.append(prac_date[i].strftime("%d %b %Y"))

        else:

            prac_date_1.append(prac_date[i])


    new_df=pd.DataFrame({'SCHOOL':school_complete_table.SCHOOL_NAME.tolist(),
          'CITY':school_complete_table.CITY.tolist(),
          'STATE':school_complete_table.STATE.tolist(),
          'COUNTRY':school_complete_table.COUNTRY.tolist(),
          'Plan_NAME':school_complete_table.MAX_PLAN.tolist(),
           'Plan_Amount':school_complete_table.Amount.tolist(),
          'School_Creation_Date':created_date_1,
          'Total_Users':school_complete_table.USER_COUNT.tolist(),                   
          'Renewal_Date':renewal_date_1,
          'Last_Practice_Date':prac_date_1,
          'Mindful_Minutes':school_complete_table.Mindful_Minutes.tolist(),
          'Practice_Sessions_CSY':school_complete_table.Practice_Sessions_CSY.tolist(),
          'Practice_Sessions_OVERALL':school_complete_table.Practice_overall.tolist(),
          'Active_in_CSY':school_complete_table.Active_CSY.tolist()
                        })
    new_df_active_csy=new_df[new_df['Active_in_CSY']=='Yes']
    data=[]
    for i,j,k,l,m,n,o,p,q,r,s,t,u,v in zip(
            new_df_active_csy.SCHOOL.tolist(),
        new_df_active_csy.Plan_NAME.tolist(),new_df_active_csy.Plan_Amount.tolist(),new_df_active_csy.Renewal_Date.tolist(),
        new_df_active_csy.CITY.tolist(),new_df.STATE.tolist(),new_df_active_csy.COUNTRY.tolist()
            ,new_df_active_csy.School_Creation_Date.tolist(),new_df_active_csy.Last_Practice_Date.tolist(),new_df.Mindful_Minutes.tolist(),
            new_df_active_csy.Practice_Sessions_CSY.tolist(),new_df_active_csy.Total_Users.tolist(),new_df.Active_in_CSY.tolist(),new_df_active_csy.Practice_Sessions_OVERALL.tolist()
        ) :       
            data.append([i,j,k,l,m,n,o,p,q,r,s,t,u,v])
    temp ={"data":data}
    
    return json.dumps(temp)





@app.route('/districtupcuser/<district>/<type>')
def Practice_districtupcuser_Bifurcation(type,district):
    
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
    
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    Type=""+type+""
    if Type =="csy":
        dateStr = str(csy_first_date())
        myDatetime = dateutil.parser.parse(dateStr)
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'MODIFIED_DATE':{'$gte':myDatetime}},
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CATEGORY':    
            {'$regex':''+district+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CATEGORY":{"$regex":''+district+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":myDatetime}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    elif Type=="lsy":
        dateStr = str(LSY_Date)
        myDatetime = dateutil.parser.parse(dateStr)
        dateStr1 = str(csy_first_date())
        myDatetime1 = dateutil.parser.parse(dateStr1)
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'MODIFIED_DATE':{'$gte':myDatetime,'$lt':myDatetime1}},
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CATEGORY':    
            {'$regex':''+district+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CATEGORY":{"$regex":''+district+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{'$gte':myDatetime,'$lt':myDatetime1}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    elif Type=="overall":
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CATEGORY':    
            {'$regex':''+district+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CATEGORY":{"$regex":''+district+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    else:
        print("NO DATA")

@app.route('/districtupcfamily/<district>/<type>')
def Practice_districtupcfamily_Bifurcation(type,district):
    
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
    
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    Type=""+type+""
    if Type =="csy":
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                 
                  {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
#                   {'MODIFIED_DATE':{'$gte':myDatetime}},
                  {'MODIFIED_DATE':{'$gte':csy_first_date()}},
                         
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CATEGORY':    
            {'$regex':''+district+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CATEGORY":{"$regex":''+district+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#         {'MODIFIED_DATE':{"$gt":myDatetime}},
        {'MODIFIED_DATE':{'$gt':csy_first_date()}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    elif Type=="lsy":
        dateStr = "2019-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
        dateStr1 = "2020-07-31T00:00:00.000Z"
        myDatetime1 = dateutil.parser.parse(dateStr1)
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                 
                  {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
#                   {'MODIFIED_DATE':{'$gte':myDatetime,'$lte':myDatetime1}},
                    {'MODIFIED_DATE':{'$gte':LSY_Date,'$lt':csy_first_date()}},
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CATEGORY':    
            {'$regex':''+district+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CATEGORY":{"$regex":''+district+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
         
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#         {'MODIFIED_DATE':{'$gte':myDatetime,'$lte':myDatetime1}},
        {'MODIFIED_DATE':{'$gte':LSY_Date,'$lt':csy_first_date()}},
                
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    elif Type=="overall":
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  
                  {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CATEGORY':    
            {'$regex':''+district+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CATEGORY":{"$regex":''+district+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
       
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    else:
        print("NO DATA")                

@app.route('/programupcuser/<program>/<type>')
def programupcuser_Practice_Bifurcation(type,program):
    
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
    
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    Type=""+type+""
    if Type =="csy":
        dateStr = str(csy_first_date())
        myDatetime = dateutil.parser.parse(dateStr)
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'MODIFIED_DATE':{'$gte':myDatetime}},
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CAP_PROGRAM':    
            {'$regex':''+program+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CAP_PROGRAM":{"$regex":''+program+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":myDatetime}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    elif Type=="lsy":
        dateStr = str(LSY_Date)
        myDatetime = dateutil.parser.parse(dateStr)
        dateStr1 = str(csy_first_date())
        myDatetime1 = dateutil.parser.parse(dateStr1)
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'MODIFIED_DATE':{'$gte':myDatetime,'$lt':myDatetime1}},
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CAP_PROGRAM':    
            {'$regex':''+program+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CAP_PROGRAM":{"$regex":''+program+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{'$gte':myDatetime,'$lt':myDatetime1}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    elif Type=="overall":
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CAP_PROGRAM':    
            {'$regex':''+program+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CAP_PROGRAM":{"$regex":''+program+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    else:
        print("NO DATA")

@app.route('/programupcfamily/<program>/<type>')
def programupcfamily_Practice_Bifurcation(type,program):
    
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
    
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    Type=""+type+""
    if Type =="csy":
        dateStr = str(csy_first_date())
        myDatetime = dateutil.parser.parse(dateStr)
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                 
                  {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'MODIFIED_DATE':{'$gte':myDatetime}},
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CAP_PROGRAM':    
            {'$regex':''+program+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CAP_PROGRAM":{"$regex":''+program+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":myDatetime}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    elif Type=="lsy":
        dateStr = str(LSY_Date)
        myDatetime = dateutil.parser.parse(dateStr)
        dateStr1 = str(csy_first_date())
        myDatetime1 = dateutil.parser.parse(dateStr1)
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                
                  {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'MODIFIED_DATE':{'$gte':myDatetime,'$lt':myDatetime1}},
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CAP_PROGRAM':    
            {'$regex':''+program+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CAP_PROGRAM":{"$regex":''+program+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
          
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{'$gte':myDatetime,'$lt':myDatetime1}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    elif Type=="overall":
        mydoc = db.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                 
                  {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'USER_ID.schoolId._id':{'$in':
                      db.school_master.distinct('_id',{'CAP_PROGRAM':    
            {'$regex':''+program+'','$options':'i'},
            'IS_PORTAL':'Y'    
            })}}
            ]}},    
            {'$group':{
                '_id':'$USER_ID._id',
                'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
                'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
                'schoolId':{'$first':'$USER_ID.schoolId._id'},
                'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
                'city':{'$first':'$USER_ID.schoolId.CITY'},
                'state':{'$first':'$USER_ID.schoolId.STATE'},
                'Playbacks':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
              }
                },
            {'$project':{
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'schoolId':'$schoolId',
                'schoolName':'$schoolName',
                'CITY':'$city',
                'STATE':'$state',
                'Playbacks':'$Playbacks',
                'Mindful_Minutes':'$Mindful_Minutes',
                'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
                }}
            ]
        )
        df= DataFrame(list(mydoc))

        mydoc1 = db.audio_track_master.aggregate([
        {"$match":
            {"$and":[
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"CAP_PROGRAM":{"$regex":''+program+'','$options':'i'}} )}},
                 {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
         
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        { "$project": {
            "USER":"$USER_ID._id",
             "EMAIL":"$USER_ID.EMAIL_ID",
              "y":{"$year":"$MODIFIED_DATE"},
              "m":{"$month":"$MODIFIED_DATE"},
              "d":{"$dayOfMonth":"$MODIFIED_DATE"},
              "h":{"$hour":"$MODIFIED_DATE"},
             }
         },
         { "$group":{ 
               "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
               "EMAIL":{"$first":"$EMAIL"},
                "total":{ "$sum": 1}}
           },

        {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
            ,"HOUR":"$_id.hour","UPC":"$total"}}
        ])
        df1= DataFrame(list(mydoc1))
        df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
        df3 = pd.merge(df, df2, how='inner',on='USER_ID')
        df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
        df3['10_minute']=round(df3['Average_Session(min)'])*10
        df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
        df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
        df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
        df5=df4['Average_sessinons_60min'].to_list()
        df6=df4['UPC'].to_list()
        temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
        return json.dumps(temp)
    else:
        print("NO DATA")


@app.route('/schoolupcuser/<name>/')
def schoolupcuser_Practice_Bifurcation(name):
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dateStr = "2020-08-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc = db.audio_track_master.aggregate(
    [{"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':myDatetime}},
            {'USER_ID.schoolId._id':{'$in':
                db.school_master.distinct('_id',{'NAME':    
        {'$regex':''+name+'','$options':'i'},
        'IS_PORTAL':'Y'    
        })}}
        ]}},    
        {'$group':{
            '_id':'$USER_ID._id',
            'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
            'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
            'schoolId':{'$first':'$USER_ID.schoolId._id'},
            'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
            'city':{'$first':'$USER_ID.schoolId.CITY'},
            'state':{'$first':'$USER_ID.schoolId.STATE'},
            'Playbacks':{'$sum':1},
            'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
        }
            },
        {'$project':{
            'USER_ID':'$_id',
            'USER_NAME':'$USER_NAME',
            'EMAIL_ID':'$EMAIL_ID',
            'schoolId':'$schoolId',
            'schoolName':'$schoolName',
            'CITY':'$city',
            'STATE':'$state',
            'Playbacks':'$Playbacks',
            'Mindful_Minutes':'$Mindful_Minutes',
            'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
            }}
        ]
    )
    df= DataFrame(list(mydoc))

    mydoc1 = db.audio_track_master.aggregate([
    {"$match":
        {"$and":[
            {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"NAME":{"$regex":''+NAME+'','$options':'i'}} )}},
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'MODIFIED_DATE':{"$gt":myDatetime}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    { "$project": {
        "USER":"$USER_ID._id",
        "EMAIL":"$USER_ID.EMAIL_ID",
        "y":{"$year":"$MODIFIED_DATE"},
        "m":{"$month":"$MODIFIED_DATE"},
        "d":{"$dayOfMonth":"$MODIFIED_DATE"},
        "h":{"$hour":"$MODIFIED_DATE"},
        }
    },
    { "$group":{ 
        "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
        "EMAIL":{"$first":"$EMAIL"},
            "total":{ "$sum": 1}}
    },

    {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
        ,"HOUR":"$_id.hour","UPC":"$total"}}
    ])
    df1= DataFrame(list(mydoc1))
    df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
    df3 = pd.merge(df, df2, how='inner',on='USER_ID')
    df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
    df3['10_minute']=round(df3['Average_Session(min)'])*10
    df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
    df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
    df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
    df5=df4['Average_sessinons_60min'].to_list()
    df6=df4['UPC'].to_list()
    temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
    return json.dumps(temp)

@app.route('/schoolupcfamily/<name>/')
def schoolupcfamily_Practice_Bifurcation(name):
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    dateStr = "2020-08-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc = db.audio_track_master.aggregate(
    [{"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
          
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':myDatetime}},
            {'USER_ID.schoolId._id':{'$in':
                db.school_master.distinct('_id',{'NAME':    
        {'$regex':''+name+'','$options':'i'},
        'IS_PORTAL':'Y'    
        })}}
        ]}},    
        {'$group':{
            '_id':'$USER_ID._id',
            'USER_NAME':{'$first':'$USER_ID.USER_NAME'},
            'EMAIL_ID':{'$first':'$USER_ID.EMAIL_ID'},
            'schoolId':{'$first':'$USER_ID.schoolId._id'},
            'schoolName':{'$first':'$USER_ID.schoolId.NAME'},
            'city':{'$first':'$USER_ID.schoolId.CITY'},
            'state':{'$first':'$USER_ID.schoolId.STATE'},
            'Playbacks':{'$sum':1},
            'Mindful_Minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}}
        }
            },
        {'$project':{
            'USER_ID':'$_id',
            'USER_NAME':'$USER_NAME',
            'EMAIL_ID':'$EMAIL_ID',
            'schoolId':'$schoolId',
            'schoolName':'$schoolName',
            'CITY':'$city',
            'STATE':'$state',
            'Playbacks':'$Playbacks',
            'Mindful_Minutes':'$Mindful_Minutes',
            'Average_Session(min)':{'$divide':['$Mindful_Minutes','$Playbacks']}
            }}
        ]
    )
    df= DataFrame(list(mydoc))

    mydoc1 = db.audio_track_master.aggregate([
    {"$match":
        {"$and":[
            {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",  {"NAME":{"$regex":''+NAME+'','$options':'i'}} )}},
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
   
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'MODIFIED_DATE':{"$gt":myDatetime}},
    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    { "$project": {
        "USER":"$USER_ID._id",
        "EMAIL":"$USER_ID.EMAIL_ID",
        "y":{"$year":"$MODIFIED_DATE"},
        "m":{"$month":"$MODIFIED_DATE"},
        "d":{"$dayOfMonth":"$MODIFIED_DATE"},
        "h":{"$hour":"$MODIFIED_DATE"},
        }
    },
    { "$group":{ 
        "_id": {"USER_ID":"$USER","year":"$y","month":"$m","day":"$d","hour":"$h"},
        "EMAIL":{"$first":"$EMAIL"},
            "total":{ "$sum": 1}}
    },

    {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","EMAIL_ID":"$EMAIL","YEAR":"$_id.year","MONTH":"$_id.month","DAY":"$_id.day"
        ,"HOUR":"$_id.hour","UPC":"$total"}}
    ])
    df1= DataFrame(list(mydoc1))
    df2=df1.groupby(["USER_ID"])['UPC'].count().reset_index()
    df3 = pd.merge(df, df2, how='inner',on='USER_ID')
    df3['Average_sessinons_60min']=round(df3['Mindful_Minutes']/df3['UPC'])*10
    df3['10_minute']=round(df3['Average_Session(min)'])*10
    df3.loc[df3['Average_sessinons_60min'] > 100, 'Average_sessinons_60min'] = 100
    df3.loc[df3['Average_sessinons_60min'] < 0, 'Average_sessinons_60min'] = 0
    df4=df3.sort_values(by=['Average_sessinons_60min'],ascending=False)
    df5=df4['Average_sessinons_60min'].to_list()
    df6=df4['UPC'].to_list()
    temp={"playback":df6,"percentage":df5,"count":int(df4["USER_ID"].count())}
    return json.dumps(temp)


@app.route('/newdonor/')
def NEW_DONOR():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-01-25T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                # {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff#.append(dfd1) 
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])

    df1=df[(df.Last_Payment_Date> '2021-06-30')]
    df2=df[(df.Last_Payment_Date< '2021-07-01')]
    new=df1[~df1['EMAIL_ID'].isin(df2['EMAIL_ID'])]
    df3=new
    newdonor=df3[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]].fillna("no info")
    count=newdonor["USER_NAME"].count()
    amount=newdonor["Payment_Amount"].sum()
    newdonor['Last_Payment_Date'] = newdonor['Last_Payment_Date'].astype('str')
    table=newdonor.values.tolist()
    temp={"count":int(count),"amount":int(amount),"data":table}
    return json.dumps(temp)


@app.route('/boardmemberdonation/')
def BOARD_MEMBER_DONOR():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    datestr7 = "2021-01-25T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                # {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    googleSheetId = '1OnsKEyX4guTg--LWsfFM2neF1L6auLH3DWGrgEt8wXk'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL).fillna("NO INFO.")
    df=dff #.append(dfd1).reset_index() 
    df['Last_Payment_Date'] = pd.to_datetime(df['Last_Payment_Date'])
    df=df[(df.Last_Payment_Date>= '2021-07-01')]
    name=["LAURA","JANICE","SAMANTHA","MICHAEL","KRISTIE","TODD","SHERITA"
        ,"PAUL SUGAR","SAIDEEP RAJ","KATHI","JANETTE"]
    pat = '|'.join(map(re.escape, name))
    df["FR"]=df.USER_NAME.str.contains(pat)
    df["FR"]=df["FR"].astype(str)
    dfer=df[df["FR"]=='True']
    borddonor=dfer[["USER_NAME","EMAIL_ID","STATE","MODE_OF_PAYMENT","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","Total_Amount"]].fillna("no info")
    count=borddonor["USER_NAME"].count() 
    amount=borddonor["Payment_Amount"].sum() 
    borddonor['Last_Payment_Date'] = borddonor['Last_Payment_Date'].astype('str')
    table=borddonor.values.tolist()
    temp={"count":int(count),"amount":int(amount),"membercount":int(11),"data":table}
    return json.dumps(temp)


#<<<<<<<--------------------------tune_in Analytics---------------------------------------->>>>>>>>>>>>>>>
#  <<<<<<<<<<<<<<<<<<<-----------------Districtwise Tune_In_Graph --------------------------------------->>>>>>>>>>>>>>>>>>>>>

@app.route('/districtwise_tuneingraph/<district>/<startdate>/<enddate>')
def districtwise_tune_in_csy_lsy(district,startdate,enddate):
    import datetime
    from datetime import timedelta
    from dateutil.relativedelta import relativedelta
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
    
    a = int(csy_first_date().strftime("%Y"))
    b = a+1

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
    
    df2=DataFrame(list(db.user_master.aggregate([{"$match":
         {'$and': [
#         {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},


    # //               {'IS_ADMIN':'Y'},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},

                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

#             {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'date':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
#                       'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},

            {'$project':{'_id':1}},



  
                                            ])))
#     print("df2",df2)
    if df2.empty == True:
        temp={"data":"No Result"}

    else:
        uid = df2["_id"].to_list()
        collection = db.tune_in_audio_track_detail
        query=[{"$match":{
                 '$and':[
                     {'USER_ID._id':{"$in":uid}},
                     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
        #               {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),'$lte':datetime.datetime(2021,7,31)}},
    #             {'MODIFIED_DATE':{'$gte': csy_first_date()}},
                         {'MODIFIED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},

                      {'INVITEE_EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'INVITEE_EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'INVITEE_EMAIL':{"$not":{"$regex":"manoj.rayat5575@gmail.com",'$options':'i'}}},


                      ]}},
                  {'$group':{
                      '_id': { 
                      'month': {'$month' :"$MODIFIED_DATE" }, 
                      'year': {'$year' :"$MODIFIED_DATE" }},
                      'prac_parent':{'$addToSet':'$INVITEE_EMAIL'}
                      }},

                      {'$project':{
                          '_id':0,
                          'month':'$_id.month',
                          'year':'$_id.year',
                          'practicing_parent':{'$size':'$prac_parent'}
                          }
                          }]
        tune_in_practice_CSY=list(collection.aggregate(query))
        tune_in_practice_CSY_df=pd.DataFrame(tune_in_practice_CSY)

        if "month" not in tune_in_practice_CSY_df.columns:
            tune_in_practice_CSY_df["month"] = "NO INFO"
        if "year" not in tune_in_practice_CSY_df.columns:
            tune_in_practice_CSY_df["year"] = "NO INFO"
        if "practicing_parent" not in tune_in_practice_CSY_df.columns:
            tune_in_practice_CSY_df["practicing_parent"] = "NO INFO"

        if tune_in_practice_CSY_df.empty:
            tune_in_practice_CSY_df.loc[len(tune_in_practice_CSY_df)] = 0

        collection1 = db.tune_in_master
        query1=[{"$match":{
                 '$and':[
                     {'USER_ID._id':{"$in":uid}},
                     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        #           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
        #               {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),'$lte':datetime.datetime(2021,7,31)}}
    #             {'MODIFIED_DATE':{'$gte': csy_first_date()}},
                         {'MODIFIED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},


                  ]}},

                  {'$group':{
                      '_id': { 
                      'month': {'$month' :"$MODIFIED_DATE" }, 
                      'year': {'$year' :"$MODIFIED_DATE" }},
                      'TUNE_IN_SEND':{'$sum':1},
                       'OPTED_OUT' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
             , 'Y' ] }, 1, 0 ] } },
             'OPTED_IN' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
             , 'N' ] }, 1, 0 ] } }
                      }
                      }
                      ,{'$project':{
                          '_id':0,
                          'month':'$_id.month',
                          'year':'$_id.year',
                          'TuneIn_Send':'$TUNE_IN_SEND',
                          'Opt_Out':'$OPTED_OUT',
                          'Opt_In':'$OPTED_IN'
                          }
                          }]
        tune_in_CSY=list(collection1.aggregate(query1))
    #     print(tune_in_CSY)
        tune_in_CSY_df=pd.DataFrame(tune_in_CSY)
    #     print(tune_in_CSY_df)

        if "month" not in tune_in_CSY_df.columns:
            tune_in_CSY_df["month"] = "NO INFO"
        if "year" not in tune_in_CSY_df.columns:
            tune_in_CSY_df["year"] = "NO INFO"
        if "TuneIn_Send" not in tune_in_CSY_df.columns:
            tune_in_CSY_df["TuneIn_Send"] = "NO INFO"
        if "Opt_Out" not in tune_in_CSY_df.columns:
            tune_in_CSY_df["Opt_Out"] = "NO INFO"
        if "Opt_In" not in tune_in_CSY_df.columns:
            tune_in_CSY_df["Opt_In"] = "NO INFO"


        if tune_in_CSY_df.empty:
            tune_in_CSY_df.loc[len(tune_in_CSY_df)] = 0


        month_df=pd.DataFrame({'month':list(range(1,13))})
        monthname=[]
        months=month_df.month.tolist()
        for i in range(len(months)):    
            monthname.append(calendar.month_abbr[months[i]])
        month_df['month_name']=monthname
        tune_in_data=tune_in_CSY_df.merge(tune_in_practice_CSY_df,on=['month','year'],how='left').fillna(0)
        tune_in_Final_CSY=month_df.merge(tune_in_data[['month','TuneIn_Send', 'Opt_Out', 'Opt_In', 'practicing_parent']],how='left',on='month').fillna(0)

        # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<----------------------------------------------------------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

        query_LSY=[{"$match":{
                 '$and':[
                     {'USER_ID._id':{"$in":uid}},
                     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
        #               {'MODIFIED_DATE':{'$gte':datetime.datetime(2019,8,1),'$lte':datetime.datetime(2020,7,31)}},
#                   {'MODIFIED_DATE':{'$gte':LSY_Date,'$lt': csy_first_date()}},
                     {'MODIFIED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},

                      {'INVITEE_EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'INVITEE_EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'INVITEE_EMAIL':{"$not":{"$regex":"manoj.rayat5575@gmail.com",'$options':'i'}}},


                      ]}},
                  {'$group':{
                      '_id': { 
                      'month': {'$month' :"$MODIFIED_DATE" }, 
                      'year': {'$year' :"$MODIFIED_DATE" }},
                      'prac_parent':{'$addToSet':'$INVITEE_EMAIL'}
                      }},

                      {'$project':{
                          '_id':0,
                          'month':'$_id.month',
                          'year':'$_id.year',
                          'practicing_parent':{'$size':'$prac_parent'}
                          }
                          }]
        tune_in_practice_LSY=list(collection.aggregate(query_LSY))
        tune_in_practice_LSY_df=pd.DataFrame(tune_in_practice_LSY)
        if tune_in_practice_LSY_df.empty:
            tune_in_practice_LSY_df=pd.DataFrame({'month':list(range(1,13)),'practicing_parent':0})
        else:
            tune_in_practice_LSY_df=tune_in_practice_LSY_df


        query1_LSY=[{"$match":{
                 '$and':[
                     {'USER_ID._id':{"$in":uid}},
                     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        #           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
        #               {'MODIFIED_DATE':{'$gte':datetime.datetime(2019,8,1),'$lte':datetime.datetime(2020,7,31)}}
#                 {'MODIFIED_DATE':{'$gte':LSY_Date,'$lt': csy_first_date()}},
                     {'MODIFIED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},

                  ]}},

                  {'$group':{
                      '_id': { 
                      'month': {'$month' :"$MODIFIED_DATE" }, 
                      'year': {'$year' :"$MODIFIED_DATE" }},
                      'TUNE_IN_SEND':{'$sum':1},
                       'OPTED_OUT' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
             , 'Y' ] }, 1, 0 ] } },
             'OPTED_IN' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
             , 'N' ] }, 1, 0 ] } }
                      }
                      }
                      ,{'$project':{
                          '_id':0,
                          'month':'$_id.month',
                          'year':'$_id.year',
                          'TuneIn_Send':'$TUNE_IN_SEND',
                          'Opt_Out':'$OPTED_OUT',
                          'Opt_In':'$OPTED_IN'
                          }
                          }]
        tune_in_LSY=list(collection1.aggregate(query1_LSY))
        tune_in_LSY_df=pd.DataFrame(tune_in_LSY)
        
        if tune_in_LSY_df.empty == True:
            tune_in_LSY_df = pd.DataFrame({'month':list(range(1,13)),'TuneIn_Send':0,'Opt_Out':0,'Opt_In':0})
        
        print(tune_in_LSY_df)
        print(tune_in_practice_LSY_df)

        tune_in_data_LSY=tune_in_LSY_df.merge(tune_in_practice_LSY_df,on=['month'],how='left').fillna(0)
        tune_in_Final_LSY=month_df.merge(tune_in_data_LSY[['month','TuneIn_Send', 'Opt_Out', 'Opt_In', 'practicing_parent']],
                                   how='left',on='month').fillna(0)

        mon=pd.DataFrame({'month_name':[8,9,10,11,12,1,2,3,4,5,6,7]})
        d = dict(enumerate(calendar.month_abbr))
        mon['month_name'] = mon['month_name'].map(d)
    #     print(mon)
        tune_in_Final_CSY = pd.merge(mon,tune_in_Final_CSY, how="left",on = "month_name")
        tune_in_Final_LSY = pd.merge(mon,tune_in_Final_LSY, how="left",on = "month_name")


    #     print(tune_in_Final_CSY)
    #     print("tune_in_Final_LSY \n",tune_in_Final_LSY)
    #     print("data",data)
        temp={'CSY':{
                'monthname':tune_in_Final_CSY.month_name.tolist(),
                'Tune_In_Send':tune_in_Final_CSY.TuneIn_Send.tolist(),
                'Opt_Out':tune_in_Final_CSY.Opt_Out.tolist(),
                'Opt_In':tune_in_Final_CSY.Opt_In.tolist(),
                'practicing_parent':tune_in_Final_CSY.practicing_parent.tolist()

            },
                  'LSY':{
                  'monthname':tune_in_Final_LSY.month_name.tolist(),
                'Tune_In_Send':tune_in_Final_LSY.TuneIn_Send.tolist(),
                'Opt_Out':tune_in_Final_LSY.Opt_Out.tolist(),
                'Opt_In':tune_in_Final_LSY.Opt_In.tolist(),
                'practicing_parent':tune_in_Final_LSY.practicing_parent.tolist()}
                 }
    return json.dumps(temp)



@app.route('/districtwise_tuneincsycard/<district>/<startdate>/<enddate>')
def districtwise_tunein_cards_csy(district,startdate,enddate):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.tune_in_audio_track_detail
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
    a = int(csy_first_date().strftime("%Y"))
    b = a+1
#     print(a,b)
    
    df2=DataFrame(list(db.user_master.aggregate([{"$match":
         {'$and': [
#         {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},


    # //               {'IS_ADMIN':'Y'},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},

                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

#             {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'date':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
#                       'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},

            {'$project':{'_id':1}},



  
                                            ])))
    print("df2",df2.shape)
    if df2.empty == True:
        temp={"data":"No Result"}
        
    else:
        uid = df2["_id"].to_list()
        tune_in_practice_CSY_df=pd.DataFrame(list(db.tune_in_audio_track_detail.aggregate([{"$match":{
                 '$and':[
                     { 'USER_ID._id':{"$in":uid}},                     
                     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                   {'MODIFIED_DATE':{"$gte": LSY_Date(),"$lt":csy_first_date()}},
                      {'MODIFIED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},
                      {'INVITEE_EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'INVITEE_EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'INVITEE_EMAIL':{"$not":{"$regex":"manoj.rayat5575@gmail.com",'$options':'i'}}},


                      ]}},
                  {'$group':{
                      '_id': { 
                      'month': {'$month' :"$MODIFIED_DATE" }, 
                      'year': {'$year' :"$MODIFIED_DATE" }},
                      'prac_parent':{'$addToSet':'$INVITEE_EMAIL'}
                      }},

                      {'$project':{
                          '_id':0,
                          'month':'$_id.month',
                          'year':'$_id.year',
                          'practicing_parent':{'$size':'$prac_parent'}
                          }
                          }])))
        print("tune_in_practice_CSY_df",tune_in_practice_CSY_df)
        if tune_in_practice_CSY_df.empty == True:
            tune_in_practice_CSY_df = pd.DataFrame({"month":[8,9,10,11,12,1,2,3,4,5,6,7], "year":[a,a,a,a,a,b,b,b,b,b,b,b],'practicing_parent': 0})
#         print("tune_in_practice_CSY_df",tune_in_practice_CSY_df)

     
        tune_in_CSY_df=pd.DataFrame(list(db.tune_in_master.aggregate([{"$match":{
                 '$and':[
                     { 'USER_ID._id':{"$in":uid}},
                     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        #           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
#                   {'MODIFIED_DATE':{"$gte": LSY_Date(),"$lt":csy_first_date()}},
                      {'MODIFIED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},
                  ]}},

                  {'$group':{
                      '_id': { 
                      'month': {'$month' :"$MODIFIED_DATE" }, 
                      'year': {'$year' :"$MODIFIED_DATE" }},
                      'TUNE_IN_SEND':{'$sum':1},
                       'OPTED_OUT' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
             , 'Y' ] }, 1, 0 ] } },
             'OPTED_IN' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
             , 'N' ] }, 1, 0 ] } }
                      }
                      }
                      ,{'$project':{
                          '_id':0,
                          'month':'$_id.month',
                          'year':'$_id.year',
                          'TuneIn_Send':'$TUNE_IN_SEND',
                          'Opt_Out':'$OPTED_OUT',
                          'Opt_In':'$OPTED_IN'
                          }
                          }])))
        print("tune_in_CSY_df",tune_in_CSY_df)
        if tune_in_CSY_df.empty == True:
            tune_in_CSY_df = pd.DataFrame({"month":[8,9,10,11,12,1,2,3,4,5,6,7], "year":[a,a,a,a,a,b,b,b,b,b,b,b],'TuneIn_Send':0,'Opt_Out':0,'Opt_In':0})
#         print("tune_in_CSY_df",tune_in_CSY_df)
        
        month_df=pd.DataFrame({'month':list(range(1,13))})
        monthname=[]
        months=month_df.month.tolist()
        for i in range(len(months)):    
            monthname.append(calendar.month_abbr[months[i]])
        month_df['month_name']=monthname
        print("month_df",month_df)
        tune_in_data=tune_in_CSY_df.merge(tune_in_practice_CSY_df,on=['month','year'],how='left').fillna(0)
        print("tune_in_data",tune_in_data)
        tune_in_Final_CSY=month_df.merge(tune_in_data[['month','TuneIn_Send', 'Opt_Out', 'Opt_In', 'practicing_parent']],how='left',on='month').fillna(0)
        cardscount=[int(tune_in_Final_CSY.TuneIn_Send.sum()),int(tune_in_Final_CSY.Opt_In.sum()),int(tune_in_Final_CSY.Opt_Out.sum()),int(tune_in_Final_CSY.practicing_parent.sum())]
        cardsname=['Tune_In_Send','Tune_In_Opt_In','Tune_In_Opt_Out','Parents_Practised']

        data=[]
        for i,j in zip(cardsname,cardscount):
            data.append([i,j])
        temp={'data':data}
    return json.dumps(temp , default =str)
# districtwise_tunein_cards_csy("Boston","2017-08-01","2022-8-31")

#  <<<<<<<<<<<<<<<<<<<-----------------Tune_In_Graph--------------------------------------->>>>>>>>>>>>>>>>>>>>>

@app.route('/Top20district_tunein')
def Top20district_tune_in():
    import datetime
    from datetime import timedelta
    from dateutil.relativedelta import relativedelta

    a = int(csy_first_date().strftime("%Y"))
    b = a+1

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass


    # myDatetime1 = dateutil.parser.parse(startdate)
    # myDatetime2 = dateutil.parser.parse(enddate)



    df=DataFrame(list(db.school_master.aggregate([
    # {"$match":{'$and': [
    # {"CATEGORY":{"$regex":"Broward","$options":"i"}},
    # {"IS_PORTAL":"Y"}
    # ]}},
    {'$project':{"sid" : "$_id",'NAME':1,"CATEGORY":1,"LOCAl_DISTRICT" :1}},])))
    df = df[['sid','NAME',"CATEGORY"]]
    df = df.fillna(0)
    df["CATEGORY"] = df["CATEGORY"].replace('NULL',"NO_DISTRICT")
    df["CATEGORY"] = df["CATEGORY"].replace('0',"NO_DISTRICT")
    df["CATEGORY"] = df["CATEGORY"].replace(0,"NO_DISTRICT")
    df["CATEGORY"] = df["CATEGORY"].replace("","NO_DISTRICT")
    df["CATEGORY"] = df["CATEGORY"].replace('5fd89a86623b9c382a91037a',"NO_DISTRICT")
#     print(df.CATEGORY.unique())

    sid = df['sid'].to_list()

    df2=DataFrame(list(db.user_master.aggregate([{"$match":
    {'$and': [
    # {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"IS_DISABLED":{"$ne":"Y"}},
    {"IS_BLOCKED":{"$ne":"Y"}},
    {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    # {'IS_ADMIN':'Y'},
    # {'CREATED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},

    {'EMAIL_ID':{'$ne':''}},
    {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

    #             {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'date':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
    #                       'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},

    {'$project':{'_id':"$_id", "sid":'$schoolId._id'}},  
    ])))
    dff=df.merge(df2,on="sid",how='left').fillna(0)
    
#     print("dff",dff)
    
    if dff.empty == True:
        temp={"data":"No Result"}

    else:
        uid = dff["_id"].to_list()

        tune_in_practice=pd.DataFrame(list(db.tune_in_audio_track_detail.aggregate([{"$match":{
        '$and':[
        {'USER_ID._id':{"$in":uid}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
        {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
        #               {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),'$lte':datetime.datetime(2021,7,31)}},
        #             {'MODIFIED_DATE':{'$gte': csy_first_date()}},
        #                  {'MODIFIED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},

        {'INVITEE_EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
        {'INVITEE_EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'INVITEE_EMAIL':{"$not":{"$regex":"manoj.rayat5575@gmail.com",'$options':'i'}}},
        ]}},
        {'$group':{
        '_id': "$USER_ID._id",'prac_parent':{'$addToSet':'$INVITEE_EMAIL'}
        }},
        {'$project':{
        "_id":1,
        'practicing_parent':{'$size':'$prac_parent'}
        }
        }])))


        tune_in=pd.DataFrame(list(db.tune_in_master.aggregate([{"$match":{
        '$and':[
        {'USER_ID._id':{"$in":uid}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #     {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #     {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
        {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #     {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),'$lte':datetime.datetime(2021,7,31)}}
    #     {'MODIFIED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},
        ]}},
        {'$group':{
        "_id":"$USER_ID._id",
        'TUNE_IN_SEND':{'$sum':1},
        'OPTED_OUT' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT', 'Y' ] }, 1, 0 ] } },
        'OPTED_IN' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT', 'N' ] }, 1, 0 ] } }
        }},
        {'$project':{
        '_id':1,
        'TuneIn_Send':'$TUNE_IN_SEND',
        'Opt_Out':'$OPTED_OUT',
        'Opt_In':'$OPTED_IN'
        }
        }])))

        finaldf = dff.merge(tune_in,on="_id",how='left').fillna(0)
        finaldf = finaldf.merge(tune_in_practice,on="_id",how='left').fillna(0)
        finaldf = finaldf.dropna()
        finaldf = finaldf.groupby(['CATEGORY']).sum()
        finaldf = finaldf.dropna()
        finaldf = finaldf[(finaldf.T != 0).any()]
        finaldf = finaldf.sort_values(['TuneIn_Send','Opt_In', 'Opt_Out'], ascending=[False, False, False]).iloc[0:20]
        
#         print(finaldf)
        
        temp={'CSY':{
        'District_Name':finaldf.index.to_list(),
        'Tune_In_Send':finaldf.TuneIn_Send.to_list(),
        'Opt_Out':finaldf.Opt_Out.to_list(),
        'Opt_In':finaldf.Opt_In.to_list(),
        'practicing_parent':finaldf.practicing_parent.to_list()
        }}

        return json.dumps(temp)



@app.route('/programwise_tuneingraph')
def programwise_tune_in():
    import datetime
    from datetime import timedelta
    from dateutil.relativedelta import relativedelta

    a = int(csy_first_date().strftime("%Y"))
    b = a+1

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass


    # myDatetime1 = dateutil.parser.parse(startdate)
    # myDatetime2 = dateutil.parser.parse(enddate)



    df2=DataFrame(list(db.user_master.aggregate([{"$match":
    {'$and': [
    # {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"IS_DISABLED":{"$ne":"Y"}},
    {"IS_BLOCKED":{"$ne":"Y"}},
    {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
    # {'IS_ADMIN':'Y'},
    # {'CREATED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},

    {'EMAIL_ID':{'$ne':''}},
    {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

    #             {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'date':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
    #                       'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},

    {'$project':{'_id':"$_id", "sid":'$schoolId._id'}},  
    ])))

    #     print("dff",dff)

    if df2.empty == True:
        temp={"data":"No Result"}

    else:
        uid = df2["_id"].to_list()

        tune_in_practice=pd.DataFrame(list(db.tune_in_audio_track_detail.aggregate([{"$match":{
        '$and':[
        {'USER_ID._id':{"$in":uid}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
        {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
        #               {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),'$lte':datetime.datetime(2021,7,31)}},
        #             {'MODIFIED_DATE':{'$gte': csy_first_date()}},
        #                  {'MODIFIED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},

        {'INVITEE_EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
        {'INVITEE_EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'INVITEE_EMAIL':{"$not":{"$regex":"manoj.rayat5575@gmail.com",'$options':'i'}}},
        ]}},
        {'$group':{
        '_id': "$USER_ID._id",'prac_parent':{'$addToSet':'$INVITEE_EMAIL'},
        'PROGRAM':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},   
        }},
        {'$project':{
        "_id":1,
        'practicing_parent':{'$size':'$prac_parent'},
        'PROGRAM':1
        }
        }])))


        tune_in=pd.DataFrame(list(db.tune_in_master.aggregate([{"$match":{
        '$and':[
        {'USER_ID._id':{"$in":uid}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #     {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #     {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
        {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #     {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),'$lte':datetime.datetime(2021,7,31)}}
    #     {'MODIFIED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},
        ]}},
        {'$group':{
        "_id":"$USER_ID._id",
        'TUNE_IN_SEND':{'$sum':1},
        'OPTED_OUT' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT', 'Y' ] }, 1, 0 ] } },
        'OPTED_IN' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT', 'N' ] }, 1, 0 ] } }
        }},
        {'$project':{
        '_id':1,
        'TuneIn_Send':'$TUNE_IN_SEND',
        'Opt_Out':'$OPTED_OUT',
        'Opt_In':'$OPTED_IN'
        }
        }])))

        finaldf = df2.merge(tune_in,on="_id",how='left').fillna(0)
        finaldf = finaldf.merge(tune_in_practice,on="_id",how='left').fillna(0)
        finaldf["PROGRAM"] = finaldf["PROGRAM"].replace(0,"OTHER")
        finaldf = finaldf.dropna()
        finaldf = finaldf.groupby(['PROGRAM']).sum()
        finaldf = finaldf.dropna()
        finaldf = finaldf[(finaldf.T != 0).any()]

    #     print(finaldf)

        temp={'CSY':{
        'Program':finaldf.index.to_list(),
        'Tune_In_Send':finaldf.TuneIn_Send.to_list(),
        'Opt_Out':finaldf.Opt_Out.to_list(),
        'Opt_In':finaldf.Opt_In.to_list(),
        'practicing_parent':finaldf.practicing_parent.to_list()
        }}
    #     print(temp)

        return json.dumps(temp)
# programwise_tune_in()



@app.route('/tuneingraph')
def tune_in_csy_lsy():
    import datetime
    from datetime import timedelta
    from dateutil.relativedelta import relativedelta
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.tune_in_audio_track_detail
    query=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
              {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #               {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),'$lte':datetime.datetime(2021,7,31)}},
            {'MODIFIED_DATE':{'$gte': csy_first_date()}},

                  {'INVITEE_EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'INVITEE_EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'INVITEE_EMAIL':{"$not":{"$regex":"manoj.rayat5575@gmail.com",'$options':'i'}}},


                  ]}},
              {'$group':{
                  '_id': { 
                  'month': {'$month' :"$MODIFIED_DATE" }, 
                  'year': {'$year' :"$MODIFIED_DATE" }},
                  'prac_parent':{'$addToSet':'$INVITEE_EMAIL'}
                  }},

                  {'$project':{
                      '_id':0,
                      'month':'$_id.month',
                      'year':'$_id.year',
                      'practicing_parent':{'$size':'$prac_parent'}
                      }
                      }]
    tune_in_practice_CSY=list(collection.aggregate(query))
    tune_in_practice_CSY_df=pd.DataFrame(tune_in_practice_CSY)

    if "month" not in tune_in_practice_CSY_df.columns:
        tune_in_practice_CSY_df["month"] = "NO INFO"
    if "year" not in tune_in_practice_CSY_df.columns:
        tune_in_practice_CSY_df["year"] = "NO INFO"
    if "practicing_parent" not in tune_in_practice_CSY_df.columns:
        tune_in_practice_CSY_df["practicing_parent"] = "NO INFO"

    if tune_in_practice_CSY_df.empty:
        tune_in_practice_CSY_df.loc[len(tune_in_practice_CSY_df)] = 0

    collection1 = db.tune_in_master
    query1=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
              {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #               {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),'$lte':datetime.datetime(2021,7,31)}}
            {'MODIFIED_DATE':{'$gte': csy_first_date()}},


              ]}},

              {'$group':{
                  '_id': { 
                  'month': {'$month' :"$MODIFIED_DATE" }, 
                  'year': {'$year' :"$MODIFIED_DATE" }},
                  'TUNE_IN_SEND':{'$sum':1},
                   'OPTED_OUT' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
         , 'Y' ] }, 1, 0 ] } },
         'OPTED_IN' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
         , 'N' ] }, 1, 0 ] } }
                  }
                  }
                  ,{'$project':{
                      '_id':0,
                      'month':'$_id.month',
                      'year':'$_id.year',
                      'TuneIn_Send':'$TUNE_IN_SEND',
                      'Opt_Out':'$OPTED_OUT',
                      'Opt_In':'$OPTED_IN'
                      }
                      }]
    tune_in_CSY=list(collection1.aggregate(query1))
    print(tune_in_CSY)
    tune_in_CSY_df=pd.DataFrame(tune_in_CSY)
    print(tune_in_CSY_df)

    if "month" not in tune_in_CSY_df.columns:
        tune_in_CSY_df["month"] = "NO INFO"
    if "year" not in tune_in_CSY_df.columns:
        tune_in_CSY_df["year"] = "NO INFO"
    if "TuneIn_Send" not in tune_in_CSY_df.columns:
        tune_in_CSY_df["TuneIn_Send"] = "NO INFO"
    if "Opt_Out" not in tune_in_CSY_df.columns:
        tune_in_CSY_df["Opt_Out"] = "NO INFO"
    if "Opt_In" not in tune_in_CSY_df.columns:
        tune_in_CSY_df["Opt_In"] = "NO INFO"


    if tune_in_CSY_df.empty:
        tune_in_CSY_df.loc[len(tune_in_CSY_df)] = 0


    month_df=pd.DataFrame({'month':list(range(1,13))})
    monthname=[]
    months=month_df.month.tolist()
    for i in range(len(months)):    
        monthname.append(calendar.month_abbr[months[i]])
    month_df['month_name']=monthname
    tune_in_data=tune_in_CSY_df.merge(tune_in_practice_CSY_df,on=['month','year'],how='left').fillna(0)
    tune_in_Final_CSY=month_df.merge(tune_in_data[['month','TuneIn_Send', 'Opt_Out', 'Opt_In', 'practicing_parent']],how='left',on='month').fillna(0)

    # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<----------------------------------------------------------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

    query_LSY=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
              {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #               {'MODIFIED_DATE':{'$gte':datetime.datetime(2019,8,1),'$lte':datetime.datetime(2020,7,31)}},
              {'MODIFIED_DATE':{'$gte':LSY_Date,'$lt': csy_first_date()}},


                  {'INVITEE_EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'INVITEE_EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'INVITEE_EMAIL':{"$not":{"$regex":"manoj.rayat5575@gmail.com",'$options':'i'}}},


                  ]}},
              {'$group':{
                  '_id': { 
                  'month': {'$month' :"$MODIFIED_DATE" }, 
                  'year': {'$year' :"$MODIFIED_DATE" }},
                  'prac_parent':{'$addToSet':'$INVITEE_EMAIL'}
                  }},

                  {'$project':{
                      '_id':0,
                      'month':'$_id.month',
                      'year':'$_id.year',
                      'practicing_parent':{'$size':'$prac_parent'}
                      }
                      }]
    tune_in_practice_LSY=list(collection.aggregate(query_LSY))
    tune_in_practice_LSY_df=pd.DataFrame(tune_in_practice_LSY)
    if tune_in_practice_LSY_df.empty:
        tune_in_practice_LSY_df=pd.DataFrame({'month':list(range(1,13)),'practicing_parent':0})
    else:
        tune_in_practice_LSY_df=tune_in_practice_LSY_df


    query1_LSY=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
              {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #               {'MODIFIED_DATE':{'$gte':datetime.datetime(2019,8,1),'$lte':datetime.datetime(2020,7,31)}}
            {'MODIFIED_DATE':{'$gte':LSY_Date,'$lt': csy_first_date()}},

              ]}},

              {'$group':{
                  '_id': { 
                  'month': {'$month' :"$MODIFIED_DATE" }, 
                  'year': {'$year' :"$MODIFIED_DATE" }},
                  'TUNE_IN_SEND':{'$sum':1},
                   'OPTED_OUT' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
         , 'Y' ] }, 1, 0 ] } },
         'OPTED_IN' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
         , 'N' ] }, 1, 0 ] } }
                  }
                  }
                  ,{'$project':{
                      '_id':0,
                      'month':'$_id.month',
                      'year':'$_id.year',
                      'TuneIn_Send':'$TUNE_IN_SEND',
                      'Opt_Out':'$OPTED_OUT',
                      'Opt_In':'$OPTED_IN'
                      }
                      }]
    tune_in_LSY=list(collection1.aggregate(query1_LSY))
    tune_in_LSY_df=pd.DataFrame(tune_in_LSY)


    tune_in_data_LSY=tune_in_LSY_df.merge(tune_in_practice_LSY_df,on=['month'],how='left').fillna(0)
    tune_in_Final_LSY=month_df.merge(tune_in_data_LSY[['month','TuneIn_Send', 'Opt_Out', 'Opt_In', 'practicing_parent']],
                               how='left',on='month').fillna(0)

    temp={'CSY':{
            'monthname':tune_in_Final_CSY.month_name.tolist(),
            'Tune_In_Send':tune_in_Final_CSY.TuneIn_Send.tolist(),
            'Opt_Out':tune_in_Final_CSY.Opt_Out.tolist(),
            'Opt_In':tune_in_Final_CSY.Opt_In.tolist(),
            'practicing_parent':tune_in_Final_CSY.practicing_parent.tolist()

        },
              'LSY':{
              'monthname':tune_in_Final_LSY.month_name.tolist(),
            'Tune_In_Send':tune_in_Final_LSY.TuneIn_Send.tolist(),
            'Opt_Out':tune_in_Final_LSY.Opt_Out.tolist(),
            'Opt_In':tune_in_Final_LSY.Opt_In.tolist(),
            'practicing_parent':tune_in_Final_LSY.practicing_parent.tolist()}
             }
    return json.dumps(temp)

#<<<<<<<<<<<<<<<<<<<<------------------------------Tune_In_LSY_Table------------------------->>>>>>>>>>>>>>>>>>>>>>>

@app.route('/tuneintable/LSY/<month>/<opt>')

def tune_in_LSY_table(month,opt):
    month=month.title()
    if opt=='Opt In':
        opt='N'
    else:
        opt='Y'        
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.tune_in_master
    query=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
              {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2019,8,1),
                      '$lte':datetime.datetime(2020,7,31)
                      }}
              ]}},
              {'$project':{
                  'PARENT_EMAIL':'$EMAIL',
                  'TEACHER_ID':'$USER_ID._id',
                  'TEACHER_NAME':'$USER_ID.USER_NAME',
                  'TEACHER_EMAIL':'$USER_ID.EMAIL_ID',
                  'SCHOOL_ID':'$USER_ID.schoolId._id',
                  'SCHOOL_NAME':'$USER_ID.schoolId.NAME',
                  'STATE':'$USER_ID.schoolId.STATE',
                  'IS_OPTED_OUT':'$IS_OPTED_OUT',
                  'CREATED_DATE':'$MODIFIED_DATE'
                  }
                  }]
    tune_in_LSY_data=list(collection.aggregate(query))
    tune_in_data_LSY_df=pd.DataFrame(tune_in_LSY_data)
    tune_in_data_LSY_df['Month_Name'] = pd.to_datetime(tune_in_data_LSY_df['CREATED_DATE'], format='%m').dt.month_name().str.slice(stop=3)
    tune_in_data_LSY_df=tune_in_data_LSY_df.fillna('')
    tune_in_month=tune_in_data_LSY_df[(tune_in_data_LSY_df['Month_Name']==month) & (tune_in_data_LSY_df['IS_OPTED_OUT']==opt)]
    data=[]
    for i,j,k,l,m,n in zip(tune_in_month.PARENT_EMAIL.tolist(),
                           tune_in_month.TEACHER_NAME.tolist(),
                           tune_in_month.TEACHER_EMAIL.tolist(),
                           tune_in_month.SCHOOL_NAME.tolist(),
                           tune_in_month.STATE.tolist(),
                           tune_in_month.IS_OPTED_OUT.tolist()
                          ):
        data.append([i,j,k,l,m,n])
    temp={'data':data}        
    return json.dumps(temp)


# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<------------------------------Tune_In_Table_CSY------------------------->>>>>>>>>>>>>>>>>>>>>>>

@app.route('/tuneintable/CSY/<month>/<opt>')

def tune_in_CSY_table(month,opt):
    month=month.title()
    if opt=='Opt In':
        opt='N'
    else:
        opt='Y'        
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.tune_in_master
    query=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
              {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),
                      '$lte':datetime.datetime(2021,7,31)
                      }}
              ]}},
              {'$project':{
                  'PARENT_EMAIL':'$EMAIL',
                  'TEACHER_ID':'$USER_ID._id',
                  'TEACHER_NAME':'$USER_ID.USER_NAME',
                  'TEACHER_EMAIL':'$USER_ID.EMAIL_ID',
                  'SCHOOL_ID':'$USER_ID.schoolId._id',
                  'SCHOOL_NAME':'$USER_ID.schoolId.NAME',
                  'STATE':'$USER_ID.schoolId.STATE',
                  'IS_OPTED_OUT':'$IS_OPTED_OUT',
                  'CREATED_DATE':'$MODIFIED_DATE'
                  }
                  }]
    tune_in_CSY_data=list(collection.aggregate(query))
    tune_in_data_CSY_df=pd.DataFrame(tune_in_CSY_data)
    tune_in_data_CSY_df['Month_Name'] = pd.to_datetime(tune_in_data_CSY_df['CREATED_DATE'], format='%m').dt.month_name().str.slice(stop=3)
    tune_in_data_CSY_df=tune_in_data_CSY_df.fillna('')
    tune_in_month=tune_in_data_CSY_df[(tune_in_data_CSY_df['Month_Name']==month) & (tune_in_data_CSY_df['IS_OPTED_OUT']==opt)]
    data=[]
    for i,j,k,l,m,n in zip(tune_in_month.PARENT_EMAIL.tolist(),
                           tune_in_month.TEACHER_NAME.tolist(),
                           tune_in_month.TEACHER_EMAIL.tolist(),
                           tune_in_month.SCHOOL_NAME.tolist(),
                           tune_in_month.STATE.tolist(),
                           tune_in_month.IS_OPTED_OUT.tolist()
                          ):
        data.append([i,j,k,l,m,n])
    temp={'data':data}        
    return json.dumps(temp)


# <<<<<<<<<<<<<<<<<<<<<<<<<<<<-------------------------CSY_Practice_Data------------------------>>>>>>>>>>>>>>>>>>>>>>

@app.route('/tuneinpractable/CSY/<month>/PRACTICE')


def tune_in_prac_table(month):
    month=month.title()
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.tune_in_audio_track_detail
    query=[{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"Sonal",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),
                          '$lte':datetime.datetime(2021,7,31)
                          }},
                      {'INVITEE_EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'INVITEE_EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'INVITEE_EMAIL':{"$not":{"$regex":"manoj.rayat5575@gmail.com",'$options':'i'}}},

      ]}},

      {'$project':{
          'PARENT_EMAIL':'$INVITEE_EMAIL',
          'PRACTICE_DATE':'$MODIFIED_DATE',
          'IS_LISTENED':'$IS_LISTENED',
          'cursorStart':'$CURSOR_START',
          'cursorEnd':'$CURSOR_END',
          'AUDIO_LENGTH':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH',
          'TEACHER_ID':'$CLASS_ID.USER_ID._id',
          'TEACHER':'$CLASS_ID.USER_ID.USER_NAME',
          'TEACHER_EMAIL':'$CLASS_ID.USER_ID.EMAIL_ID',
          'SCHOOL_ID':'$CLASS_ID.USER_ID.schoolId._id',
          'SCHOOL_NAME':'$CLASS_ID.USER_ID.schoolId.NAME',
          'STATE':'$CLASS_ID.USER_ID.schoolId.NAME',      
          'AUDIO_NAME':'$PROGRAM_AUDIO_ID.AUDIO_NAME',
          'PROGRAM':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP'
          }
          }]
    tune_in_prac_CSY_data=list(collection.aggregate(query))
    tune_in_prac_data_CSY_df=pd.DataFrame(tune_in_prac_CSY_data)
    tune_in_prac_data_CSY_df=tune_in_prac_data_CSY_df.dropna(axis=0, subset=['AUDIO_LENGTH']).reset_index(drop=True)
    tune_in_prac_data_CSY_df['cursorStart']=tune_in_prac_data_CSY_df['cursorStart'].fillna(0)
    tune_in_prac_data_CSY_df.loc[(tune_in_prac_data_CSY_df['cursorEnd'].isnull())
                                 & (tune_in_prac_data_CSY_df['IS_LISTENED']=='Y')                             
                                 , 'cursorEnd'] = tune_in_prac_data_CSY_df['AUDIO_LENGTH']
    tune_in_prac_data_CSY_df.loc[(tune_in_prac_data_CSY_df['cursorEnd']>tune_in_prac_data_CSY_df['AUDIO_LENGTH'])                            
                                 , 'cursorEnd'] = tune_in_prac_data_CSY_df['AUDIO_LENGTH']
    tune_in_prac_data_CSY_df.loc[(tune_in_prac_data_CSY_df['cursorEnd'].isnull()) & (tune_in_prac_data_CSY_df['cursorStart']<1)
                                 , 'cursorEnd'] = tune_in_prac_data_CSY_df['cursorStart']
    tune_in_prac_data_CSY_df.loc[(tune_in_prac_data_CSY_df['cursorEnd'].isnull()) & (tune_in_prac_data_CSY_df['cursorStart']<1)
                                 , 'cursorEnd'] = tune_in_prac_data_CSY_df['cursorStart']
    tune_in_prac_data_CSY_df.loc[(tune_in_prac_data_CSY_df['cursorEnd'].isnull()) & (tune_in_prac_data_CSY_df['cursorStart']>1)
                                 , 'cursorEnd'] = tune_in_prac_data_CSY_df['AUDIO_LENGTH']
    tune_in_prac_data_CSY_df['SCHOOL_NAME'].fillna('',inplace=True)
    tune_in_prac_data_CSY_df['STATE'].fillna('',inplace=True)
    tune_in_prac_data_CSY_df['Played_Percentage']=round(((tune_in_prac_data_CSY_df['cursorEnd']-tune_in_prac_data_CSY_df['cursorStart'])/tune_in_prac_data_CSY_df['AUDIO_LENGTH']*100),0)
    tune_in_prac_data_CSY_df['Month_Name'] = pd.to_datetime(tune_in_prac_data_CSY_df['PRACTICE_DATE'], format='%m').dt.month_name().str.slice(stop=3)
    tune_in_prac_data_CSY_df1=tune_in_prac_data_CSY_df[tune_in_prac_data_CSY_df['Month_Name']==str(month)]
    data=[]
    for i,j,k,l,m,n,o in zip(tune_in_prac_data_CSY_df1.PARENT_EMAIL.tolist(),
                               tune_in_prac_data_CSY_df1.TEACHER.tolist(),
                                 tune_in_prac_data_CSY_df1.TEACHER_EMAIL.tolist(),
                                 tune_in_prac_data_CSY_df1.SCHOOL_NAME.tolist(),
                                 tune_in_prac_data_CSY_df1.AUDIO_NAME.tolist(),
                                 tune_in_prac_data_CSY_df1.PROGRAM.tolist(),
                                tune_in_prac_data_CSY_df1.Played_Percentage.tolist()

                                ):
        data.append([i,j,k,l,m,n,o])

    temp={'data':data}
    return json.dumps(temp)

# <<<<<<<<<<<<<<<<<<<<<<<<<<---------Tune_In_CSY_Cards-------------------->>>>>>>>>>>>>>>>>>>>>>>>>>

@app.route('/tuneincsycard')
def tunein_cards_csy():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.tune_in_audio_track_detail
    query=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
              {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),
                  '$lte':datetime.datetime(2021,7,31)
                  }},
                  {'INVITEE_EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'INVITEE_EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'INVITEE_EMAIL':{"$not":{"$regex":"manoj.rayat5575@gmail.com",'$options':'i'}}},


                  ]}},
              {'$group':{
                  '_id': { 
                  'month': {'$month' :"$MODIFIED_DATE" }, 
                  'year': {'$year' :"$MODIFIED_DATE" }},
                  'prac_parent':{'$addToSet':'$INVITEE_EMAIL'}
                  }},

                  {'$project':{
                      '_id':0,
                      'month':'$_id.month',
                      'year':'$_id.year',
                      'practicing_parent':{'$size':'$prac_parent'}
                      }
                      }]
    tune_in_practice_CSY=list(collection.aggregate(query))
    tune_in_practice_CSY_df=pd.DataFrame(tune_in_practice_CSY)

    collection1 = db.tune_in_master
    query1=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    #           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
              {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1),
                  '$lte':datetime.datetime(2021,7,31)
                  }}
              ]}},

              {'$group':{
                  '_id': { 
                  'month': {'$month' :"$MODIFIED_DATE" }, 
                  'year': {'$year' :"$MODIFIED_DATE" }},
                  'TUNE_IN_SEND':{'$sum':1},
                   'OPTED_OUT' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
         , 'Y' ] }, 1, 0 ] } },
         'OPTED_IN' :  {'$sum' : {'$cond': [ {'$eq': [ '$IS_OPTED_OUT'
         , 'N' ] }, 1, 0 ] } }
                  }
                  }
                  ,{'$project':{
                      '_id':0,
                      'month':'$_id.month',
                      'year':'$_id.year',
                      'TuneIn_Send':'$TUNE_IN_SEND',
                      'Opt_Out':'$OPTED_OUT',
                      'Opt_In':'$OPTED_IN'
                      }
                      }]
    tune_in_CSY=list(collection1.aggregate(query1))
    tune_in_CSY_df=pd.DataFrame(tune_in_CSY)
    month_df=pd.DataFrame({'month':list(range(1,13))})
    monthname=[]
    months=month_df.month.tolist()
    for i in range(len(months)):    
        monthname.append(calendar.month_abbr[months[i]])
    month_df['month_name']=monthname
    tune_in_data=tune_in_CSY_df.merge(tune_in_practice_CSY_df,on=['month','year'],how='left').fillna(0)
    tune_in_Final_CSY=month_df.merge(tune_in_data[['month','TuneIn_Send', 'Opt_Out', 'Opt_In', 'practicing_parent']],how='left',on='month').fillna(0)
    cardscount=[tune_in_Final_CSY.TuneIn_Send.sum(),tune_in_Final_CSY.Opt_In.sum(),tune_in_Final_CSY.Opt_Out.sum(),tune_in_Final_CSY.practicing_parent.sum()]
    cardsname=['Tune_In_Send','Tune_In_Opt_In','Tune_In_Opt_Out','Parents_Practised']

    data=[]
    for i,j in zip(cardsname,cardscount):
        data.append([i,j])
    temp={'data':data}
    return json.dumps(temp)

@app.route('/tuneinspider/<district>')   
def tunein_spider(district):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    dfti = DataFrame(list(db.tune_in_master.aggregate([
       {"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                          {"USER_ID.DISTRICT_ID._id":ObjectId(""+district+"")},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}}
                  ]}}
                      ,{'$project':{
                          '_id':1,
                          'IS_OPTED_OUT':1,
                          'EMAIL':1,
                          'CREATED_DATE':1,
                          'Teacher':'$USER_ID.EMAIL_ID',
                          'school':'$USER_ID.schoolId.NAME',
                          'USER_ID':"$USER_ID._id",
                          'ID':"$USER_ID.schoolId._id",
                          'STATE':"$USER_ID.schoolId.STATE"
                          }
                          }
        ]))).fillna("NO INFO")
    email_id=dfti["EMAIL"].tolist()
    dfatd = DataFrame(list(db.tune_in_audio_track_detail.aggregate([
       {"$match":{
                 '$and':[
                         { 'INVITEE_EMAIL':{"$in": email_id}},
                     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
                      {'INVITEE_EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'INVITEE_EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'INVITEE_EMAIL':{"$not":{"$regex":"manoj.rayat5575@gmail.com",'$options':'i'}}},
                      ]}},
                  {'$group':{
                      '_id': "$INVITEE_EMAIL" , 
                      'Practice_Count':{'$sum':1}
                      }},
                      {'$project':{
                          '_id':0,
                          'EMAIL':'$_id',
                          'practice_count1':'$Practice_Count'}
                          }
                          ]))).fillna(0)
    dfti["TUNE_ID"]="TUNE IN SPIDER"
    if dfatd.empty == True:
        dfti['practice_count12']=0
        dfti['practice_count1']=0
        dfdb=dfti   
        tune=dfdb[["TUNE_ID",'practice_count1']]
        tune1=tune.groupby(['TUNE_ID'])['practice_count1'].sum().reset_index()
        links0 = tune1.rename(columns={'TUNE_ID' : 'name', 'practice_count1' : 'Tune-in Count'}).to_dict('r')
        school=dfdb[['school','practice_count1','ID']]
        school1=school.groupby(['ID','school'])['practice_count1'].sum().reset_index()
        school2=school1[['school','practice_count1']]
        links1 = school2.rename(columns={'school' : 'name', 'practice_count1' : 'Tune-in Count'}).to_dict('r')
        teacher=dfdb[['Teacher','practice_count12']]
        teacher1=teacher.groupby(['Teacher'])['practice_count12'].sum().reset_index()
        teacher2=dfdb[['Teacher','practice_count12']]
        links2 = teacher2.rename(columns={'Teacher' : 'name', 'practice_count12' : 'Tune-in Count'}).to_dict('r')
        parent=dfdb[['EMAIL','practice_count1']]
        links3 = parent.rename(columns={'EMAIL' : 'name', 'practice_count1' : 'Tune-in Count'}).to_dict('r')
        links0.extend(links1)
        links0.extend(links2)
        links0.extend(links3)
        dfdb.loc[(dfdb['IS_OPTED_OUT'] == "Y") , 'hex'] = '#EC3D09' #Y
        dfdb.loc[(dfdb['IS_OPTED_OUT'] == "N") , 'hex'] = '#05D324' #N
        dfcolor=dfdb[['EMAIL','hex']]
        linkcolor = dfcolor.rename(columns={'EMAIL' : 'name', 'hex' : 'hex'}).to_dict('r')
        teacherst=dfdb[['school','Teacher']]
        teacherst1 = teacherst.drop_duplicates(subset='Teacher', keep="first")
        links4 = teacherst1.rename(columns={'school' : 'source', 'Teacher' : 'target'}).to_dict('r')
        schoolst=dfdb[['TUNE_ID','school','ID']]
        schoolst1 = schoolst.drop_duplicates(subset='ID', keep="first")
        schoolst2=schoolst1[['TUNE_ID','school']]
        links5 = schoolst2.rename(columns={'TUNE_ID' : 'source', 'school' : 'target'}).to_dict('r')
        parentst=dfdb[['Teacher','EMAIL']]
        links6 = parentst.rename(columns={'Teacher' : 'source', 'EMAIL' : 'target'}).to_dict('r')
        results = []
        for n in links4:
            for m in links5:
                if m['target']==n['source']:
                    results.append(m)
        res_list = [i for n, i in enumerate(results) if i not in results[n + 1:]] 
        for n in links4:
            for m in res_list:
                if m['target']==n['source']:
                    res_list.append(n)
        res_list.extend(links6)
        res_list1 = [i for n, i in enumerate(res_list) if i not in res_list[n + 1:]] 
    #     for n in links6:
    #         for m in res_list:
    #             if m['target']==n['source']:
    #                 res_list.append(n)
    #     res_list.extend(links6)
        temp={"nodes":links0,"links":res_list1,"attributes":linkcolor}
    else:
        dfdb=pd.merge(dfti, dfatd, on='EMAIL',how='left').fillna(0)
        dfdb['practice_count12']=0
        tune=dfdb[["TUNE_ID",'practice_count1']]
        tune1=tune.groupby(['TUNE_ID'])['practice_count1'].sum().reset_index()
        links0 = tune1.rename(columns={'TUNE_ID' : 'name', 'practice_count1' : 'Tune-in Count'}).to_dict('r')
        school=dfdb[['school','practice_count1','ID']]
        school1=school.groupby(['ID','school'])['practice_count1'].sum().reset_index()
        school2=school1[['school','practice_count1']]
        links1 = school2.rename(columns={'school' : 'name', 'practice_count1' : 'Tune-in Count'}).to_dict('r')
        teacher=dfdb[['Teacher','practice_count12']]
        teacher1=teacher.groupby(['Teacher'])['practice_count12'].sum().reset_index()
        teacher2=dfdb[['Teacher','practice_count12']]
        links2 = teacher2.rename(columns={'Teacher' : 'name', 'practice_count12' : 'Tune-in Count'}).to_dict('r')
        parent=dfdb[['EMAIL','practice_count1']]
        links3 = parent.rename(columns={'EMAIL' : 'name', 'practice_count1' : 'Tune-in Count'}).to_dict('r')
        links0.extend(links1)
        links0.extend(links2)
        links0.extend(links3)
        dfdb.loc[(dfdb['IS_OPTED_OUT'] == "Y") , 'hex'] = '#EC3D09' #Y
        dfdb.loc[(dfdb['IS_OPTED_OUT'] == "N") , 'hex'] = '#05D324' #N
        dfcolor=dfdb[['EMAIL','hex']]
        linkcolor = dfcolor.rename(columns={'EMAIL' : 'name', 'hex' : 'hex'}).to_dict('r')
        teacherst=dfdb[['school','Teacher']]
        teacherst1 = teacherst.drop_duplicates(subset='Teacher', keep="first")
        links4 = teacherst1.rename(columns={'school' : 'source', 'Teacher' : 'target'}).to_dict('r')
        schoolst=dfdb[['TUNE_ID','school','ID']]
        schoolst1 = schoolst.drop_duplicates(subset='ID', keep="first")
        schoolst2=schoolst1[['TUNE_ID','school']]
        links5 = schoolst2.rename(columns={'TUNE_ID' : 'source', 'school' : 'target'}).to_dict('r')
        parentst=dfdb[['Teacher','EMAIL']]
        links6 = parentst.rename(columns={'Teacher' : 'source', 'EMAIL' : 'target'}).to_dict('r')
        results = []
        for n in links4:
            for m in links5:
                if m['target']==n['source']:
                    results.append(m)
        res_list = [i for n, i in enumerate(results) if i not in results[n + 1:]] 
        for n in links4:
            for m in res_list:
                if m['target']==n['source']:
                    res_list.append(n)
        res_list.extend(links6)
        res_list1 = [i for n, i in enumerate(res_list) if i not in res_list[n + 1:]] 
    #     for n in links6:
    #         for m in res_list:
    #             if m['target']==n['source']:
    #                 res_list.append(n)
    #     res_list.extend(links6)
        temp={"nodes":links0,"links":res_list1,"attributes":linkcolor}
    return(json.dumps(temp))

####################################### Bill Me Later Analysis###########################################
@app.route("/BillMeLaterAnalysis")
def billmelateranalysis():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1 = db.subscription_master
    collection2 = db.audio_track_master

    user1 =[{"$match":
             {'$and': [
                 {"MODE_OF_PAYMENT":"payLater"},
    #              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},        
                     {'USER_ID.EMAIL_ID':{'$ne':''}},            
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$USER_ID.schoolId._id',"STATE" : {"$first" : "$USER_ID.schoolId.STATE"},"School Name" : {"$first" : "$USER_ID.schoolId.NAME"},"LAST_PAYMENT_AMOUNT" : {"$first" : "$LAST_PAYMENT_AMOUNT"} ,"LAST_PAYMENT_DATE" : {"$first" : "$LAST_PAYMENT_DATE"} ,"SUBSCRIPTION_DATE": {'$first':"$SUBSCRIPTION_DATE"},'SCHOOL':{'$addToSet':'$USER_ID.schoolId._id'},'Max Classes':{'$sum':'$USER_ID.MAX_CLASSES'},"NO_OF_INVITES" : {"$sum" : "$PLAN_ID.NO_OF_INVITES"},'Plan Name':{'$first':'$PLAN_ID.PLAN_NAME'}}},
                      {'$project':{'_id':1,"Last_Payment_Amount": "$LAST_PAYMENT_AMOUNT", "Last_Payment_Date": "$LAST_PAYMENT_DATE","State" : "$STATE","School Name" : 1,'Plan Name':'$Plan Name',"Payment_Mode" : "$MODE_OF_PAYMENT",'Max Classes' : '$Max Classes',"Invites":"$NO_OF_INVITES",  "Subscription_Date" :  "$SUBSCRIPTION_DATE"}},
                       ]
    update1=list(collection1.aggregate(user1))
    df1=pd.DataFrame(update1)

    user2 = [{"$match":
         {'$and': [
    #              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //        
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #              {'MODIFIED_DATE':{'$lt':datetime.datetime(2020,8,1)}},
    #                  
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','ID':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}, "Mindful_Minutes":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}}}},
                  {'$project':{'_id':1,'Practice_Count':'$ID','program':1,'Mindful_Minutes':'$Mindful_Minutes'}},
                   ]
    update2=list(collection2.aggregate(user2))
    df2=pd.DataFrame(update2)
    #Final Dataframe Containing all required data
    df3=pd.merge(df1,df2, on = "_id", how = "left")
    df3['Month']=pd.to_datetime(df3["Last_Payment_Date"]).dt.strftime('%m')

    ###########################   TASK 1 ########################################################

    # Historical last payment amount paid for per month
    # Data's Trend and Seasonality 
    dff = df3
    dff['Year_Month']=pd.to_datetime(dff["Last_Payment_Date"]).dt.strftime('%Y-%m')
    dff = dff.groupby(['Year_Month']).sum().reset_index()
    dff = dff.sort_values(by='Year_Month', ascending = True)
    dff = dff[:-1]

    dff["Pct_Amount"] = dff["Last_Payment_Amount"].pct_change()*100
    dff["Pct_Practice"] = dff["Practice_Count"].pct_change()*100
    dff["Pct_Mindful_Minutes"] = dff["Mindful_Minutes"].pct_change()*100

    dff = dff.set_index('Year_Month')
    idx =(pd.MultiIndex.from_product(dff.index.str.split('-', expand=True).levels).map('-'.join))
    dff = dff.reindex(idx, fill_value=0).rename_axis('Year_Month').reset_index()
    dff0 = dff[6:-6]

    #for graph one
    list1=dff0["Year_Month"].tolist()
    list2=dff0["Last_Payment_Amount"].tolist()
    list3=dff0["Pct_Amount"].tolist()
    list4=dff0["Practice_Count"].tolist()
    list5=dff0["Mindful_Minutes"].tolist()

    dict1 = {'Year_Month':list1,'Amount':list2}
    ###########################   TASK 2 ########################################################

    #YOY growth Monthly
    # Historical last payment amount paid for month by month comparison

    dff['Month']=pd.to_datetime(dff["Year_Month"]).dt.strftime('%m')
    dff['Year']=pd.to_datetime(dff["Year_Month"]).dt.strftime('%Y')
    dff = dff.sort_values(by=["Month","Year"])
    dff.reset_index(inplace = True) 
    dff1 = dff[["Last_Payment_Amount",'Month','Year']]
    dff1 = dff1.pivot_table(index=['Month'],columns=['Year'], values='Last_Payment_Amount').fillna(0)
    dff1.index = ["January","February","March","April","May","June","July","August","September","October","November","December"]

    #for graph two
    list11=dff1.index.tolist()
    list12=dff1.columns.tolist()
    list13=dff1.values.tolist()

    dict2 = {'Month':list11,'Year':list12,'Amount':list13}
    ###########################   TASK 3 ########################################################

    # financial year from June to May for years(18-19, 19-20, 20-21)
    # June to May monthly graph for every financial year

    dff2 = dff[["Last_Payment_Amount",'Month','Year','Year_Month']]
    dff2.sort_values(by='Year')
    dff2 = dff2.set_index('Year_Month')
    idx =(pd.MultiIndex.from_product(dff2.index.str.split('-', expand=True).levels).map('-'.join))
    dff2 = dff2.reindex(idx, fill_value=0).rename_axis('Year_Month').reset_index()

    year18_19 = dff2[6:18]
    year19_20 = dff2[18:30]
    year20_21 = dff2[30:42]

    # for graph 3

    #financialyear 2018 to 2019
    list21 = year18_19.Year_Month.tolist()
    list31 = year18_19.Last_Payment_Amount.tolist()

    dict3 = {'2018_2019': list21,'Amount':list31}

    #financialyear 2019 to 2020
    list22 = year19_20.Year_Month.tolist()
    list32 = year19_20.Last_Payment_Amount.tolist()

    dict4 = {'2019_2020': list22,'Amount':list32}

    #financialyear 2020 to 2021
    list23 = year20_21.Year_Month.tolist()
    list33 = year20_21.Last_Payment_Amount.tolist()

    dict5 = {'2020_2021': list23,'Amount':list33}



    ###########################   TASK 4 ########################################################
    # financial year from June to May for years(18-19, 19-20, 20-21)
    # yearly graph showing total amount for every financial year 
    amount_1819 =year18_19.Last_Payment_Amount.sum()
    amount_1920 =year19_20.Last_Payment_Amount.sum()
    amount_2021 =year20_21.Last_Payment_Amount.sum()
    years = ['2018-2029', '2019-2020', '2020-2021']
    amount =[amount_1819,amount_1920,amount_2021]
    dict6 = {'Financial_Year':years, 'Amount':amount}

    # Master dictionary containing all above dictionaries
    master_dict = {'A': dict1,'B': dict2,'C':dict3,'D': dict4, 'E': dict5, 'F':dict6}
    return json.dumps(master_dict)



#<<<<<<<<<-------------------------DISTRICT_DDT_DASHBOARD_CODE_START--------------------------->>>>>>>>>>>>>

#<<<<<<<<<<<<<<<<<<-----------------------------DDT_CARDS_CSY---------------------------------->>>>>>>>>>>>>>>>>>>>>>>
@app.route('/districtddtcard/<districtid>')
def ddt_card(districtid):
    
    disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
            '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
            '5f2609807a1c0000950bb475':'Agawam School district',
            '5f2609807a1c0000950bb481':'Alameda Unified School District',
            '5f2609807a1c0000950bb47a':'Alpine School District',
            '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
            '5f2609807a1c0000950bb463':'Austin Independent School District',
            '5f59e4836451a9089d7d4007':'Belleville School District',
            '5f2609807a1c0000950bb46d':'Broward County Public Schools',
            '5f2609807a1c0000950bb46c':'Chico Unified School District',
            '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
            '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
            '5f2609807a1c0000950bb45c':'Comox Valley School District(sd71)',
            '5f2609807a1c0000950bb480':'Dell Texas',
            '5f7413ef9387fd71ce6387cb':'Douglas County School District',
            '5f895191609e08b76029f641':'Early learning Sarasota',
            '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
            '5f2609807a1c0000950bb461':'Englewood Public School District',
            '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
            '5f2609807a1c0000950bb47d':'Flint Public Schools',
            '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
            '5f2609807a1c0000950bb450':'Goleta District',
            '5f2609807a1c0000950bb474':'Greenburgh-North Castle (GNC) Union Free School District',
            '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
            '5f2609807a1c0000950bb476':'Hillsborough County',
            '5f2609807a1c0000950bb455':'Krum Independent School District',
            '5f2609807a1c0000950bb47e':'La Joya School District',
            '5f2609807a1c0000950bb467':'Lincolnshire Schools',
            '5f2609807a1c0000950bb45a':'LAUSD',
            '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
            '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
            '5fbcdf0ba84e48a64412a798':'Needham School District',
            '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
            '5f6994386451a9089d7d4009':'Ogden school district',
            '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
            '5fd704da04a848e368de5dc6':'Oakland Unified School District',
            '5f8fcd33609e08b76029f644':'Paradise Unified School District',
            '5f2609807a1c0000950bb466':'Pinellas County Schools',
            '5f2609807a1c0000950bb471':'Racine Unified Schools',
            '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
            '5f2609807a1c0000950bb478':'San Diego Unified School District',
            '5f2609807a1c0000950bb470':'San Leandro Unified School District',
            '5f2609807a1c0000950bb477':'Sarasota County',
            '5f2609807a1c0000950bb473':'Skillman Foundation',
            '5f2609807a1c0000950bb46a':'Springfield Public Schools',
            '5f2609807a1c0000950bb468':'Utah Board of Education',
            '5f698b826451a9089d7d4008':'Wayne Metro',
            '5f2609807a1c0000950bb45b':'Westfield Public School District',
            '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
            '5f2609807a1c0000950bb45d':'Youngstown',
    '5f2609807a1c0000950bb464':'Equity Education',
    '5f2609807a1c0000950bb469':'LSF -  Head Start',
    '5f2609807a1c0000950bb46e':'District 25 New York Schools',
    '5f2609807a1c0000950bb46f':'Paradise Schools',
    '5f2609807a1c0000950bb479':'Panorama Education',
    '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
    '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
    '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
    '5fe2e25d4d0ca68d7baf889d':'BGCA',
    '5fe318b14d0ca68d7baf889e':'BLUE',
    '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
    '6017ab3043ca9c39151838d4':'Oswego School District',
    '60239a84e57dc27613699d57':'Austin Independent School District',
    '6023a6d79e8e623753fc305c':'Boulder Valley School District',
    '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
    '6023a7269e8e623753fc305e':'Fulton County School System',
    '6023a7499e8e623753fc305f':'Manatee County School District',
    '6023a76f9e8e623753fc3060':'San Jose Unified School District',
    '6023a7949e8e623753fc3061':'Wasatch County School District',}

    district=disdic[districtid]

    #school summary df
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.subscription_master
    query=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
                     {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {"schoolId._id":{"$in":db.school_master.distinct( "_id", 
                                                                       { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}      


                    ]}},          
              {'$group':{
                  '_id':'$schoolId._id',
                  'schoolname':{'$first':'$schoolId.NAME'},
                  'CITY':{'$first':'$schoolId.CITY'},
                  'STATE':{'$first':'$schoolId.STATE'},
                  'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                  'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                  'CREATED_DATE':{'$min':'$CREATED_DATE'},
                  'USER_COUNT':{'$addToSet':'$_id'}}},
              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'SCHOOL_NAME':'$schoolname',
                  'CITY':'$CITY',
                  'STATE':'$STATE',
                  'COUNTRY':'$COUNTRY',
                  'ROLE_ID':'$ROLE_ID',
                  'CREATED_DATE':'$CREATED_DATE',
                  'USER_COUNT':{'$size':'$USER_COUNT'}
                  }}]
    school_summary=list(collection.aggregate(query))
    school_summary_df=pd.DataFrame(school_summary)

    #admin summary info

    query2=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
          {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}
             ,{'IS_ADMIN':'Y'},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$schoolId._id',
                  'SCHOOL_NAME':'$schoolId.NAME',
                  'ADMIN_ID':'$_id',
                  'ADMIN_NAME':'$USER_NAME',
                  'ADMIN_EMAIL':'$EMAIL_ID',
                  'DISTRICT_ID':'$DISTRICT_ID._id',
                  'DISTRICT_NAME':'$DISTRICT_ID.DISTRICT_NAME',
                  'ROLE_ID':'$ROLE_ID.ROLE_ID',
                  'D_CATEGORY':'$D_CATEGORY'         
                  }}]
    admin_summary=list(collection.aggregate(query2))
    admin_summary_df=pd.DataFrame(admin_summary)
    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y',
                                                "schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}


                                                })
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)

    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y',
                                                "schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}


                                                })
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)

    #practice summary

    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                     {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}       
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_summary=list(collection3.aggregate(query5))
    school_prac_summary_df=pd.DataFrame(school_prac_summary)

    #csy practice summary

    query6=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
               {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}},
            {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}


              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User_CSY':{'$size':'$Active_User'},
                 'Last_Practice_Date_CSY':'$Last_Prac_Date',
                 'Practice_Sessions_CSY':'$Practice_Sessions',
                 'Mindful_Minutes_CSY':'$Mindful_Minutes'
                 }
                 }]
    school_prac_active_csy=list(collection3.aggregate(query6))
    school_prac_active_csy_df=pd.DataFrame(school_prac_active_csy)

    d1=school_summary_df.merge(admin_summary_df[['SCHOOL_ID', 'ADMIN_ID', 'ADMIN_NAME', 'ADMIN_EMAIL',
           'DISTRICT_ID', 'DISTRICT_NAME']],on='SCHOOL_ID',how='left')
    d2=d1.merge(admin_sm_summary_df,on='ADMIN_ID',how='left')
    d3=d2.merge(school_prac_summary_df,on='SCHOOL_ID',how='left')
    d4=d3.merge(school_prac_active_csy_df,on='SCHOOL_ID',how='left')
    d4[['Practice_Sessions',
           'Mindful_Minutes', 'Active_User',
           'Practice_Sessions_CSY', 'Mindful_Minutes_CSY','Active_User_CSY']]=d4[['Practice_Sessions',
           'Mindful_Minutes', 'Active_User',
           'Practice_Sessions_CSY', 'Mindful_Minutes_CSY','Active_User_CSY']].replace(np.nan, 0)
    d4[['Last_Practice_Date','Last_Practice_Date_CSY']]=d4[['Last_Practice_Date','Last_Practice_Date_CSY']].fillna('NO PRACTICE')

    d5=d4.sort_values('Mindful_Minutes_CSY',ascending=False).reset_index(drop=True)

    mm_csy=d5.Mindful_Minutes_CSY.tolist()

    type=[]
    for i in range(len(mm_csy)):
        if mm_csy[i]==0:
            type.append('dormant')
        elif mm_csy[i]<=round(d4.Mindful_Minutes_CSY.mean()):
            type.append('below average')
        else:
            type.append('above average')

    d5['prac_Type']=type

    d_csy=d5.groupby('prac_Type')['prac_Type'].count().to_frame(name = 'Count').reset_index()
    prac_Stand=pd.DataFrame({'prac_Type':['dormant','below average','above average']})
    d_csy=prac_Stand.merge(d_csy,on='prac_Type',how='left').fillna(0)

    prac_types=d_csy['Count'].tolist()
    temp={'District_Average_Mindful_Minutes':round(d4.Mindful_Minutes_CSY.mean()),
         'Schools_below_Average':prac_types[1],
          'Schools_above_Average':prac_types[2],
          'Dormant_Schools':prac_types[0] }
    
    return json.dumps({'data':temp})


#<<<<<<<<<<<<<<<<<<------------------------DDT_CHART---------------->>>>>>>>>>>>>>>>>

@app.route('/districtddtchart/<districtid>')
def ddt_chart(districtid):
    disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
        '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
        '5f2609807a1c0000950bb475':'Agawam School district',
        '5f2609807a1c0000950bb481':'Alameda Unified School District',
        '5f2609807a1c0000950bb47a':'Alpine School District',
        '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
        '5f2609807a1c0000950bb463':'Austin Independent School District',
        '5f59e4836451a9089d7d4007':'Belleville School District',
        '5f2609807a1c0000950bb46d':'Broward County Public Schools',
        '5f2609807a1c0000950bb46c':'Chico Unified School District',
        '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
        '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
        '5f2609807a1c0000950bb45c':'Comox Valley School District(sd71)',
        '5f2609807a1c0000950bb480':'Dell Texas',
        '5f7413ef9387fd71ce6387cb':'Douglas County School District',
        '5f895191609e08b76029f641':'Early learning Sarasota',
        '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
        '5f2609807a1c0000950bb461':'Englewood Public School District',
        '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
        '5f2609807a1c0000950bb47d':'Flint Public Schools',
        '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
        '5f2609807a1c0000950bb450':'Goleta District',
        '5f2609807a1c0000950bb474':'Greenburgh-North Castle (GNC) Union Free School District',
        '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
        '5f2609807a1c0000950bb476':'Hillsborough County',
        '5f2609807a1c0000950bb455':'Krum Independent School District',
        '5f2609807a1c0000950bb47e':'La Joya School District',
        '5f2609807a1c0000950bb467':'Lincolnshire Schools',
        '5f2609807a1c0000950bb45a':'LAUSD',
        '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
        '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
        '5fbcdf0ba84e48a64412a798':'Needham School District',
        '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
        '5f6994386451a9089d7d4009':'Ogden school district',
        '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
        '5fd704da04a848e368de5dc6':'Oakland Unified School District',
        '5f8fcd33609e08b76029f644':'Paradise Unified School District',
        '5f2609807a1c0000950bb466':'Pinellas County Schools',
        '5f2609807a1c0000950bb471':'Racine Unified Schools',
        '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
        '5f2609807a1c0000950bb478':'San Diego Unified School District',
        '5f2609807a1c0000950bb470':'San Leandro Unified School District',
        '5f2609807a1c0000950bb477':'Sarasota County',
        '5f2609807a1c0000950bb473':'Skillman Foundation',
        '5f2609807a1c0000950bb46a':'Springfield Public Schools',
        '5f2609807a1c0000950bb468':'Utah Board of Education',
        '5f698b826451a9089d7d4008':'Wayne Metro',
        '5f2609807a1c0000950bb45b':'Westfield Public School District',
        '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
        '5f2609807a1c0000950bb45d':'Youngstown',
    '5f2609807a1c0000950bb464':'Equity Education',
    '5f2609807a1c0000950bb469':'LSF -  Head Start',
    '5f2609807a1c0000950bb46e':'District 25 New York Schools',
    '5f2609807a1c0000950bb46f':'Paradise Schools',
    '5f2609807a1c0000950bb479':'Panorama Education',
    '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
    '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
    '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
    '5fe2e25d4d0ca68d7baf889d':'BGCA',
    '5fe318b14d0ca68d7baf889e':'BLUE',
    '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
    '6017ab3043ca9c39151838d4':'Oswego School District',
    '60239a84e57dc27613699d57':'Austin Independent School District',
    '6023a6d79e8e623753fc305c':'Boulder Valley School District',
    '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
    '6023a7269e8e623753fc305e':'Fulton County School System',
    '6023a7499e8e623753fc305f':'Manatee County School District',
    '6023a76f9e8e623753fc3060':'San Jose Unified School District',
    '6023a7949e8e623753fc3061':'Wasatch County School District',}


    district=disdic[districtid]

    #school summary df
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.subscription_master
    query=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
                     {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {"schoolId._id":{"$in":db.school_master.distinct( "_id", 
                                                                       { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}      


                    ]}},          
              {'$group':{
                  '_id':'$schoolId._id',
                  'schoolname':{'$first':'$schoolId.NAME'},
                  'CITY':{'$first':'$schoolId.CITY'},
                  'STATE':{'$first':'$schoolId.STATE'},
                  'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                  'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                  'CREATED_DATE':{'$min':'$CREATED_DATE'},
                  'USER_COUNT':{'$addToSet':'$_id'}}},
              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'SCHOOL_NAME':'$schoolname',
                  'CITY':'$CITY',
                  'STATE':'$STATE',
                  'COUNTRY':'$COUNTRY',
                  'ROLE_ID':'$ROLE_ID',
                  'CREATED_DATE':'$CREATED_DATE',
                  'USER_COUNT':{'$size':'$USER_COUNT'}
                  }}]
    school_summary=list(collection.aggregate(query))
    school_summary_df=pd.DataFrame(school_summary)

    #admin summary info

    query2=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
          {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}
             ,{'IS_ADMIN':'Y'},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$schoolId._id',
                  'SCHOOL_NAME':'$schoolId.NAME',
                  'ADMIN_ID':'$_id',
                  'ADMIN_NAME':'$USER_NAME',
                  'ADMIN_EMAIL':'$EMAIL_ID',
                  'DISTRICT_ID':'$DISTRICT_ID._id',
                  'DISTRICT_NAME':'$DISTRICT_ID.DISTRICT_NAME',
                  'ROLE_ID':'$ROLE_ID.ROLE_ID',
                  'D_CATEGORY':'$D_CATEGORY'         
                  }}]
    admin_summary=list(collection.aggregate(query2))
    admin_summary_df=pd.DataFrame(admin_summary)
    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y',
                                                "schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}


                                                })
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)

    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y',
                                                "schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}


                                                })
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)

    #practice summary

    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                     {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}       
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_summary=list(collection3.aggregate(query5))
    school_prac_summary_df=pd.DataFrame(school_prac_summary)

    #csy practice summary

    query6=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
               {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}},
            {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}


              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User_CSY':{'$size':'$Active_User'},
                 'Last_Practice_Date_CSY':'$Last_Prac_Date',
                 'Practice_Sessions_CSY':'$Practice_Sessions',
                 'Mindful_Minutes_CSY':'$Mindful_Minutes'
                 }
                 }]
    school_prac_active_csy=list(collection3.aggregate(query6))
    school_prac_active_csy_df=pd.DataFrame(school_prac_active_csy)

    d1=school_summary_df.merge(admin_summary_df[['SCHOOL_ID', 'ADMIN_ID', 'ADMIN_NAME', 'ADMIN_EMAIL',
           'DISTRICT_ID', 'DISTRICT_NAME']],on='SCHOOL_ID',how='left')
    d2=d1.merge(admin_sm_summary_df,on='ADMIN_ID',how='left')
    d3=d2.merge(school_prac_summary_df,on='SCHOOL_ID',how='left')
    d4=d3.merge(school_prac_active_csy_df,on='SCHOOL_ID',how='left')
    d4[['Practice_Sessions',
           'Mindful_Minutes', 'Active_User',
           'Practice_Sessions_CSY', 'Mindful_Minutes_CSY','Active_User_CSY']]=d4[['Practice_Sessions',
           'Mindful_Minutes', 'Active_User',
           'Practice_Sessions_CSY', 'Mindful_Minutes_CSY','Active_User_CSY']].replace(np.nan, 0)
    d4[['Last_Practice_Date','Last_Practice_Date_CSY']]=d4[['Last_Practice_Date','Last_Practice_Date_CSY']].fillna('NO PRACTICE')

    d5=d4.sort_values('Mindful_Minutes_CSY',ascending=False).reset_index(drop=True)

    mm_csy=d5.Mindful_Minutes_CSY.tolist()

    type=[]
    for i in range(len(mm_csy)):
        if mm_csy[i]==0:
            type.append('dormant')
        elif mm_csy[i]<=round(d4.Mindful_Minutes_CSY.mean()):
            type.append('below average')
        else:
            type.append('above average')

    d5['prac_Type']=type

    d_csy=d5.groupby('prac_Type')['prac_Type'].count().to_frame(name = 'Count').reset_index()

    prac_Stand=pd.DataFrame({'prac_Type':['dormant','below average','above average']})

    d_csy=prac_Stand.merge(d_csy,on='prac_Type',how='left').fillna(0)




    mm_overall=d5.Mindful_Minutes.tolist()

    type_overall=[]

    for i in range(len(mm_overall)):

        if mm_overall[i]==0:
            type_overall.append('dormant')
        elif mm_overall[i]<=round(d4.Mindful_Minutes.mean()):
            type_overall.append('below average')
        else:
            type_overall.append('above average')

    d5['prac_Type_overall']=type_overall

    d_overall=d5.groupby('prac_Type_overall')['prac_Type_overall'].count().to_frame(name = 'Count').reset_index()
    d_overall=prac_Stand.merge(d_overall,left_on='prac_Type',right_on='prac_Type_overall',how='left').fillna(0)
    
    temp={'CSY':{'Practice_Standard':d_csy.prac_Type.tolist(),
                 'School_Count':d_csy.Count.tolist()},
          'Overall':{
              'Practice_Standard':d_overall.prac_Type_overall.tolist(),
                 'School_Count':d_overall.Count.tolist()},
          }
    
    return json.dumps({'data':temp})


#<<<<<<<<<<<<<<<<<<<<<<<<<--------------------------TABLE_OVERALL_COLUMN----------->>>>>>>>>>>>>>>>>>>>>>>>>>>

@app.route('/districtddtoveralltable/<districtid>/<practype>')

def ddt_overall_table(districtid,practype):    
    practice=str(practype).lower()    
    disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
        '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
        '5f2609807a1c0000950bb475':'Agawam School district',
        '5f2609807a1c0000950bb481':'Alameda Unified School District',
        '5f2609807a1c0000950bb47a':'Alpine School District',
        '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
        '5f2609807a1c0000950bb463':'Austin Independent School District',
        '5f59e4836451a9089d7d4007':'Belleville School District',
        '5f2609807a1c0000950bb46d':'Broward County Public Schools',
        '5f2609807a1c0000950bb46c':'Chico Unified School District',
        '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
        '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
        '5f2609807a1c0000950bb45c':'Comox Valley School District(sd71)',
        '5f2609807a1c0000950bb480':'Dell Texas',
        '5f7413ef9387fd71ce6387cb':'Douglas County School District',
        '5f895191609e08b76029f641':'Early learning Sarasota',
        '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
        '5f2609807a1c0000950bb461':'Englewood Public School District',
        '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
        '5f2609807a1c0000950bb47d':'Flint Public Schools',
        '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
        '5f2609807a1c0000950bb450':'Goleta District',
        '5f2609807a1c0000950bb474':'Greenburgh-North Castle (GNC) Union Free School District',
        '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
        '5f2609807a1c0000950bb476':'Hillsborough County',
        '5f2609807a1c0000950bb455':'Krum Independent School District',
        '5f2609807a1c0000950bb47e':'La Joya School District',
        '5f2609807a1c0000950bb467':'Lincolnshire Schools',
        '5f2609807a1c0000950bb45a':'LAUSD',
        '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
        '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
        '5fbcdf0ba84e48a64412a798':'Needham School District',
        '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
        '5f6994386451a9089d7d4009':'Ogden school district',
        '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
        '5fd704da04a848e368de5dc6':'Oakland Unified School District',
        '5f8fcd33609e08b76029f644':'Paradise Unified School District',
        '5f2609807a1c0000950bb466':'Pinellas County Schools',
        '5f2609807a1c0000950bb471':'Racine Unified Schools',
        '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
        '5f2609807a1c0000950bb478':'San Diego Unified School District',
        '5f2609807a1c0000950bb470':'San Leandro Unified School District',
        '5f2609807a1c0000950bb477':'Sarasota County',
        '5f2609807a1c0000950bb473':'Skillman Foundation',
        '5f2609807a1c0000950bb46a':'Springfield Public Schools',
        '5f2609807a1c0000950bb468':'Utah Board of Education',
        '5f698b826451a9089d7d4008':'Wayne Metro',
        '5f2609807a1c0000950bb45b':'Westfield Public School District',
        '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
        '5f2609807a1c0000950bb45d':'Youngstown',
    '5f2609807a1c0000950bb464':'Equity Education',
    '5f2609807a1c0000950bb469':'LSF -  Head Start',
    '5f2609807a1c0000950bb46e':'District 25 New York Schools',
    '5f2609807a1c0000950bb46f':'Paradise Schools',
    '5f2609807a1c0000950bb479':'Panorama Education',
    '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
    '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
    '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
    '5fe2e25d4d0ca68d7baf889d':'BGCA',
    '5fe318b14d0ca68d7baf889e':'BLUE',
    '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
    '6017ab3043ca9c39151838d4':'Oswego School District',
    '60239a84e57dc27613699d57':'Austin Independent School District',
    '6023a6d79e8e623753fc305c':'Boulder Valley School District',
    '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
    '6023a7269e8e623753fc305e':'Fulton County School System',
    '6023a7499e8e623753fc305f':'Manatee County School District',
    '6023a76f9e8e623753fc3060':'San Jose Unified School District',
    '6023a7949e8e623753fc3061':'Wasatch County School District',}
    district=disdic[districtid]
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.subscription_master
    query=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
                     {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {"schoolId._id":{"$in":db.school_master.distinct( "_id", 
                                                                       { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}      


                    ]}},          
              {'$group':{
                  '_id':'$schoolId._id',
                  'schoolname':{'$first':'$schoolId.NAME'},
                  'CITY':{'$first':'$schoolId.CITY'},
                  'STATE':{'$first':'$schoolId.STATE'},
                  'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                  'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                  'CREATED_DATE':{'$min':'$CREATED_DATE'},
                  'USER_COUNT':{'$addToSet':'$_id'}}},
              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'SCHOOL_NAME':'$schoolname',
                  'CITY':'$CITY',
                  'STATE':'$STATE',
                  'COUNTRY':'$COUNTRY',
                  'ROLE_ID':'$ROLE_ID',
                  'CREATED_DATE':'$CREATED_DATE',
                  'USER_COUNT':{'$size':'$USER_COUNT'}
                  }}]
    school_summary=list(collection.aggregate(query))
    school_summary_df=pd.DataFrame(school_summary)

    #admin summary info

    query2=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
          {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}
             ,{'IS_ADMIN':'Y'},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$schoolId._id',
                  'SCHOOL_NAME':'$schoolId.NAME',
                  'ADMIN_ID':'$_id',
                  'ADMIN_NAME':'$USER_NAME',
                  'ADMIN_EMAIL':'$EMAIL_ID',
                  'DISTRICT_ID':'$DISTRICT_ID._id',
                  'DISTRICT_NAME':'$DISTRICT_ID.DISTRICT_NAME',
                  'ROLE_ID':'$ROLE_ID.ROLE_ID',
                  'D_CATEGORY':'$D_CATEGORY'         
                  }}]
    admin_summary=list(collection.aggregate(query2))
    admin_summary_df=pd.DataFrame(admin_summary)
    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y',
                                                "schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}


                                                })
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)

    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y',
                                                "schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}


                                                })
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)

    #practice summary

    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                     {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}       
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_summary=list(collection3.aggregate(query5))
    school_prac_summary_df=pd.DataFrame(school_prac_summary)

    #csy practice summary

    query6=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
               {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}},
            {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}


              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User_CSY':{'$size':'$Active_User'},
                 'Last_Practice_Date_CSY':'$Last_Prac_Date',
                 'Practice_Sessions_CSY':'$Practice_Sessions',
                 'Mindful_Minutes_CSY':'$Mindful_Minutes'
                 }
                 }]
    school_prac_active_csy=list(collection3.aggregate(query6))
    school_prac_active_csy_df=pd.DataFrame(school_prac_active_csy)

    d1=school_summary_df.merge(admin_summary_df[['SCHOOL_ID', 'ADMIN_ID', 'ADMIN_NAME', 'ADMIN_EMAIL',
           'DISTRICT_ID', 'DISTRICT_NAME']],on='SCHOOL_ID',how='left')
    d2=d1.merge(admin_sm_summary_df,on='ADMIN_ID',how='left')
    d3=d2.merge(school_prac_summary_df,on='SCHOOL_ID',how='left')
    d4=d3.merge(school_prac_active_csy_df,on='SCHOOL_ID',how='left')
    d4[['Practice_Sessions',
           'Mindful_Minutes', 'Active_User',
           'Practice_Sessions_CSY', 'Mindful_Minutes_CSY','Active_User_CSY']]=d4[['Practice_Sessions',
           'Mindful_Minutes', 'Active_User',
           'Practice_Sessions_CSY', 'Mindful_Minutes_CSY','Active_User_CSY']].replace(np.nan, 0)
    d4[['Last_Practice_Date','Last_Practice_Date_CSY']]=d4[['Last_Practice_Date','Last_Practice_Date_CSY']].fillna('NO PRACTICE')
    d4['Renewal_Date']=d4['Renewal_Date'].fillna('NO')
    d5=d4.sort_values('Mindful_Minutes_CSY',ascending=False).reset_index(drop=True)

    created_date=d5['CREATED_DATE'].tolist()
    renewal_date=d5['Renewal_Date'].tolist()
    prac_date_overall=d5['Last_Practice_Date'].tolist()
    prac_date_C=d5['Last_Practice_Date_CSY'].tolist()



    created_date_1=[]
    renewal_date_1=[]
    prac_date_all=[]
    prac_date_CSY=[]




    for i in range(len(created_date)):
        if created_date[i]!='':
            created_date_1.append(created_date[i].strftime("%d %b %Y "))
        else:
            created_date_1.append('NO CREATED DATE')

        if renewal_date[i]!='NO RENEWAL DATE':
            renewal_date_1.append(renewal_date[i].strftime("%d %b %Y "))
        else:
            renewal_date_1.append('NO RENEWAL DATE')    

        if prac_date_overall[i]!='NO PRACTICE':
            prac_date_all.append(prac_date_overall[i].strftime("%d %b %Y "))
        else:
            prac_date_all.append('NO PRACTICE')        

        if prac_date_C[i]!='NO PRACTICE':
            prac_date_CSY.append(prac_date_C[i].strftime("%d %b %Y "))
        else:
            prac_date_CSY.append('NO PRACTICE')


    d5['CREATED_DATE']=created_date_1
    d5['Renewal_Date']=renewal_date_1
    d5['Last_Practice_Date']=prac_date_all
    d5['Last_Practice_Date_CSY']=prac_date_CSY

    mm_csy=d5.Mindful_Minutes_CSY.tolist()

    type=[]
    for i in range(len(mm_csy)):
        if mm_csy[i]==0:
            type.append('dormant')
        elif mm_csy[i]<=round(d4.Mindful_Minutes_CSY.mean()):
            type.append('below average')
        else:
            type.append('above average')

    d5['prac_Type']=type

    mm_overall=d5.Mindful_Minutes.tolist()

    type_overall=[]

    for i in range(len(mm_overall)):

        if mm_overall[i]==0:
            type_overall.append('dormant')
        elif mm_overall[i]<=round(d4.Mindful_Minutes.mean()):
            type_overall.append('below average')
        else:
            type_overall.append('above average')

    d5['prac_Type_overall']=type_overall
    d_final_overall=d5[d5['prac_Type_overall']==practice]
    data=[]
    for i,j,k,l,m,n,o,p,q,r,s,t in zip(
        d_final_overall.SCHOOL_NAME.tolist(),d_final_overall.CITY.tolist(),d_final_overall.STATE.tolist(),d_final_overall.CREATED_DATE.tolist(),
        d_final_overall.ADMIN_NAME.tolist(),d_final_overall.ADMIN_EMAIL.tolist(),d_final_overall.Renewal_Date.tolist(),
        d_final_overall.Last_Practice_Date.tolist(),d_final_overall.USER_COUNT.tolist(),d_final_overall.Active_User.tolist(),
        d_final_overall.Practice_Sessions.tolist(),d_final_overall.Mindful_Minutes.tolist()):
        data.append([i,j,k,l,m,n,o,p,q,r,s,t])

    return json.dumps({'temp':data})

@app.route('/mongospidercleschcard/<district>')
def MONGO_CLE_SCH_CARD():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('I#L@teST^m0NGO_2o20!')
    client = MongoClient("mongodb://%s:%s@54.184.165.106:27017/" % (username, password))
    db=client.compass
    #####################CLEVER#######################
    collection3 = db.user_master.aggregate([
    {"$match":{"schoolId":{"$exists":1}}},
    {"$match":
        {"$and":[ 
            {"_id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                {"DISTRICT_ID._id":ObjectId(""+district+"")},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME","USER_NAME":1,"CREATED_DATE":{"$dateToString": { "format": "%Y-%m-%d", "date":"$CREATED_DATE"}},
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME"}}
    ])
    dfclever= DataFrame(list(collection3)).fillna(0)
    if dfclever.empty == True:
        column_names1 = ["ID","USER_ID","school_name","USER_NAME","CREATED_DATE","email_id","district_name","count(last_logged_in)","practice_count12","role_type"]
        final1clever = pd.DataFrame(columns = column_names1)
    else:
        user_list1=dfclever["USER_ID"].tolist()
        collection4=db.login_logs.aggregate([{"$match":{"USER_ID._id":{
                            "$in":user_list1
                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$group":{"_id":"$USER_ID._id",
                "count":{"$first":"$LAST_LOGGED_IN"},
                }},
        {"$project":{"_id":0,"USER_ID":"$_id","count(last_logged_in)":{"$dateToString": { "format": "%Y-%m-%d", "date":"$count"}}}}
                ])
        dfcleverlog= DataFrame(list(collection4)).fillna(0)
        collection5 = db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list1
                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$match":
            {"$and":[
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":datetime.datetime(2019,7,31)}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
        {"$match":
        {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        {"$group":{"_id":{"USER_ID":"$USER_ID._id"},
                "NEW":{"$addToSet":"$USER_ID._id"},
                "count":{"$sum":1},
                "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
                }},
            {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","practice_count12":"$count"}}
        ])
        dfcleverprac= DataFrame(list(collection5)).fillna(0)
        collection9 = db.subscription_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list1
                        }    }},
            {'$group':{'_id':'$USER_ID._id','subsdate':{'$first':{"$dateToString": { "format": "%Y-%m-%d", "date":'$SUBSCRIPTION_EXPIRE_DATE'}}}}},
                {'$project':{'_id':0,"USER_ID":"$_id",'Subscription_expire_date':'$subsdate'}}
        ])
        dfcleversub= DataFrame(list(collection9)).fillna(0)
        finalclever=pd.merge(dfclever, dfcleverlog, on='USER_ID',how='left').fillna(0)
        final1clever=pd.merge(finalclever, dfcleverprac, on='USER_ID',how='left').fillna(0)
        final2clever=pd.merge(final1clever, dfcleversub, on='USER_ID',how='left').fillna(0)
        final2clever["role_type"]="CLEVER"
    ######################################################################################
    #####################schoology#######################
    collection6 = db.user_master.aggregate([
    {"$match":{"schoolId":{"$exists":1}}},
    {"$match":
        {"$and":[
            {"_id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                {"DISTRICT_ID._id":ObjectId(""+district+"")},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME","USER_NAME":1,"CREATED_DATE":{"$dateToString": { "format": "%Y-%m-%d", "date":"$CREATED_DATE"}},
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME"}}
    ])
    dfschoology= DataFrame(list(collection6)).fillna(0)
    if dfschoology.empty == True:
        column_names = ["ID","USER_ID","school_name","USER_NAME","CREATED_DATE","email_id","district_name","count(last_logged_in)","practice_count12","role_type"]
        final1schoology = pd.DataFrame(columns = column_names)
    else:
        user_list2=dfschoology["USER_ID"].tolist()
        collection7=db.login_logs.aggregate([{"$match":{"USER_ID._id":{
                            "$in":user_list2
                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$group":{"_id":"$USER_ID._id",
                "count":{"$first":"$LAST_LOGGED_IN"},
                }},
        {"$project":{"_id":0,"USER_ID":"$_id","count(last_logged_in)":{"$dateToString": { "format": "%Y-%m-%d", "date":"$count"}}}}
                ])
        dfschoologylog= DataFrame(list(collection7)).fillna(0)
        collection8 = db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list2
                        }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$match":
            {"$and":[
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":datetime.datetime(2019,7,31)}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
        {"$match":
        {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        {"$group":{"_id":{"USER_ID":"$USER_ID._id"},
                "NEW":{"$addToSet":"$USER_ID._id"},
                "count":{"$sum":1},
                "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
                }},
            {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","practice_count12":"$count"}}
        ])
        collection10 = db.subscription_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list2
                        }    }},
            {'$group':{'_id':'$USER_ID._id','subsdate':{'$first':{"$dateToString": { "format": "%Y-%m-%d", "date":'$SUBSCRIPTION_EXPIRE_DATE'}}}}},
                {'$project':{'_id':0,"USER_ID":"$_id",'Subscription_expire_date':'$subsdate'}}
        ])
        dfschoologysub= DataFrame(list(collection10)).fillna(0)
        dfschoologyprac= DataFrame(list(collection8)).fillna(0)
        finalschoology=pd.merge(dfschoology, dfschoologylog, on='USER_ID',how='left').fillna(0)
        final1schoology=pd.merge(finalschoology, dfschoologyprac, on='USER_ID',how='left').fillna(0)
        final2schoology=pd.merge(final1schoology,dfschoologysub, on='USER_ID',how='left').fillna(0)
        final2schoology["role_type"]="SCHOOLOGY"
    ######################################################################################
    final3 = pd.concat([final2clever, final1schoology], ignore_index=True, sort=False)
    df=final3[["ID","USER_ID","school_name","USER_NAME","CREATED_DATE","email_id","district_name","count(last_logged_in)","practice_count12",'Subscription_expire_date',"role_type"]]
    dftable=df[["USER_NAME","email_id","school_name","CREATED_DATE","count(last_logged_in)",'Subscription_expire_date',"practice_count12","role_type"]]
    temp={"data":dftable.values.tolist()}
    return json.dumps(temp)

#<<<<<<<<<<<<<<<<<<<<-------------------------------CSY_TABLE_DDT-------------------------->>>>>>>>>>>>>>>>>>>>>>

@app.route('/districtddtCSYtable/<districtid>/<practype>')
def ddt_CSY_table(districtid,practype):    
    practice=str(practype).lower()    
    disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
        '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
        '5f2609807a1c0000950bb475':'Agawam School district',
        '5f2609807a1c0000950bb481':'Alameda Unified School District',
        '5f2609807a1c0000950bb47a':'Alpine School District',
        '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
        '5f2609807a1c0000950bb463':'Austin Independent School District',
        '5f59e4836451a9089d7d4007':'Belleville School District',
        '5f2609807a1c0000950bb46d':'Broward County Public Schools',
        '5f2609807a1c0000950bb46c':'Chico Unified School District',
        '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
        '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
        '5f2609807a1c0000950bb45c':'Comox Valley School District(sd71)',
        '5f2609807a1c0000950bb480':'Dell Texas',
        '5f7413ef9387fd71ce6387cb':'Douglas County School District',
        '5f895191609e08b76029f641':'Early learning Sarasota',
        '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
        '5f2609807a1c0000950bb461':'Englewood Public School District',
        '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
        '5f2609807a1c0000950bb47d':'Flint Public Schools',
        '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
        '5f2609807a1c0000950bb450':'Goleta District',
        '5f2609807a1c0000950bb474':'Greenburgh-North Castle (GNC) Union Free School District',
        '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
        '5f2609807a1c0000950bb476':'Hillsborough County',
        '5f2609807a1c0000950bb455':'Krum Independent School District',
        '5f2609807a1c0000950bb47e':'La Joya School District',
        '5f2609807a1c0000950bb467':'Lincolnshire Schools',
        '5f2609807a1c0000950bb45a':'LAUSD',
        '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
        '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
        '5fbcdf0ba84e48a64412a798':'Needham School District',
        '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
        '5f6994386451a9089d7d4009':'Ogden school district',
        '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
        '5fd704da04a848e368de5dc6':'Oakland Unified School District',
        '5f8fcd33609e08b76029f644':'Paradise Unified School District',
        '5f2609807a1c0000950bb466':'Pinellas County Schools',
        '5f2609807a1c0000950bb471':'Racine Unified Schools',
        '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
        '5f2609807a1c0000950bb478':'San Diego Unified School District',
        '5f2609807a1c0000950bb470':'San Leandro Unified School District',
        '5f2609807a1c0000950bb477':'Sarasota County',
        '5f2609807a1c0000950bb473':'Skillman Foundation',
        '5f2609807a1c0000950bb46a':'Springfield Public Schools',
        '5f2609807a1c0000950bb468':'Utah Board of Education',
        '5f698b826451a9089d7d4008':'Wayne Metro',
        '5f2609807a1c0000950bb45b':'Westfield Public School District',
        '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
        '5f2609807a1c0000950bb45d':'Youngstown',
    '5f2609807a1c0000950bb464':'Equity Education',
    '5f2609807a1c0000950bb469':'LSF -  Head Start',
    '5f2609807a1c0000950bb46e':'District 25 New York Schools',
    '5f2609807a1c0000950bb46f':'Paradise Schools',
    '5f2609807a1c0000950bb479':'Panorama Education',
    '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
    '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
    '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
    '5fe2e25d4d0ca68d7baf889d':'BGCA',
    '5fe318b14d0ca68d7baf889e':'BLUE',
    '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
    '6017ab3043ca9c39151838d4':'Oswego School District',
    '60239a84e57dc27613699d57':'Austin Independent School District',
    '6023a6d79e8e623753fc305c':'Boulder Valley School District',
    '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
    '6023a7269e8e623753fc305e':'Fulton County School System',
    '6023a7499e8e623753fc305f':'Manatee County School District',
    '6023a76f9e8e623753fc3060':'San Jose Unified School District',
    '6023a7949e8e623753fc3061':'Wasatch County School District',}
    district=disdic[districtid]
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    collection2 = db.subscription_master
    query=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
                     {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {"schoolId._id":{"$in":db.school_master.distinct( "_id", 
                                                                       { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}      


                    ]}},          
              {'$group':{
                  '_id':'$schoolId._id',
                  'schoolname':{'$first':'$schoolId.NAME'},
                  'CITY':{'$first':'$schoolId.CITY'},
                  'STATE':{'$first':'$schoolId.STATE'},
                  'COUNTRY':{'$first':'$schoolId.COUNTRY'},
                  'ROLE_ID':{'$min':'$ROLE_ID.ROLE_ID'},
                  'CREATED_DATE':{'$min':'$CREATED_DATE'},
                  'USER_COUNT':{'$addToSet':'$_id'}}},
              {'$project':{'_id':0,
                  'SCHOOL_ID':'$_id',
                  'SCHOOL_NAME':'$schoolname',
                  'CITY':'$CITY',
                  'STATE':'$STATE',
                  'COUNTRY':'$COUNTRY',
                  'ROLE_ID':'$ROLE_ID',
                  'CREATED_DATE':'$CREATED_DATE',
                  'USER_COUNT':{'$size':'$USER_COUNT'}
                  }}]
    school_summary=list(collection.aggregate(query))
    school_summary_df=pd.DataFrame(school_summary)

    #admin summary info

    query2=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
          {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}
             ,{'IS_ADMIN':'Y'},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}}]}},          

              {'$project':{'_id':0,
                  'SCHOOL_ID':'$schoolId._id',
                  'SCHOOL_NAME':'$schoolId.NAME',
                  'ADMIN_ID':'$_id',
                  'ADMIN_NAME':'$USER_NAME',
                  'ADMIN_EMAIL':'$EMAIL_ID',
                  'DISTRICT_ID':'$DISTRICT_ID._id',
                  'DISTRICT_NAME':'$DISTRICT_ID.DISTRICT_NAME',
                  'ROLE_ID':'$ROLE_ID.ROLE_ID',
                  'D_CATEGORY':'$D_CATEGORY'         
                  }}]
    admin_summary=list(collection.aggregate(query2))
    admin_summary_df=pd.DataFrame(admin_summary)
    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y',
                                                "schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}


                                                })
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)

    #admin_Subscription_master summary
    query4=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'USER_ID._id':{'$in':
                  db.user_master.distinct('_id',{'IS_ADMIN':'Y',
                                                "schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}


                                                })
                  }}
              ]}},
              {'$group':{
                  '_id':'$USER_ID._id',
                  'Renewal_Date':{'$max':'$SUBSCRIPTION_EXPIRE_DATE'},
                  'PLAN_ID':{'$max':'$PLAN_ID.PLAN_ID'},
                  'PLAN_NAME':{'$first':'$PLAN_ID.PLAN_NAME'}
                  }},
                  {'$project':{'_id':0,
                      'ADMIN_ID':'$_id',
                      'Renewal_Date':'$Renewal_Date',
                      'PLAN_ID':'$PLAN_ID',
                      'PLAN_NAME':'$PLAN_NAME'
                      }}]
    admin_sm_summary=list(collection2.aggregate(query4))
    admin_sm_summary_df=pd.DataFrame(admin_sm_summary)

    #practice summary

    collection3 = db.audio_track_master
    query5=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                     {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}       
              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User':{'$size':'$Active_User'},
                 'Last_Practice_Date':'$Last_Prac_Date',
                 'Practice_Sessions':'$Practice_Sessions',
                 'Mindful_Minutes':'$Mindful_Minutes'
                 }
                 }]
    school_prac_summary=list(collection3.aggregate(query5))
    school_prac_summary_df=pd.DataFrame(school_prac_summary)

    #csy practice summary

    query6=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
               {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}},
            {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id",
                                                             { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}}


              ]}},

              {'$group':{
                  '_id':'$USER_ID.schoolId._id',
                  'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                  'Active_User':{'$addToSet':'$USER_ID._id'},
                  'Practice_Sessions':{'$sum':1},
                  'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':
                          ['$CURSOR_END','$cursorStart']},60]},0]}}  
                  }},

             {'$project':{'_id':0,
                 'SCHOOL_ID':'$_id',
                 'Active_User_CSY':{'$size':'$Active_User'},
                 'Last_Practice_Date_CSY':'$Last_Prac_Date',
                 'Practice_Sessions_CSY':'$Practice_Sessions',
                 'Mindful_Minutes_CSY':'$Mindful_Minutes'
                 }
                 }]
    school_prac_active_csy=list(collection3.aggregate(query6))
    school_prac_active_csy_df=pd.DataFrame(school_prac_active_csy)

    d1=school_summary_df.merge(admin_summary_df[['SCHOOL_ID', 'ADMIN_ID', 'ADMIN_NAME', 'ADMIN_EMAIL',
           'DISTRICT_ID', 'DISTRICT_NAME']],on='SCHOOL_ID',how='left')
    d2=d1.merge(admin_sm_summary_df,on='ADMIN_ID',how='left')
    d3=d2.merge(school_prac_summary_df,on='SCHOOL_ID',how='left')
    d4=d3.merge(school_prac_active_csy_df,on='SCHOOL_ID',how='left')
    d4[['Practice_Sessions',
           'Mindful_Minutes', 'Active_User',
           'Practice_Sessions_CSY', 'Mindful_Minutes_CSY','Active_User_CSY']]=d4[['Practice_Sessions',
           'Mindful_Minutes', 'Active_User',
           'Practice_Sessions_CSY', 'Mindful_Minutes_CSY','Active_User_CSY']].replace(np.nan, 0)
    d4[['Last_Practice_Date','Last_Practice_Date_CSY']]=d4[['Last_Practice_Date','Last_Practice_Date_CSY']].fillna('NO PRACTICE')
    d4['Renewal_Date']=d4['Renewal_Date'].fillna('NO')
    d5=d4.sort_values('Mindful_Minutes_CSY',ascending=False).reset_index(drop=True)

    created_date=d5['CREATED_DATE'].tolist()
    renewal_date=d5['Renewal_Date'].tolist()
    prac_date_overall=d5['Last_Practice_Date'].tolist()
    prac_date_C=d5['Last_Practice_Date_CSY'].tolist()



    created_date_1=[]
    renewal_date_1=[]
    prac_date_all=[]
    prac_date_CSY=[]




    for i in range(len(created_date)):
        if created_date[i]!='':
            created_date_1.append(created_date[i].strftime("%d %b %Y "))
        else:
            created_date_1.append('NO CREATED DATE')

        if renewal_date[i]!='NO RENEWAL DATE':
            renewal_date_1.append(renewal_date[i].strftime("%d %b %Y "))
        else:
            renewal_date_1.append('NO RENEWAL DATE')    

        if prac_date_overall[i]!='NO PRACTICE':
            prac_date_all.append(prac_date_overall[i].strftime("%d %b %Y "))
        else:
            prac_date_all.append('NO PRACTICE')        

        if prac_date_C[i]!='NO PRACTICE':
            prac_date_CSY.append(prac_date_C[i].strftime("%d %b %Y "))
        else:
            prac_date_CSY.append('NO PRACTICE')


    d5['CREATED_DATE']=created_date_1
    d5['Renewal_Date']=renewal_date_1
    d5['Last_Practice_Date']=prac_date_all
    d5['Last_Practice_Date_CSY']=prac_date_CSY

    mm_csy=d5.Mindful_Minutes_CSY.tolist()

    type=[]
    for i in range(len(mm_csy)):
        if mm_csy[i]==0:
            type.append('dormant')
        elif mm_csy[i]<=round(d4.Mindful_Minutes_CSY.mean()):
            type.append('below average')
        else:
            type.append('above average')

    d5['prac_Type']=type

    mm_overall=d5.Mindful_Minutes.tolist()

    type_overall=[]

    for i in range(len(mm_overall)):

        if mm_overall[i]==0:
            type_overall.append('dormant')
        elif mm_overall[i]<=round(d4.Mindful_Minutes.mean()):
            type_overall.append('below average')
        else:
            type_overall.append('above average')

    d5['prac_Type_overall']=type_overall
    d_final_overall=d5[d5['prac_Type']==practice]
    data=[]
    for i,j,k,l,m,n,o,p,q,r,s,t in zip(
        d_final_overall.SCHOOL_NAME.tolist(),d_final_overall.CITY.tolist(),d_final_overall.STATE.tolist(),d_final_overall.CREATED_DATE.tolist(),
        d_final_overall.ADMIN_NAME.tolist(),d_final_overall.ADMIN_EMAIL.tolist(),d_final_overall.Renewal_Date.tolist(),
        d_final_overall.Last_Practice_Date.tolist(),d_final_overall.USER_COUNT.tolist(),d_final_overall.Active_User.tolist(),
        d_final_overall.Practice_Sessions.tolist(),d_final_overall.Mindful_Minutes.tolist()):
        data.append([i,j,k,l,m,n,o,p,q,r,s,t])

    return json.dumps({'temp':data})

@app.route('/questtimeseriestable')
def questtimeseriestable():
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.user_master.aggregate([
    {"$match":
        {"$and":[ 
           {"IS_QUEST_OBTAINED":"Y"},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'QUEST_OBTAINED_DATE':{'$gte':datetime.datetime(2021,8,1)}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"_id":0,"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME","USER_NAME":1,"CREATED_DATE":{"$dateToString": { "format": "%Y-%m-%d", "date":"$CREATED_DATE"}},
                "email_id":"$EMAIL_ID"}}

    ])
    df= DataFrame(list(collection)).fillna(0)
    userids=df["USER_ID"].tolist()
    database = client["compass"]
    collection = database["user_master"]
    query = {}
    query["_id"] = {
        u"$in": userids}
    query["USER_NAME"] = {
        u"$not": Regex(u".*TEST.*", "i")
    }
    query["IS_DISABLED"] = {
        u"$ne": u"Y"
    }

    query["INCOMPLETE_SIGNUP"] = {
        u"$ne": u"Y"
    }



    projection = {}
    projection["USER_ID.USER_ID"] = 1.0
    projection["EMAIL_ID"] = 1.0
    projection["CREATED_DATE"] = 1.0

    projection["USER_NAME"] = 1.0

    projection["schoolId.ADDRESS"] = 1.0
    projection["schoolId.CITY"] = 1.0
    projection["schoolId.STATE"] = 1.0
    projection["schoolId.COUNTRY"] = 1.0
    projection["schoolId.NAME"] = 1.0

    cursor = collection.find(query, projection = projection)
    dfum=(list(cursor))
    dfum=pd.json_normalize(dfum, max_level=1)
    # print(dfum,"usermaster")
    email=list(dfum['EMAIL_ID'])
    totaluser=len(email)
    collection = database["audio_track_master"]
    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(MODIFIED_DATE)": {
                    u"$max": u"$MODIFIED_DATE"
                },
                u"COUNT(USER_ID\u1390_id)": {
                    u"$sum": 1
                }
            }
        }, 
        {
            u"$project": {
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"MAX(MODIFIED_DATE)": u"$MAX(MODIFIED_DATE)",
                u"COUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfatd=list(cursor)
    dfatd=pd.json_normalize(dfatd, max_level=1)
    #     print(dfatd)
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {
            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfsbm=list(cursor)
    dfsbm=pd.json_normalize(dfsbm, max_level=1)
    #     print(dfatd,"atd pracice data")

    try:
        dffinal=pd.merge(dfum,dfatd,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
    except:
        dfum['MAX(MODIFIED_DATE)']='NO PRACTICE'
        dfum['COUNT(USER_ID᎐_id)']=0
        dffinal=dfum
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))


    email=list(dfum['EMAIL_ID'])
    totaluser=len(email)
    dffinalnew['MAX(MODIFIED_DATE)'].fillna("NO PRACTICE", inplace=True)
    dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)'].fillna(" ", inplace=True)
    dffinalnew['COUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
    #     pracsum=sum(list(dffinalnew['COUNT(USER_ID᎐_id)']))
    dffinalnew.fillna(value=pd.np.nan, inplace=True)
    #     print(dffinalnew)
    schname=["NO SCHOOL INFO"]
    try:
        schname=dffinalnew["schoolId.NAME"].tolist()
    except:
        schname=["NO SCHOOL INFO"]


    MAX=[]
    for i in dffinalnew['MAX(MODIFIED_DATE)']:
        if  i != 'NO PRACTICE' :
            MAX.append(i.strftime("%d %b %Y "))
        else:
            MAX.append("NO PRACTICE")
    SUBSCRIPTION_EXPIRE_DATE=[]
    for i in dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)']:
        if  i != ' ' :
            SUBSCRIPTION_EXPIRE_DATE.append(i.strftime("%d %b %Y "))
        else:
            SUBSCRIPTION_EXPIRE_DATE.append(" ")        
    CREATED_DATE=[]
    for i in dffinalnew['CREATED_DATE']:
        if  i != ' ' :
            CREATED_DATE.append(i.strftime("%d %b %Y "))
        else:
            CREATED_DATE.append(" ")
    data=[]

    for Z,T,k,l,m,o,p in zip(schname,dffinalnew['USER_NAME'].tolist(),dffinalnew['EMAIL_ID'].tolist(),CREATED_DATE,MAX,SUBSCRIPTION_EXPIRE_DATE,dffinalnew['COUNT(USER_ID᎐_id)'].tolist()):
        #print(p,q,r)
        data.append([Z,T,k,l,m,o,p])
    temp={"data":data}
    return json.dumps(temp)

@app.route('/heatmap_activation_streak')
def quest_activation_heatmap():
    from collections import OrderedDict
    QUEST_OBTAINED_USER=pd.DataFrame(list(db_live.user_master.aggregate([{"$match":{
        '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}},
        {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
        {'IS_QUEST_OBTAINED':'Y'}
        ]}},

        {'$project':{
            '_id':0,
            'USER_ID':'$_id',
            'QUEST_OBTAIN_DATE':'$QUEST_OBTAINED_DATE'
            }}
        ])))

    QUEST_OBTAINED_USER=QUEST_OBTAINED_USER[QUEST_OBTAINED_USER['QUEST_OBTAIN_DATE'].notnull()].reset_index(drop=True)
    quest_history=pd.DataFrame(list(db_live.user_quest_history.aggregate([{"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
                                        {'$project':{
                                            '_id':0,
                                            'USER_ID':'$USER_ID._id',                                         
                                            'QUEST_OBTAIN_DATE':'$QUEST_OBT_IN_DATE'
                                                                                }}
                                        ])))
    def date_to_string(dates):
        date_=dates.strftime('%Y-%m-%d')
        return date_
    def quest_last_day(dates):
        last_date=(dates+relativedelta(days=41)).strftime("%Y-%m-%d")
        return last_date
    QUEST_OBTAINED_USER['QUEST_START_DAY']=QUEST_OBTAINED_USER['QUEST_OBTAIN_DATE'].apply(date_to_string)
    QUEST_OBTAINED_USER['QUEST_FINISH_DAY']=QUEST_OBTAINED_USER['QUEST_OBTAIN_DATE'].apply(quest_last_day)
    quest_history['QUEST_START_DAY']=quest_history['QUEST_OBTAIN_DATE'].apply(date_to_string)
    quest_history['QUEST_FINISH_DAY']=quest_history['QUEST_OBTAIN_DATE'].apply(quest_last_day)    
    qh_no_entry=list(set(QUEST_OBTAINED_USER['USER_ID'])-set(quest_history['USER_ID']))
    quest_data=pd.concat([QUEST_OBTAINED_USER,quest_history],ignore_index=True)
    quest_data_final=quest_data.drop_duplicates(subset=['USER_ID','QUEST_START_DAY'],keep='first').reset_index(drop=True)
    qh_um=pd.DataFrame(list(db_live.user_master.aggregate([{'$match':{'$and':[
        {'_id':{'$in':list(quest_data_final['USER_ID'])}}
        ]}},{'$project':{'_id':0,
                        'USER_ID':'$_id',
                        'USER_NAME':'$USER_NAME',
                        'EMAIL_ID':'$EMAIL_ID',
                        'SCHOOL_ID':'$schoolId._id',
                        'SCHOOL_NAME':'$schoolId.NAME',
                        'CHANNEL':'$UTM_MEDIUM',
                        'SIGNUP':'$CREATED_DATE'
                        }}])))
    quest_history_data_new_final=quest_data_final.merge(qh_um,how='left',on='USER_ID')
    quest_history_data_new_final=quest_history_data_new_final[quest_history_data_new_final['SIGNUP'].notnull()].reset_index(drop=True)
    quest_history_data_new_final=quest_history_data_new_final[pd.to_datetime(quest_history_data_new_final['QUEST_START_DAY'])>pd.to_datetime(csy_first_date())].reset_index(drop=True)
    df=quest_history_data_new_final.copy()
#     to make python and mongodb week of the day same
    df['DM']=[pd.to_datetime(i).weekday()+2 for i in df['QUEST_START_DAY']]
    df.loc[df['DM']==8,'DM']=1
    df['month_']=[pd.to_datetime(i).month for i in df['QUEST_START_DAY']]
# logic for current school year data
    month=[]
    for i in range(len(df)):        
        if df['month_'][i]>7:            
            month.append(df['month_'][i]-7)
        else:
            month.append(df['month_'][i]+5)
    df['month']=month

    df=df.groupby(['DM','month'])['USER_ID'].count().reset_index().rename(columns={'USER_ID':'pc'})
    df=df.sort_values(by=['DM','month']).reset_index(drop=True)

    dislist=list(set(df["DM"]))
    # #   
    df1=df[["DM","month","pc"]]
    # # print(df2)
    overall=pd.DataFrame(columns=["DM","month","pc"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df[df["DM"]==k]
        df45.reset_index()
    #     print(df45)

        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]
    #         print(df45)
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        df2 = pd.concat(result)
    #     print(df2)

    #     finaldf=finaldf.sort_values(by=['name'])
    SUN= df2[(df2.DM == 1)].reset_index(drop = True)
    SUN = SUN['pc'].tolist()
    MON= df2[(df2.DM == 2)].reset_index(drop = True)
    MON = MON['pc'].tolist()
    TUE= df2[(df2.DM == 3)].reset_index(drop = True)
    TUE = TUE['pc'].tolist()
    WED= df2[(df2.DM == 4)].reset_index(drop = True)
    WED = WED['pc'].tolist()
    THU= df2[(df2.DM == 5)].reset_index(drop = True)
    THU = THU['pc'].tolist()
    FRI= df2[(df2.DM == 6)].reset_index(drop = True)
    FRI = FRI['pc'].tolist()
    SAT= df2[(df2.DM == 7)].reset_index(drop = True)
    SAT = SAT['pc'].tolist()
    data = {
               'SUNDAY':SUN,'MONDAY':MON,
               'TUESDAY':TUE,'WEDNESDAY':WED,
               'THURSDAY':THU,'FRIDAY':FRI,
               'SATURDAY':SAT}
    # #     print(data)
    dataframe=pd.DataFrame.from_dict(data,orient='index')
    #     print(dataframe)
    DF=list(dataframe.sum(axis=0))

    DF = pd.Series(DF, index = dataframe.columns)
    DF = dataframe.append(DF, ignore_index=True)
    # df=dataframe.append(DF,orient='index')
#     DF.columns =['JAN', 'FEB', 'MAR','APR','MAY','JUN','JUL','AUG','SEP','OCT','NOV','DEC']
    DF.columns =['AUG','SEP','OCT','NOV','DEC','JAN', 'FEB', 'MAR','APR','MAY','JUN','JUL']
    DF.index=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL']
    DF=DF.T
    for label, row in DF.iterrows():
        DF.loc[label,'SUN'] = row['SUNDAY']/row['TOTAL'] * 100
        DF.loc[label,'MON'] = row['MONDAY']/row['TOTAL'] * 100
        DF.loc[label,'TUE'] = row['TUESDAY']/row['TOTAL'] * 100
        DF.loc[label,'WED'] = row['WEDNESDAY']/row['TOTAL'] * 100
        DF.loc[label,'THU'] = row['THURSDAY']/row['TOTAL'] * 100
        DF.loc[label,'FRI'] = row['FRIDAY']/row['TOTAL'] * 100
        DF.loc[label,'SAT'] = row['SATURDAY']/row['TOTAL'] * 100

    DF = DF.drop(['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY','TOTAL'], axis=1)
    DF=DF.T
    DF=DF.round()
    DF=DF.fillna(0)
    day=DF.values.tolist()
    key=['SUNDAY','MONDAY','TUESDAY','WEDNESDAY','THURSDAY','FRIDAY','SATURDAY']
    data={'meanTemp':{key[0]:day[0],key[1]:day[1],key[2]:day[2],key[3]:day[3],key[4]:day[4],key[5]:day[5],key[6]:day[6]}}
    return json.dumps(data,sort_keys=False)


@app.route('/queststreaktable/<num>')
def queststreaktable(num):
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.user_master.aggregate([
    {"$match":
        {"$and":[ 
           {"IS_QUEST_OBTAINED":"Y"},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"_id":0,"USER_ID":"$_id",
                "QUEST_OBTAINED_DATE":{"$dateToString": { "format": "%Y-%m-%d", "date": "$QUEST_OBTAINED_DATE"}}}}

    ])
    df= DataFrame(list(collection)).fillna(0)
    user_list=df["USER_ID"].tolist()
    collection1 =db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list

                        }}},
        {"$match":
            {"$and":[
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":datetime.datetime(2021,1,14)}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
        {"$match":
        {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        {"$group":{"_id":{"USER_ID":"$USER_ID._id",'MODIFIED_DATE':'$MODIFIED_DATE'},
                "NEW":{"$addToSet":"$USER_ID._id"},
                "count":{"$sum":1},
                "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
                }},
            {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","MODIFIED_DATE":{ "$dateToString": { "format": "%Y-%m-%d", "date":"$_id.MODIFIED_DATE"}},"practice_count12":"$count"}}

        ])
    df1= DataFrame(list(collection1)).fillna(0)
    df3=pd.merge(df, df1, on='USER_ID',how='right').fillna(0)
    df3.loc[(df3['MODIFIED_DATE'] >= df3['QUEST_OBTAINED_DATE']) & (df3['USER_ID'] == df3['USER_ID']), 'hex'] = '#00a651'  #ACTIVE
    df3.drop(df3[df3['hex'] != "#00a651"].index, inplace = True) 
    df4=df3.groupby(["USER_ID","MODIFIED_DATE"])["practice_count12"].count().reset_index()
    df4['Dates'] = pd.to_datetime(df4["MODIFIED_DATE"]).dt.day
    df4['MODIFIED_DATE'] = pd.to_datetime(df4["MODIFIED_DATE"])
    s = df4.groupby('USER_ID').MODIFIED_DATE.diff().dt.days.ne(1).cumsum()
    df5=df4.groupby(['USER_ID', s]).size().reset_index(level=1, drop=True)
    streak=df5.reset_index()
    streak.columns=["USER_ID","STREAK"]
    user_streak=streak.groupby(["USER_ID"])["STREAK"].max().reset_index()
    user_streak['STREAK'] = user_streak['STREAK'].apply(str)
    user= user_streak[user_streak.STREAK.str.contains(""+num+"",case=False)] 
    userids=user["USER_ID"].tolist()
    database = client["compass"]
    collection = database["user_master"]
    query = {}
    query["_id"] = {
        u"$in": userids}
    query["USER_NAME"] = {
        u"$not": Regex(u".*TEST.*", "i")
    }
    query["IS_DISABLED"] = {
        u"$ne": u"Y"
    }

    query["INCOMPLETE_SIGNUP"] = {
        u"$ne": u"Y"
    }



    projection = {}
    projection["USER_ID.USER_ID"] = 1.0
    projection["EMAIL_ID"] = 1.0
    projection["CREATED_DATE"] = 1.0

    projection["USER_NAME"] = 1.0

    projection["schoolId.ADDRESS"] = 1.0
    projection["schoolId.CITY"] = 1.0
    projection["schoolId.STATE"] = 1.0
    projection["schoolId.COUNTRY"] = 1.0
    projection["schoolId.NAME"] = 1.0

    cursor = collection.find(query, projection = projection)
    dfum=(list(cursor))
    dfum=pd.json_normalize(dfum, max_level=1)
    # print(dfum,"usermaster")
    email=list(dfum['EMAIL_ID'])
    totaluser=len(email)
    collection = database["audio_track_master"]
    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(MODIFIED_DATE)": {
                    u"$max": u"$MODIFIED_DATE"
                },
                u"COUNT(USER_ID\u1390_id)": {
                    u"$sum": 1
                }
            }
        }, 
        {
            u"$project": {
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"MAX(MODIFIED_DATE)": u"$MAX(MODIFIED_DATE)",
                u"COUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfatd=list(cursor)
    dfatd=pd.json_normalize(dfatd, max_level=1)
    #     print(dfatd)
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {
            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfsbm=list(cursor)
    dfsbm=pd.json_normalize(dfsbm, max_level=1)
    #     print(dfatd,"atd pracice data")

    try:
        dffinal=pd.merge(dfum,dfatd,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
    except:
        dfum['MAX(MODIFIED_DATE)']='NO PRACTICE'
        dfum['COUNT(USER_ID᎐_id)']=0
        dffinal=dfum
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))


    email=list(dfum['EMAIL_ID'])
    totaluser=len(email)
    dffinalnew['MAX(MODIFIED_DATE)'].fillna("NO PRACTICE", inplace=True)
    dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)'].fillna(" ", inplace=True)
    dffinalnew['COUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
    #     pracsum=sum(list(dffinalnew['COUNT(USER_ID᎐_id)']))
    dffinalnew.fillna(value=pd.np.nan, inplace=True)
    #     print(dffinalnew)
    schname=["NO SCHOOL INFO"]
    try:
        schname=dffinalnew["schoolId.NAME"].tolist()
    except:
        schname=["NO SCHOOL INFO"]


    MAX=[]
    for i in dffinalnew['MAX(MODIFIED_DATE)']:
        if  i != 'NO PRACTICE' :
            MAX.append(i.strftime("%d %b %Y "))
        else:
            MAX.append("NO PRACTICE")
    SUBSCRIPTION_EXPIRE_DATE=[]
    for i in dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)']:
        if  i != ' ' :
            SUBSCRIPTION_EXPIRE_DATE.append(i.strftime("%d %b %Y "))
        else:
            SUBSCRIPTION_EXPIRE_DATE.append(" ")        
    CREATED_DATE=[]
    for i in dffinalnew['CREATED_DATE']:
        if  i != ' ' :
            CREATED_DATE.append(i.strftime("%d %b %Y "))
        else:
            CREATED_DATE.append(" ")
    data=[]

    for Z,T,k,l,m,o,p in zip(schname,dffinalnew['USER_NAME'].tolist(),dffinalnew['EMAIL_ID'].tolist(),CREATED_DATE,MAX,SUBSCRIPTION_EXPIRE_DATE,dffinalnew['COUNT(USER_ID᎐_id)'].tolist()):
        #print(p,q,r)
        data.append([Z,T,k,l,m,o,p])
    temp={"data":data}
    return json.dumps(temp)

@app.route('/questactivestreaktable/<num>')
def questactivestreaktable(num):
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.user_master.aggregate([
    {"$match":
        {"$and":[ 
           {"IS_QUEST_OBTAINED":"Y"},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"_id":0,"USER_ID":"$_id",

                "QUEST_OBTAINED_DATE":{"$dateToString": { "format": "%Y-%m-%d", "date": "$QUEST_OBTAINED_DATE"}}}}

    ])
    df= DataFrame(list(collection)).fillna(0)
    user_list=df["USER_ID"].tolist()
    collection1 =db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                            "$in":user_list

                        }}},
        {"$match":
            {"$and":[
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'MODIFIED_DATE':{"$gt":datetime.datetime(2021,1,14)}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
        {"$match":
        {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        {"$group":{"_id":{"USER_ID":"$USER_ID._id",'MODIFIED_DATE':'$MODIFIED_DATE'},
                "NEW":{"$addToSet":"$USER_ID._id"},
                "count":{"$sum":1},
                "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
                }},
            {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","MODIFIED_DATE":{ "$dateToString": { "format": "%Y-%m-%d", "date":"$_id.MODIFIED_DATE"}},"practice_count12":"$count"}}

        ])
    df1= DataFrame(list(collection1)).fillna(0)
    df3=pd.merge(df, df1, on='USER_ID',how='right').fillna(0)
    df3.loc[(df3['MODIFIED_DATE'] >= df3['QUEST_OBTAINED_DATE']) & (df3['USER_ID'] == df3['USER_ID']), 'hex'] = '#00a651'  #ACTIVE
    df3.drop(df3[df3['hex'] != "#00a651"].index, inplace = True) 
    df4=df3.groupby(["USER_ID","MODIFIED_DATE"])["practice_count12"].count().reset_index()
    df4['Dates'] = pd.to_datetime(df4["MODIFIED_DATE"]).dt.day
    df4['MODIFIED_DATE'] = pd.to_datetime(df4["MODIFIED_DATE"])
    s = df4.groupby('USER_ID').MODIFIED_DATE.diff().dt.days.ne(1).cumsum()
    df5=df4.groupby(['USER_ID', s]).size().reset_index(level=1, drop=True)
    streak=df5.reset_index()
    streak.columns=["USER_ID","STREAK"]
    user_streak=streak.groupby(["USER_ID"])["STREAK"].max().reset_index()
    #################################Time_Diffrence#############################
    df3T=pd.merge(df, df1, on='USER_ID',how='right').fillna(0)
    df3T.loc[(df3T['MODIFIED_DATE'] == df3T['QUEST_OBTAINED_DATE']) & (df3T['USER_ID'] == df3T['USER_ID']), 'hex'] = '#00a651'  #ACTIVE
    df3T.drop(df3T[df3T['hex'] != "#00a651"].index, inplace = True) 
    df4T=df3T.groupby(["USER_ID","MODIFIED_DATE"])["practice_count12"].count().reset_index()
    df4T['Dates'] = pd.to_datetime(df4T["MODIFIED_DATE"]).dt.day
    df4T['MODIFIED_DATE'] = pd.to_datetime(df4T["MODIFIED_DATE"])
    df4T['Time_diff']= pd.to_datetime(df4T["MODIFIED_DATE"], errors='coerce') - pd.Timestamp.now().normalize()
    df4T['Time_diff']=df4T['Time_diff'].dt.days
    df4T['Time_diff'] = df4T['Time_diff'].abs()
    df6=pd.merge(df4T,user_streak,on="USER_ID",how="left")
    df6.drop(df6[df6['Time_diff'] != df6['STREAK']].index, inplace = True)
    df6['STREAK'] = df6['STREAK'].apply(str)
    user= df6[df6.STREAK.str.contains(""+num+"",case=False)] 
    userids=user["USER_ID"].tolist()
    print(userids)
    database = client["compass"]
    collection = database["user_master"]
    query = {}
    query["_id"] = {
        u"$in": userids}
    query["USER_NAME"] = {
        u"$not": Regex(u".*TEST.*", "i")
    }
    query["IS_DISABLED"] = {
        u"$ne": u"Y"
    }

    query["INCOMPLETE_SIGNUP"] = {
        u"$ne": u"Y"
    }



    projection = {}
    projection["USER_ID.USER_ID"] = 1.0
    projection["EMAIL_ID"] = 1.0
    projection["CREATED_DATE"] = 1.0

    projection["USER_NAME"] = 1.0

    projection["schoolId.ADDRESS"] = 1.0
    projection["schoolId.CITY"] = 1.0
    projection["schoolId.STATE"] = 1.0
    projection["schoolId.COUNTRY"] = 1.0
    projection["schoolId.NAME"] = 1.0

    cursor = collection.find(query, projection = projection)
    dfum=(list(cursor))
    dfum=pd.json_normalize(dfum, max_level=1)
    # print(dfum,"usermaster")
    email=list(dfum['EMAIL_ID'])
    totaluser=len(email)
    collection = database["audio_track_master"]
    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(MODIFIED_DATE)": {
                    u"$max": u"$MODIFIED_DATE"
                },
                u"COUNT(USER_ID\u1390_id)": {
                    u"$sum": 1
                }
            }
        }, 
        {
            u"$project": {
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"MAX(MODIFIED_DATE)": u"$MAX(MODIFIED_DATE)",
                u"COUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfatd=list(cursor)
    dfatd=pd.json_normalize(dfatd, max_level=1)
    #     print(dfatd)
    collection = database["subscription_master"]

    # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

    pipeline = [
        {
            u"$match": {
                u"USER_ID.EMAIL_ID": {
                    u"$in": email
                }
            }
        }, 
        {
            u"$group": {
                u"_id": {
                    u"USER_ID\u1390_id": u"$USER_ID._id"
                },
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                    u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                }
            }
        }, 
        {
            u"$project": {
                u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                u"_id": 0
            }
        }
    ]

    cursor = collection.aggregate(
        pipeline, 
        allowDiskUse = True
    )
    dfsbm=list(cursor)
    dfsbm=pd.json_normalize(dfsbm, max_level=1)
    #     print(dfatd,"atd pracice data")

    try:
        dffinal=pd.merge(dfum,dfatd,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
    except:
        dfum['MAX(MODIFIED_DATE)']='NO PRACTICE'
        dfum['COUNT(USER_ID᎐_id)']=0
        dffinal=dfum
        dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))


    email=list(dfum['EMAIL_ID'])
    totaluser=len(email)
    dffinalnew['MAX(MODIFIED_DATE)'].fillna("NO PRACTICE", inplace=True)
    dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)'].fillna(" ", inplace=True)
    dffinalnew['COUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
    #     pracsum=sum(list(dffinalnew['COUNT(USER_ID᎐_id)']))
    dffinalnew.fillna(value=pd.np.nan, inplace=True)
    #     print(dffinalnew)
    schname=["NO SCHOOL INFO"]
    try:
        schname=dffinalnew["schoolId.NAME"].tolist()
    except:
        schname=["NO SCHOOL INFO"]


    MAX=[]
    for i in dffinalnew['MAX(MODIFIED_DATE)']:
        if  i != 'NO PRACTICE' :
            MAX.append(i.strftime("%d %b %Y "))
        else:
            MAX.append("NO PRACTICE")
    SUBSCRIPTION_EXPIRE_DATE=[]
    for i in dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)']:
        if  i != ' ' :
            SUBSCRIPTION_EXPIRE_DATE.append(i.strftime("%d %b %Y "))
        else:
            SUBSCRIPTION_EXPIRE_DATE.append(" ")        
    CREATED_DATE=[]
    for i in dffinalnew['CREATED_DATE']:
        if  i != ' ' :
            CREATED_DATE.append(i.strftime("%d %b %Y "))
        else:
            CREATED_DATE.append(" ")
    data=[]

    for Z,T,k,l,m,o,p in zip(schname,dffinalnew['USER_NAME'].tolist(),dffinalnew['EMAIL_ID'].tolist(),CREATED_DATE,MAX,SUBSCRIPTION_EXPIRE_DATE,dffinalnew['COUNT(USER_ID᎐_id)'].tolist()):
        #print(p,q,r)
        data.append([Z,T,k,l,m,o,p])
    temp={"data":data}
    return json.dumps(temp)


@app.route('/campaignstatapi')
def campaignapi():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.campaign_data
    query=[{'$match':{'$and':[
    # //     { 'FIRST_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    # //                    {'EMAIL':{"$not":{"$regex":"test",'$options':'i'}}},
    # //                      {'EMAIL':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //                      {'CAMPAIGN_ID.CAMPAIGN_DESC':{"$not":{"$regex":"1gen",'$options':'i'}}},
                         {'CAMPAIGN_ID.CAMPAIGN_DESC':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'IS_PAYMENT_SUCCESS':'Y'}        
          ]}},
          {'$group':{
              '_id':'$CAMPAIGN_ID._id',
              'CAMPAIGN_NAME':{'$first':'$CAMPAIGN_ID.H_TEXT'},
              'CREATED_DATE':{'$first':'$CAMPAIGN_ID.CREATED_DATE'},
                  'RAISED_AMOUNT':{'$sum':'$AMOUNT'},
                  'TARGET_AMOUNT':{'$first':'$CAMPAIGN_ID.TOTAL_TARGET_AMOUNT'},
              }}]
    campaign_data=list(collection.aggregate(query))
    campaign_data_df=pd.DataFrame(campaign_data)
    collection2 = db.campaign_detail
    query2=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'CAMPAIGN_DESC':{"$not":{"$regex":"test",'$options':'i'}}},
              {'CAMPAIGN_DESC':{"$not":{"$regex":"test",'$options':'i'}}}
              ]}},
              {'$project':{
                  'RAISED_AMOUNT':'$RAISED_AMOUNT',
                  'SCHOOL_ID':'$SCHOOL_ID._id',
                  'SCHOOL_NAME':'$SCHOOL_ID.NAME',
                  'CITY':'$SCHOOL_ID.CITY',
                  'STATE':'$SCHOOL_ID.STATE',
                  'USER_ID':'$USER_ID._id',
                  'USER_NAME':'$USER_ID.USER_NAME',
                  'USER_EMAIL':'$USER_ID.EMAIL_ID'
                  }
                  }]
    campaign_detail=list(collection2.aggregate(query2))
    campaign_detail_df=pd.DataFrame(campaign_detail)
    collection3 = db.subscription_master
    query3=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
              {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'IS_PAYMENT_SUCCESS':'Y'},
              {'USER_ID._id':{
                  '$in':
                  db.campaign_detail.distinct('USER_ID._id')
                  }}
              ]}},
              {'$project':{
                  '_id':0,
                  'SCHOOL_ID':'$USER_ID.schoolId._id',
                  'LAST_PAYMENT_AMOUNT':'$LAST_PAYMENT_AMOUNT',
                 }}]
    already_paid=list(collection3.aggregate(query3))
    already_paid_amount_df=pd.DataFrame(already_paid)
    
    table1=campaign_data_df.merge(campaign_detail_df,on='_id',how='inner')
    table2=table1.merge(already_paid_amount_df,how='left',on='SCHOOL_ID')
    table2['TOTAL_RAISED_AMOUNT']=table2.RAISED_AMOUNT_x+table2.LAST_PAYMENT_AMOUNT
    table2['LEFT_AMOUNT']=table2.TARGET_AMOUNT-table2.TOTAL_RAISED_AMOUNT
    final_table=table2.copy()
    final_table['_id']=final_table['_id'].astype('str')
    temp={
        'CAMPAIGN_ID':final_table['_id'].tolist(),
        'CAMPAIGN_NAME':final_table['CAMPAIGN_NAME'].tolist(),
        'RAISED_AMOUNT':final_table['TOTAL_RAISED_AMOUNT'].tolist(),
        'LEFT_AMOUNT':final_table['LEFT_AMOUNT'].tolist(),
        'TARGET_AMOUNT':final_table['TARGET_AMOUNT'].tolist()}
    return json.dumps({'data':temp})


@app.route("/user_journey_score/<name>")

def new0(name):
    graph={}
    from datetime import datetime
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = MongoClient(mongo_uri)
# #     from datetime import datetime
#     today1= datetime.utcnow().replace(day=27) + timedelta(days=3)
#     print(today1)
#     tod1= today1+ timedelta(hours=4)
#     print(tod1)
#     start= tod1-timedelta(days=180)
#     start1=start.replace(day=1)
    
    db = client["compass"]
    df11=DataFrame(list(db.user_master.aggregate([
        {"$match":{"$and":[
        {"EMAIL_ID":name},
             {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'EMAIL_ID':{"$ne":''}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
#       {'schoolId.NAME':{"$not":{"$regex":'test', '$options':'i'}}},
#          {'EMAIL_ID':{"$not":{"$regex":"Test",'$options':'i'}}},
#     {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_NAME':{"$not":{"$regex":"TEST",'$options':'i'}}},
#     {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}
        ]}},
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME",'user':"$USER_NAME",
                 "Address":"$schoolId.ADDRESS","COUNTRY":"$schoolId.COUNTRY","CITY":"$schoolId.CITY","STATE":"$schoolId.STATE","USER_NAME":"$USER_NAME", 'SIGN_UP_DATE':{"$dateToString":{"format":"%Y-%m-%d","date":'$CREATED_DATE'}},
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME","ROLE":'$ROLE_ID.ROLE_NAME'
                }}
    ])))
    if df11.empty == True:
        data={'Result':0}
    else:
        df11
    column1 =['USER_ID',"ID","school_name",'user',"SIGN_UP_DATE","Address","COUNTRY","CITY","STATE","USER_NAME","email_id","district_name","ROLE"]
    for i in column1:
        if i not in df11.columns:
            df11[i] = 'No info'

   
    df11["ROLE"].replace({"PRESENT": "PARENT", "user":"Teacher",'admin':'ADMIN','donor':'donor','oms':'OMS'}, inplace=True)
    
    email=df11['USER_ID'].tolist()
    school=df11['ID'].tolist()
    
    
    df2=DataFrame(list(db.user_master.aggregate([
        {"$match":{"$and":[
        {"schoolId._id":{"$in":school}},
            
             {'IS_ADMIN':'Y'},
        ]}},
    {"$project":{"ADMIN_EMAIL":"$EMAIL_ID","ADMIN_NAME":"$USER_NAME"}}
    ])))
    column2 =['ADMIN_NAME',"ADMIN_EMAIL"]
    
    
    if df2.empty==True:
        df2=pd.DataFrame({"ADMIN_EMAIL":['No info'],'ADMIN_NAME':['No info']})
    
    for i in column2:       
        if i not in df2.columns:
            df2[i] = 'No info'
#        
    ADMIN_NAME=df2['ADMIN_NAME'].tolist()
    ADMIN_EMAIL=df2['ADMIN_EMAIL'].tolist()

    df33=DataFrame(list(db.audio_track_master.aggregate([
        {"$match":{'$and':[
                       {'USER_ID._id':{"$in":email}},
                            {'MODIFIED_DATE':{'$gte':csy_first_date()}}]}},    
              
         
        {'$group':{'_id' : '$USER_ID._id', 'pc':{'$sum':1},'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}},
        'AUDIO_DAY':{'$last':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
        'PROGRAM':{'$last':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
        'AUDIO':{'$last':'$PROGRAM_AUDIO_ID.AUDIO_NAME'},
        'last_practice_date':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}}}, }}
           
        ])))
    column3 =['last_practice_date',"AUDIO_DAY",'PROGRAM','AUDIO','pc','Mindful_Minutes']
    if df33.empty==True:
        df33=pd.DataFrame({"last_practice_date":['No Practice'],'AUDIO_DAY':['No info'],'PROGRAM':['No info'],'AUDIO':['No info'],'pc':['0'],'Mindful_Minutes':['0']})
        minutes=df33['Mindful_Minutes'][0]
    else:
        df33
        minutes=int(round(df33['Mindful_Minutes'][0]))

    for i in column3:
        if i not in df33.columns:
            df33[i] = 'No info'
            
    userprac_trend=DataFrame(list(db.audio_track_master.aggregate([{"$match":{
    '$and':[
         {'USER_ID._id':{"$in":email}},
  
    {'MODIFIED_DATE':{'$gte':csy_first_date()
    }},
    ]}},
    {'$group':{'_id':'$PROGRAM_AUDIO_ID._id','audio_day':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'}, 'modified_date':{'$max':'$MODIFIED_DATE'},
                 'Program_Name':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
              'Audio_Length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'}, 'start':{'$min':'$cursorStart'},'end':{'$max':'$CURSOR_END'  }           
    }}])))
    if userprac_trend.empty is True:
        completed=0
        count=0
    else:
        columns=userprac_trend.columns
            #     print(columns)
        if not 'Start' in columns :
            userprac_trend['Start']=0
        else:
            userprac_trend
        userprac_trend.start.fillna(0, inplace=True)

        userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

        userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

        userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

        userprac_trend[userprac_trend.completed_precentage < 0]=0


        userprac_trend['start']=userprac_trend['start'].fillna(0)
        userprac_trend['end']=userprac_trend['end'].fillna(0)
        userprac_trend['completed_precentage']=userprac_trend['completed_precentage'].fillna(0)
        userprac_trend['_id']=userprac_trend['_id'].fillna(0)
        count=userprac_trend['_id'].count()
        completed_audio=userprac_trend[userprac_trend.completed_precentage == 100].reset_index()
        completed=completed_audio['completed_precentage'].count()
    
    df4=DataFrame(list(db.subscription_master.aggregate([
        {"$match":{'$and':[
                       {'USER_ID._id':{"$in":email}},
                          ]}},    
              
         
        {'$project':{'_id' : 0,
        'PLAN':'$PLAN_ID.PLAN_NAME',
        'Renewal_date':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$SUBSCRIPTION_EXPIRE_DATE'}}}, }}
           
        ])))
    if df4.empty==True:
        df4=pd.DataFrame({"Renewal_date":['No info'],'PLAN':['No info']})
    else:
        plan=df4['PLAN'][0]
        df4
    print(plan)
    

    column4 =['Renewal_date',"PLAN"]
    for i in column4:
        if i not in df4.columns:
            df4[i] = 'No info'

    df5=DataFrame(list(db.audio_feedback.aggregate([
        {"$match":{'$and':[
                       {'USER._id':{"$in":email}},
            {'MODIFIED_DATE':{'$gte':csy_first_date()}}
#             {'COMMENT':{'$ne':None}}
                          ]}},    
          
        {'$group':{'_id' : '$USER._id', 'rating':{"$avg":"$RATING"},'COMMENT':{'$last':'$COMMENT'},
        
        'COMMENT_DATE':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}}},}}
           
        ])))
    if df5.empty==True:
        df5=pd.DataFrame({"COMMENT_DATE":['No Comment'],'rating':['No Rating'],'COMMENT':['No Comment']})
        rating= df5['rating'][0]
    else:
        rating=int(round(df5['rating'][0]))
   
    column5 =['COMMENT_DATE',"rating","COMMENT"]
    for i in column5:
        if i not in df5.columns:
            df5[i] = 'No info'

    print(rating)
    
    df6=DataFrame(list(db.login_tracking.aggregate([
        {"$match":{'$and':[
                       {'USER_ID._id':{"$in":email}},
            {'CREATED_DATE':{'$gte':csy_first_date()}}

                          ]}},    

        {'$group':{'_id' : '$USER_ID._id', 'login_count_CSY':{'$sum':1},
        
        'LAST_LOGGED_IN':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$CREATED_DATE'}}},}}
           
        ]))) 
    if df6.empty==True:
        df6=pd.DataFrame({"LAST_LOGGED_IN":['No info'],'login_count_CSY':['0']})
    column6 =['LAST_LOGGED_IN',"login_count_CSY"]
    for i in column6:
        if i not in df6.columns:
            if i == "login_count_CSY":
                df6[i] = 'No info'


   

    
#     =====For practice history chart
    df1 = DataFrame(list(db.audio_track_master.aggregate([{"$match":
        {"$and" :[
             {'USER_ID._id':{"$in":email}},
            {"MODIFIED_DATE":{"$gte": csy_first_date()
#                                     
                                }},
            ]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Users_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    if df1.empty == True:
        df1=pd.DataFrame({'Practice_date':[],'Users_Practice_CSY':[]})
    else:
        df1
   
    df3 = DataFrame(list(db.audio_track_master.aggregate([{"$match":{'$and':[
        
                       {'USER_ID._id':{"$in":email}},
                    {'MODIFIED_DATE':{"$gte":LSY_Date(),"$lt": csy_first_date()}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'}, 
                        'Total_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Total_Practice_LSY':'$Total_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    if df3.empty == True:
        df3=pd.DataFrame({'Practice_date':[],'Total_Practice_LSY':[]})
    else:
        df3
    df1['Practice_date'] = pd.to_datetime(df1['Practice_date'])


    df55=df1.sort_values(by='Practice_date')
    
    df77=pd.date_range(start=str(csy_first_date().date()), end=str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1)))
    df99 = pd.DataFrame(df77,columns = ["Practice_date"])
    df99['value'] = 0

    uscy1= df55.merge(df99, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    uscy1['Practice_date']=uscy1['Practice_date'].astype(np.int64)/int(1e6)
    uscy=uscy1[["Practice_date","Users_Practice_CSY"]].values.tolist()

    df3['Practice_date'] = pd.to_datetime(df3['Practice_date'])
    df44=df3.sort_values(by='Practice_date')
    dfl=pd.date_range(start=str(csy_first_date().date()-relativedelta(years=1)), end=str(csy_first_date().date()-relativedelta(days=1)))
    dfl9 = pd.DataFrame(dfl,columns = ["Practice_date"])
    dfl9['value'] = 0
    plcy1= df44.merge(dfl9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    plcy1['Practice_date']=plcy1['Practice_date'].astype(np.int64)/int(1e6)
    plcy=plcy1[["Practice_date","Total_Practice_LSY"]].values.tolist()


    temp={'data':{'csy':uscy,'lsy':plcy}}

    data={'Info':[{'ROLE':df11['ROLE'][0],'school_id':df11['ID'][0],'SIGN_UP_DATE':df11['SIGN_UP_DATE'][0],
        'Star_5_Ratings_Recieved':rating,'DISTRICT':df11['district_name'][0],'USER_NAME':df11['user'][0] ,'USER_EMAIL':df11['email_id'][0],   
        'SCHOOL_MINDFUL_MINUTES':minutes,
           'SCHOOL_NAME':df11['school_name'][0],'ADDRESS':df11['Address'][0],'STATE':df11['STATE'][0],'CITY':df11['CITY'][0],'COUNTRY':df11['COUNTRY'][0],
           'ADMIN_EMAIL':ADMIN_EMAIL,'ADMIN_NAME':ADMIN_NAME,'SCHOOL_PRACTICE_COUNT':str(df33['pc'][0]),
           'Last_AUDIO':df33['AUDIO'][0],'Last_PROGRAM':df33['PROGRAM'][0],'Unique_audio_play':count, 'Completed_audio':completed,
           'Last_AUDIO_DAY':df33['AUDIO_DAY'][0],'login_count_csy':str(df6['login_count_CSY'][0]),
           'LAST_LOGGED_IN':df6['LAST_LOGGED_IN'][0],'Comment':df5['COMMENT'][0],'Last_Comment_date':df5['COMMENT_DATE'][0],
           'RENEWAL_DATE':df4['Renewal_date'][0],'LAST_PRACTICE_DATE':df33['last_practice_date'][0],
          'PLAN_NAME':df4['PLAN'][0]}],
          'chart':temp
         }

    return json.dumps(data,default=str)
# new0('sadhna@1gen.io')
   

@app.route("/family___journey_score/<name>")

def new0_family_(name):
    graph={}
    from datetime import datetime
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = MongoClient(mongo_uri)
# #     from datetime import datetime
#     today1= datetime.utcnow().replace(day=27) + timedelta(days=3)
#     print(today1)
#     tod1= today1+ timedelta(hours=4)
#     print(tod1)
#     start= tod1-timedelta(days=180)
#     start1=start.replace(day=1)
    
    db = client["compass"]
    df11=DataFrame(list(db.user_master.aggregate([
        {"$match":{"$and":[
        {"EMAIL_ID":name},
             {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'EMAIL_ID':{"$ne":''}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}},
#       {'schoolId.NAME':{"$not":{"$regex":'test', '$options':'i'}}},
#          {'EMAIL_ID':{"$not":{"$regex":"Test",'$options':'i'}}},
#     {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_NAME':{"$not":{"$regex":"TEST",'$options':'i'}}},
#     {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}
        ]}},
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME",'user':"$USER_NAME",
                 "Address":"$schoolId.ADDRESS","COUNTRY":"$schoolId.COUNTRY","CITY":"$schoolId.CITY","STATE":"$schoolId.STATE","USER_NAME":"$USER_NAME", 'SIGN_UP_DATE':{"$dateToString":{"format":"%Y-%m-%d","date":'$CREATED_DATE'}},
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME","ROLE":'$ROLE_ID.ROLE_NAME'
                }}
    ])))
    if df11.empty == True:
        data={'Result':0}
    else:
        df11
    column1 =['USER_ID',"ID","school_name",'user',"SIGN_UP_DATE","Address","COUNTRY","CITY","STATE","USER_NAME","email_id","district_name","ROLE"]
    for i in column1:
        if i not in df11.columns:
            df11[i] = 'No info'

   
    df11["ROLE"].replace({"PRESENT": "PARENT", "user":"Teacher",'admin':'ADMIN','donor':'donor','oms':'OMS'}, inplace=True)
    
    email=df11['USER_ID'].tolist()
    school=df11['ID'].tolist()
    
    
    df2=DataFrame(list(db.user_master.aggregate([
        {"$match":{"$and":[
        {"schoolId._id":{"$in":school}},
            
             {'IS_ADMIN':'Y'},
        ]}},
    {"$project":{"ADMIN_EMAIL":"$EMAIL_ID","ADMIN_NAME":"$USER_NAME"}}
    ])))
    column2 =['ADMIN_NAME',"ADMIN_EMAIL"]
    
    
    if df2.empty==True:
        df2=pd.DataFrame({"ADMIN_EMAIL":['No info'],'ADMIN_NAME':['No info']})
    
    for i in column2:       
        if i not in df2.columns:
            df2[i] = 'No info'
#        
    ADMIN_NAME=df2['ADMIN_NAME'].tolist()
    ADMIN_EMAIL=df2['ADMIN_EMAIL'].tolist()

    df33=DataFrame(list(db.audio_track_master.aggregate([
        {"$match":{'$and':[
                       {'USER_ID._id':{"$in":email}},
                            {'MODIFIED_DATE':{'$gte':csy_first_date()}}]}},    
              
         
        {'$group':{'_id' : '$USER_ID._id', 'pc':{'$sum':1},'Mindful_Minutes':{'$sum':{'$round':
                      [{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']},60]},0]}},
        'AUDIO_DAY':{'$last':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
        'PROGRAM':{'$last':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
        'AUDIO':{'$last':'$PROGRAM_AUDIO_ID.AUDIO_NAME'},
        'last_practice_date':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}}}, }}
           
        ])))
    column3 =['last_practice_date',"AUDIO_DAY",'PROGRAM','AUDIO','pc','Mindful_Minutes']
    if df33.empty==True:
        df33=pd.DataFrame({"last_practice_date":['No Practice'],'AUDIO_DAY':['No info'],'PROGRAM':['No info'],'AUDIO':['No info'],'pc':['0'],'Mindful_Minutes':['0']})
        minutes=df33['Mindful_Minutes'][0]
    else:
        df33
        minutes=int(round(df33['Mindful_Minutes'][0]))

    for i in column3:
        if i not in df33.columns:
            df33[i] = 'No info'
            
    userprac_trend=DataFrame(list(db.audio_track_master.aggregate([{"$match":{
    '$and':[
         {'USER_ID._id':{"$in":email}},
  
    {'MODIFIED_DATE':{'$gte':csy_first_date()
    }},
    ]}},
    {'$group':{'_id':'$PROGRAM_AUDIO_ID._id','audio_day':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'}, 'modified_date':{'$max':'$MODIFIED_DATE'},
                 'Program_Name':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
              'Audio_Length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'}, 'start':{'$min':'$cursorStart'},'end':{'$max':'$CURSOR_END'  }           
    }}])))
    if userprac_trend.empty is True:
        completed=0
        count=0
    else:
        columns=userprac_trend.columns
            #     print(columns)
        if not 'Start' in columns :
            userprac_trend['Start']=0
        else:
            userprac_trend
        userprac_trend.start.fillna(0, inplace=True)

        userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

        userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

        userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

        userprac_trend[userprac_trend.completed_precentage < 0]=0


        userprac_trend['start']=userprac_trend['start'].fillna(0)
        userprac_trend['end']=userprac_trend['end'].fillna(0)
        userprac_trend['completed_precentage']=userprac_trend['completed_precentage'].fillna(0)
        userprac_trend['_id']=userprac_trend['_id'].fillna(0)
        count=userprac_trend['_id'].count()
        completed_audio=userprac_trend[userprac_trend.completed_precentage == 100].reset_index()
        completed=completed_audio['completed_precentage'].count()
    
    df4=DataFrame(list(db.subscription_master.aggregate([
        {"$match":{'$and':[
                       {'USER_ID._id':{"$in":email}},
                          ]}},    
              
         
        {'$project':{'_id' : 0,
        'PLAN':'$PLAN_ID.PLAN_NAME',
        'Renewal_date':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$SUBSCRIPTION_EXPIRE_DATE'}}}, }}
           
        ])))
    if df4.empty==True:
        df4=pd.DataFrame({"Renewal_date":['No info'],'PLAN':['No info']})
    else:
        plan=df4['PLAN'][0]
        df4
    print(plan)
    

    column4 =['Renewal_date',"PLAN"]
    for i in column4:
        if i not in df4.columns:
            df4[i] = 'No info'

    df5=DataFrame(list(db.audio_feedback.aggregate([
        {"$match":{'$and':[
                       {'USER._id':{"$in":email}},
            {'MODIFIED_DATE':{'$gte':csy_first_date()}}
#             {'COMMENT':{'$ne':None}}
                          ]}},    
          
        {'$group':{'_id' : '$USER._id', 'rating':{"$avg":"$RATING"},'COMMENT':{'$last':'$COMMENT'},
        
        'COMMENT_DATE':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}}},}}
           
        ])))
    if df5.empty==True:
        df5=pd.DataFrame({"COMMENT_DATE":['No Comment'],'rating':['No Rating'],'COMMENT':['No Comment']})
        rating= df5['rating'][0]
    else:
        rating=int(round(df5['rating'][0]))
   
    column5 =['COMMENT_DATE',"rating","COMMENT"]
    for i in column5:
        if i not in df5.columns:
            df5[i] = 'No info'

    print(rating)
    
    df6=DataFrame(list(db.login_tracking.aggregate([
        {"$match":{'$and':[
                       {'USER_ID._id':{"$in":email}},
            {'CREATED_DATE':{'$gte':csy_first_date()}}

                          ]}},    

        {'$group':{'_id' : '$USER_ID._id', 'login_count_CSY':{'$sum':1},
        
        'LAST_LOGGED_IN':{'$max':{"$dateToString":{"format":"%Y-%m-%d","date":'$CREATED_DATE'}}},}}
           
        ]))) 
    if df6.empty==True:
        df6=pd.DataFrame({"LAST_LOGGED_IN":['No info'],'login_count_CSY':['0']})
    column6 =['LAST_LOGGED_IN',"login_count_CSY"]
    for i in column6:
        if i not in df6.columns:
            if i == "login_count_CSY":
                df6[i] = 'No info'


   

    
#     =====For practice history chart
    df1 = DataFrame(list(db.audio_track_master.aggregate([{"$match":
        {"$and" :[
             {'USER_ID._id':{"$in":email}},
            {"MODIFIED_DATE":{"$gte": csy_first_date()
#                                     
                                }},
            ]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Users_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    if df1.empty == True:
        df1=pd.DataFrame({'Practice_date':[],'Users_Practice_CSY':[]})
    else:
        df1
   
    df3 = DataFrame(list(db.audio_track_master.aggregate([{"$match":{'$and':[
        
                       {'USER_ID._id':{"$in":email}},
                    {'MODIFIED_DATE':{"$gte":LSY_Date(),"$lt": csy_first_date()}}]}},
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'}, 
                        'Total_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d","date":'$date'}}, 
                        'Total_Practice_LSY':'$Total_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
    if df3.empty == True:
        df3=pd.DataFrame({'Practice_date':[],'Total_Practice_LSY':[]})
    else:
        df3
    df1['Practice_date'] = pd.to_datetime(df1['Practice_date'])


    df55=df1.sort_values(by='Practice_date')
    
    df77=pd.date_range(start=str(csy_first_date().date()), end=str(csy_first_date().date()+relativedelta(years=1)-relativedelta(days=1)))
    df99 = pd.DataFrame(df77,columns = ["Practice_date"])
    df99['value'] = 0

    uscy1= df55.merge(df99, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    uscy1['Practice_date']=uscy1['Practice_date'].astype(np.int64)/int(1e6)
    uscy=uscy1[["Practice_date","Users_Practice_CSY"]].values.tolist()

    df3['Practice_date'] = pd.to_datetime(df3['Practice_date'])
    df44=df3.sort_values(by='Practice_date')
    dfl=pd.date_range(start=str(csy_first_date().date()-relativedelta(years=1)), end=str(csy_first_date().date()-relativedelta(days=1)))
    dfl9 = pd.DataFrame(dfl,columns = ["Practice_date"])
    dfl9['value'] = 0
    plcy1= df44.merge(dfl9, on="Practice_date", how='right').fillna(0).sort_values(by='Practice_date')
    plcy1['Practice_date']=plcy1['Practice_date'].astype(np.int64)/int(1e6)
    plcy=plcy1[["Practice_date","Total_Practice_LSY"]].values.tolist()


    temp={'data':{'csy':uscy,'lsy':plcy}}

    data={'Info':[{'ROLE':df11['ROLE'][0],'school_id':df11['ID'][0],'SIGN_UP_DATE':df11['SIGN_UP_DATE'][0],
        'Star_5_Ratings_Recieved':rating,'DISTRICT':df11['district_name'][0],'USER_NAME':df11['user'][0] ,'USER_EMAIL':df11['email_id'][0],   
        'SCHOOL_MINDFUL_MINUTES':minutes,
           'SCHOOL_NAME':df11['school_name'][0],'ADDRESS':df11['Address'][0],'STATE':df11['STATE'][0],'CITY':df11['CITY'][0],'COUNTRY':df11['COUNTRY'][0],
           'ADMIN_EMAIL':ADMIN_EMAIL,'ADMIN_NAME':ADMIN_NAME,'SCHOOL_PRACTICE_COUNT':str(df33['pc'][0]),
           'Last_AUDIO':df33['AUDIO'][0],'Last_PROGRAM':df33['PROGRAM'][0],'Unique_audio_play':count, 'Completed_audio':completed,
           'Last_AUDIO_DAY':df33['AUDIO_DAY'][0],'login_count_csy':str(df6['login_count_CSY'][0]),
           'LAST_LOGGED_IN':df6['LAST_LOGGED_IN'][0],'Comment':df5['COMMENT'][0],'Last_Comment_date':df5['COMMENT_DATE'][0],
           'RENEWAL_DATE':df4['Renewal_date'][0],'LAST_PRACTICE_DATE':df33['last_practice_date'][0],
          'PLAN_NAME':df4['PLAN'][0]}],
          'chart':temp
         }

    return json.dumps(data,default=str)

# new0('sandra.quotson@youngstown.k12.oh.us')






















# @app.route("/user_journey_score/<name>")
# def new0(name):
#     def userjourneyinfo(name):
#         username = urllib.parse.quote_plus('admin')
#         password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#         client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
#         db=client.compass
#         dateStr = "2020-08-01T00:00:00.000Z"
#         myDatetime = dateutil.parser.parse(dateStr)
       
#         collection2 = db.user_master
#         user2=[
#             {"$match":{'$and':[ {"EMAIL_ID":{'$regex':name, '$options':'i'}},
#                 {"ROLE_ID._id":{"$ne":ObjectId("5f155b8a3b6800007900da2b")}},
#                 {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                                {"USER_NAME":{ "$ne": ""}},
#                        {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                           {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                          {"EMAIL_ID":{ "$ne": ""}},  
                          
#                 {'IS_BLOCKED':{"$ne":'Y'}}, 
#                 {'IS_DISABLED':{"$ne":'Y'}}, 
#                 {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                 {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#             ]}},
       
    
#             { "$project": { "USER_NAME":"$USER_NAME","USER_EMAIL":"$EMAIL_ID",
#                           "SIGN_UP_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$CREATED_DATE"}},
#                              "SCHOOL_NAME":"$schoolId.NAME", 
#         "ADDRESS":"$schoolId.ADDRESS","COUNTRY":"$schoolId.COUNTRY", "CITY":"$schoolId.CITY", "STATE":"$schoolId.STATE", 
#         "DISTRICT_NAME": "$DISTRICT_ID.DISTRICT_NAME","SCHOOL_ID":"$schoolId._id","_id":0,"USER_ID":"$_id"}}
#         ]
#         update2=list(collection2.aggregate(user2))
#         df=pd.DataFrame(update2)
#         list_of_names1=df["USER_ID"].to_list()
#         list_of_names = df["SCHOOL_ID"].to_list()
        
#         collection = db.user_master
#         user=[
#              {"$match":{'$and':[ { "schoolId._id":{"$in":list_of_names}},
#                                 {"ROLE_ID._id":{"$ne":ObjectId("5f155b8a3b6800007900da2b")}},
#                  {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                                {"USER_NAME":{ "$ne": ""}},
#                        {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                          {"EMAIL_ID":{ "$ne": ""}},  
                         
#                 {'IS_BLOCKED':{"$ne":'Y'}}, 
#                 {'IS_DISABLED':{"$ne":'Y'}}, 
#                 {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                 {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#                   { "IS_ADMIN":"Y"},                    
#         ]}},
#                   { "$project": { "ADMIN_ID":"$_id","_id":0
#                                 }}
#             ]
#         update=list(collection.aggregate(user))
#         df0=pd.DataFrame(update)
#         list_of_names2=df0["ADMIN_ID"].to_list()
        
#         collection = db.subscription_master
#         user=[
#             {"$match":{'$and':[ { "USER_ID._id":{"$in":list_of_names2}},
#                    {"USER_ID.ROLE_ID._id":{ "$ne":ObjectId("5f155b8a3b6800007900da2b")}},            
#                 {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                                {"USER_ID.USER_NAME":{ "$ne": ""}},
#                        {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                           {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                          {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                         
#                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
#                 {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                 {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#                 {"USER_ID.IS_ADMIN":"Y"},
           
#                               ] }},
#         { "$project": { 
#                "ADMIN_NAME":"$USER_ID.USER_NAME", "ADMIN_EMAIL":"$USER_ID.EMAIL_ID",
#             "RENEWAL_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$SUBSCRIPTION_EXPIRE_DATE"}},

#                      "PLAN_NAME":"$PLAN_ID.PLAN_NAME",  "SCHOOL_ID":"$USER_ID.schoolId._id","_id":0}}

#             ]
#         update =list(collection.aggregate(user))
#         df1 =pd.DataFrame(update)
#         df01=pd.merge(df,df1,on="SCHOOL_ID",how="left")
        
#         collection3 = db.audio_track_master 
#         user3=[
#         {"$match":{'$and':[ {'MODIFIED_DATE':{"$gt":myDatetime}},
#                            { "USER_ID._id":{"$in":list_of_names1}},
#                            {"USER_ID.ROLE_ID._id":{ "$ne":ObjectId("5f155b8a3b6800007900da2b")}},
#             {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                                {"USER_ID.USER_NAME":{ "$ne": ""}},
#                        {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                           {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                          {"USER_ID.EMAIL_ID":{ "$ne": ""}}, 
#                           {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
#                 {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                 {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#                               ] }},

#             {"$group":{"_id": "$USER_ID._id","USER_PRACTICE_COUNT":{"$sum":1},
#             "USER_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}}, 
#                     "LAST_PRACTICE_DATE":{"$last":"$MODIFIED_DATE"},
#                       }},
#         { "$project": {"USER_MINDFUL_MINUTES":1,"USER_PRACTICE_COUNT":1,"USER_ID":"$_id","_id":0,
#                        "LAST_PRACTICE_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$LAST_PRACTICE_DATE"}},
#                       }}
#         ]
#         update3=list(collection3.aggregate(user3))
#         df2=pd.DataFrame(update3).fillna(0)
#         if df2.empty:
            
#             df12=df01
#             df12["USER_MINDFUL_MINUTES"]=0
#             df12["USER_PRACTICE_COUNT"]=0
#             df12["USER_ID"]=list_of_names1[0]
#             df12["LAST_PRACTICE_DATE"]="NOT PRACTICING"
#         else:
            
#             df12=pd.merge(df01,df2,on="USER_ID",how="left")
        
#         collection = db.login_logs
#         user=[
#              {"$match":{'$and':[ { "USER_ID._id":{"$in":list_of_names1}},
#                  {"USER_ID.ROLE_ID._id":{ "$ne":ObjectId("5f155b8a3b6800007900da2b")}},
#                  {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                                {"USER_ID.USER_NAME":{ "$ne": ""}},
#                        {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                           {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                          {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
#                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
#                 {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                 {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#                               ] }},
#         { "$project": {  
#                        "LAST_LOGGED_IN":{"$dateToString":{"format":"%Y-%m-%d","date":"$LAST_LOGGED_IN"}},
#                        "USER_ID":"$USER_ID._id","_id":0}}                      
#         ]
#         update=list(collection.aggregate(user))
#         df3=pd.DataFrame(update).fillna(0)
        
#         if df3.empty:
           
#             df123=df12
#             df123["USER_ID"]=list_of_names1[0]
#             df123["LAST_LOGGED_IN"]="NOT LOGGED IN"
    
#         else:    
#             df123=pd.merge(df12,df3,on="USER_ID",how="left")
       
#         collection = db.audio_track_master
#         user=[
#         {"$match":{'$and':[ { "USER_ID.schoolId._id":{"$in":list_of_names}},
#                    {"USER_ID.ROLE_ID._id":{ "$ne":ObjectId("5f155b8a3b6800007900da2b")}},        
#             {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                                {"USER_ID.USER_NAME":{ "$ne": ""}},
#                        {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                           {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                          {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
#                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
#                 {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                 {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#                               ] }},
#             {"$group":{"_id":"$USER_ID.schoolId._id","SCHOOL_PRACTICE_COUNT":{"$sum":1},
#             "SCHOOL_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}},
#                       }},
#         { "$project": {"SCHOOL_MINDFUL_MINUTES":1,"SCHOOL_PRACTICE_COUNT":1,"_id":0, "SCHOOL_ID":"$_id",}}
#         ]
#         update=list(collection.aggregate(user))
#         df4=pd.DataFrame(update).fillna(0)
        
        
#         if df4.empty :
            
            
#             df1234 = df123
#             df1234["SCHOOL_MINDFUL_MINUTES"]=0
#             df1234["SCHOOL_PRACTICE_COUNT"]=0
#             df1234["SCHOOL_ID"]=list_of_names[0]
            
#         else:
            
#             df1234=pd.merge(df123,df4,on="SCHOOL_ID",how="left")
        
        
#         collection = db.user_master
#         user=[
#         {"$match":{'$and':[ { "schoolId._id":{"$in":list_of_names}},
#                            {"ROLE_ID._id":{"$ne":ObjectId("5f155b8a3b6800007900da2b")}},                   
#             {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                                {"USER_NAME":{ "$ne": ""}},
#                        {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                           {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                          {"EMAIL_ID":{ "$ne": ""}},  
#                  {'IS_BLOCKED':{"$ne":'Y'}}, 
#                 {'IS_DISABLED':{"$ne":'Y'}}, 
#                 {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                 {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#                               ] }},
#             {"$group":{"_id": "$schoolId._id","SCHOOL_USER_COUNT":{"$sum":1},

#                       }},
#             { "$project": {"SCHOOL_USER_COUNT":1,"_id":0, "SCHOOL_ID":"$_id"}}
#         ]
#         update=list(collection.aggregate(user))
#         df5=pd.DataFrame(update)
#         df12345=pd.merge(df1234,df5,on="SCHOOL_ID",how="left")
 
#         df12345["USER_MINDFUL_MINUTES"]=round(df12345["USER_MINDFUL_MINUTES"],2)
#         df12345["SCHOOL_MINDFUL_MINUTES"]=round(df12345["SCHOOL_MINDFUL_MINUTES"],2)
#         df12345=df12345.astype(str)
#         dict=df12345.to_dict('records')
#         return (dict)

#     def userjourneychart(name):
#         mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
#         client = pymongo.MongoClient(mongo_uri)
#         db = client.compass
#         dateStr = "2020-08-01T00:00:00.000Z"
#         myDatetime = dateutil.parser.parse(dateStr)
#         collection2 = db.user_master
#         user2=[
#                 {"$match":{'$and':[ {"EMAIL_ID":{'$regex':name, '$options':'i'}},
#                     {"ROLE_ID._id":{"$ne":ObjectId("5f155b8a3b6800007900da2b")}},
#                     {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                                    {"USER_NAME":{ "$ne": ""}},
#                            {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                               {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                              {"EMAIL_ID":{ "$ne": ""}},  
#                     {'IS_BLOCKED':{"$ne":'Y'}}, 
#                     {'IS_DISABLED':{"$ne":'Y'}}, 
#                     {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                     {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#                 ]}},
            
#                 { "$project": { "USER_ID":"$_id","_id":0,      
#                               }}  
#             ]
#         update2=list(collection2.aggregate(user2))
#         df1=pd.DataFrame(update2)
#         list_of_names1=df1["USER_ID"].to_list()

#         collection3 = db.audio_track_master
#         user3=[
#         {"$match":{'$and':[  {'MODIFIED_DATE':{"$gt":myDatetime}},
#                             { "USER_ID._id":{"$in":list_of_names1}},
#                            {"USER_ID.ROLE_ID._id":{ "$ne":ObjectId("5f155b8a3b6800007900da2b")}}, 
#             {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
#                                {"USER_ID.USER_NAME":{ "$ne": ""}},
#                        {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
#                           {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
#                          {"USER_ID.EMAIL_ID":{ "$ne": ""}}, 
#                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#                 {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
#                 {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#                 {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
#                               ] }},
#             { "$project": { "MODIFIED_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}},
#                            "CURSOR_END":1,"cursorStart":1}},

#             {"$group":{"_id": "$MODIFIED_DATE","PRACTICE_COUNT":{"$sum":1},
#             "MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}}, 

#                       }},
#         { "$project": {"MINDFUL_MINUTES":1,"PRACTICE_COUNT":1}}
#         ]
#         update3=list(collection3.aggregate(user3))
#         df2=pd.DataFrame(update3)
#         if df2.empty:
#             temp={'data':[]}
#             return (temp)
#         else: 
#             df14i=df2[["_id","PRACTICE_COUNT"]]
#             df14i['_id'] = pd.to_datetime(df14i['_id'])
#             df15i=df14i.sort_values(by='_id')
#             df15i['_id']=df15i['_id'].astype(np.int64)/int(1e6)
#             shp=df15i[["_id","PRACTICE_COUNT"]].values.tolist()
#             df15i['Cumulative_Amount'] = df15i['PRACTICE_COUNT'].cumsum()
#             df16i=df15i[['_id','Cumulative_Amount']]
#             shpcum=df16i.values.tolist()
#             temp={'data':{'shp':shp,'shpcum':shpcum}}
#             return (temp)  
  
  
#     dict={"Info":userjourneyinfo(name),"Chart":userjourneychart(name)}
#     return json.dumps(dict)

@app.route("/usercomparison/<name>/<name1>")
def new(name,name1):
    def usercomparisoninfo(name):
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
        client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
        db=client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
       
        collection2 = db.user_master
        user2=[
            {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        #     {"IS_ADMIN":"Y"},
             {"EMAIL_ID":{'$regex':name, '$options':'i'}},
            ]}},
       
    
            { "$project": { "USER_NAME":"$USER_NAME","USER_EMAIL":"$EMAIL_ID",
                          "SIGN_UP_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$CREATED_DATE"}},
                             "SCHOOL_NAME":"$schoolId.NAME", 
        "ADDRESS":"$schoolId.ADDRESS","COUNTRY":"$schoolId.COUNTRY", "CITY":"$schoolId.CITY", "STATE":"$schoolId.STATE", 
        "DISTRICT_NAME": "$DISTRICT_ID.DISTRICT_NAME","SCHOOL_ID":"$schoolId._id","_id":0,"USER_ID":"$_id"}}
        ]
        update2=list(collection2.aggregate(user2))
        df=pd.DataFrame(update2)
        list_of_names1=df["USER_ID"].to_list()
        list_of_names = df["SCHOOL_ID"].to_list()
        
        collection = db.user_master
        user=[
             {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                         {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},

           { "IS_ADMIN":"Y"},
            { "schoolId._id":{"$in":list_of_names}},                    
        ]}},
                  { "$project": { "ADMIN_ID":"$_id","_id":0
                                }}
            ]
        update=list(collection.aggregate(user))
        df0=pd.DataFrame(update)
        list_of_names2=df0["ADMIN_ID"].to_list()
        
        collection = db.subscription_master
        user=[
            {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
              { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
            { "USER_ID._id":{"$in":list_of_names2}},
           {"USER_ID.IS_ADMIN":"Y"},
           #"USER_ID.EMAIL_ID": "2011380@ljisd.com"
                              ] }},
        { "$project": { 
               "ADMIN_NAME":"$USER_ID.USER_NAME", "ADMIN_EMAIL":"$USER_ID.EMAIL_ID",
            "RENEWAL_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$SUBSCRIPTION_EXPIRE_DATE"}},
#             "RENEWAL DATE":"$SUBSCRIPTION_EXPIRE_DATE",

                     "PLAN_NAME":"$PLAN_ID.PLAN_NAME",  "SCHOOL_ID":"$USER_ID.schoolId._id","_id":0}}

            ]
        update =list(collection.aggregate(user))
        df1 =pd.DataFrame(update)
        df01=pd.merge(df,df1,on="SCHOOL_ID",how="left")
        
        collection3 = db.audio_track_master 
        user3=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}}, 
                          {'MODIFIED_DATE':{"$gt":myDatetime}},
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
#             { "$project": { "MODIFIED_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}},
#                            "CURSOR_END":1,"cursorStart":1}},

            {"$group":{"_id": "$USER_ID._id","USER_PRACTICE_COUNT":{"$sum":1},
            "USER_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}}, 
                    "LAST_PRACTICE_DATE":{"$last":"$MODIFIED_DATE"},
                      }},
        { "$project": {"USER_MINDFUL_MINUTES":1,"USER_PRACTICE_COUNT":1,"USER_ID":"$_id","_id":0,
                       "LAST_PRACTICE_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$LAST_PRACTICE_DATE"}},
                      }}
        ]
        update3=list(collection3.aggregate(user3))
        df2=pd.DataFrame(update3).fillna(0)
        if df2.empty:
            
            df12=df01
            df12["USER_MINDFUL_MINUTES"]=0
            df12["USER_PRACTICE_COUNT"]=0
            df12["USER_ID"]=list_of_names1[0]
            df12["LAST_PRACTICE_DATE"]="NOT PRACTICING"
        else:
            
            df12=pd.merge(df01,df2,on="USER_ID",how="left")
        
        collection = db.login_logs
        user=[

             {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
        #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
            { "USER_ID._id":{"$in":list_of_names1}},
           #"IS_ADMIN":"Y"}},
           #"USER_ID.EMAIL_ID": "2011380@ljisd.com"
                              ] }},
        { "$project": { 
#             "LAST LOGGED IN":"$LAST_LOGGED_IN", 
                       "LAST_LOGGED_IN":{"$dateToString":{"format":"%Y-%m-%d","date":"$LAST_LOGGED_IN"}},
                       "USER_ID":"$USER_ID._id","_id":0}}                      
        ]
        update=list(collection.aggregate(user))
        df3=pd.DataFrame(update).fillna(0)
        
        if df3.empty:
           
            df123=df12
            df123["USER_ID"]=list_of_names1[0]
            df123["LAST_LOGGED_IN"]="NOT LOGGED IN"
    
        else:    
            df123=pd.merge(df12,df3,on="USER_ID",how="left")
       
        collection = db.audio_track_master
        user=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID.schoolId._id":{"$in":list_of_names}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            {"$group":{"_id":"$USER_ID.schoolId._id","SCHOOL_PRACTICE_COUNT":{"$sum":1},
            "SCHOOL_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}},
                      }},
        { "$project": {"SCHOOL_MINDFUL_MINUTES":1,"SCHOOL_PRACTICE_COUNT":1,"_id":0, "SCHOOL_ID":"$_id",}}
        ]
        update=list(collection.aggregate(user))
        df4=pd.DataFrame(update).fillna(0)
        
        
        if df4.empty :
            
            
            df1234 = df123
            df1234["SCHOOL_MINDFUL_MINUTES"]=0
            df1234["SCHOOL_PRACTICE_COUNT"]=0
            df1234["SCHOOL_ID"]=list_of_names[0]
            
        else:
            
            df1234=pd.merge(df123,df4,on="SCHOOL_ID",how="left")
        
        
        collection = db.user_master
        user=[
        {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "schoolId._id":{"$in":list_of_names}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            {"$group":{"_id": "$schoolId._id","SCHOOL_USER_COUNT":{"$sum":1},

                      }},
            { "$project": {"SCHOOL_USER_COUNT":1,"_id":0, "SCHOOL_ID":"$_id"}}
        ]
        update=list(collection.aggregate(user))
        df5=pd.DataFrame(update)
        df12345=pd.merge(df1234,df5,on="SCHOOL_ID",how="left")


#         df12345['SIGN UP DATE']=pd.to_datetime(df12345["SIGN UP DATE"]).dt.strftime('%Y-%m-%d')
#         df12345["RENEWAL DATE"]= pd.to_datetime(df12345["RENEWAL DATE"]).dt.strftime("%Y-%m-%d")
#         if "LAST PRACTICE DATE" in df12345.columns :
#             df12345["LAST PRACTICE DATE"]= pd.to_datetime(df12345["LAST PRACTICE DATE"]).dt.strftime("%Y-%m-%d")
            
#         else: 
#             df12345["LAST PRACTICE DATE"]="NO PRACTICE INFO"
            
#         df12345["LAST PRACTICE DATE"]= pd.to_datetime(df12345["LAST PRACTICE DATE"]).dt.strftime("%Y-%m-%d")
#         df12345["LAST LOGGED IN"]= pd.to_datetime(df12345["LAST LOGGED IN"]).dt.strftime("%Y-%m-%d") 
        df12345["SCHOOL_ID"]=str(df12345["SCHOOL_ID"])
        df12345["USER_ID"]=str(df12345["USER_ID"])
    #     df12345["USER PRACTICE COUNT"]=str(df12345["USER PRACTICE COUNT"])
        df12345["USER_MINDFUL_MINUTES"]=round(df12345["USER_MINDFUL_MINUTES"],2)
    #     df12345["SCHOOL PRACTICE COUNT"]=str(df12345["SCHOOL PRACTICE COUNT"])
        df12345["SCHOOL_MINDFUL_MINUTES"]=round(df12345["SCHOOL_MINDFUL_MINUTES"],2)
        dict=df12345.to_dict('records')
        return (dict)

    def usercomparisonchart(name):
        mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
        client = pymongo.MongoClient(mongo_uri)
        db = client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
        collection2 = db.user_master
        user2=[
                {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                                   {"USER_NAME":{ "$ne": ""}},
                           {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                              {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                             {"EMAIL_ID":{ "$ne": ""}},  
                              # {"schoolId":{"$exists":1 }}, # remove for family
                    {'IS_BLOCKED':{"$ne":'Y'}}, 
                    {'IS_DISABLED':{"$ne":'Y'}}, 
                    {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            #     {"IS_ADMIN":"Y"},
                 {"EMAIL_ID":{'$regex':name, '$options':'i'}},
                ]}},
            #  {"$group":{"_id":"$schoolId._id","School_User_count":{"$addToSet":"$_id"},

            #                'School_id':{'$first':'$schoolId._id'},
            #               }},
                { "$project": {
            #         "SCHOOL ID":"$schoolId._id","_id":0, "USER NAME":"$USER_NAME","USER EMAIL":"$EMAIL_ID",
                                   "USER_ID":"$_id","_id":0,       
                                           #         "CREATED_DATE" : 1,
            #                    "School_User_count":{"$size":"$School_User_count"}
                              }}  
            ]
        update2=list(collection2.aggregate(user2))
        df1=pd.DataFrame(update2)
        list_of_names1=df1["USER_ID"].to_list()

        collection3 = db.audio_track_master
        user3=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}}, 
                          {'MODIFIED_DATE':{"$gt":myDatetime}},
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            { "$project": { "MODIFIED_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}},
                           "CURSOR_END":1,"cursorStart":1}},

            {"$group":{"_id": "$MODIFIED_DATE","PRACTICE_COUNT":{"$sum":1},
            "MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}}, 

                      }},
        { "$project": {"MINDFUL_MINUTES":1,"PRACTICE_COUNT":1}}
        ]
        update3=list(collection3.aggregate(user3))
        df2=pd.DataFrame(update3)
        if df2.empty:
            temp={'data':[]}
            return (temp)
        else: 
            df14i=df2[["_id","PRACTICE_COUNT"]]
            df14i['_id'] = pd.to_datetime(df14i['_id'])
            df15i=df14i.sort_values(by='_id')
            df15i['_id']=df15i['_id'].astype(np.int64)/int(1e6)
            shp=df15i[["_id","PRACTICE_COUNT"]].values.tolist()
            df15i['Cumulative_Amount'] = df15i['PRACTICE_COUNT'].cumsum()
            df16i=df15i[['_id','Cumulative_Amount']]
            shpcum=df16i.values.tolist()
            temp={'data':{'shp':shp,'shpcum':shpcum}}
            return (temp)  

    def usercomparisoninfo1(name1):
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
        client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
        db=client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
       
        collection2 = db.user_master
        user2=[
            {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        #     {"IS_ADMIN":"Y"},
             {"EMAIL_ID":{'$regex':name1, '$options':'i'}},
            ]}},
       
    
            { "$project": { "USER_NAME":"$USER_NAME","USER_EMAIL":"$EMAIL_ID",
                          "SIGN_UP_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$CREATED_DATE"}},
                             "SCHOOL_NAME":"$schoolId.NAME", 
        "ADDRESS":"$schoolId.ADDRESS","COUNTRY":"$schoolId.COUNTRY", "CITY":"$schoolId.CITY", "STATE":"$schoolId.STATE", 
        "DISTRICT_NAME": "$DISTRICT_ID.DISTRICT_NAME","SCHOOL_ID":"$schoolId._id","_id":0,"USER_ID":"$_id"}}
        ]
        update2=list(collection2.aggregate(user2))
        df=pd.DataFrame(update2)
        list_of_names1=df["USER_ID"].to_list()
        list_of_names = df["SCHOOL_ID"].to_list()
        
        collection = db.user_master
        user=[
             {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                         {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},

           { "IS_ADMIN":"Y"},
            { "schoolId._id":{"$in":list_of_names}},                    
        ]}},
                  { "$project": { "ADMIN_ID":"$_id","_id":0
                                }}
            ]
        update=list(collection.aggregate(user))
        df0=pd.DataFrame(update)
        list_of_names2=df0["ADMIN_ID"].to_list()
        
        collection = db.subscription_master
        user=[
            {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
              { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
            { "USER_ID._id":{"$in":list_of_names2}},
           {"USER_ID.IS_ADMIN":"Y"},
           #"USER_ID.EMAIL_ID": "2011380@ljisd.com"
                              ] }},
        { "$project": { 
               "ADMIN_NAME":"$USER_ID.USER_NAME", "ADMIN_EMAIL":"$USER_ID.EMAIL_ID",
            "RENEWAL_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$SUBSCRIPTION_EXPIRE_DATE"}},
#             "RENEWAL DATE":"$SUBSCRIPTION_EXPIRE_DATE",

                     "PLAN_NAME":"$PLAN_ID.PLAN_NAME", "SCHOOL_ID":"$USER_ID.schoolId._id","_id":0}}

            ]
        update =list(collection.aggregate(user))
        df1 =pd.DataFrame(update)
        df01=pd.merge(df,df1,on="SCHOOL_ID",how="left")
        
        collection3 = db.audio_track_master 
        user3=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}}, 
                          {'MODIFIED_DATE':{"$gt":myDatetime}},
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
#             { "$project": { "MODIFIED_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}},
#                            "CURSOR_END":1,"cursorStart":1}},

            {"$group":{"_id": "$USER_ID._id","USER_PRACTICE_COUNT":{"$sum":1},
            "USER_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}}, 
                    "LAST_PRACTICE_DATE":{"$last":"$MODIFIED_DATE"},
                      }},
        { "$project": {"USER_MINDFUL_MINUTES":1,"USER_PRACTICE_COUNT":1,"USER_ID":"$_id","_id":0,
                       "LAST_PRACTICE_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$LAST_PRACTICE_DATE"}},
                      }}
        ]
        update3=list(collection3.aggregate(user3))
        df2=pd.DataFrame(update3).fillna(0)
        if df2.empty:
            
            df12=df01
            df12["USER_MINDFUL_MINUTES"]=0
            df12["USER_PRACTICE_COUNT"]=0
            df12["USER_ID"]=list_of_names1[0]
            df12["LAST_PRACTICE_DATE"]="NOT PRACTICING"
        else:
            
            df12=pd.merge(df01,df2,on="USER_ID",how="left")
        
        collection = db.login_logs
        user=[

             {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
        #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
            { "USER_ID._id":{"$in":list_of_names1}},
           #"IS_ADMIN":"Y"}},
           #"USER_ID.EMAIL_ID": "2011380@ljisd.com"
                              ] }},
        { "$project": { 
#             "LAST LOGGED IN":"$LAST_LOGGED_IN", 
                       "LAST_LOGGED_IN":{"$dateToString":{"format":"%Y-%m-%d","date":"$LAST_LOGGED_IN"}},
                       "USER_ID":"$USER_ID._id","_id":0}}                      
        ]
        update=list(collection.aggregate(user))
        df3=pd.DataFrame(update).fillna(0)
        
        if df3.empty:
           
            df123=df12
            df123["USER_ID"]=list_of_names1[0]
            df123["LAST_LOGGED_IN"]="NOT LOGGED IN"
    
        else:    
            df123=pd.merge(df12,df3,on="USER_ID",how="left")
       
        collection = db.audio_track_master
        user=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID.schoolId._id":{"$in":list_of_names}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            {"$group":{"_id":"$USER_ID.schoolId._id","SCHOOL_PRACTICE_COUNT":{"$sum":1},
            "SCHOOL_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}},
                      }},
        { "$project": {"SCHOOL_MINDFUL_MINUTES":1,"SCHOOL_PRACTICE_COUNT":1,"_id":0, "SCHOOL_ID":"$_id",}}
        ]
        update=list(collection.aggregate(user))
        df4=pd.DataFrame(update).fillna(0)
        
        
        if df4.empty :
            
            
            df1234 = df123
            df1234["SCHOOL_MINDFUL_MINUTES"]=0
            df1234["SCHOOL_PRACTICE_COUNT"]=0
            df1234["SCHOOL_ID"]=list_of_names[0]
            
        else:
            
            df1234=pd.merge(df123,df4,on="SCHOOL_ID",how="left")
        
        
        collection = db.user_master
        user=[
        {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "schoolId._id":{"$in":list_of_names}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            {"$group":{"_id": "$schoolId._id","SCHOOL_USER_COUNT":{"$sum":1},

                      }},
            { "$project": {"SCHOOL_USER_COUNT":1,"_id":0, "SCHOOL_ID":"$_id"}}
        ]
        update=list(collection.aggregate(user))
        df5=pd.DataFrame(update)
        df12345=pd.merge(df1234,df5,on="SCHOOL_ID",how="left")


#         df12345['SIGN UP DATE']=pd.to_datetime(df12345["SIGN UP DATE"]).dt.strftime('%Y-%m-%d')
#         df12345["RENEWAL DATE"]= pd.to_datetime(df12345["RENEWAL DATE"]).dt.strftime("%Y-%m-%d")
#         if "LAST PRACTICE DATE" in df12345.columns :
#             df12345["LAST PRACTICE DATE"]= pd.to_datetime(df12345["LAST PRACTICE DATE"]).dt.strftime("%Y-%m-%d")
            
#         else: 
#             df12345["LAST PRACTICE DATE"]="NO PRACTICE INFO"
            
#         df12345["LAST PRACTICE DATE"]= pd.to_datetime(df12345["LAST PRACTICE DATE"]).dt.strftime("%Y-%m-%d")
#         df12345["LAST LOGGED IN"]= pd.to_datetime(df12345["LAST LOGGED IN"]).dt.strftime("%Y-%m-%d") 
        df12345["SCHOOL_ID"]=str(df12345["SCHOOL_ID"])
        df12345["USER_ID"]=str(df12345["USER_ID"])
    #     df12345["USER PRACTICE COUNT"]=str(df12345["USER PRACTICE COUNT"])
        df12345["USER_MINDFUL_MINUTES"]=round(df12345["USER_MINDFUL_MINUTES"],2)
    #     df12345["SCHOOL PRACTICE COUNT"]=str(df12345["SCHOOL PRACTICE COUNT"])
        df12345["SCHOOL_MINDFUL_MINUTES"]=round(df12345["SCHOOL_MINDFUL_MINUTES"],2)
        dict=df12345.to_dict('records')
        return (dict)

    def usercomparisonchart1(name1):
        mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
        client = pymongo.MongoClient(mongo_uri)
        db = client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
        collection2 = db.user_master
        user2=[
                {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                                   {"USER_NAME":{ "$ne": ""}},
                           {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                              {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                             {"EMAIL_ID":{ "$ne": ""}},  
                              # {"schoolId":{"$exists":1 }}, # remove for family
                    {'IS_BLOCKED':{"$ne":'Y'}}, 
                    {'IS_DISABLED':{"$ne":'Y'}}, 
                    {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            #     {"IS_ADMIN":"Y"},
                 {"EMAIL_ID":{'$regex':name1, '$options':'i'}},
                ]}},
            #  {"$group":{"_id":"$schoolId._id","School_User_count":{"$addToSet":"$_id"},

            #                'School_id':{'$first':'$schoolId._id'},
            #               }},
                { "$project": {
            #         "SCHOOL ID":"$schoolId._id","_id":0, "USER NAME":"$USER_NAME","USER EMAIL":"$EMAIL_ID",
                               "USER_ID":"$_id","_id":0, 
            #         "CREATED_DATE" : 1,
            #                    "School_User_count":{"$size":"$School_User_count"}
                              }}  
            ]
        update2=list(collection2.aggregate(user2))
        df1=pd.DataFrame(update2)
        list_of_names1=df1["USER_ID"].to_list()

        collection3 = db.audio_track_master
        user3=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}}, 
                          {'MODIFIED_DATE':{"$gt":myDatetime}},
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            { "$project": { "MODIFIED_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}},
                           "CURSOR_END":1,"cursorStart":1}},

            {"$group":{"_id": "$MODIFIED_DATE","PRACTICE_COUNT":{"$sum":1},
            "MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}}, 

                      }},
        { "$project": {"MINDFUL_MINUTES":1,"PRACTICE_COUNT":1}}
        ]
        update3=list(collection3.aggregate(user3))
        df2=pd.DataFrame(update3)
        if df2.empty:
            temp={'data':[]}
            return (temp)
        else: 
            df14i=df2[["_id","PRACTICE_COUNT"]]
            df14i['_id'] = pd.to_datetime(df14i['_id'])
            df15i=df14i.sort_values(by='_id')
            df15i['_id']=df15i['_id'].astype(np.int64)/int(1e6)
            shp=df15i[["_id","PRACTICE_COUNT"]].values.tolist()
            df15i['Cumulative_Amount'] = df15i['PRACTICE_COUNT'].cumsum()
            df16i=df15i[['_id','Cumulative_Amount']]
            shpcum=df16i.values.tolist()
            temp={'data':{'shp':shp,'shpcum':shpcum}}
            return (temp)  
  
    dict={"Info1":usercomparisoninfo(name),"Chart1":usercomparisonchart(name),
          "Info2":usercomparisoninfo(name1),"Chart2":usercomparisonchart(name1)}
    return json.dumps(dict)

@app.route("/schoolcomparison/<name>/<name1>")
def new1(name,name1):
    def schoolcomparisoninfo(name):
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
        client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
        db=client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
       
        collection = db.school_master
        user=[
            {"$match":{"$and":[{'NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'_id':ObjectId(name)},
#           { "_id":{'$in':name, '$options':'i'}},                      
        {'NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'NAME':{"$ne":""}}
        ]}},
        { "$project":{ "SCHOOL_NAME":"$NAME", "ADDRESS":1, "STATE":1, "CITY":1, "DISTRICT_NAME": "$CATEGORY",
                      "SCHOOL_ID":"$_id","_id":0,
                     "SCHOOL_SIGN_UP_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$CREATED_DATE"}},}}
            ]
        update=list(collection.aggregate(user))
        df=pd.DataFrame(update).replace({'DISTRICT_NAME':"NULL"}, {'DISTRICT_NAME': 'NO INFO'}, regex=True)
        
        
        list_of_names=df["SCHOOL_ID"].to_list()
        collection = db.user_master
        user=[
             {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                         {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},

           { "IS_ADMIN":"Y"},
            { "schoolId._id":{"$in":list_of_names}},                    
        ]}},
                  { "$project": { "ADMIN_ID":"$_id","_id":0
                                }}
            ]
        update=list(collection.aggregate(user))
        df0=pd.DataFrame(update)
        list_of_names0=df0["ADMIN_ID"].to_list()
        collection = db.subscription_master
        user=[
         {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
              { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
           {"USER_ID.IS_ADMIN":"Y"},
           {"USER_ID._id":{"$in":list_of_names0}}
                              ] }},
        { "$project": { 
               "ADMIN_NAME":"$USER_ID.USER_NAME", "ADMIN_EMAIL":"$USER_ID.EMAIL_ID",
            "RENEWAL_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$SUBSCRIPTION_EXPIRE_DATE"}},
#             "RENEWAL DATE":"$SUBSCRIPTION_EXPIRE_DATE",

#                      "PLAN NAME":"$PLAN_ID.PLAN_NAME",
            "SCHOOL_ID":"$USER_ID.schoolId._id","_id":0}}
        ]
        update=list(collection.aggregate(user))
        df1=pd.DataFrame(update)
        df01=pd.merge(df,df1,on="SCHOOL_ID",how="left")
        collection = db.user_master
        user=[
            {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        #     {"IS_ADMIN":"Y"},
            {"schoolId._id":{"$in":list_of_names}}
            ]}},
        #  {"$group":{"_id":"$schoolId._id","School_User_count":{"$addToSet":"$_id"},

        #                'School_id':{'$first':'$schoolId._id'},
        #               }},
            { "$project": {"SCHOOL_ID":"$schoolId._id","_id":0, "USER_NAME":"$USER_NAME","USER_EMAIL":"$EMAIL_ID",
                           "USER_ID":"$_id",
                           "USER_SIGN_UP_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$CREATED_DATE"}},
        #                    "School_User_count":{"$size":"$School_User_count"}
                          }}  
        ]
        update=list(collection.aggregate(user))
        df2=pd.DataFrame(update)
        SCHOOL_USER_COUNT=len(df2)
        df12=pd.merge(df01,df2,on="SCHOOL_ID",how="left")
        list_of_names1=df12["USER_ID"].to_list()
        collection = db.audio_track_master
        user=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}}, 
                         {'MODIFIED_DATE':{"$gte":myDatetime}}, 
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            {"$group":{"_id": "$USER_ID._id","USER_PRACTICE_COUNT":{"$sum":1},
            "USER_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}},
               "LAST_PRACTICE_DATE":{"$last":"$MODIFIED_DATE"},         
                       
                      }},
        { "$project": {"USER_MINDFUL_MINUTES":1,"USER_PRACTICE_COUNT":1,"_id":0,"USER_ID":"$_id",
                      "LAST_PRACTICE_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$LAST_PRACTICE_DATE"}},
                      }}
        ]
        update=list(collection.aggregate(user))
        df3=pd.DataFrame(update).fillna(0)
        
        if df3.empty:

            df123=df12
            df123["SCHOOL_USER_COUNT"]=SCHOOL_USER_COUNT
            df123["SCHOOL_PRACTICE_COUNT"]=0
            df123["SCHOOL_MINDFUL_MINUTES"]=0
            df123["USER_ID"]=list_of_names1
            df123["LAST_PRACTICE_DATE"]="NOT PRACTICING"

        else:
            SCHOOL_PRACTICE_COUNT=sum(df3["USER_PRACTICE_COUNT"])
            SCHOOL_MINDFUL_MINUTES=sum(df3["USER_MINDFUL_MINUTES"])
            df123=pd.merge(df12,df3,on="USER_ID",how="left")
            df123["SCHOOL_USER_COUNT"]=SCHOOL_USER_COUNT
            df123["SCHOOL_PRACTICE_COUNT"]=SCHOOL_PRACTICE_COUNT
            df123["SCHOOL_MINDFUL_MINUTES"]=SCHOOL_MINDFUL_MINUTES
            df123["SCHOOL_MINDFUL_MINUTES"]=round(df123["SCHOOL_MINDFUL_MINUTES"])


    
        

#         df123['SIGN UP DATE']=pd.to_datetime(df123["SIGN UP DATE"]).dt.strftime('%Y-%m-%d')
#         df123["RENEWAL DATE"]= pd.to_datetime(df123["RENEWAL DATE"]).dt.strftime("%Y-%m-%d")
        df123["SCHOOL_ID"]=str(df123["SCHOOL_ID"])
        df123["USER_ID"]=str(df123["USER_ID"])
        df123=df123.astype(str)
#         df123["SCHOOL_MINDFUL_MINUTES"]=round(df123["SCHOOL_MINDFUL_MINUTES"])

    #     dict1=df123.to_dict("records")
        dict={"SCHOOL_SIGN_UP_DATE":df123['SCHOOL_SIGN_UP_DATE'][0],
              
                  "SCHOOL_NAME":df123["SCHOOL_NAME"][0],"ADDRESS":df123["ADDRESS"][0],
                   "CITY":df123["CITY"][0],"STATE":df123["STATE"][0],"DISTRICT_NAME":df123["DISTRICT_NAME"][0],
                   "ADMIN_EMAIL":df123["ADMIN_EMAIL"][0],"ADMIN_NAME":df123["ADMIN_NAME"][0],
#                    "RENEWAL DATE":df123["RENEWAL DATE"][0],
              "SCHOOL_USER_COUNT":SCHOOL_USER_COUNT,
#                    "PLAN NAME":df123["PLAN NAME"][0],
               "SCHOOL_PRACTICE_COUNT":df123["SCHOOL_PRACTICE_COUNT"][0],
          "SCHOOL_MINDFUL_MINUTES":df123["SCHOOL_MINDFUL_MINUTES"][0]}
        return (dict)

    def schoolcomparisonchart(name):
        mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
        client = pymongo.MongoClient(mongo_uri)
        db = client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
        
        collection1 = db.school_master
        user1=[
            {"$match":{"$and":[{'NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#         { "NAME": name},
        {'_id':ObjectId(name)},
        {'NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'NAME':{"$ne":""}}
        ]}},
        { "$project":{ 
        #     "SCHOOL NAME":"$NAME", "ADDRESS":1, "STATE":1, "CITY":1, "DISTRICT NAME": "$CATEGORY",
                      "SCHOOL_ID":"$_id","_id":0,
        #               "SIGN UP DATE":"$CREATED_DATE"
                     }}
            ]
        update1=list(collection1.aggregate(user1))
        df=pd.DataFrame(update1)
        list_of_names=df["SCHOOL_ID"].to_list()
        collection2 = db.user_master
        user2=[
            {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        #     {"IS_ADMIN":"Y"},
            {"schoolId._id":{"$in":list_of_names}}
            ]}},
        #  {"$group":{"_id":"$schoolId._id","School_User_count":{"$addToSet":"$_id"},

        #                'School_id':{'$first':'$schoolId._id'},
        #               }},
            { "$project": {
        #         "SCHOOL ID":"$schoolId._id","_id":0, "USER NAME":"$USER_NAME","USER EMAIL":"$EMAIL_ID",
                           "USER_ID":"$_id", "_id":0,
        #         "CREATED_DATE" : 1,
        #                    "School_User_count":{"$size":"$School_User_count"}
                          }}  
        ]
        update2=list(collection2.aggregate(user2))
        df1=pd.DataFrame(update2)
        list_of_names1=df1["USER_ID"].to_list()

        collection3 = db.audio_track_master
        user3=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}}, 
                          {'MODIFIED_DATE':{"$gte":myDatetime}},
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            
           { "$project": { "MODIFIED_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}},
                           "CURSOR_END":1,"cursorStart":1}},

            {"$group":{"_id": "$MODIFIED_DATE","PRACTICE_COUNT":{"$sum":1},
            "MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}}, 

                      }},
        { "$project": {"MINDFUL_MINUTES":1,"PRACTICE_COUNT":1}}
        ]
        update3=list(collection3.aggregate(user3))
        df2=pd.DataFrame(update3)
        
        if df2.empty:
            temp={'data':[]}
            return (temp)
        else: 
            df14i=df2[["_id","PRACTICE_COUNT"]]
            df14i['_id'] = pd.to_datetime(df14i['_id'])
            df15i=df14i.sort_values(by='_id')
            df15i['_id']=df15i['_id'].astype(np.int64)/int(1e6)
            shp=df15i[["_id","PRACTICE_COUNT"]].values.tolist()
            df15i['Cumulative_Amount'] = df15i['PRACTICE_COUNT'].cumsum()
            df16i=df15i[['_id','Cumulative_Amount']]
            shpcum=df16i.values.tolist()
            temp={'data':{'shp':shp,'shpcum':shpcum}}
            return (temp)  

    def schoolcomparisoninfo1(name1):
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
        client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
        db=client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
       
        collection = db.school_master
        user=[
            {"$match":{"$and":[{'NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'_id':ObjectId(name1)},
#           { "_id":{'$in':name, '$options':'i'}},                      
        {'NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'NAME':{"$ne":""}}
        ]}},
        { "$project":{ "SCHOOL_NAME":"$NAME", "ADDRESS":1, "STATE":1, "CITY":1, "DISTRICT_NAME": "$CATEGORY",
                      "SCHOOL_ID":"$_id","_id":0,
                     "SCHOOL_SIGN_UP_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$CREATED_DATE"}},}}
            ]
        update=list(collection.aggregate(user))
        df=pd.DataFrame(update).replace({'DISTRICT_NAME':"NULL"}, {'DISTRICT_NAME': 'NO INFO'}, regex=True)
        
        
        list_of_names=df["SCHOOL_ID"].to_list()
        collection = db.user_master
        user=[
             {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                         {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},

           { "IS_ADMIN":"Y"},
            { "schoolId._id":{"$in":list_of_names}},                    
        ]}},
                  { "$project": { "ADMIN_ID":"$_id","_id":0
                                }}
            ]
        update=list(collection.aggregate(user))
        df0=pd.DataFrame(update)
        list_of_names0=df0["ADMIN_ID"].to_list()
        collection = db.subscription_master
        user=[
         {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
              { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
           {"USER_ID.IS_ADMIN":"Y"},
           {"USER_ID._id":{"$in":list_of_names0}}
                              ] }},
        { "$project": { 
               "ADMIN_NAME":"$USER_ID.USER_NAME", "ADMIN_EMAIL":"$USER_ID.EMAIL_ID",
            "RENEWAL_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$SUBSCRIPTION_EXPIRE_DATE"}},
#             "RENEWAL DATE":"$SUBSCRIPTION_EXPIRE_DATE",

#                      "PLAN NAME":"$PLAN_ID.PLAN_NAME",
            "SCHOOL_ID":"$USER_ID.schoolId._id","_id":0}}
        ]
        update=list(collection.aggregate(user))
        df1=pd.DataFrame(update)
        df01=pd.merge(df,df1,on="SCHOOL_ID",how="left")
        collection = db.user_master
        user=[
            {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        #     {"IS_ADMIN":"Y"},
            {"schoolId._id":{"$in":list_of_names}}
            ]}},
        #  {"$group":{"_id":"$schoolId._id","School_User_count":{"$addToSet":"$_id"},

        #                'School_id':{'$first':'$schoolId._id'},
        #               }},
            { "$project": {"SCHOOL_ID":"$schoolId._id","_id":0, "USER_NAME":"$USER_NAME","USER_EMAIL":"$EMAIL_ID",
                           "USER_ID":"$_id",
                           "USER_SIGN_UP_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$CREATED_DATE"}},
        #                    "School_User_count":{"$size":"$School_User_count"}
                          }}  
        ]
        update=list(collection.aggregate(user))
        df2=pd.DataFrame(update)
        SCHOOL_USER_COUNT=len(df2)
        df12=pd.merge(df01,df2,on="SCHOOL_ID",how="left")
        list_of_names1=df12["USER_ID"].to_list()
        collection = db.audio_track_master
        user=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}}, 
                         {'MODIFIED_DATE':{"$gte":myDatetime}}, 
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            {"$group":{"_id": "$USER_ID._id","USER_PRACTICE_COUNT":{"$sum":1},
            "USER_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}},
               "LAST_PRACTICE_DATE":{"$last":"$MODIFIED_DATE"},         
                       
                      }},
        { "$project": {"USER_MINDFUL_MINUTES":1,"USER_PRACTICE_COUNT":1,"_id":0,"USER_ID":"$_id",
                      "LAST_PRACTICE_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$LAST_PRACTICE_DATE"}},
                      }}
        ]
        update=list(collection.aggregate(user))
        df3=pd.DataFrame(update).fillna(0)
        
        if df3.empty:

            df123=df12
            df123["SCHOOL_USER_COUNT"]=SCHOOL_USER_COUNT
            df123["SCHOOL_PRACTICE_COUNT"]=0
            df123["SCHOOL_MINDFUL_MINUTES"]=0
            df123["USER_ID"]=list_of_names1
            df123["LAST_PRACTICE_DATE"]="NOT PRACTICING"

        else:
            SCHOOL_PRACTICE_COUNT=sum(df3["USER_PRACTICE_COUNT"])
            SCHOOL_MINDFUL_MINUTES=sum(df3["USER_MINDFUL_MINUTES"])
            df123=pd.merge(df12,df3,on="USER_ID",how="left")
            df123["SCHOOL_USER_COUNT"]=SCHOOL_USER_COUNT
            df123["SCHOOL_PRACTICE_COUNT"]=SCHOOL_PRACTICE_COUNT
            df123["SCHOOL_MINDFUL_MINUTES"]=SCHOOL_MINDFUL_MINUTES
            df123["SCHOOL_MINDFUL_MINUTES"]=round(df123["SCHOOL_MINDFUL_MINUTES"])


    
        

#         df123['SIGN UP DATE']=pd.to_datetime(df123["SIGN UP DATE"]).dt.strftime('%Y-%m-%d')
#         df123["RENEWAL DATE"]= pd.to_datetime(df123["RENEWAL DATE"]).dt.strftime("%Y-%m-%d")
        df123["SCHOOL_ID"]=str(df123["SCHOOL_ID"])
        df123["USER_ID"]=str(df123["USER_ID"])
        df123=df123.astype(str)
#         df123["SCHOOL_MINDFUL_MINUTES"]=round(df123["SCHOOL_MINDFUL_MINUTES"])

    #     dict1=df123.to_dict("records")
        dict={"SCHOOL_SIGN_UP_DATE":df123['SCHOOL_SIGN_UP_DATE'][0],
              
                  "SCHOOL_NAME":df123["SCHOOL_NAME"][0],"ADDRESS":df123["ADDRESS"][0],
                   "CITY":df123["CITY"][0],"STATE":df123["STATE"][0],"DISTRICT_NAME":df123["DISTRICT_NAME"][0],
                   "ADMIN_EMAIL":df123["ADMIN_EMAIL"][0],"ADMIN_NAME":df123["ADMIN_NAME"][0],
#                    "RENEWAL DATE":df123["RENEWAL DATE"][0],
              "SCHOOL_USER_COUNT":SCHOOL_USER_COUNT,
#                    "PLAN NAME":df123["PLAN NAME"][0],
               "SCHOOL_PRACTICE_COUNT":df123["SCHOOL_PRACTICE_COUNT"][0],
          "SCHOOL_MINDFUL_MINUTES":df123["SCHOOL_MINDFUL_MINUTES"][0]}
        return (dict)

    def schoolcomparisonchart1(name1):
        mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
        client = pymongo.MongoClient(mongo_uri)
        db = client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
        
        collection1 = db.school_master
        user1=[
            {"$match":{"$and":[{'NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#         { "NAME": name},
        {'_id':ObjectId(name1)},
        {'NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'NAME':{"$ne":""}}
        ]}},
        { "$project":{ 
        #     "SCHOOL NAME":"$NAME", "ADDRESS":1, "STATE":1, "CITY":1, "DISTRICT NAME": "$CATEGORY",
                      "SCHOOL_ID":"$_id","_id":0,
        #               "SIGN UP DATE":"$CREATED_DATE"
                     }}
            ]
        update1=list(collection1.aggregate(user1))
        df=pd.DataFrame(update1)
        list_of_names=df["SCHOOL_ID"].to_list()
        collection2 = db.user_master
        user2=[
            {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        #     {"IS_ADMIN":"Y"},
            {"schoolId._id":{"$in":list_of_names}}
            ]}},
        #  {"$group":{"_id":"$schoolId._id","School_User_count":{"$addToSet":"$_id"},

        #                'School_id':{'$first':'$schoolId._id'},
        #               }},
            { "$project": {
        #         "SCHOOL ID":"$schoolId._id","_id":0, "USER NAME":"$USER_NAME","USER EMAIL":"$EMAIL_ID",
                           "USER_ID":"$_id","_id":0, 
        #         "CREATED_DATE" : 1,
        #                    "School_User_count":{"$size":"$School_User_count"}
                          }}  
        ]
        update2=list(collection2.aggregate(user2))
        df1=pd.DataFrame(update2)
        list_of_names1=df1["USER_ID"].to_list()

        collection3 = db.audio_track_master
        user3=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}}, 
                          {'MODIFIED_DATE':{"$gte":myDatetime}},
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            
           { "$project": { "MODIFIED_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}},
                           "CURSOR_END":1,"cursorStart":1}},

            {"$group":{"_id": "$MODIFIED_DATE","PRACTICE_COUNT":{"$sum":1},
            "MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}}, 

                      }},
        { "$project": {"MINDFUL_MINUTES":1,"PRACTICE_COUNT":1}}
        ]
        update3=list(collection3.aggregate(user3))
        df2=pd.DataFrame(update3)
        
        if df2.empty:
            temp={'data':[]}
            return (temp)
        else: 
            df14i=df2[["_id","PRACTICE_COUNT"]]
            df14i['_id'] = pd.to_datetime(df14i['_id'])
            df15i=df14i.sort_values(by='_id')
            df15i['_id']=df15i['_id'].astype(np.int64)/int(1e6)
            shp=df15i[["_id","PRACTICE_COUNT"]].values.tolist()
            df15i['Cumulative_Amount'] = df15i['PRACTICE_COUNT'].cumsum()
            df16i=df15i[['_id','Cumulative_Amount']]
            shpcum=df16i.values.tolist()
            temp={'data':{'shp':shp,'shpcum':shpcum}}
            return (temp)  
        
    dict={"Info1":schoolcomparisoninfo(name),"Chart1":schoolcomparisonchart(name),
          "Info2":schoolcomparisoninfo1(name1),"Chart2":schoolcomparisonchart1(name1)}
    return json.dumps(dict)

@app.route("/districtcomparison/<name>/<name1>")
def new2(name,name1):
    def districtcomparisoninfo(name):
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
        client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
        db=client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
        
        disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
        '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
        '5f2609807a1c0000950bb475':'Agawam School district',
        '5f2609807a1c0000950bb481':'Alameda Unified School District',
        '5f2609807a1c0000950bb47a':'Alpine School District',
        '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
        '5f2609807a1c0000950bb463':'Austin Independent School District',
        '5f59e4836451a9089d7d4007':'Belleville School District',
        '5f2609807a1c0000950bb46d':'Broward County Public Schools',
        '5f2609807a1c0000950bb46c':'Chico Unified School District',
        '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
        '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
        '5f2609807a1c0000950bb45c':'Comox Valley School District',
        '5f2609807a1c0000950bb480':'Dell Texas',
        '5f7413ef9387fd71ce6387cb':'Douglas County School District',
        '5f895191609e08b76029f641':'Early learning Sarasota',
        '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
        '5f2609807a1c0000950bb461':'Englewood Public School District',
        '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
        '5f2609807a1c0000950bb47d':'Flint Public Schools',
        '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
        '5f2609807a1c0000950bb450':'Goleta District',
        '5f2609807a1c0000950bb474':'Greenburgh North Castle Union Free School District',
        '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
        '5f2609807a1c0000950bb476':'Hillsborough County',
        '5f2609807a1c0000950bb455':'Krum Independent School District',
        '5f2609807a1c0000950bb47e':'La Joya School District',
        '5f2609807a1c0000950bb467':'Lincolnshire Schools',
        '5f2609807a1c0000950bb45a':'LAUSD',
        '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
        '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
        '5fbcdf0ba84e48a64412a798':'Needham School District',
        '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
        '5f6994386451a9089d7d4009':'Ogden school district',
        '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
        '5fd704da04a848e368de5dc6':'Oakland Unified School District',
        '5f8fcd33609e08b76029f644':'Paradise Unified School District',
        '5f2609807a1c0000950bb466':'Pinellas County Schools',
        '5f2609807a1c0000950bb471':'Racine Unified Schools',
        '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
        '5f2609807a1c0000950bb478':'San Diego Unified School District',
        '5f2609807a1c0000950bb470':'San Leandro Unified School District',
        '5f2609807a1c0000950bb477':'Sarasota County',
        '5f2609807a1c0000950bb473':'Skillman Foundation',
        '5f2609807a1c0000950bb46a':'Springfield Public Schools',
        '5f2609807a1c0000950bb468':'Utah Board of Education',
        '5f698b826451a9089d7d4008':'Wayne Metro',
        '5f2609807a1c0000950bb45b':'Westfield Public School District',
        '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
        '5f2609807a1c0000950bb45d':'Youngstown',
        '5f2609807a1c0000950bb464':'Equity Education',
        '5f2609807a1c0000950bb469':'LSF -  Head Start',
        '5f2609807a1c0000950bb46e':'District 25 New York Schools',
        '5f2609807a1c0000950bb46f':'Paradise Schools',
        '5f2609807a1c0000950bb479':'Panorama Education',
        '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
        '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
        '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
        '5fe2e25d4d0ca68d7baf889d':'BGCA',
        '5fe318b14d0ca68d7baf889e':'BLUE',
        '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
        '6017ab3043ca9c39151838d4':'Oswego School District',
        '60239a84e57dc27613699d57':'Austin Independent School District',
        '6023a6d79e8e623753fc305c':'Boulder Valley School District',
        '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
        '6023a7269e8e623753fc305e':'Fulton County School System',
        '6023a7499e8e623753fc305f':'Manatee County School District',
        '6023a76f9e8e623753fc3060':'San Jose Unified School District',
        '6023a7949e8e623753fc3061':'Wasatch County School District'}
        district=disdic[name]
       
        
        collection = db.school_master
        user=[
            {"$match":{"$and":[{'NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'NAME':{"$ne":""}},
        {"CATEGORY":{'$regex':district,'$options':'i'}},                       
        ]}},
             { "$project":{"SCHOOL_ID":"$_id","_id":0 ,"SCHOOL_NAME":"$NAME","CITY":1,"STATE":1,"DISTRICT_NAME":"$CATEGORY"}}    
            ]
        update=list(collection.aggregate(user))
        df=pd.DataFrame(update)
        DISTRICT_SCHOOL_COUNT=len(df)
        list_of_names=df["SCHOOL_ID"].to_list()
        
        collection = db.user_master
        user=[
          {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {"schoolId._id":{"$in":list_of_names}}   
                            ]}},
        #  {"$group":{"_id":"$_id",
        #             "SCHOOL ID": {"$first": "$schoolId._id" },
        #             "SCHOOL NAME": {"$first": "$schoolId.NAME"},
        #             "USER NAME":{ "$first":"$USER_NAME"},
        #             "USER EMAIL":{"$first":"$EMAIL_ID"}
        #               }},
            { "$project": {"SCHOOL_NAME":"$schoolId.NAME", "CITY":"$schoolId.CITY","STATE":"$schoolId.STATE",
                          "USER_ID":"$_id","_id":0,"SCHOOL_ID":"$schoolId._id","USER_NAME":"$USER_NAME","USER_EMAIL":"$EMAIL_ID" 
                          }}

            ]
        update=list(collection.aggregate(user))
        df1=pd.DataFrame(update)
        DISTRICT_USER_COUNT=len(df1)
        list_of_names1=df1["USER_ID"].to_list()
        df01=pd.merge(df,df1,on="SCHOOL_ID",how="left").fillna(0)
        
        collection = db.audio_track_master
        user=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                 {'MODIFIED_DATE':{"$gte":myDatetime}},         
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            {"$group":{"_id": "$USER_ID._id","USER_PRACTICE_COUNT":{"$sum":1},
            "USER_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}},
        #               'School_id':{'$first':'$USER_ID.schoolId._id'}, 
                      }},
        { "$project": {"USER_MINDFUL_MINUTES":1,"USER_PRACTICE_COUNT":1,"_id":0,"USER_ID":"$_id"}}
        ]
        update=list(collection.aggregate(user))
        df2=pd.DataFrame(update).fillna(0)
        
        if df2.empty:

            df12=df01
            
            df12["DISTRICT_SCHOOL_COUNT"]=DISTRICT_SCHOOL_COUNT
            df12["DISTRICT_USER_COUNT"]=DISTRICT_USER_COUNT
            df12["DISTRICT_PRACTICE_COUNT"]=0
            df12["DISTRICT_MINDFUL_MINUTES"]=0
            df12["USER_ID"]=list_of_names1
            

        else:
            DISTRICT_PRACTICE_COUNT=sum(df2["USER_PRACTICE_COUNT"])
            DISTRICT_MINDFUL_MINUTES=df2["USER_MINDFUL_MINUTES"].sum()
            df12=pd.merge(df01,df2,on="USER_ID",how="left").fillna(0)
            df12["DISTRICT_SCHOOL_COUNT"]=DISTRICT_SCHOOL_COUNT
            df12["DISTRICT_USER_COUNT"]=DISTRICT_USER_COUNT
            df12["DISTRICT_PRACTICE_COUNT"]=DISTRICT_PRACTICE_COUNT
            df12["DISTRICT_MINDFUL_MINUTES"]=DISTRICT_MINDFUL_MINUTES
            df12["DISTRICT_MINDFUL_MINUTES"]=round(df12["DISTRICT_MINDFUL_MINUTES"])
        
    
        collection = db.user_master
        user=[
             {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                         {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},

           { "IS_ADMIN":"Y"},
            { "schoolId._id":{"$in":list_of_names}},                    
        ]}},
                  { "$project": { "ADMIN_ID":"$_id","_id":0
                                }}
            ]
        update=list(collection.aggregate(user))
        df0=pd.DataFrame(update)
        list_of_names0=df0["ADMIN_ID"].to_list()
        
        collection = db.subscription_master
        user=[
         {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
              { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
           {"USER_ID.IS_ADMIN":"Y"},
           {"USER_ID._id":{"$in":list_of_names0}}
                              ] }},
        { "$project": { 
               "ADMIN_NAME":"$USER_ID.USER_NAME", "ADMIN_EMAIL":"$USER_ID.EMAIL_ID",
           "RENEWAL_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$SUBSCRIPTION_EXPIRE_DATE"}},

                     "PLAN_NAME":"$PLAN_ID.PLAN_NAME",  "SCHOOL_ID":"$USER_ID.schoolId._id","_id":0}}
        ]
        update=list(collection.aggregate(user))
        df3=pd.DataFrame(update)
        df123=pd.merge(df12,df3,on="SCHOOL_ID",how="left").fillna(0)
    #     df123["DISTRICT_SCHOOL_COUNT"]=DISTRICT_SCHOOL_COUNT
    #     df123["DISTRICT_USER_COUNT"]=DISTRICT_USER_COUNT
    #     df123["DISTRICT_PRACTICE_COUNT"]=DISTRICT_PRACTICE_COUNT
    #     df123["DISTRICT_MINDFUL_MINUTES"]=DISTRICT_MINDFUL_MINUTES

    #     df123["RENEWAL DATE"]= pd.to_datetime(df123["RENEWAL DATE"]).dt.strftime("%Y-%m-%d") 
#         df123["SCHOOL_ID"]=str(df123["SCHOOL_ID"])
#         df123["USER_ID"]=str(df123["USER_ID"])
        df123=df123.astype(str)
    #     df123["DISTRICT_MINDFUL_MINUTES"]=round(df123["DISTRICT_MINDFUL_MINUTES"],2)

    #     dict1=df123.to_dict('records')

        dict={ "DISTRICT_SCHOOL_COUNT":df123["DISTRICT_SCHOOL_COUNT"][0],
               "DISTRICT_USER_COUNT":df123["DISTRICT_USER_COUNT"][0],
               "DISTRICT_PRACTICE_COUNT":df123["DISTRICT_PRACTICE_COUNT"][0],
               "DISTRICT_MINDFUL_MINUTES":df123["DISTRICT_MINDFUL_MINUTES"][0],
               "DISTRICT_NAME":df123["DISTRICT_NAME"][0],
                
                }
        return (dict)

    def districtcomparisonchart(name):
        mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
        client = pymongo.MongoClient(mongo_uri)
        db = client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
        
        disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
        '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
        '5f2609807a1c0000950bb475':'Agawam School district',
        '5f2609807a1c0000950bb481':'Alameda Unified School District',
        '5f2609807a1c0000950bb47a':'Alpine School District',
        '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
        '5f2609807a1c0000950bb463':'Austin Independent School District',
        '5f59e4836451a9089d7d4007':'Belleville School District',
        '5f2609807a1c0000950bb46d':'Broward County Public Schools',
        '5f2609807a1c0000950bb46c':'Chico Unified School District',
        '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
        '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
        '5f2609807a1c0000950bb45c':'Comox Valley School District',
        '5f2609807a1c0000950bb480':'Dell Texas',
        '5f7413ef9387fd71ce6387cb':'Douglas County School District',
        '5f895191609e08b76029f641':'Early learning Sarasota',
        '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
        '5f2609807a1c0000950bb461':'Englewood Public School District',
        '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
        '5f2609807a1c0000950bb47d':'Flint Public Schools',
        '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
        '5f2609807a1c0000950bb450':'Goleta District',
        '5f2609807a1c0000950bb474':'Greenburgh North Castle Union Free School District',
        '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
        '5f2609807a1c0000950bb476':'Hillsborough County',
        '5f2609807a1c0000950bb455':'Krum Independent School District',
        '5f2609807a1c0000950bb47e':'La Joya School District',
        '5f2609807a1c0000950bb467':'Lincolnshire Schools',
        '5f2609807a1c0000950bb45a':'LAUSD',
        '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
        '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
        '5fbcdf0ba84e48a64412a798':'Needham School District',
        '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
        '5f6994386451a9089d7d4009':'Ogden school district',
        '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
        '5fd704da04a848e368de5dc6':'Oakland Unified School District',
        '5f8fcd33609e08b76029f644':'Paradise Unified School District',
        '5f2609807a1c0000950bb466':'Pinellas County Schools',
        '5f2609807a1c0000950bb471':'Racine Unified Schools',
        '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
        '5f2609807a1c0000950bb478':'San Diego Unified School District',
        '5f2609807a1c0000950bb470':'San Leandro Unified School District',
        '5f2609807a1c0000950bb477':'Sarasota County',
        '5f2609807a1c0000950bb473':'Skillman Foundation',
        '5f2609807a1c0000950bb46a':'Springfield Public Schools',
        '5f2609807a1c0000950bb468':'Utah Board of Education',
        '5f698b826451a9089d7d4008':'Wayne Metro',
        '5f2609807a1c0000950bb45b':'Westfield Public School District',
        '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
        '5f2609807a1c0000950bb45d':'Youngstown',
        '5f2609807a1c0000950bb464':'Equity Education',
        '5f2609807a1c0000950bb469':'LSF -  Head Start',
        '5f2609807a1c0000950bb46e':'District 25 New York Schools',
        '5f2609807a1c0000950bb46f':'Paradise Schools',
        '5f2609807a1c0000950bb479':'Panorama Education',
        '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
        '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
        '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
        '5fe2e25d4d0ca68d7baf889d':'BGCA',
        '5fe318b14d0ca68d7baf889e':'BLUE',
        '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
        '6017ab3043ca9c39151838d4':'Oswego School District',
        '60239a84e57dc27613699d57':'Austin Independent School District',
        '6023a6d79e8e623753fc305c':'Boulder Valley School District',
        '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
        '6023a7269e8e623753fc305e':'Fulton County School System',
        '6023a7499e8e623753fc305f':'Manatee County School District',
        '6023a76f9e8e623753fc3060':'San Jose Unified School District',
        '6023a7949e8e623753fc3061':'Wasatch County School District'}
        district=disdic[name]
        
    
        collection1 = db.school_master
        user1=[
            {"$match":{"$and":[{'NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'NAME':{"$ne":""}},
        {"CATEGORY":{'$regex':district,'$options':'i'}},                       
        ]}},
        { "$project":{ 
        #     "SCHOOL NAME":"$NAME", "ADDRESS":1, "STATE":1, "CITY":1, "DISTRICT NAME": "$CATEGORY",
                      "SCHOOL_ID":"$_id","_id":0,
        #               "SIGN UP DATE":"$CREATED_DATE"
                     }}
            ]
        update1=list(collection1.aggregate(user1))
        df=pd.DataFrame(update1)
        list_of_names=df["SCHOOL_ID"].to_list()
        
        collection2 = db.user_master
        user2=[
            {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {"schoolId._id":{"$in":list_of_names}}   
                            ]}},
        #  {"$group":{"_id":"$schoolId._id","School_User_count":{"$addToSet":"$_id"},

        #                'School_id':{'$first':'$schoolId._id'},
        #               }},
            { "$project": {
        #         "SCHOOL ID":"$schoolId._id","_id":0, "USER NAME":"$USER_NAME","USER EMAIL":"$EMAIL_ID",
                           "USER_ID":"$_id","_id":0, 
        #         "CREATED_DATE" : 1,
        #                    "School_User_count":{"$size":"$School_User_count"}
                          }}  
        ]
        update2=list(collection2.aggregate(user2))
        df1=pd.DataFrame(update2)
        list_of_names1=df1["USER_ID"].to_list()

        collection3 = db.audio_track_master
        user3=[
         {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                 {'MODIFIED_DATE':{"$gte":myDatetime}},         
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            { "$project": { "MODIFIED_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}},
                           "CURSOR_END":1,"cursorStart":1}},

            {"$group":{"_id": "$MODIFIED_DATE","PRACTICE_COUNT":{"$sum":1},
            "MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}}, 

                      }},
        { "$project": {"MINDFUL_MINUTES":1,"PRACTICE_COUNT":1}}
        ]
        update3=list(collection3.aggregate(user3))
        df2=pd.DataFrame(update3).fillna(0)
                                    
        if df2.empty:
            temp={'data':[]}
            return (temp)
        else:
            df14i=df2[["_id","PRACTICE_COUNT"]]
            print(df14i["PRACTICE_COUNT"].sum())
            df14i['_id'] = pd.to_datetime(df14i['_id'])
            df15i=df14i.sort_values(by='_id')
            df15i['_id']=df15i['_id'].astype(np.int64)/int(1e6)
            shp=df15i[["_id","PRACTICE_COUNT"]].values.tolist()
            df15i['Cumulative_Amount'] = df15i['PRACTICE_COUNT'].cumsum()
            df16i=df15i[['_id','Cumulative_Amount']]
            shpcum=df16i.values.tolist()
            temp={'data':{'shp':shp,'shpcum':shpcum}}
            return (temp) 
    

    def districtcomparisoninfo1(name1):
        username = urllib.parse.quote_plus('admin')
        password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
        client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
        db=client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)

        disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
        '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
        '5f2609807a1c0000950bb475':'Agawam School district',
        '5f2609807a1c0000950bb481':'Alameda Unified School District',
        '5f2609807a1c0000950bb47a':'Alpine School District',
        '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
        '5f2609807a1c0000950bb463':'Austin Independent School District',
        '5f59e4836451a9089d7d4007':'Belleville School District',
        '5f2609807a1c0000950bb46d':'Broward County Public Schools',
        '5f2609807a1c0000950bb46c':'Chico Unified School District',
        '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
        '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
        '5f2609807a1c0000950bb45c':'Comox Valley School District',
        '5f2609807a1c0000950bb480':'Dell Texas',
        '5f7413ef9387fd71ce6387cb':'Douglas County School District',
        '5f895191609e08b76029f641':'Early learning Sarasota',
        '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
        '5f2609807a1c0000950bb461':'Englewood Public School District',
        '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
        '5f2609807a1c0000950bb47d':'Flint Public Schools',
        '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
        '5f2609807a1c0000950bb450':'Goleta District',
        '5f2609807a1c0000950bb474':'Greenburgh North Castle Union Free School District',
        '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
        '5f2609807a1c0000950bb476':'Hillsborough County',
        '5f2609807a1c0000950bb455':'Krum Independent School District',
        '5f2609807a1c0000950bb47e':'La Joya School District',
        '5f2609807a1c0000950bb467':'Lincolnshire Schools',
        '5f2609807a1c0000950bb45a':'LAUSD',
        '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
        '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
        '5fbcdf0ba84e48a64412a798':'Needham School District',
        '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
        '5f6994386451a9089d7d4009':'Ogden school district',
        '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
        '5fd704da04a848e368de5dc6':'Oakland Unified School District',
        '5f8fcd33609e08b76029f644':'Paradise Unified School District',
        '5f2609807a1c0000950bb466':'Pinellas County Schools',
        '5f2609807a1c0000950bb471':'Racine Unified Schools',
        '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
        '5f2609807a1c0000950bb478':'San Diego Unified School District',
        '5f2609807a1c0000950bb470':'San Leandro Unified School District',
        '5f2609807a1c0000950bb477':'Sarasota County',
        '5f2609807a1c0000950bb473':'Skillman Foundation',
        '5f2609807a1c0000950bb46a':'Springfield Public Schools',
        '5f2609807a1c0000950bb468':'Utah Board of Education',
        '5f698b826451a9089d7d4008':'Wayne Metro',
        '5f2609807a1c0000950bb45b':'Westfield Public School District',
        '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
        '5f2609807a1c0000950bb45d':'Youngstown',
        '5f2609807a1c0000950bb464':'Equity Education',
        '5f2609807a1c0000950bb469':'LSF -  Head Start',
        '5f2609807a1c0000950bb46e':'District 25 New York Schools',
        '5f2609807a1c0000950bb46f':'Paradise Schools',
        '5f2609807a1c0000950bb479':'Panorama Education',
        '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
        '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
        '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
        '5fe2e25d4d0ca68d7baf889d':'BGCA',
        '5fe318b14d0ca68d7baf889e':'BLUE',
        '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
        '6017ab3043ca9c39151838d4':'Oswego School District',
        '60239a84e57dc27613699d57':'Austin Independent School District',
        '6023a6d79e8e623753fc305c':'Boulder Valley School District',
        '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
        '6023a7269e8e623753fc305e':'Fulton County School System',
        '6023a7499e8e623753fc305f':'Manatee County School District',
        '6023a76f9e8e623753fc3060':'San Jose Unified School District',
        '6023a7949e8e623753fc3061':'Wasatch County School District'}
        district=disdic[name1]

        collection = db.school_master
        user=[
            {"$match":{"$and":[{'NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'NAME':{"$ne":""}},
        {"CATEGORY":{'$regex':district,'$options':'i'}},                       
        ]}},
             { "$project":{"SCHOOL_ID":"$_id","_id":0 ,"SCHOOL_NAME":"$NAME","CITY":1,"STATE":1,"DISTRICT_NAME":"$CATEGORY"}}    
            ]
        update=list(collection.aggregate(user))
        df=pd.DataFrame(update)
        DISTRICT_SCHOOL_COUNT=len(df)
        list_of_names=df["SCHOOL_ID"].to_list()
        
        collection = db.user_master
        user=[
          {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {"schoolId._id":{"$in":list_of_names}}   
                            ]}},
        #  {"$group":{"_id":"$_id",
        #             "SCHOOL ID": {"$first": "$schoolId._id" },
        #             "SCHOOL NAME": {"$first": "$schoolId.NAME"},
        #             "USER NAME":{ "$first":"$USER_NAME"},
        #             "USER EMAIL":{"$first":"$EMAIL_ID"}
        #               }},
            { "$project": {"SCHOOL_NAME":"$schoolId.NAME", "CITY":"$schoolId.CITY","STATE":"$schoolId.STATE",
                          "USER_ID":"$_id","_id":0,"SCHOOL_ID":"$schoolId._id","USER_NAME":"$USER_NAME","USER_EMAIL":"$EMAIL_ID" }}

            ]
        update=list(collection.aggregate(user))
        df1=pd.DataFrame(update)
        DISTRICT_USER_COUNT=len(df1)
        list_of_names1=df1["USER_ID"].to_list()
        df01=pd.merge(df,df1,on="SCHOOL_ID",how="left").fillna(0)
        collection = db.audio_track_master
        user=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                 {'MODIFIED_DATE':{"$gte":myDatetime}},         
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            {"$group":{"_id": "$USER_ID._id","USER_PRACTICE_COUNT":{"$sum":1},
            "USER_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}},
        #               'School_id':{'$first':'$USER_ID.schoolId._id'}, 
                      }},
        { "$project": {"USER_MINDFUL_MINUTES":1,"USER_PRACTICE_COUNT":1,"_id":0,"USER_ID":"$_id"}}
        ]
        update=list(collection.aggregate(user))
        df2=pd.DataFrame(update).fillna(0)
        
        if df2.empty:

            df12=df01
            
            df12["DISTRICT_SCHOOL_COUNT"]=DISTRICT_SCHOOL_COUNT
            df12["DISTRICT_USER_COUNT"]=DISTRICT_USER_COUNT
            df12["DISTRICT_PRACTICE_COUNT"]=0
            df12["DISTRICT_MINDFUL_MINUTES"]=0
            df12["USER_ID"]=list_of_names1
            

        else:
            DISTRICT_PRACTICE_COUNT=sum(df2["USER_PRACTICE_COUNT"])
            DISTRICT_MINDFUL_MINUTES=df2["USER_MINDFUL_MINUTES"].sum()
            df12=pd.merge(df01,df2,on="USER_ID",how="left").fillna(0)
            df12["DISTRICT_SCHOOL_COUNT"]=DISTRICT_SCHOOL_COUNT
            df12["DISTRICT_USER_COUNT"]=DISTRICT_USER_COUNT
            df12["DISTRICT_PRACTICE_COUNT"]=DISTRICT_PRACTICE_COUNT
            df12["DISTRICT_MINDFUL_MINUTES"]=DISTRICT_MINDFUL_MINUTES
            df12["DISTRICT_MINDFUL_MINUTES"]=round(df12["DISTRICT_MINDFUL_MINUTES"])
        
       
        collection = db.user_master
        user=[
             {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                         {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                          # {"schoolId":{"$exists":1 }}, # remove for family
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},

           { "IS_ADMIN":"Y"},
            { "schoolId._id":{"$in":list_of_names}},                    
        ]}},
                  { "$project": { "ADMIN_ID":"$_id","_id":0
                                }}
            ]
        update=list(collection.aggregate(user))
        df0=pd.DataFrame(update)
        list_of_names0=df0["ADMIN_ID"].to_list()
        
        collection = db.subscription_master
        user=[
         {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
              { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
           {"USER_ID.IS_ADMIN":"Y"},
           {"USER_ID._id":{"$in":list_of_names0}}
                              ] }},
        { "$project": { 
               "ADMIN_NAME":"$USER_ID.USER_NAME", "ADMIN_EMAIL":"$USER_ID.EMAIL_ID",
            "RENEWAL_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":"$SUBSCRIPTION_EXPIRE_DATE"}},

                     "PLAN_NAME":"$PLAN_ID.PLAN_NAME",  "SCHOOL_ID":"$USER_ID.schoolId._id","_id":0}}
        ]
        update=list(collection.aggregate(user))
        df3=pd.DataFrame(update)
        df123=pd.merge(df12,df3,on="SCHOOL_ID",how="left").fillna(0)
    #     df123["DISTRICT_SCHOOL_COUNT"]=DISTRICT_SCHOOL_COUNT
    #     df123["DISTRICT_USER_COUNT"]=DISTRICT_USER_COUNT
    #     df123["DISTRICT_PRACTICE_COUNT"]=DISTRICT_PRACTICE_COUNT
    #     df123["DISTRICT_MINDFUL_MINUTES"]=DISTRICT_MINDFUL_MINUTES

    #     df123["RENEWAL DATE"]= pd.to_datetime(df123["RENEWAL DATE"]).dt.strftime("%Y-%m-%d") 
#         df123["SCHOOL_ID"]=str(df123["SCHOOL_ID"])
#         df123["USER_ID"]=str(df123["USER_ID"])
        df123=df123.astype(str)
    #     df123["DISTRICT_MINDFUL_MINUTES"]=round(df123["DISTRICT_MINDFUL_MINUTES"],2)

    #     dict1=df123.to_dict('records')

        dict={ "DISTRICT_SCHOOL_COUNT":df123["DISTRICT_SCHOOL_COUNT"][0],
               "DISTRICT_USER_COUNT":df123["DISTRICT_USER_COUNT"][0],
               "DISTRICT_PRACTICE_COUNT":df123["DISTRICT_PRACTICE_COUNT"][0],
               "DISTRICT_MINDFUL_MINUTES":df123["DISTRICT_MINDFUL_MINUTES"][0],
               "DISTRICT_NAME":df123["DISTRICT_NAME"][0]
                }
        return (dict)

    def districtcomparisonchart1(name1):
        mongo_uri = "mongodb://admin:" + urllib.parse.quote("I#L@teST^m0NGO_2o20!") + "@54.184.165.106:27017/"
        client = pymongo.MongoClient(mongo_uri)
        db = client.compass
        dateStr = "2020-08-01T00:00:00.000Z"
        myDatetime = dateutil.parser.parse(dateStr)
        
        disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
        '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
        '5f2609807a1c0000950bb475':'Agawam School district',
        '5f2609807a1c0000950bb481':'Alameda Unified School District',
        '5f2609807a1c0000950bb47a':'Alpine School District',
        '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
        '5f2609807a1c0000950bb463':'Austin Independent School District',
        '5f59e4836451a9089d7d4007':'Belleville School District',
        '5f2609807a1c0000950bb46d':'Broward County Public Schools',
        '5f2609807a1c0000950bb46c':'Chico Unified School District',
        '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
        '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
        '5f2609807a1c0000950bb45c':'Comox Valley School District',
        '5f2609807a1c0000950bb480':'Dell Texas',
        '5f7413ef9387fd71ce6387cb':'Douglas County School District',
        '5f895191609e08b76029f641':'Early learning Sarasota',
        '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
        '5f2609807a1c0000950bb461':'Englewood Public School District',
        '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
        '5f2609807a1c0000950bb47d':'Flint Public Schools',
        '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
        '5f2609807a1c0000950bb450':'Goleta District',
        '5f2609807a1c0000950bb474':'Greenburgh North Castle Union Free School District',
        '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
        '5f2609807a1c0000950bb476':'Hillsborough County',
        '5f2609807a1c0000950bb455':'Krum Independent School District',
        '5f2609807a1c0000950bb47e':'La Joya School District',
        '5f2609807a1c0000950bb467':'Lincolnshire Schools',
        '5f2609807a1c0000950bb45a':'LAUSD',
        '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
        '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
        '5fbcdf0ba84e48a64412a798':'Needham School District',
        '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
        '5f6994386451a9089d7d4009':'Ogden school district',
        '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
        '5fd704da04a848e368de5dc6':'Oakland Unified School District',
        '5f8fcd33609e08b76029f644':'Paradise Unified School District',
        '5f2609807a1c0000950bb466':'Pinellas County Schools',
        '5f2609807a1c0000950bb471':'Racine Unified Schools',
        '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
        '5f2609807a1c0000950bb478':'San Diego Unified School District',
        '5f2609807a1c0000950bb470':'San Leandro Unified School District',
        '5f2609807a1c0000950bb477':'Sarasota County',
        '5f2609807a1c0000950bb473':'Skillman Foundation',
        '5f2609807a1c0000950bb46a':'Springfield Public Schools',
        '5f2609807a1c0000950bb468':'Utah Board of Education',
        '5f698b826451a9089d7d4008':'Wayne Metro',
        '5f2609807a1c0000950bb45b':'Westfield Public School District',
        '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
        '5f2609807a1c0000950bb45d':'Youngstown',
        '5f2609807a1c0000950bb464':'Equity Education',
        '5f2609807a1c0000950bb469':'LSF -  Head Start',
        '5f2609807a1c0000950bb46e':'District 25 New York Schools',
        '5f2609807a1c0000950bb46f':'Paradise Schools',
        '5f2609807a1c0000950bb479':'Panorama Education',
        '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
        '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
        '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
        '5fe2e25d4d0ca68d7baf889d':'BGCA',
        '5fe318b14d0ca68d7baf889e':'BLUE',
        '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
        '6017ab3043ca9c39151838d4':'Oswego School District',
        '60239a84e57dc27613699d57':'Austin Independent School District',
        '6023a6d79e8e623753fc305c':'Boulder Valley School District',
        '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
        '6023a7269e8e623753fc305e':'Fulton County School System',
        '6023a7499e8e623753fc305f':'Manatee County School District',
        '6023a76f9e8e623753fc3060':'San Jose Unified School District',
        '6023a7949e8e623753fc3061':'Wasatch County School District'}
        district=disdic[name1]
        
        collection1 = db.school_master
        user1=[
           {"$match":{"$and":[{'NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'NAME':{"$ne":""}},
        {"CATEGORY":{'$regex':district,'$options':'i'}},                       
        ]}},
        { "$project":{ 
        #     "SCHOOL NAME":"$NAME", "ADDRESS":1, "STATE":1, "CITY":1, "DISTRICT NAME": "$CATEGORY",
                      "SCHOOL_ID":"$_id","_id":0,
        #               "SIGN UP DATE":"$CREATED_DATE"
                     }}
            ]
        update1=list(collection1.aggregate(user1))
        df=pd.DataFrame(update1)
        list_of_names=df["SCHOOL_ID"].to_list()
        
        collection2 = db.user_master
        user2=[
            {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_NAME":{ "$ne": ""}},
                       {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"EMAIL_ID":{ "$ne": ""}},  
                {'IS_BLOCKED':{"$ne":'Y'}}, 
                {'IS_DISABLED':{"$ne":'Y'}}, 
                {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {"schoolId._id":{"$in":list_of_names}}   
                            ]}},
        #  {"$group":{"_id":"$schoolId._id","School_User_count":{"$addToSet":"$_id"},

        #                'School_id':{'$first':'$schoolId._id'},
        #               }},
            { "$project": {
        #         "SCHOOL ID":"$schoolId._id","_id":0, "USER NAME":"$USER_NAME","USER EMAIL":"$EMAIL_ID",
                           "USER_ID":"$_id","_id":0, 
        #         "CREATED_DATE" : 1,
        #                    "School_User_count":{"$size":"$School_User_count"}
                          }}  
        ]
        update2=list(collection2.aggregate(user2))
        df1=pd.DataFrame(update2)
        list_of_names1=df1["USER_ID"].to_list()

        collection3 = db.audio_track_master
        user3=[
        {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
                               {"USER_ID.USER_NAME":{ "$ne": ""}},
                       {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
                          {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
                         {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
                           # {"schoolId":{"$exists":1 }}, # remove for family
                 {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
                 {'MODIFIED_DATE':{"$gte":myDatetime}},         
                {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
         #       { "USER_ID.ROLE_ID.ROLE_NAME":{'$not': { "$regex": "PRESENT","$options":"i"}}},
         #       { "USER_ID.ROLE_ID.ROLE_ID":{'$ne': 3}},
             { "USER_ID._id":{"$in":list_of_names1}},
            #"IS_ADMIN":"Y"}},
         #  {"USER_ID.schoolId._id":ObjectId('5f4f85ef6556502c6c845fce')}
                              ] }},
            { "$project": { "MODIFIED_DATE":{"$dateToString":{"format":"%Y-%m-%d","date":'$MODIFIED_DATE'}},
                           "CURSOR_END":1,"cursorStart":1}},

            {"$group":{"_id": "$MODIFIED_DATE","PRACTICE_COUNT":{"$sum":1},
            "MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}}, 

                      }},
        { "$project": {"MINDFUL_MINUTES":1,"PRACTICE_COUNT":1}}
        ]
        update3=list(collection3.aggregate(user3))
        df2=pd.DataFrame(update3).fillna(0)
        
        if df2.empty:
            temp={'data':[]}
            return (temp)
        else: 
            df14i=df2[["_id","PRACTICE_COUNT"]]
            df14i['_id'] = pd.to_datetime(df14i['_id'])
            df15i=df14i.sort_values(by='_id')
            df15i['_id']=df15i['_id'].astype(np.int64)/int(1e6)
            shp=df15i[["_id","PRACTICE_COUNT"]].values.tolist()
            df15i['Cumulative_Amount'] = df15i['PRACTICE_COUNT'].cumsum()
            df16i=df15i[['_id','Cumulative_Amount']]
            shpcum=df16i.values.tolist()
            temp={'data':{'shp':shp,'shpcum':shpcum}}
            return (temp)
        
    dict={"Info1":districtcomparisoninfo(name),"Chart1":districtcomparisonchart(name),
          "Info2":districtcomparisoninfo1(name1),"Chart2":districtcomparisonchart1(name1)}
    return json.dumps(dict)


# @app.route('/AVG_audio_completion_daily_greater_than50/<datestr>')

# def avg_audio_completed_greater_than_50___(datestr):
#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
#     db=client.compass
#     collection1= db.audio_track_master
    
#     mydatetime= dateutil.parser.parse(datestr)
#     yester= pd.to_datetime(mydatetime) - timedelta(days=1)
#     tod= mydatetime
#     start_15day=tod- timedelta(days=8)
#     startend= start_15day+timedelta(days=1)
    

#     qr1=[{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte': yester, '$lt':tod
#     }},
#     ]}},


#     {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
#                  'AUDIO_ID':'$PROGRAM_AUDIO_ID.AUDIO_ID', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
#               'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

#     }}]

#     list1= list(collection1.aggregate(qr1))
#     userprac_trend= DataFrame(list1)

#     userprac_trend.start.fillna(0, inplace=True)

#     userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

#     userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

#     #     userprac_trend_1=userprac_trend[userprac_trend.completed_precentage>=75]
#     # d=userprac_trend.groupby('AUDIO_ID')['completed_precentage'].mean().reset_index()

#     userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

#     # dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)



#     userprac_trend=userprac_trend[userprac_trend.completed_precentage >50]
# #     userprac_trend[userprac_trend.completed_precentage < 0]=0
#     # d['completed_precentage']=round(d['completed_precentage'],0)

#     dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

#     dd['cumulativesum_line']= dd['Audio_Count'].cumsum()

#     # dd[dd.completed_precentage< 0]=0


#     percentage_of_audio_completed= dd.completed_precentage.tolist(),
#     number_of_audios_compelted=dd.Audio_Count.tolist()
#     cumulative_audio_completion=dd.cumulativesum_line.tolist()

#     temp={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
#          'cumulative_audio_completion':cumulative_audio_completion}

#     data={'temp':temp}

#     return json.dumps(data)


@app.route('/AVG_audio_completion_daily_less_than50/<datestr>')
def avg_audio_completed_____(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass

    collection1= db.audio_track_master
    mydatetime= dateutil.parser.parse(datestr)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)


    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': yester, '$lte':tod
    }},
    ]}},


    {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
                 'AUDIO_ID':'$PROGRAM_AUDIO_ID._id', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
              'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

    }}]

    list1= list(collection1.aggregate(qr1))
    userprac_trend= DataFrame(list1)

    userprac_trend.start.fillna(0, inplace=True)

    userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

    userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

    userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

    dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

    userprac_trend[userprac_trend.completed_precentage < 0]=0

    
    userprac_trend['start']=userprac_trend['start'].fillna(0)
    userprac_trend['end']=userprac_trend['end'].fillna(0)
    userprac_trend['completed_precentage']=userprac_trend['completed_precentage'].fillna(0)
    userprac_trend['AUDIO_ID']=userprac_trend['AUDIO_ID'].fillna(0)

    
    dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

    dd['cumulativesum_line']= dd['Audio_Count'].cumsum()


    percentage_of_audio_completed= dd.completed_precentage.tolist(),
    number_of_audios_compelted=dd.Audio_Count.tolist()
    cumulative_audio_completion=dd.cumulativesum_line.tolist()

    temp={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
         'cumulative_audio_completion':cumulative_audio_completion}

    data={'temp':temp}


    return json.dumps(data)

# blaaaa
    # client = MongoClient('mongodb://IE-tech:I#^m0NgO_2o20!@35.88.43.45:27017/')

@app.route('/ratingcardsdaily_card/<datestr>')
def dailyfeedback_ratingssss___(datestr):
    import datetime
    import math
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection2=db.audio_feedback
    mydatetime= dateutil.parser.parse(datestr)
    #     yester= pd.to_datetime(mydatetime) - timedelta(days=1)
    #     tod= mydatetime
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)


    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)


    #TEACHERS COMMENT PER FEEDBACK LAST WEEK
    query1=[
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lte':tod}}    ,    
    #         {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed=list(collection2.aggregate(query1))
    if len(commentsonfeed)>0:
        commentsonfeedback=pd.DataFrame(commentsonfeed)
        comments_per_feedback_teacher=commentsonfeedback[['rating']]
    else:
        comments_per_feedback_teacher=pd.DataFrame({'rating':[0]})


    #PARENTS COMMENT PER FEEDBACK LAST WEEK
    querya=[
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lte':tod}}    ,    
    #        {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}}]}},


    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed2=list(collection2.aggregate(querya))
    if len(commentsonfeed2)>0:
        commentsonfeedback2=pd.DataFrame(commentsonfeed2)
        comments_per_feedback_parents=commentsonfeedback2[['rating']]
    else:
        comments_per_feedback_parents=pd.DataFrame({'rating':[0]})



    #TEACHERS COMMENT PER FEEDBACK before LAST WEEK
    query4=[
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lte':startend}}    ,   
    #        {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed11=list(collection2.aggregate(query4))
    if len(commentsonfeed11)>0:
        commentsonfeedback11=pd.DataFrame(commentsonfeed11)
        comments_per_feedback_before_last_week_teachers=commentsonfeedback11[['rating']]
    else:
        comments_per_feedback_before_last_week_teachers=pd.DataFrame({'rating':[0]})



    #  PARENTS COMMENT PER FEEDBACK before LAST WEEK
    queryB=[
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lt':startend}},    
    #         {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}}]}},


    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed200=list(collection2.aggregate(queryB))
    if len(commentsonfeed200)>0:
        commentsonfeedback20=pd.DataFrame(commentsonfeed200)
        comments_per_feedback_before_last_week_parents=commentsonfeedback20[['rating']]
    else:
        comments_per_feedback_before_last_week_parents=pd.DataFrame({'rating':[0]})



    # AVERAGE FEEDBACK RATING LAST WEEK
    query6=[
    {"$match":{'$and':[
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lt':tod}}    ,    
    #         {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}}]}},
    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rating=list(collection2.aggregate(query6))
    if len(avg_rating)>0:
        avg_ratings=pd.DataFrame(avg_rating)
        avg_ratings_lastweek=avg_ratings[['RATING']]
        avg_ratings_last_week=pd.DataFrame({'avg_ratings_lastweek':round(avg_ratings_lastweek[avg_ratings_lastweek['RATING']!=0]['RATING'].mean(),1)}, index=[0])
    else:
        avg_ratings_lastweek=pd.DataFrame({'RATING':[0]})
        avg_ratings_last_week=pd.DataFrame({'avg_ratings_lastweek':[0]})





    query60=[
    {"$match":{'$and':[
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lt':startend}}    ,   
    #         {'COMMENT':{'$nin':['',' ',None]}},

    {'RATING':{'$ne':0}}]}},

    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rate=list(collection2.aggregate(query60))
    if len(avg_rate)>0:
        avg_ratin=pd.DataFrame(avg_rate)
        avg_ratings_before_lastweek=avg_ratin[['RATING']]
        avg_ratings_beforee_last_week=pd.DataFrame({'avg_ratings_before_lastweek':round(avg_ratings_before_lastweek[avg_ratings_before_lastweek['RATING']!=0]['RATING'].mean(),1)}, index=[0])
    else:
        avg_ratings_before_lastweek=pd.DataFrame({'RATING':[0]})
        avg_ratings_beforee_last_week=pd.DataFrame({'avg_ratings_before_lastweek':[0]})



    TEACHER_Comment_per_feedbackchange=[]
    teacher_PERCENTAGE_change=[]
    if comments_per_feedback_before_last_week_teachers['rating'].iloc[0]> comments_per_feedback_teacher['rating'].iloc[0]:
        xx=comments_per_feedback_before_last_week_teachers['rating'].iloc[0]-comments_per_feedback_teacher['rating'].iloc[0]
        if comments_per_feedback_before_last_week_teachers['rating'].iloc[0]==0:
            yy= round(xx/1*100,2)
        else:
            yy=xx/comments_per_feedback_before_last_week_teachers['rating'].iloc[0]


    #     if math.isnan(yy):
    #         yy=0
    #     else:
    #         yy=yy
    #     zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('-1')
        teacher_PERCENTAGE_change.append(yy)

    elif comments_per_feedback_teacher['rating'].iloc[0] == comments_per_feedback_before_last_week_teachers['rating'].iloc[0]:
        xx=comments_per_feedback_teacher['rating'].iloc[0]-comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        yy= xx/comments_per_feedback_teacher['rating'].iloc[0]
    #     if math.isnan(yy):
    #         yy=0
    #     else:
    #         yy=yy
    #     zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('0')
        teacher_PERCENTAGE_change.append(yy)

    else:
        pp=comments_per_feedback_teacher['rating'].iloc[0]-comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        if comments_per_feedback_before_last_week_teachers['rating'].iloc[0]==0:
            qq= round(pp/1*100,2)
        else:
            qq= pp/comments_per_feedback_before_last_week_teachers['rating'].iloc[0]


    #     if math.isnan(qq):
    #         qq=0
    #     else:
    #         qq=qq 
    #     rr=round(qq*100,2)
        TEACHER_Comment_per_feedbackchange.append('1')
        teacher_PERCENTAGE_change.append(qq)
        
    import math
    teacher_PERCENTAGE_change=[0 if math.isnan(i) else i for i in teacher_PERCENTAGE_change] 


    PARENT_Comment_per_feedbackchange=[]
    parent_PERCENTAGE_change=[]
    if comments_per_feedback_before_last_week_parents['rating'].iloc[0]> comments_per_feedback_parents['rating'].iloc[0]:
        pp=comments_per_feedback_before_last_week_parents['rating'].iloc[0]- comments_per_feedback_parents['rating'].iloc[0]
        if comments_per_feedback_before_last_week_parents['rating'].iloc[0]==0:
            qq=round(pp/1*100,2)
        else:
            qq= pp/comments_per_feedback_before_last_week_parents['rating'].iloc[0]
    #     if math.isnan(qq):
    #         qq=0
    #     else:
    #         qq=qq 
    #     rr=round(qq*100,2)
        PARENT_Comment_per_feedbackchange.append('-1')
        parent_PERCENTAGE_change.append(qq)

    elif comments_per_feedback_parents['rating'].iloc[0] == comments_per_feedback_before_last_week_parents['rating'].iloc[0]:
        pp=comments_per_feedback_parents['rating'].iloc[0]-comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        qq= pp/comments_per_feedback_parents['rating'].iloc[0]
    #     if math.isnan(qq):
    #         qq=0
    #     else:
    #         qq=qq 
    #     rr=round(qq*100,2)
        PARENT_Comment_per_feedbackchange.append('0')
        parent_PERCENTAGE_change.append(qq)

    else:
        pp=comments_per_feedback_parents['rating'].iloc[0]-comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        if comments_per_feedback_before_last_week_parents['rating'].iloc[0]==0:
            qq= round(pp/1*100,2)
        else:
            qq= pp/comments_per_feedback_before_last_week_parents['rating'].iloc[0]


    #     if math.isnan(qq):
    #         qq=0
    #     else:
    #         qq=qq 
    #     rr=round(qq*100,2)
        PARENT_Comment_per_feedbackchange.append('1')
        parent_PERCENTAGE_change.append(qq)
    
    import math
    parent_PERCENTAGE_change=[0 if math.isnan(i) else i for i in parent_PERCENTAGE_change] 
    


    Average_FEEDBACK_Rating_change=[]
    Average_feedback_PERCENTAGE=[]
    if avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]> avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]:
        aa=avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]- avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
        if avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]==0:
            bb= round(aa/1*100,2)
        else:
            bb= aa/avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]


    #     if math.isnan(bb):
    #         bb=0
    #     else:
    #         bb=bb            
    #     cc= round(bb*100,2)
        Average_FEEDBACK_Rating_change.append('-1')
        Average_feedback_PERCENTAGE.append(bb)


    elif avg_ratings_last_week['avg_ratings_lastweek'].iloc[0] == avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]:
        aa=avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]-avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        bb= aa/avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
    #     if math.isnan(bb):
    #         bb=0
    #     else:
    #         bb=bb            
    #     cc= round(bb*100,2)
        Average_FEEDBACK_Rating_change.append('0')
        Average_feedback_PERCENTAGE.append(bb)

    else:
        aa=avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]-avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        if avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]==0:
            bb= round(aa/1*100,2)
        else:
            bb= aa/avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]


    #     if math.isnan(bb):
    #         bb=0
    #     else:
    #         bb=bb            
    #     cc= round(bb*100,2)

        Average_FEEDBACK_Rating_change.append('1')
        Average_feedback_PERCENTAGE.append(bb)



    data_final=pd.DataFrame({'TEACHER_FEEDBACK_RATING_LAST_WEEK':comments_per_feedback_teacher['rating'].tolist(),
                             'TEACHER_FEEDBACK_RATING_BEFORE_LAST_WEEK':comments_per_feedback_before_last_week_teachers['rating'].tolist(),

    'PARENT_FEEDBACK_RATING_LAST_WEEK':comments_per_feedback_parents['rating'].tolist(),
    'PARENT_FEEDBACK_RATING_BEFORE_LAST_WEEK':comments_per_feedback_before_last_week_parents['rating'].tolist(),

     'avg_ratings_before_lastweek':avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].tolist(),
     'Average_Rating_lastweek':avg_ratings_last_week['avg_ratings_lastweek'].tolist(),

      'TEACHER_Comment_per_feedbackchange':TEACHER_Comment_per_feedbackchange,
       'teacher_PERCENTAGE_change':teacher_PERCENTAGE_change,                      
      'PARENT_Comment_per_feedbackchange':PARENT_Comment_per_feedbackchange,
       'parent_PERCENTAGE_change':parent_PERCENTAGE_change,                      
      'Average_FEEDBACK_Rating_change':Average_FEEDBACK_Rating_change,
       'Average_feedback_PERCENTAGE':Average_feedback_PERCENTAGE                   
                                })   


    temp={}
    for j in range(len(data_final.columns)):
        key = data_final.columns[j]
        value = [str(data_final[data_final.columns[j]].iloc[0])]
        temp.update({key:value})
        #     print(temp)
    return json.dumps(temp)


@app.route('/last_day_pr/<datestr>')
def practice_cards_24hrs____(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master
    mydatetime= dateutil.parser.parse(datestr)
#     -timedelta(hours=24)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
#     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': yester, '$lt':tod
    }},
    ]}},

    {'$group':{'_id':'null', 

    'parents_playback_24hr': {'$sum':{'$cond':[{'$eq':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_24hr': {'$sum':{'$cond':[{'$ne':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_24hr': {'$sum':1}            
    }}]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    df_atm1[['parents_playback_24hr', 'teachers_playback_24hr','total_playback_24hr']]




    qr2=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start_15day
                , '$lte': startend
    }},
    ]}},

    {'$group':{'_id':'null', 

    'parents_playback_48hrs': {'$sum':{'$cond':[{'$eq':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_48hrs': {'$sum':{'$cond':[{'$ne':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_48hrs': {'$sum':1}            
    }}]

    list2= list(collection1.aggregate(qr2))
    df_atm2= DataFrame(list2)
    df_atm2[['parents_playback_48hrs', 'teachers_playback_48hrs','total_playback_48hrs']]




    PARENTSCHANGE=[]
    PARENT_percentagechange=[]
    if df_atm2['parents_playback_48hrs'].iloc[0] > df_atm1['parents_playback_24hr'].iloc[0]:
        xx=df_atm2['parents_playback_48hrs'].iloc[0]-df_atm1['parents_playback_24hr'].iloc[0]
        if df_atm2['parents_playback_48hrs'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:
            yy=xx/df_atm2['parents_playback_48hrs'].iloc[0]
            
#         if math.isnan(yy):
#             yy=0
#         else:
#             yy=yy
#         zz= round(yy*100,2)
        PARENTSCHANGE.append('-1')
        PARENT_percentagechange.append(yy)

    elif df_atm2['parents_playback_48hrs'].iloc[0] == df_atm1['parents_playback_24hr'].iloc[0]:
        xx=df_atm2['parents_playback_48hrs'].iloc[0]-df_atm1['parents_playback_24hr'].iloc[0]
        yy= xx/df_atm2['parents_playback_48hrs'].iloc[0]
        if math.isnan(yy):
            yy=0
        else:
            yy=yy
        zz= round(yy*100,2)
        PARENTSCHANGE.append('0')
        PARENT_percentagechange.append(zz)

    else:
        xx=df_atm1['parents_playback_24hr'].iloc[0]-df_atm2['parents_playback_48hrs'].iloc[0]
        if df_atm2['parents_playback_48hrs'].iloc[0]==0:
            yy= round(xx/1*100,2)
        else:
            yy= xx/df_atm2['parents_playback_48hrs'].iloc[0]
            
#         if math.isnan(yy):
#             yy=0
#         else:
#             yy=yy
#         zz= round(yy*100,2)
        PARENTSCHANGE.append('1')
        PARENT_percentagechange.append(yy)



    TEACHERSCHANGE=[]
    TEACHER_percentagechange=[]
    if df_atm2['teachers_playback_48hrs'].iloc[0] > df_atm1['teachers_playback_24hr'].iloc[0]:
        aa=df_atm2['teachers_playback_48hrs'].iloc[0]-df_atm1['teachers_playback_24hr'].iloc[0]
        if df_atm2['teachers_playback_48hrs'].iloc[0]==0:
            bb=round(aa/1*100,2)
        else:            
            bb= aa/df_atm2['teachers_playback_48hrs'].iloc[0]   
#         if math.isnan(bb):
#             bb=0
#         else:
#             bb=bb
#         cc= round(bb*100,2)
        TEACHERSCHANGE.append('-1')
        TEACHER_percentagechange.append(bb)

    elif df_atm2['teachers_playback_48hrs'].iloc[0] == df_atm1['teachers_playback_24hr'].iloc[0]:
        aa=df_atm2['teachers_playback_48hrs'].iloc[0]-df_atm1['teachers_playback_24hr'].iloc[0]
        bb= aa/df_atm2['teachers_playback_48hrs'].iloc[0]
        if math.isnan(bb):
            bb=0
        else:
            bb=bb
        cc= round(bb*100,2)
        TEACHERSCHANGE.append('0')
        TEACHER_percentagechange.append(cc)


    else:
        aa=df_atm1['teachers_playback_24hr'].iloc[0]-df_atm2['teachers_playback_48hrs'].iloc[0]
        if df_atm2['teachers_playback_48hrs'].iloc[0]==0:
            bb= round(aa/1*100,2)
        else:
            
            bb= aa/df_atm2['teachers_playback_48hrs'].iloc[0]
#         if math.isnan(bb):
#             bb=0
#         else:
#             bb=bb
#         cc= round(bb*100,2)
        TEACHERSCHANGE.append('1')
        TEACHER_percentagechange.append(bb)


    TOTALCHANGE=[]
    TOTAL_percentagechange=[]
    if df_atm2['total_playback_48hrs'].iloc[0] > df_atm1['total_playback_24hr'].iloc[0]:
        pp=df_atm2['total_playback_48hrs'].iloc[0]-df_atm1['total_playback_24hr'].iloc[0]
        if df_atm2['total_playback_48hrs'].iloc[0]==0:
            qq= round(pp/1*100,2)
        else:
            
            qq= pp/df_atm2['total_playback_48hrs'].iloc[0]
#         if math.isnan(qq):
#             qq=0
#         else:
#             qq=qq
#         rr= round(qq*100,2)
        TOTALCHANGE.append('-1')
        TOTAL_percentagechange.append(qq)


    elif df_atm2['total_playback_48hrs'].iloc[0] == df_atm1['total_playback_24hr'].iloc[0]:
        pp=df_atm2['total_playback_48hrs'].iloc[0]-df_atm1['total_playback_24hr'].iloc[0]
        qq= pp/df_atm2['total_playback_48hrs'].iloc[0]
        if math.isnan(qq):
            qq=0
        else:
            qq=qq
        rr= round(qq*100,2)
        TOTALCHANGE.append('0')
        TOTAL_percentagechange.append(rr)


    else: 
        pp=df_atm1['total_playback_24hr'].iloc[0]-df_atm2['total_playback_48hrs'].iloc[0]
        if df_atm2['total_playback_48hrs'].iloc[0]==0:
            qq= round(pp/1*100,2)
        else:
            
            qq= pp/df_atm2['total_playback_48hrs'].iloc[0]
#         if math.isnan(qq):
#             qq=0
#         else:
#             qq=qq
#         rr= round(qq*100,2)
        TOTALCHANGE.append('1')
        TOTAL_percentagechange.append(qq)


    parents_playback_24hr=df_atm1['parents_playback_24hr'].tolist()
    teachers_playback_24hr=df_atm1['teachers_playback_24hr'].tolist()
    total_playback_24hr=df_atm1['total_playback_24hr'].tolist()
    parents_playback_48hrs =df_atm2['parents_playback_48hrs'].tolist()
    teachers_playback_48hrs= df_atm2['teachers_playback_48hrs'].tolist()
    total_playback_48hrs= df_atm2['total_playback_48hrs'].tolist()


    temp={'parents_playback_24hr':parents_playback_24hr, 'PARENTSCHANGE':PARENTSCHANGE, 'PARENT_percentagechange':PARENT_percentagechange,
          'teachers_playback_24hr':teachers_playback_24hr, 'TEACHERSCHANGE':TEACHERSCHANGE, 'TEACHER_percentagechange':TEACHER_percentagechange,
          'total_playback_24hr':total_playback_24hr, 'TOTALCHANGE':TOTALCHANGE, 'TOTAL_percentagechange':TOTAL_percentagechange,
          'parents_playback_48hrs':parents_playback_48hrs, 'teachers_playback_48hrs':teachers_playback_48hrs,
          'total_playback_48hrs':total_playback_48hrs
         }
    
    return json.dumps(temp)



@app.route('/SIGNUPS_dailycomparsion/<datestr>') #test3
def SIGNUP_cards_24hrs___(datestr):
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.user_master

    mydatetime= dateutil.parser.parse(datestr)
#     -timedelta(hours=24)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)

#     yesterday = pd.to_datetime(mydatetime) - timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)

#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)

#     tod= today

#     start= tod-timedelta(days=1)
#     yester= yesterday

#     start_15day=tod-timedelta(days=8)
#     startend= start_15day+timedelta(days=1)

    qr1=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gt':yester , '$lte':tod}}
    ]}},
    {'$group':{'_id':'null', 
    'parents_signup_last_week': {'$sum':{'$cond':[{'$eq':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_signup_last_week': {'$sum':{'$cond':[{'$ne':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_signup_last_week': {'$sum':1}            
    }}]
    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
    df_atm1=df_atm[['parents_signup_last_week', 'teachers_signup_last_week','total_signup_last_week']]
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start_15day
                , '$lt': startend}}
    ]}},
    {'$group':{'_id':'null', 
    'parents_signup_last_to_lastweek': {'$sum':{'$cond':[{'$eq':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_signup_last_to_lastweek': {'$sum':{'$cond':[{'$ne':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_signup_last_to_lastweek': {'$sum':1}            
    }}]
    list2= list(collection1.aggregate(qr2))
    df_atm= DataFrame(list2)

    df_atm2=df_atm[['parents_signup_last_to_lastweek', 'teachers_signup_last_to_lastweek','total_signup_last_to_lastweek']]


    parentschange=[]
    parents_Percentage_Change=[]
    if df_atm2['parents_signup_last_to_lastweek'].iloc[0] > df_atm1['parents_signup_last_week'].iloc[0]:
        xx=df_atm2['parents_signup_last_to_lastweek'].iloc[0]-df_atm1['parents_signup_last_week'].iloc[0]
        if df_atm2['parents_signup_last_to_lastweek'].iloc[0]==0:
            yy= round(xx/1*100,2)
        else:        
            yy= xx/df_atm2['parents_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)
        parentschange.append('-1')
        parents_Percentage_Change.append(yy)

    elif df_atm2['parents_signup_last_to_lastweek'].iloc[0] == df_atm1['parents_signup_last_week'].iloc[0]:
        xx=df_atm2['parents_signup_last_to_lastweek'].iloc[0]-df_atm1['parents_signup_last_week'].iloc[0]
        if df_atm2['parents_signup_last_to_lastweek'].iloc[0] & df_atm1['parents_signup_last_week'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:
        
            yy= xx/df_atm2['parents_signup_last_to_lastweek'].iloc[0]
                
#         zz= round(yy*100,2)
        parentschange.append('0')
        parents_Percentage_Change.append(yy)

    else:
        xx=df_atm1['parents_signup_last_week'].iloc[0]-df_atm2['parents_signup_last_to_lastweek'].iloc[0]
        if df_atm2['parents_signup_last_to_lastweek'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:
            
            yy= xx/df_atm2['parents_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)
        parentschange.append('1')
        parents_Percentage_Change.append(yy)


    teacherschange=[]
    Teacher_percentage_change=[]
    if df_atm2['teachers_signup_last_to_lastweek'].iloc[0] > df_atm1['teachers_signup_last_week'].iloc[0]:
        xx=df_atm2['teachers_signup_last_to_lastweek'].iloc[0]-df_atm1['teachers_signup_last_week'].iloc[0]
        yy= xx/df_atm2['teachers_signup_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('-1')
        Teacher_percentage_change.append(zz)

    elif df_atm2['teachers_signup_last_to_lastweek'].iloc[0] == df_atm1['teachers_signup_last_week'].iloc[0]:
        xx=df_atm2['teachers_signup_last_to_lastweek'].iloc[0]-df_atm1['teachers_signup_last_week'].iloc[0]
        if df_atm2['teachers_signup_last_to_lastweek'].iloc[0] &df_atm1['teachers_signup_last_week'].iloc[0]==0:
            yy= round(xx/1*100,2)
        else:
            yy= xx/df_atm2['teachers_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)

        teacherschange.append('0')
        Teacher_percentage_change.append(yy)

    else:
        xx=df_atm1['teachers_signup_last_week'].iloc[0]-df_atm2['teachers_signup_last_to_lastweek'].iloc[0]
        if df_atm2['teachers_signup_last_to_lastweek'].iloc[0]==0:
            yy= round(xx/1*100,2)
        else:
            yy= xx/df_atm2['teachers_signup_last_to_lastweek'].iloc[0]
        
#         zz= round(yy*100,2)
        teacherschange.append('1')
        Teacher_percentage_change.append(yy)


    totalchange=[]
    Total_percentage_change=[]
    if df_atm2['total_signup_last_to_lastweek'].iloc[0] > df_atm1['total_signup_last_week'].iloc[0]:
        xx=df_atm2['total_signup_last_to_lastweek'].iloc[0]-df_atm1['total_signup_last_week'].iloc[0]
        
        if df_atm2['total_signup_last_to_lastweek'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:
            
            yy= xx/df_atm2['total_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)
        totalchange.append('-1')
        Total_percentage_change.append(yy)
        
    elif df_atm2['total_signup_last_to_lastweek'].iloc[0] == df_atm1['total_signup_last_week'].iloc[0]:        
        xx=df_atm2['total_signup_last_to_lastweek'].iloc[0]-df_atm1['total_signup_last_week'].iloc[0]
        if df_atm2['total_signup_last_to_lastweek'].iloc[0] & df_atm1['total_signup_last_week'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:
            yy= xx/df_atm2['total_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)
        totalchange.append('0')
        Total_percentage_change.append(yy)
    else:
        xx=df_atm1['total_signup_last_week'].iloc[0]-df_atm2['total_signup_last_to_lastweek'].iloc[0]
        if df_atm2['total_signup_last_to_lastweek'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:
            yy= xx/df_atm2['total_signup_last_to_lastweek'].iloc[0]
#         zz= round(yy*100,2)
        totalchange.append('1')
        Total_percentage_change.append(yy)


    data=pd.DataFrame({'parents_signup_yesterday':df_atm1['parents_signup_last_week'].tolist(),
                       'teachers_signup_yesterday':df_atm1['teachers_signup_last_week'].tolist(),
    'total_signup_yesterday':df_atm1['total_signup_last_week'].tolist(),
                       'parentschanged':parentschange, 'parents_Percentage_Change':parents_Percentage_Change,
                       'teacherschanged':teacherschange, 'Teacher_percentage_change':Teacher_percentage_change,
          'totalchanged':totalchange, 'Total_percentage_change':Total_percentage_change,
               'parents_signup_lastweek':df_atm2['parents_signup_last_to_lastweek'].tolist(),
                     'teachers_signup_lastweek':  df_atm2['teachers_signup_last_to_lastweek'].tolist(),
                'total_signup_lastweek':       df_atm2['total_signup_last_to_lastweek'].tolist()

                      })  
    temp2={}

    for j in range(len(data.columns)):
        key= data.columns[j]
        value=[str(data[data.columns[j]].iloc[0])]
        temp2.update({key:value})
    return json.dumps(temp2)






@app.route('/AVG_audio_completion_weekly_less_50/<datestr>')
def avg_audio_completed_less___(datestr):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master

    mydatetime= dateutil.parser.parse(datestr)
    # mydatetime= dateutil.parser.parse(datestr)-timedelta(hours=24)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    print(start)



    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': start, '$lt':yester
    }},
    ]}},


    {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
                 'AUDIO_ID':'$PROGRAM_AUDIO_ID._id', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
              'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

    }}]

    list1= list(collection1.aggregate(qr1))
    userprac_trend= DataFrame(list1)

    userprac_trend.start.fillna(0, inplace=True)

    userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

    userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

    #     userprac_trend_1=userprac_trend[userprac_trend.completed_precentage>=75]
    # d=userprac_trend.groupby('AUDIO_ID')['completed_precentage'].mean().reset_index()

    userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

    # dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)



    # userprac_trend=userprac_trend[userprac_trend.completed_precentage <=50]
    userprac_trend[userprac_trend.completed_precentage < 0]=0
    # d['completed_precentage']=round(d['completed_precentage'],0)
    userprac_trend

    userprac_trend['start']=userprac_trend['start'].fillna(0)
    userprac_trend['end']=userprac_trend['end'].fillna(0)
    userprac_trend['completed_precentage']=userprac_trend['completed_precentage'].fillna(0)
    userprac_trend['AUDIO_ID']=userprac_trend['AUDIO_ID'].fillna(0)

    dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

    dd['cumulativesum_line']= dd['Audio_Count'].cumsum()

    # dd[dd.completed_precentage< 0]=0


    percentage_of_audio_completed= dd.completed_precentage.tolist(),
    number_of_audios_compelted=dd.Audio_Count.tolist()
    cumulative_audio_completion=dd.cumulativesum_line.tolist()

    temp={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
         'cumulative_audio_completion':cumulative_audio_completion}

    data={'temp':temp}

    return json.dumps(data)


# @app.route('/AVG_audio_completion_weekly_more_50/<datestr>')
# def avg_audio_completed_more__(datestr):

#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
#     db=client.compass
#     collection1= db.audio_track_master
#     # datetime.datetime.now() - datetime.timedelta(days=7)
    
#     mydatetime= dateutil.parser.parse(datestr)
#     yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
#     print(yester)
#     tod=mydatetime+ timedelta(hours=4)

#     start= tod- timedelta(days=8)+timedelta(days=1)
#     print(start)





#     qr1=[{"$match":{
#     '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},

#     {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
#     {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#     {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte': start, '$lt':yester
#     }},
#     ]}},


#     {'$project':{'_id':'$USER_ID._id', 'modified_date':'$MODIFIED_DATE',
#                  'AUDIO_ID':'$PROGRAM_AUDIO_ID.AUDIO_ID', 'Program_Name':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
#               'Audio_Length':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH', 'start':'$cursorStart','end':'$CURSOR_END'             

#     }}]

#     list1= list(collection1.aggregate(qr1))
#     userprac_trend= DataFrame(list1)

#     userprac_trend.start.fillna(0, inplace=True)

#     userprac_trend.loc[(userprac_trend['Audio_Length']<userprac_trend['end']),'end'] = userprac_trend['Audio_Length']

#     userprac_trend['completed_precentage']=round(((userprac_trend.end-userprac_trend.start)/userprac_trend.Audio_Length*100),0)

#     #     userprac_trend_1=userprac_trend[userprac_trend.completed_precentage>=75]
#     # d=userprac_trend.groupby('AUDIO_ID')['completed_precentage'].mean().reset_index()

#     userprac_trend['completed_precentage']=round(userprac_trend['completed_precentage'],0)

#     # dd=userprac_trend.groupby('completed_precentage').count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)



#     userprac_trend=userprac_trend[userprac_trend.completed_precentage >50]
# #     userprac_trend[userprac_trend.completed_precentage < 0]=0
#     # d['completed_precentage']=round(d['completed_precentage'],0)

#     dd=userprac_trend.groupby('completed_precentage')['AUDIO_ID'].count().reset_index().rename({'AUDIO_ID':'Audio_Count'},axis=1)

#     dd['cumulativesum_line']= dd['Audio_Count'].cumsum()

#     # dd[dd.completed_precentage< 0]=0


#     percentage_of_audio_completed= dd.completed_precentage.tolist(),
#     number_of_audios_compelted=dd.Audio_Count.tolist()
#     cumulative_audio_completion=dd.cumulativesum_line.tolist()

#     temp={'percentage_of_audio_completed':percentage_of_audio_completed,'number_of_audios_compelted':number_of_audios_compelted,
#          'cumulative_audio_completion':cumulative_audio_completion}

#     data={'temp':temp}

#     return json.dumps(data)


@app.route('/Weekly_power_users_having_streaks/<datestr>')
def power_users_weekly___(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    mydatetime= dateutil.parser.parse(datestr)
    
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    print(start)
    
    now= mydatetime- timedelta(hours=5.5)
    print(now)

    collection= db.audio_track_master
    qratm=[{"$match":
             {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                 {'MODIFIED_DATE':{'$gte':start, '$lt':yester}},

                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{'$ne':''}},
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'USER_ID':'$USER_ID._id',
                      'EMAIL_ID':'$USER_ID.EMAIL_ID',
        'PRACTICE_DATE':'$MODIFIED_DATE'},
        }},
        ]
    bifur= list(collection.aggregate(qratm))
    blah=DataFrame(bifur)
    #     df1= blah['_id']
    df_1 = pd.json_normalize(blah['_id'])
    df_final = pd.concat([blah,df_1], axis =  1)
    df_final['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final['date_now']= yester.strftime("%Y-%m-%d")
    df_final['PRACTICE_DATE'] = pd.to_datetime(df_final['PRACTICE_DATE'])
    df_final['date_now'] = pd.to_datetime(df_final['date_now'])
    df_final['days'] = (df_final['date_now'] - df_final['PRACTICE_DATE']).dt.days
    df_final1=df_final[['USER_ID','PRACTICE_DATE','EMAIL_ID','days']]
    date_list=df_final1.PRACTICE_DATE.tolist()
    # streak_empty=[]
    days=[]

    for k in range(len(date_list)):
        z=(now-date_list[k]).days
        days.append(z)
        
    df_final1['days']=days
    df_final2=df_final1.sort_values('PRACTICE_DATE', ascending=True)
    df_final2['PRACTICE_DATE']=df_final2['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final3= df_final2.groupby(['USER_ID', 'PRACTICE_DATE']).agg({'days':['max']})
    df_final3.columns=['days_max']
    df_final3= df_final3.reset_index()
    df_final3.sort_values('PRACTICE_DATE', ascending=True)
    #     df_final3.isnull().sum()
    df1 = df_final3.groupby('USER_ID')['days_max'].apply(list).reset_index(name='grouping')
    list_of_list=df1.grouping.tolist()
    def streak_count_function(streak_list):
        streak_list.sort()
        streak_count=[]
        counter = 1
        for i in range(len(streak_list)):
            if i != (len(streak_list) - 1):
                diff = streak_list[i+1] - streak_list[i]
                if diff == 1:
                    counter += 1
                else:
                    streak_count.append(counter)
                    counter = 1
            else:
                streak_count.append(counter)
        return(max(streak_count)) 
    streak_empty=[]
    for i in range(len(list_of_list)):
        streak_empty.append(streak_count_function(list_of_list[i]))
    df1['streak_frequencyy']=streak_empty
    df22=df1.groupby(['streak_frequencyy'], as_index=False)['USER_ID'].count()
    df22 = df22.reset_index(drop=True)
    dataframe=pd.DataFrame(df22)
    dataframe.rename(columns={'USER_ID':'Number_of_classroom_users_having_streak','streak_frequencyy':'STREAK'},inplace=True)
    dfff=dataframe.sort_values('STREAK', ascending=False)
    # =====================
    collection= db.audio_track_master
    qratmm=[{"$match":
             {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                 {'MODIFIED_DATE':{'$gte':start, '$lt':yester}},

                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{'$ne':''}},
                     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'USER_ID':'$USER_ID._id',
                      'EMAIL_ID':'$USER_ID.EMAIL_ID',
        'PRACTICE_DATE':'$MODIFIED_DATE'},
        }},
        ]
    present= list(collection.aggregate(qratmm))
    blahhh=DataFrame(present)
    #     df1= blah['_id']
    df_11 = pd.json_normalize(blahhh['_id'])
    df_final_11 = pd.concat([blahhh,df_11], axis =  1)
    df_final_11['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final_11['date_now']= now.strftime("%Y-%m-%d")
    df_final_11['PRACTICE_DATE'] = pd.to_datetime(df_final_11['PRACTICE_DATE'])
    df_final_11['date_now'] = pd.to_datetime(df_final_11['date_now'])
    df_final_11['days'] = (df_final_11['date_now'] - df_final_11['PRACTICE_DATE']).dt.days
    df_final_11_11=df_final_11[['USER_ID','PRACTICE_DATE','EMAIL_ID','days']]
    date_list_=df_final_11_11.PRACTICE_DATE.tolist()
    # streak_empty=[]
    daysss=[]
    for k in range(len(date_list_)):
        z=(now-date_list_[k]).days
        daysss.append(z)
    df_final_11['daysss']=daysss
    df_final22=df_final_11.sort_values('PRACTICE_DATE', ascending=True)
    df_final22['PRACTICE_DATE']=df_final22['PRACTICE_DATE'].dt.strftime("%Y-%m-%d")
    df_final33= df_final22.groupby(['USER_ID', 'PRACTICE_DATE']).agg({'days':['max']})
    df_final33.columns=['days_max']
    df_final33= df_final33.reset_index()
    df_final33.sort_values('PRACTICE_DATE', ascending=True)
    #     df_final3.isnull().sum()
    df1111 = df_final33.groupby('USER_ID')['days_max'].apply(list).reset_index(name='grouping')
    list_of_list_=df1111.grouping.tolist()
    def streak_count_function_present(streak_list_):
        streak_list_.sort()
        streak_count_=[]
        counter = 1
        for i in range(len(streak_list_)):
            if i != (len(streak_list_) - 1):
                diff = streak_list_[i+1] - streak_list_[i]
                if diff == 1:
                    counter += 1
                else:
                    streak_count_.append(counter)
                    counter = 1
            else:
                streak_count_.append(counter)
        return(max(streak_count_)) 
    streak_emptyy=[]
    for i in range(len(list_of_list_)):
        streak_emptyy.append(streak_count_function_present(list_of_list_[i]))
    df1111['streak_frequencyy']=streak_emptyy
    df2222=df1111.groupby(['streak_frequencyy'], as_index=False)['USER_ID'].count()
    df2222 = df2222.reset_index(drop=True)
    dataframe11=pd.DataFrame(df2222)
    dataframe11.rename(columns={'USER_ID':'Number_of_present_users_having_streak','streak_frequencyy':'STREAK'},inplace=True)
    dfff11=dataframe11.sort_values('STREAK', ascending=False)
    final=dfff11.merge(dfff, on='STREAK', how='outer')
    power_user_streaks=final.sort_values('STREAK').reset_index(drop=True)
    power_user_streaks['Number_of_present_users_having_streak']=power_user_streaks['Number_of_present_users_having_streak'].fillna(0)
    power_user_streaks['Number_of_classroom_users_having_streak']=power_user_streaks['Number_of_classroom_users_having_streak'].fillna(0)
    ACTIVETREND={'STREAK':power_user_streaks['STREAK'].values.tolist(),'number_of_streaks_Home':power_user_streaks['Number_of_present_users_having_streak'].values.tolist(),'number_of_streaks_classroom':power_user_streaks['Number_of_classroom_users_having_streak'].values.tolist()}
    ACTIVETREND=[ACTIVETREND]
    return json.dumps(ACTIVETREND)

# power_users_weekly__('2021-03-22')




@app.route('/playback_cards_week/<datestr>')
def practice_cards_WEEKLY__(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    
    
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    print(start_15day)

#     tz = timezone('UTC')
#     date=datetime.datetime.now(tz) 
#     yesterday = pd.to_datetime(date) - timedelta(days=1)
#     # todaydate=today.strftime("%Y-%m-%d")
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)

#     print(yesterday,"yessss")
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
    
#     print(today,"today")
#     tod= today+ timedelta(hours=4)
# # yester-timedelta(days=8)
#     start= tod-timedelta(days=8)+timedelta(days=1)
#     yester= yesterday+timedelta(hours=4)+timedelta(days=1)
#     start_15day=tod-timedelta(days=15)+timedelta(days=1)

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'USER_ID.EMAIL_ID':{'$nin':['',' ',None]}},
    {'MODIFIED_DATE':{'$gt':start , '$lte':yester}}
    ]}},
    {'$group':{'_id':'null', 
    'parents_playback_last_week': {'$sum':{'$cond':[{'$eq':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_last_week': {'$sum':{'$cond':[{'$ne':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_last_week': {'$sum':1}                  
    }}]
    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
    df_atm1=df_atm[['parents_playback_last_week', 'teachers_playback_last_week','total_playback_last_week']]
    qr2=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start_15day
                , '$lt': start}}
    ]}},
    {'$group':{'_id':'null', 
    'parents_playback_last_to_lastweek': {'$sum':{'$cond':[{'$eq':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_last_to_lastweek': {'$sum':{'$cond':[{'$ne':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_last_to_lastweek': {'$sum':1}            
    }}]
    list2= list(collection1.aggregate(qr2))
    df_atm= DataFrame(list2)
    df_atm2=df_atm[['parents_playback_last_to_lastweek', 'teachers_playback_last_to_lastweek','total_playback_last_to_lastweek']]
    
    
    parentschange=[]
    parents_percentage_change=[]
    if df_atm2['parents_playback_last_to_lastweek'].iloc[0] > df_atm1['parents_playback_last_week'].iloc[0]:
        xx=df_atm2['parents_playback_last_to_lastweek'].iloc[0]-df_atm1['parents_playback_last_week'].iloc[0]
        yy= xx/df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('-1')
        parents_percentage_change.append(zz)

    elif df_atm2['parents_playback_last_to_lastweek'].iloc[0] == df_atm1['parents_playback_last_week'].iloc[0]:
        xx=df_atm2['parents_playback_last_to_lastweek'].iloc[0]-df_atm1['parents_playback_last_week'].iloc[0]
        yy= xx/df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('0')
        parents_percentage_change.append(zz)
        
    else:
        xx=df_atm1['parents_playback_last_week'].iloc[0]-df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('1')
        parents_percentage_change.append(zz)

    
    
    teacherschange=[]
    teachers_percentage_change=[]
    if df_atm2['teachers_playback_last_to_lastweek'].iloc[0] > df_atm1['teachers_playback_last_week'].iloc[0]:
        xx=df_atm2['teachers_playback_last_to_lastweek'].iloc[0]-df_atm1['teachers_playback_last_week'].iloc[0]
        yy= xx/df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('-1')
        teachers_percentage_change.append(zz)

    elif df_atm2['teachers_playback_last_to_lastweek'].iloc[0] == df_atm1['teachers_playback_last_week'].iloc[0]:
        xx=df_atm2['teachers_playback_last_to_lastweek'].iloc[0]-df_atm1['teachers_playback_last_week'].iloc[0]
        yy= xx/df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('0')
        teachers_percentage_change.append(zz)

    else:
        xx=df_atm1['teachers_playback_last_week'].iloc[0]-df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('1')
        teachers_percentage_change.append(zz)

    
    
    totalchange=[]
    total_percentage_change=[]
    if df_atm2['total_playback_last_to_lastweek'].iloc[0] > df_atm1['total_playback_last_week'].iloc[0]:
        xx=df_atm2['total_playback_last_to_lastweek'].iloc[0]-df_atm1['total_playback_last_week'].iloc[0]
        yy= xx/df_atm2['total_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('-1')
        total_percentage_change.append(zz)
        
    elif df_atm2['total_playback_last_to_lastweek'].iloc[0] == df_atm1['total_playback_last_week'].iloc[0]:
        xx=df_atm2['total_playback_last_to_lastweek'].iloc[0]-df_atm1['total_playback_last_week'].iloc[0]
        yy= xx/df_atm2['total_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('0')
        total_percentage_change.append(zz)

    else:
        xx=df_atm1['total_playback_last_week'].iloc[0]-df_atm2['total_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm2['total_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('1')
        total_percentage_change.append(zz)
        
        
    data=pd.DataFrame({'parents_playback_last_week':df_atm1['parents_playback_last_week'].tolist(),
                       'teachers_playback_last_week':df_atm1['teachers_playback_last_week'].tolist(),
    'total_playback_last_week':df_atm1['total_playback_last_week'].tolist(),
                       'parentschange':parentschange,'parents_percentage_change':parents_percentage_change,
                       'teacherschange':teacherschange, 'teachers_percentage_change':teachers_percentage_change,
          'totalchange':totalchange, 'total_percentage_change':total_percentage_change,
                      'teachers_playback_last_to_lastweek':df_atm2['teachers_playback_last_to_lastweek'].iloc[0],
         'parents_playback_last_to_lastweek':df_atm2['parents_playback_last_to_lastweek'].iloc[0]              
                       
                      })  
    
    
    temp2={}
    for j in range(len(data.columns)):
        key= data.columns[j]
        value=[str(data[data.columns[j]].iloc[0])]
        temp2.update({key:value})
        
        
    return json.dumps(temp2)




@app.route('/SIGNUPS_WEEK/<datestr>') #test3
def SIGNUP_cards_WEEKLYY__(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.user_master
    
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    print(start_15day)
    
    qr1=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gt':start , '$lte':yester}}

    ]}},
    {'$group':{'_id':'null', 
    'parents_playback_last_week': {'$sum':{'$cond':[{'$eq':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_last_week': {'$sum':{'$cond':[{'$ne':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_last_week': {'$sum':1}            
    }}]
    
    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
    df_atm1=df_atm[['parents_playback_last_week', 'teachers_playback_last_week','total_playback_last_week']]
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start_15day
            , '$lt': start}}
    ]}},
    {'$group':{'_id':'null', 
    'parents_playback_last_to_lastweek': {'$sum':{'$cond':[{'$eq':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_last_to_lastweek': {'$sum':{'$cond':[{'$ne':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_last_to_lastweek': {'$sum':1}            
    }}]
    list2= list(collection1.aggregate(qr2))
    df_atm= DataFrame(list2)
    df_atm2=df_atm[['parents_playback_last_to_lastweek', 'teachers_playback_last_to_lastweek','total_playback_last_to_lastweek']]
    
    parentschange=[]
    parents_percentage_change=[]
    if df_atm2['parents_playback_last_to_lastweek'].iloc[0] > df_atm1['parents_playback_last_week'].iloc[0]:
        xx=df_atm2['parents_playback_last_to_lastweek'].iloc[0]-df_atm1['parents_playback_last_week'].iloc[0]
        yy= xx/df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('-1')
        parents_percentage_change.append(zz)
        
    elif df_atm2['parents_playback_last_to_lastweek'].iloc[0] == df_atm1['parents_playback_last_week'].iloc[0]:
        xx=df_atm2['parents_playback_last_to_lastweek'].iloc[0]-df_atm1['parents_playback_last_week'].iloc[0]
        yy= xx/df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('0')
        parents_percentage_change.append(zz)

    else:
        xx=df_atm1['parents_playback_last_week'].iloc[0]-df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm2['parents_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        parentschange.append('1')
        parents_percentage_change.append(zz)
        
        
    teacherschange=[]
    teachers_percentage_change=[]
    if df_atm2['teachers_playback_last_to_lastweek'].iloc[0] > df_atm1['teachers_playback_last_week'].iloc[0]:
        xx=df_atm2['teachers_playback_last_to_lastweek'].iloc[0]-df_atm1['teachers_playback_last_week'].iloc[0]
        yy= xx/df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('-1')
        teachers_percentage_change.append(zz)
        
    elif df_atm2['teachers_playback_last_to_lastweek'].iloc[0] == df_atm1['teachers_playback_last_week'].iloc[0]:
        xx=df_atm2['teachers_playback_last_to_lastweek'].iloc[0]-df_atm1['teachers_playback_last_week'].iloc[0]
        yy= xx/df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('0')
        teachers_percentage_change.append(zz)
    
    else:
        xx=df_atm1['teachers_playback_last_week'].iloc[0]-df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm2['teachers_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('1')
        teachers_percentage_change.append(zz)
        
        
    totalchange=[]
    total_percentage_change=[]
    
    if df_atm2['total_playback_last_to_lastweek'].iloc[0] > df_atm1['total_playback_last_week'].iloc[0]:
        xx=df_atm2['total_playback_last_to_lastweek'].iloc[0]-df_atm1['total_playback_last_week'].iloc[0]
        yy= xx/df_atm2['total_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('-1')
        total_percentage_change.append(zz)
        
    elif df_atm2['total_playback_last_to_lastweek'].iloc[0] == df_atm1['total_playback_last_week'].iloc[0]:
        xx=df_atm2['total_playback_last_to_lastweek'].iloc[0]-df_atm1['total_playback_last_week'].iloc[0]
        yy= xx/df_atm2['total_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('0')
        total_percentage_change.append(zz)
        
    else:
        xx=df_atm1['total_playback_last_week'].iloc[0]-df_atm2['total_playback_last_to_lastweek'].iloc[0]
        yy= xx/df_atm2['total_playback_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        totalchange.append('1')
        total_percentage_change.append(zz)

    data=pd.DataFrame({'parents_signup_last_week':df_atm1['parents_playback_last_week'].tolist(),
                       'teachers_signup_last_week':df_atm1['teachers_playback_last_week'].tolist(),
    'total_signup_last_week':df_atm1['total_playback_last_week'].tolist(),
                       'parentschanged':parentschange, 'parents_percentage_change':parents_percentage_change,
                       'teacherschanged':teacherschange, 'teachers_percentage_change':teachers_percentage_change,
          'totalchanged':totalchange, 'total_percentage_change':total_percentage_change,
                    'teachers_signup_last_to_last_week'  :df_atm2['teachers_playback_last_to_lastweek'],
                       'parents_signup_last_to_last_week':df_atm2['teachers_playback_last_to_lastweek'],
                       
                      })  
    temp2={}
    for j in range(len(data.columns)):
        key= data.columns[j]
        value=[str(data[data.columns[j]].iloc[0])]
        temp2.update({key:value})
    return json.dumps(temp2)



@app.route('/comparison1/<datestr>') #test2
def weekly_compare_chart___(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    
    
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    print(start_15day)
    
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     tod= today+ timedelta(hours=4)
#     # yester-timedelta(days=8)
#     start= tod-timedelta(days=8)+timedelta(days=1)
#     yester= yesterday+timedelta(hours=4)+timedelta(days=1)
#     start_15day=tod-timedelta(days=15)+timedelta(days=1)
    
    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            
            {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
      
#     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start , '$lt':yester
    }},
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_WEEK_PRACTICE_parents':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
    df_atm
    LAST_WEEK_PRACTICE_parents=df_atm[['_id','LAST_WEEK_PRACTICE_parents']]
    qr2=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
               {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},        
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start_15day
                    , '$lt': start}}
        ]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_TO_LAST_WEEK_PRACTICE_parents':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list2= list(collection1.aggregate(qr2))
    df_at2m= DataFrame(list2)
    LAST_TO_LAST_WEEK_PRACTICE_parents=df_at2m[['_id','LAST_TO_LAST_WEEK_PRACTICE_parents']]
    join_final1= pd.merge(LAST_WEEK_PRACTICE_parents, LAST_TO_LAST_WEEK_PRACTICE_parents, on='_id', how='left')    
# =========================================
    qr3=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
    {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},      
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start , '$lt':yester
    }},
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_WEEK_PRACTICE_TEACHERS':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list3= list(collection1.aggregate(qr3))
    df_atm3= DataFrame(list3)
    df_atm3
    LAST_WEEK_PRACTICE_TEACHERS=df_atm3[['_id','LAST_WEEK_PRACTICE_TEACHERS']]
    qr4=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
         {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},       
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start_15day
                    , '$lt': start}}
        ]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_TO_LAST_WEEK_PRACTICE_teachers':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list4= list(collection1.aggregate(qr4))
    df_atm4= DataFrame(list4)
    LAST_TO_LAST_WEEK_PRACTICE_teachers=df_atm4[['_id','LAST_TO_LAST_WEEK_PRACTICE_teachers']]
    join_final2= pd.merge(LAST_WEEK_PRACTICE_TEACHERS, LAST_TO_LAST_WEEK_PRACTICE_teachers, on='_id', how='left') 
    
        
        
# =========================================
    qr5=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
     {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
     {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},      
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start , '$lt':yester
    }},
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_WEEK_PRACTICE_schoology':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list5= list(collection1.aggregate(qr5))
    df_atm5= DataFrame(list5)
    df_atm5
    LAST_WEEK_PRACTICE_schoology=df_atm5[['_id','LAST_WEEK_PRACTICE_schoology']]
    qr6=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
         {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},      
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start_15day
                    , '$lt': start}}
        ]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_TO_LAST_WEEK_PRACTICE_schoology':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list6= list(collection1.aggregate(qr6))
    df_atm6= DataFrame(list6)
    LAST_TO_LAST_WEEK_PRACTICE_schoology=df_atm6[['_id','LAST_TO_LAST_WEEK_PRACTICE_schoology']]
    join_final3= pd.merge(LAST_WEEK_PRACTICE_schoology, LAST_TO_LAST_WEEK_PRACTICE_schoology, on='_id', how='left') 
       
# =========================================
    qr7=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
     {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
     {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},      
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start , '$lt':yester
    }},
    ]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_WEEK_PRACTICE_clever':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list7= list(collection1.aggregate(qr7))
    df_atm7= DataFrame(list7)
    df_atm7
    LAST_WEEK_PRACTICE_clever=df_atm7[['_id','LAST_WEEK_PRACTICE_clever']]
    qr8=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
         {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},         
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start_15day
                    , '$lt': start}}
        ]}},
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
    'LAST_TO_LAST_WEEK_PRACTICE_clever':{'$sum':1}
    }}, {'$sort':{'_id':1}}
     ]
    list8= list(collection1.aggregate(qr8))
    df_atm8= DataFrame(list8)
    LAST_TO_LAST_WEEK_PRACTICE_clever=df_atm8[['_id','LAST_TO_LAST_WEEK_PRACTICE_clever']]
    join_final4= pd.merge(LAST_WEEK_PRACTICE_clever, LAST_TO_LAST_WEEK_PRACTICE_clever, on='_id', how='left') 
    
    days=pd.DataFrame({'_id':[1,2,3,4,5,6,7],'day':['Sunday', 'Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']})
    
    df1=pd.merge(days,join_final1, on='_id',how='left')
    df2=pd.merge(df1,join_final2, on='_id',how='left')
    df3=pd.merge(df2,join_final3, on='_id',how='left')
    df4=pd.merge(df3,join_final4, on='_id',how='left').fillna(0)
    df4=df4.astype(int, errors='ignore')
    df4.columns
    lists=[]
    
    for i in df4.columns:
        
        i=df4[i].tolist()
        lists.append(i)  
    weekdata={"day":lists[1],
     "count_last_week_parents":lists[2],
    'count_last_to_lastweek_parents':lists[3],
    'count_last_week_teachers':lists[4],
    'count_last_to_last_week_teachers':lists[5],
    'count_last_week_schoology':lists[6],
    'count_last_to_last_week_schoology':lists[7],
    'count_last_week_clever':lists[8],
    'count_last_to_last_week_clever':lists[9]}
    temp={'weekdata':weekdata}
    return json.dumps(temp)
    
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>------- PRACTICE BIFURCATION API------------------>>>>>>>>>
@app.route('/comparison1/<datestr>/<charttype>') #test2
def weekly__compare__chart__(datestr,charttype):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    
    
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    print(start_15day)
    
#     # yesterday= datetime.now(tz=timezone.utc)- timedelta(days=1)
#     yesterday= datetime.datetime.combine(datetime.datetime.utcnow() -timedelta(days=1),datetime.time.min)
#     today= datetime.datetime.combine(datetime.datetime.utcnow(),datetime.time.min)
#     tod= today+ timedelta(hours=4)
#     # yester-timedelta(days=8)
#     start= tod-timedelta(days=8)+timedelta(days=1)
#     yester= yesterday+timedelta(hours=4)+timedelta(days=1)
#     start_15day=tod-timedelta(days=15)+timedelta(days=1)

    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
    
        qr1=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},

                {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},

        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 

    #     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start , '$lt':yester
        }},
        ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_WEEK_PRACTICE_parents':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list1= list(collection1.aggregate(qr1))
        df_atm= DataFrame(list1)
        df_atm
        LAST_WEEK_PRACTICE_parents=df_atm[['_id','LAST_WEEK_PRACTICE_parents']]
        qr2=[{"$match":{
            '$and':[
                {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    #         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                   {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},  
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'MODIFIED_DATE':{'$gte':start_15day
                        , '$lt': start}}
            ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
            {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_TO_LAST_WEEK_PRACTICE_parents':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list2= list(collection1.aggregate(qr2))
        df_at2m= DataFrame(list2)
        LAST_TO_LAST_WEEK_PRACTICE_parents=df_at2m[['_id','LAST_TO_LAST_WEEK_PRACTICE_parents']]
        join_final1= pd.merge(LAST_WEEK_PRACTICE_parents, LAST_TO_LAST_WEEK_PRACTICE_parents, on='_id', how='left')    
    # =========================================
        qr3=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
        {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}}, 
        {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start , '$lt':yester
        }},
        ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_WEEK_PRACTICE_TEACHERS':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list3= list(collection1.aggregate(qr3))
        df_atm3= DataFrame(list3)
        df_atm3
        LAST_WEEK_PRACTICE_TEACHERS=df_atm3[['_id','LAST_WEEK_PRACTICE_TEACHERS']]
        qr4=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},  
             {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'MODIFIED_DATE':{'$gte':start_15day
                        , '$lt': start}}
            ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
            {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_TO_LAST_WEEK_PRACTICE_teachers':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list4= list(collection1.aggregate(qr4))
        df_atm4= DataFrame(list4)
        LAST_TO_LAST_WEEK_PRACTICE_teachers=df_atm4[['_id','LAST_TO_LAST_WEEK_PRACTICE_teachers']]
        join_final2= pd.merge(LAST_WEEK_PRACTICE_TEACHERS, LAST_TO_LAST_WEEK_PRACTICE_teachers, on='_id', how='left') 



    # =========================================
        qr5=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#         {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
         {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
         {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start , '$lt':yester
        }},
        ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_WEEK_PRACTICE_schoology':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list5= list(collection1.aggregate(qr5))
        df_atm5= DataFrame(list5)
        df_atm5
        LAST_WEEK_PRACTICE_schoology=df_atm5[['_id','LAST_WEEK_PRACTICE_schoology']]
        qr6=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}}, 
             {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'MODIFIED_DATE':{'$gte':start_15day
                        , '$lt': start}}
            ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
            {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_TO_LAST_WEEK_PRACTICE_schoology':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list6= list(collection1.aggregate(qr6))
        df_atm6= DataFrame(list6)
        LAST_TO_LAST_WEEK_PRACTICE_schoology=df_atm6[['_id','LAST_TO_LAST_WEEK_PRACTICE_schoology']]
        join_final3= pd.merge(LAST_WEEK_PRACTICE_schoology, LAST_TO_LAST_WEEK_PRACTICE_schoology, on='_id', how='left') 

    # =========================================
        qr7=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#         {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
         {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},  
        {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start , '$lt':yester
        }},
        ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_WEEK_PRACTICE_clever':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list7= list(collection1.aggregate(qr7))
        df_atm7= DataFrame(list7)
        print(df_atm7)
        LAST_WEEK_PRACTICE_clever=df_atm7[['_id','LAST_WEEK_PRACTICE_clever']]
        qr8=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}}, 
             {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'MODIFIED_DATE':{'$gte':start_15day
                        , '$lt': start}}
            ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
            {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_TO_LAST_WEEK_PRACTICE_clever':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list8= list(collection1.aggregate(qr8))
        df_atm8= DataFrame(list8)
        LAST_TO_LAST_WEEK_PRACTICE_clever=df_atm8[['_id','LAST_TO_LAST_WEEK_PRACTICE_clever']]
        join_final4= pd.merge(LAST_WEEK_PRACTICE_clever, LAST_TO_LAST_WEEK_PRACTICE_clever, on='_id', how='left') 
        
        
        
        
        
        # ========================================= CANVAS
        qr77=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#         {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
         {"USER_ID._id":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}},  
        {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start , '$lt':yester
        }},
        ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_WEEK_PRACTICE_canvas':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list77= list(collection1.aggregate(qr77))
        df_atm77= DataFrame(list77)
        if df_atm77.empty == True:
            df_atm77 = pd.DataFrame({'_id':[1,2,3,4,5,6,7],'LAST_WEEK_PRACTICE_canvas':0})
            
        LAST_WEEK_PRACTICE_canvas=df_atm77[['_id','LAST_WEEK_PRACTICE_canvas']]
        
        qr88=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}, 
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'MODIFIED_DATE':{'$gte':start_15day
                        , '$lt': start}}
            ]}},
             practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
            {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_TO_LAST_WEEK_PRACTICE_canvas':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list88= list(collection1.aggregate(qr88))
        df_atm88= DataFrame(list88)
        if df_atm88.empty == True:
            df_atm88 = pd.DataFrame({'_id':[1,2,3,4,5,6,7],'LAST_TO_LAST_WEEK_PRACTICE_canvas':0})
        LAST_TO_LAST_WEEK_PRACTICE_canvas=df_atm88[['_id','LAST_TO_LAST_WEEK_PRACTICE_canvas']]
        join_final44= pd.merge(LAST_WEEK_PRACTICE_canvas, LAST_TO_LAST_WEEK_PRACTICE_canvas, on='_id', how='left') 
        
        
        
        
    
        
        

        days=pd.DataFrame({'_id':[1,2,3,4,5,6,7],'day':['Sunday', 'Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']})

        df1=pd.merge(days,join_final1, on='_id',how='left')
        df2=pd.merge(df1,join_final2, on='_id',how='left')
        df3=pd.merge(df2,join_final3, on='_id',how='left')
        df4=pd.merge(df3,join_final4, on='_id',how='left').fillna(0)
        df4=pd.merge(df4,join_final44, on='_id',how='left').fillna(0)
        df4=df4.astype(int, errors='ignore')
        df4.columns
        lists=[]

        for i in df4.columns:

            i=df4[i].tolist()
            lists.append(i)  
        weekdata={"day":lists[1],
         "count_last_week_parents":lists[2],
        'count_last_to_lastweek_parents':lists[3],
        'count_last_week_teachers':lists[4],
        'count_last_to_last_week_teachers':lists[5],
        'count_last_week_schoology':lists[6],
        'count_last_to_last_week_schoology':lists[7],
        'count_last_week_clever':lists[8],
        'count_last_to_last_week_clever':lists[9],
        'count_last_week_canvas':lists[10],
        'count_last_to_last_week_canvas':lists[11]}
        temp={'weekdata':weekdata}
        return json.dumps(temp)
    else:
        qr1=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},

                {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},

        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 

    #     {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start , '$lt':yester
        }},
        ]}},
#              practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_WEEK_PRACTICE_parents':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list1= list(collection1.aggregate(qr1))
        df_atm= DataFrame(list1)
        df_atm
        LAST_WEEK_PRACTICE_parents=df_atm[['_id','LAST_WEEK_PRACTICE_parents']]
        qr2=[{"$match":{
            '$and':[
                {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    #         {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
                   {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                 {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                 {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},  
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'MODIFIED_DATE':{'$gte':start_15day
                        , '$lt': start}}
            ]}},
#              practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
            {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_TO_LAST_WEEK_PRACTICE_parents':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list2= list(collection1.aggregate(qr2))
        df_at2m= DataFrame(list2)
        LAST_TO_LAST_WEEK_PRACTICE_parents=df_at2m[['_id','LAST_TO_LAST_WEEK_PRACTICE_parents']]
        join_final1= pd.merge(LAST_WEEK_PRACTICE_parents, LAST_TO_LAST_WEEK_PRACTICE_parents, on='_id', how='left')    
    # =========================================
        qr3=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
        {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
        {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}}, 
        {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start , '$lt':yester
        }},
        ]}},
#              practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_WEEK_PRACTICE_TEACHERS':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list3= list(collection1.aggregate(qr3))
        df_atm3= DataFrame(list3)
        df_atm3
        LAST_WEEK_PRACTICE_TEACHERS=df_atm3[['_id','LAST_WEEK_PRACTICE_TEACHERS']]
        qr4=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},  
             {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'MODIFIED_DATE':{'$gte':start_15day
                        , '$lt': start}}
            ]}},
#              practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
            {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_TO_LAST_WEEK_PRACTICE_teachers':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list4= list(collection1.aggregate(qr4))
        df_atm4= DataFrame(list4)
        LAST_TO_LAST_WEEK_PRACTICE_teachers=df_atm4[['_id','LAST_TO_LAST_WEEK_PRACTICE_teachers']]
        join_final2= pd.merge(LAST_WEEK_PRACTICE_TEACHERS, LAST_TO_LAST_WEEK_PRACTICE_teachers, on='_id', how='left') 



    # =========================================
        qr5=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#         {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
         {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
         {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start , '$lt':yester
        }},
        ]}},
#              practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_WEEK_PRACTICE_schoology':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list5= list(collection1.aggregate(qr5))
        df_atm5= DataFrame(list5)
        df_atm5
        LAST_WEEK_PRACTICE_schoology=df_atm5[['_id','LAST_WEEK_PRACTICE_schoology']]
        qr6=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}}, 
             {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'MODIFIED_DATE':{'$gte':start_15day
                        , '$lt': start}}
            ]}},
#              practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
            {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_TO_LAST_WEEK_PRACTICE_schoology':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list6= list(collection1.aggregate(qr6))
        df_atm6= DataFrame(list6)
        LAST_TO_LAST_WEEK_PRACTICE_schoology=df_atm6[['_id','LAST_TO_LAST_WEEK_PRACTICE_schoology']]
        join_final3= pd.merge(LAST_WEEK_PRACTICE_schoology, LAST_TO_LAST_WEEK_PRACTICE_schoology, on='_id', how='left') 

    # =========================================
        qr7=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#         {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
         {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},  
        {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start , '$lt':yester
        }},
        ]}},
#              practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_WEEK_PRACTICE_clever':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list7= list(collection1.aggregate(qr7))
        df_atm7= DataFrame(list7)

        LAST_WEEK_PRACTICE_clever=df_atm7[['_id','LAST_WEEK_PRACTICE_clever']]
        qr8=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}}, 
             {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'MODIFIED_DATE':{'$gte':start_15day
                        , '$lt': start}}
            ]}},
#              practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
            {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_TO_LAST_WEEK_PRACTICE_clever':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list8= list(collection1.aggregate(qr8))
        df_atm8= DataFrame(list8)
        LAST_TO_LAST_WEEK_PRACTICE_clever=df_atm8[['_id','LAST_TO_LAST_WEEK_PRACTICE_clever']]
        join_final4= pd.merge(LAST_WEEK_PRACTICE_clever, LAST_TO_LAST_WEEK_PRACTICE_clever, on='_id', how='left') 
        
        
        
        
        
        # ========================================= CANVAS
        qr77=[{"$match":{
        '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
#         {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
         {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
         {"USER_ID._id":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}},  
        {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
        {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'MODIFIED_DATE':{'$gte':start , '$lt':yester
        }},
        ]}},
#              practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
        {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_WEEK_PRACTICE_canvas':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list77= list(collection1.aggregate(qr77))
        df_atm77= DataFrame(list77)
        if df_atm77.empty == True:
            df_atm77 = pd.DataFrame({'_id':[1,2,3,4,5,6,7],'LAST_WEEK_PRACTICE_canvas':0})
            
        LAST_WEEK_PRACTICE_canvas=df_atm77[['_id','LAST_WEEK_PRACTICE_canvas']]
        
        qr88=[{"$match":{
            '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
#             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
             {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
             {"USER_ID._id":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}, 
             {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'MODIFIED_DATE':{'$gte':start_15day
                        , '$lt': start}}
            ]}},
#              practice_cond_dictonary_list[0],
#                         practice_cond_dictonary_list[1],
#                          threshcond[0],
            {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 
        'LAST_TO_LAST_WEEK_PRACTICE_canvas':{'$sum':1}
        }}, {'$sort':{'_id':1}}
         ]
        list88= list(collection1.aggregate(qr88))
        df_atm88= DataFrame(list88)
        if df_atm88.empty == True:
            df_atm88 = pd.DataFrame({'_id':[1,2,3,4,5,6,7],'LAST_TO_LAST_WEEK_PRACTICE_canvas':0})
        LAST_TO_LAST_WEEK_PRACTICE_canvas=df_atm88[['_id','LAST_TO_LAST_WEEK_PRACTICE_canvas']]
        join_final44= pd.merge(LAST_WEEK_PRACTICE_canvas, LAST_TO_LAST_WEEK_PRACTICE_canvas, on='_id', how='left') 
        
        
        
        
    
        
        

        days=pd.DataFrame({'_id':[1,2,3,4,5,6,7],'day':['Sunday', 'Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']})

        df1=pd.merge(days,join_final1, on='_id',how='left')
        df2=pd.merge(df1,join_final2, on='_id',how='left')
        df3=pd.merge(df2,join_final3, on='_id',how='left')
        df4=pd.merge(df3,join_final4, on='_id',how='left').fillna(0)
        df4=pd.merge(df4,join_final44, on='_id',how='left').fillna(0)
        df4=df4.astype(int, errors='ignore')
#         print("df4 \n",df4)
        df4.columns
        lists=[]

        for i in df4.columns:

            i=df4[i].tolist()
            lists.append(i)  
#         print(lists)
        weekdata={"day":lists[1],
         "count_last_week_parents":lists[2],
        'count_last_to_lastweek_parents':lists[3],
        'count_last_week_teachers':lists[4],
        'count_last_to_last_week_teachers':lists[5],
        'count_last_week_schoology':lists[6],
        'count_last_to_last_week_schoology':lists[7],
        'count_last_week_clever':lists[8],
        'count_last_to_last_week_clever':lists[9],
        'count_last_week_canvas':lists[10],
        'count_last_to_last_week_canvas':lists[11]}
        temp={'weekdata':weekdata}
        return json.dumps(temp)




@app.route('/weeklyfeedcard/<datestr>')
def feedbackweekcardssss___(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
#     print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
#     print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
#     print(start_15day)
    
    
#TEACHERS COMMENT PER FEEDBACK LAST WEEK
    query1=[
    {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
#             {'COMMENT':{'$nin':['',' ',None]}},
               {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed=list(collection2.aggregate(query1))
    commentsonfeedback=pd.DataFrame(commentsonfeed)
    if commentsonfeedback.empty:
        commentsonfeedback = pd.DataFrame(index=[0], columns=['_id','rating'])
        commentsonfeedback = commentsonfeedback.fillna(0)
    
    comments_per_feedback_teacher=commentsonfeedback[['rating']]
    comments_per_feedback_teacher['rating']=commentsonfeedback['rating'].astype(int)
    
    
#PARENTS COMMENT PER FEEDBACK LAST WEEK
    querya=[
    {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
#                         {'COMMENT':{'$nin':['',' ',None]}},
               {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed2=list(collection2.aggregate(querya))
    commentsonfeedback2=pd.DataFrame(commentsonfeed2)
    if commentsonfeedback2.empty:
        commentsonfeedback2 = pd.DataFrame(index=[0], columns=['_id','rating'])
        commentsonfeedback2 = commentsonfeedback2.fillna(0)
    
    comments_per_feedback_parents=commentsonfeedback2[['rating']]
    comments_per_feedback_parents['rating']=comments_per_feedback_parents['rating'].astype(int)
    
    

    
#TEACHERS COMMENT PER FEEDBACK before LAST WEEK
    query4=[
    {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start_15day,
                             '$lt':start
                             }},
#                         {'COMMENT':{'$nin':['',' ',None]}},
               {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed11=list(collection2.aggregate(query4))
    commentsonfeedback11=pd.DataFrame(commentsonfeed11)
    if commentsonfeedback11.empty:
        commentsonfeedback11 = pd.DataFrame(index=[0], columns=['_id','rating'])
        commentsonfeedback11 = commentsonfeedback11.fillna(0)
    
    comments_per_feedback_before_last_week_teachers=commentsonfeedback11[['rating']]
    comments_per_feedback_before_last_week_teachers['rating']=comments_per_feedback_before_last_week_teachers['rating'].astype(int)
    

    
#  PARENTS COMMENT PER FEEDBACK before LAST WEEK
    queryB=[
     {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start_15day,
                             '$lt':start
                             }},
#                         {'COMMENT':{'$nin':['',' ',None]}},
               {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed200=list(collection2.aggregate(queryB))
    commentsonfeedback20=pd.DataFrame(commentsonfeed200)
    if commentsonfeedback20.empty:
        commentsonfeedback20 = pd.DataFrame(index=[0], columns=['_id','rating'])
        commentsonfeedback20 = commentsonfeedback20.fillna(0)
    
    comments_per_feedback_before_last_week_parents=commentsonfeedback20[['rating']]
    comments_per_feedback_before_last_week_parents['rating']=comments_per_feedback_before_last_week_parents['rating'].astype(int)

    
# AVERAGE FEEDBACK RATING LAST WEEK
    query6=[
    {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
#             {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
#                         {'COMMENT':{'$nin':['',' ',None]}},
               {'RATING':{'$ne':0}}]}},
    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rating=list(collection2.aggregate(query6))
    avg_ratings=pd.DataFrame(avg_rating)
    if avg_ratings.empty:
        avg_ratings = pd.DataFrame(index=[0], columns=['_id','rating'])
        avg_ratings = avg_ratings.fillna(0)
    
    avg_ratings_lastweek=avg_ratings[['RATING']]
    avg_ratings_lastweek['RATING']=avg_ratings_lastweek['RATING'].astype(int)

    
    avg_ratings_last_week=pd.DataFrame({'avg_ratings_lastweek':round(avg_ratings_lastweek[avg_ratings_lastweek['RATING']!=0]['RATING'].mean(),1)}, index=[0])

    
   
    query60=[
     {"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start_15day,
                             '$lt':yester
                             }},
#                         {'COMMENT':{'$nin':['',' ',None]}},
               {'RATING':{'$ne':0}}
           ]}},
    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rate=list(collection2.aggregate(query60))
    avg_ratin=pd.DataFrame(avg_rate)
    if avg_ratin.empty:
        avg_ratin = pd.DataFrame(index=[0], columns=['_id','rating'])
        avg_ratin = avg_ratin.fillna(0)
    
    avg_ratings_before_lastweek=avg_ratin[['RATING']]
    avg_ratings_before_lastweek['RATING']=avg_ratings_before_lastweek['RATING'].astype(int)
    avg_ratings_beforee_last_week=pd.DataFrame({'avg_ratings_before_lastweek':round(avg_ratings_before_lastweek[avg_ratings_before_lastweek['RATING']!=0]['RATING'].mean(),1)}, index=[0])



    
    TEACHER_Comment_per_feedbackchange=[]
    teacher_PERCENTAGE_change=[]
    if comments_per_feedback_before_last_week_teachers['rating'].iloc[0]> comments_per_feedback_teacher['rating'].iloc[0]:
        xx=comments_per_feedback_before_last_week_teachers['rating'].iloc[0]-comments_per_feedback_teacher['rating'].iloc[0]
        yy= xx/comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('-1')
        teacher_PERCENTAGE_change.append(zz)
        
    elif comments_per_feedback_teacher['rating'].iloc[0] == comments_per_feedback_before_last_week_teachers['rating'].iloc[0]:
        xx=comments_per_feedback_teacher['rating'].iloc[0]-comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        yy= xx/comments_per_feedback_teacher['rating'].iloc[0]
        zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('0')
        teacher_PERCENTAGE_change.append(zz)
        
    else:
        xx=comments_per_feedback_teacher['rating'].iloc[0]-comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        yy= xx/comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('1')
        teacher_PERCENTAGE_change.append(zz)
        


    PARENT_Comment_per_feedbackchange=[]
    parent_PERCENTAGE_change=[]
    if comments_per_feedback_before_last_week_parents['rating'].iloc[0]> comments_per_feedback_parents['rating'].iloc[0]:
        xx=comments_per_feedback_before_last_week_parents['rating'].iloc[0]-comments_per_feedback_parents['rating'].iloc[0]
        yy= xx/comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        zz= round(yy*100,2)
        PARENT_Comment_per_feedbackchange.append('-1')
        parent_PERCENTAGE_change.append(zz)
        
    elif comments_per_feedback_before_last_week_parents['rating'].iloc[0] ==comments_per_feedback_parents['rating'].iloc[0]:
        xx=comments_per_feedback_before_last_week_parents['rating'].iloc[0]-comments_per_feedback_parents['rating'].iloc[0]
        yy= xx/comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        zz= round(yy*100,2)
        PARENT_Comment_per_feedbackchange.append('0')
        parent_PERCENTAGE_change.append(zz)
        
    else:
        xx=comments_per_feedback_parents['rating'].iloc[0]-comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        yy= xx/comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        zz= round(yy*100,2)
        PARENT_Comment_per_feedbackchange.append('1')
        parent_PERCENTAGE_change.append(zz)
        


    Average_FEEDBACK_Rating_change=[]
    Average_feedback_PERCENTAGE=[]
    if avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]> avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]:
        xx=avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]-avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
        yy= xx/avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        zz= round(yy*100,2)
        Average_FEEDBACK_Rating_change.append('-1')
        Average_feedback_PERCENTAGE.append(zz)
        
        
    elif avg_ratings_last_week['avg_ratings_lastweek'].iloc[0] == avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]:
        xx=avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]-avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
        yy= xx/avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        zz= round(yy*100,2)
        Average_FEEDBACK_Rating_change.append('0')
        Average_feedback_PERCENTAGE.append(zz)
        
    else:
        xx=avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]-avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        yy= xx/avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        zz= round(yy*100,2)
        Average_FEEDBACK_Rating_change.append('1')
        Average_feedback_PERCENTAGE.append(zz)



    data_final=pd.DataFrame({'TEACHER_FEEDBACK_RATING_LAST_WEEK':comments_per_feedback_teacher['rating'].tolist(),
                             'TEACHER_FEEDBACK_RATING_BEFORE_LAST_WEEK':comments_per_feedback_before_last_week_teachers['rating'].tolist(),
                             
    'PARENT_FEEDBACK_RATING_LAST_WEEK':comments_per_feedback_parents['rating'].tolist(),
    'PARENT_FEEDBACK_RATING_BEFORE_LAST_WEEK':comments_per_feedback_before_last_week_parents['rating'].tolist(),
                                 
     'Average_Rating_lastweek':avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].tolist(),
     'Average_Rating_lastweek':avg_ratings_last_week['avg_ratings_lastweek'].tolist(),
                             
      'TEACHER_Comment_per_feedbackchange':TEACHER_Comment_per_feedbackchange,
       'teacher_PERCENTAGE_change':teacher_PERCENTAGE_change,                      
      'PARENT_Comment_per_feedbackchange':PARENT_Comment_per_feedbackchange,
       'parent_PERCENTAGE_change':parent_PERCENTAGE_change,                      
      'Average_FEEDBACK_Rating_change':Average_FEEDBACK_Rating_change,
       'Average_feedback_PERCENTAGE':Average_feedback_PERCENTAGE                      
                                })   
    
    temp={}
    for j in range(len(data_final.columns)):
        key = data_final.columns[j]
        value = [str(data_final[data_final.columns[j]].iloc[0])]
        temp.update({key:value})
    return json.dumps(temp)




@app.route('/dailyfeedratingtable_TEACHERS/<datestr>')
def dailyyy_feedback_table_TEACHERS__(datestr):
    username=urllib.parse.quote_plus('admin')
    password=urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1 =db.audio_track_master
    collection2 = db.audio_feedback

    mydatetime= dateutil.parser.parse(datestr)
#     yester= pd.to_datetime(mydatetime) - timedelta(days=1)
#     tod= mydatetime
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)

    qr1= [{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
            {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester,
                             '$lte':tod
                             }},
    ]}},
    {'$group':{'_id':'$USER_ID._id',
               'PRACTICE_COUNT':{'$sum':1},
           'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
           'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
           'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
               'Audio_name':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_NAME'},
               'Audio_length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'},
               'Language':{'$first':'$PROGRAM_AUDIO_ID.LANGUAGE'},

          'CITY':{'$first':'$USER_ID.schoolId.CITY'},
           'STATE':{'$first':'$USER_ID.schoolId.STATE'},
                'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}},
                    'PlayBack_Time_Percent':{'$sum':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}
                                            }}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)

    qr2= [{"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':yester,
                             '$lte':tod
                             }},
#             {'COMMENT':{'$nin':['',' ',None]}},
               {'RATING':{'$ne':0}}]}},


    {'$project':{'_id':'$USER._id', 'USER_NAME':'$USER.USER_NAME',
               'EMAIL':'$USER.EMAIL_ID',
                 'DEVICE_USED':'$DEVICE_USED',
               'SCHOOL':'$USER.schoolId.NAME',
    #            'CREATED_DATE':'$CREATED_DATE',
                    'CREATED_DATE':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},
               'COMMENT':'$COMMENT',
#                  'ACTION_DATE':'$MODIFIED_DATE',
         'RATING':'$RATING',
         'COMMENT':'$COMMENT'
        }} ,
    {'$sort':{'RATING':-1}}    ]  


    list2= list(collection2.aggregate(qr2))
    audio1= DataFrame(list2)
    
    if audio1.empty:
        return json.dumps({'data':"NO DATA AVAILABLE"})
    else:
        audio=pd.merge(audio1,df_atm1, on='_id', how='left')
        audio=audio.sort_values(by='COMMENT',ascending=False).reset_index(drop=True)
        audio['AUDIO_DAY']=audio['AUDIO_DAY'].fillna('')
        audio['PROGRAM_NAME']=audio['PROGRAM_NAME'].fillna('')
        audio['Program']=audio[['PROGRAM_NAME', 'AUDIO_DAY']].agg(' '.join, axis=1)
        audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'Program','COMMENT','CREATED_DATE','RATING','Language']]
        audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
        audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
        audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
        audio2['RATING'].fillna('', inplace=True)
        audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
        audio2['Program'].fillna('NO PROGRAM NAME FOUND', inplace=True)
        # audio2['RATING']=str(audio2['RATING'].iloc[0])
        audio2['RATING']=audio2['RATING'].replace(0, '')
        audio2['Language'].fillna('NO LANGUAGE FOUND', inplace=True)
        audio2['CREATED_DATE']=audio2['CREATED_DATE'].fillna('')
#         audio2=audio2.drop(['STATE', 'CITY'], axis=1)
        temp={'data':audio2.values.tolist()}
        temp={'data':audio2.values.tolist()}
        
        return json.dumps(temp)


@app.route('/dailyfeedratingtable_PARENTS/<datestr>')
def dailyyy_feedback_table_PARENTS__(datestr):
    username=urllib.parse.quote_plus('admin')
    password=urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1 =db.audio_track_master
    collection2 = db.audio_feedback

    mydatetime= dateutil.parser.parse(datestr)
#     yester= pd.to_datetime(mydatetime) - timedelta(days=1)
#     tod= mydatetime
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)


    qr1= [{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
            {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester,
                             '$lte':tod
                             }},
    ]}},
    {'$group':{'_id':'$USER_ID._id',
               'PRACTICE_COUNT':{'$sum':1},
           'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
           'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
           'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
               'Audio_name':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_NAME'},
               'Audio_length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'},
               'Language':{'$first':'$PROGRAM_AUDIO_ID.LANGUAGE'},

          'CITY':{'$first':'$USER_ID.schoolId.CITY'},
           'STATE':{'$first':'$USER_ID.schoolId.STATE'},
                'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}},
                    'PlayBack_Time_Percent':{'$sum':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}
                                            }}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)

    qr2= [{"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':yester,
                             '$lte':tod
                             }},
#             {'COMMENT':{'$nin':['',' ',None]}},
               {'RATING':{'$ne':0}}]}},


    {'$project':{'_id':'$USER._id', 'USER_NAME':'$USER.USER_NAME',
               'EMAIL':'$USER.EMAIL_ID',
                 'DEVICE_USED':'$DEVICE_USED',
               'SCHOOL':'$USER.schoolId.NAME',
               'CREATED_DATE':'$CREATED_DATE',
               'COMMENT':'$COMMENT', 'ACTION_DATE':'$MODIFIED_DATE',
         'RATING':'$RATING',
         'COMMENT':'$COMMENT'
        }} ,
    {'$sort':{'RATING':-1}}    ]  


    list2= list(collection2.aggregate(qr2))
    audio1= DataFrame(list2)
    if audio1.empty:
        
        temp = pd.DataFrame(index=[0], columns=['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'Program','COMMENT','CREATED_DATE','RATING','Language'])
        temp = temp.fillna('')
        temp={'data':temp.values.tolist()}        
        return json.dumps(temp)
#         return json.dumps({'data':[]})
    
    audio=pd.merge(audio1,df_atm1, on='_id', how='left')
    audio=audio.sort_values(by='COMMENT',ascending=False).reset_index(drop=True)
    audio['AUDIO_DAY']=audio['AUDIO_DAY'].fillna('')
    audio['PROGRAM_NAME']=audio['PROGRAM_NAME'].fillna('')
    audio['Program']=audio[['PROGRAM_NAME', 'AUDIO_DAY']].agg(' '.join, axis=1)
    audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'Program','COMMENT','CREATED_DATE','RATING','Language']]
    audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['RATING'].fillna('', inplace=True)
    audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
    audio2['Program'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    # audio2['RATING']=str(audio2['RATING'].iloc[0])
    audio2['RATING']=audio2['RATING'].replace(0, '')
    audio2['Language'].fillna('NO LANGUAGE FOUND', inplace=True)
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].fillna('')
    temp={'data':audio2.values.tolist()}
    return json.dumps(temp)


        

@app.route('/districtddtcard/<datestr>/<districtid>')
def feedback_district_chart__(datestr,districtid):
    
    disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
            '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
            '5f2609807a1c0000950bb475':'Agawam School district',
            '5f2609807a1c0000950bb481':'Alameda Unified School District',
            '5f2609807a1c0000950bb47a':'Alpine School District',
            '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
            '5f2609807a1c0000950bb463':'Austin Independent School District',
            '5f59e4836451a9089d7d4007':'Belleville School District',
            '5f2609807a1c0000950bb46d':'Broward County Public Schools',
            '5f2609807a1c0000950bb46c':'Chico Unified School District',
            '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
            '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
            '5f2609807a1c0000950bb45c':'Comox Valley School District(sd71)',
            '5f2609807a1c0000950bb480':'Dell Texas',
            '5f7413ef9387fd71ce6387cb':'Douglas County School District',
            '5f895191609e08b76029f641':'Early learning Sarasota',
            '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
            '5f2609807a1c0000950bb461':'Englewood Public School District',
            '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
            '5f2609807a1c0000950bb47d':'Flint Public Schools',
            '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
            '5f2609807a1c0000950bb450':'Goleta District',
            '5f2609807a1c0000950bb474':'Greenburgh-North Castle (GNC) Union Free School District',
            '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
            '5f2609807a1c0000950bb476':'Hillsborough County',
            '5f2609807a1c0000950bb455':'Krum Independent School District',
            '5f2609807a1c0000950bb47e':'La Joya School District',
            '5f2609807a1c0000950bb467':'Lincolnshire Schools',
            '5f2609807a1c0000950bb45a':'LAUSD',
            '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
            '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
            '5fbcdf0ba84e48a64412a798':'Needham School District',
            '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
            '5f6994386451a9089d7d4009':'Ogden school district',
            '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
            '5fd704da04a848e368de5dc6':'Oakland Unified School District',
            '5f8fcd33609e08b76029f644':'Paradise Unified School District',
            '5f2609807a1c0000950bb466':'Pinellas County Schools',
            '5f2609807a1c0000950bb471':'Racine Unified Schools',
            '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
            '5f2609807a1c0000950bb478':'San Diego Unified School District',
            '5f2609807a1c0000950bb470':'San Leandro Unified School District',
            '5f2609807a1c0000950bb477':'Sarasota County',
            '5f2609807a1c0000950bb473':'Skillman Foundation',
            '5f2609807a1c0000950bb46a':'Springfield Public Schools',
            '5f2609807a1c0000950bb468':'Utah Board of Education',
            '5f698b826451a9089d7d4008':'Wayne Metro',
            '5f2609807a1c0000950bb45b':'Westfield Public School District',
            '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
            '5f2609807a1c0000950bb45d':'Youngstown',
    '5f2609807a1c0000950bb464':'Equity Education',
    '5f2609807a1c0000950bb469':'LSF -  Head Start',
    '5f2609807a1c0000950bb46e':'District 25 New York Schools',
    '5f2609807a1c0000950bb46f':'Paradise Schools',
    '5f2609807a1c0000950bb479':'Panorama Education',
    '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
    '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
    '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
    '5fe2e25d4d0ca68d7baf889d':'BGCA',
    '5fe318b14d0ca68d7baf889e':'BLUE',
    '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
    '6017ab3043ca9c39151838d4':'Oswego School District',
    '60239a84e57dc27613699d57':'Austin Independent School District',
    '6023a6d79e8e623753fc305c':'Boulder Valley School District',
    '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
    '6023a7269e8e623753fc305e':'Fulton County School System',
    '6023a7499e8e623753fc305f':'Manatee County School District',
    '6023a76f9e8e623753fc3060':'San Jose Unified School District',
    '6023a7949e8e623753fc3061':'Wasatch County School District',}

    district=disdic[districtid]
    
    username=urllib.parse.quote_plus('admin')
    password=urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client=MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))

    db=client.compass
    collection = db.audio_track_master
    collection2=db.audio_feedback
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    print(start_15day)
    # district=disdic[districtid]

    qr1=[
        {"$match":{"$and":[
        {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
        {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
        {'USER.IS_DISABLE':{"$ne":'Y'}},
        {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
        {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
            {'COMMENT':{'$nin':['',' ',None]}},
        {'RATING':{'$ne':0}},
        {'USER.schoolId._id':{'$in':db.school_master.distinct('_id',{ "CATEGORY":{'$regex':district, '$options':'i'}})}},
#                                                   )}},
        {"MODIFIED_DATE":{"$gte": start, '$lt': yester}}
        ]}},
        {'$group':{'_id':'$RATING', 
                   'no_of_rating':{'$sum':1}

        }}, {'$sort':{'_id':-1}}
        ]


    dis= list(collection2.aggregate(qr1))
    df1= DataFrame(dis)



    qr2=[
        {"$match":{"$and":[
        {'USER.EMAIL_ID':{"$not":{"$regex":'test','$options':'i'}}},
        {'USER.USER_NAME':{"$not":{"$regex":'test','$options':'i'}}},
        {'USER.IS_DISABLE':{"$ne":'Y'}},
        {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'USER.EMAIL_ID':{"$not":{"$regex":'1gen','$options':'i'}}},
        {'USER.EMAIL_ID':{'$nin':['',' ',None]}},
            {'COMMENT':{'$nin':['',' ',None]}},
        {'RATING':{'$ne':0}},
               {'USER.schoolId._id':{'$in':db.school_master.distinct('_id',{ "CATEGORY":{'$regex':district, '$options':'i'}})}},
#                                                   )}},


        {"MODIFIED_DATE":{"$gte": start_15day, '$lt': start}}
        ]}},
        {'$group':{'_id':'$RATING', 
                   'no_of_rating':{'$sum':1}
  
        }}, {'$sort':{'_id':-1}}
        ]


    dis2= list(collection2.aggregate(qr2))
    df2= DataFrame(dis2)

    print(district)
    distid=df1['_id'].values.tolist()
    distpract=df1['no_of_rating'].values.tolist()

    distid2=df2['_id'].values.tolist()
    distpract2=df2['no_of_rating'].values.tolist()

    temp={'rating_lastweek':distid, 'Number_of_Ratings_given_lastweek':distpract, 
          'rating_before_last_week':distid2,
         'Number_of_Ratings_given_Before_lastweek':distpract2,
          'dsitrict_name':[district],
          
         }
    
    return json.dumps(temp)




@app.route('/feedback_table_weekly_PARENTS/<datestr>')
def weekly_feedback_table__(datestr):    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@54.202.61.130:27017/" % (username,password))
    db=client.compass
    collection1 =db.audio_track_master
    collection2 = db.audio_feedback
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    # print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    #     print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    #     print(start_15day)


    qr1= [{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
            {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
    ]}},
    {'$group':{'_id':'$USER_ID._id',
               'PRACTICE_COUNT':{'$sum':1},
           'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
           'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
           'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
               'Audio_name':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_NAME'},
               'Audio_length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'},
               'Language':{'$first':'$PROGRAM_AUDIO_ID.LANGUAGE'},

          'CITY':{'$first':'$USER_ID.schoolId.CITY'},
           'STATE':{'$first':'$USER_ID.schoolId.STATE'},
                'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}},
                    'PlayBack_Time_Percent':{'$sum':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}
                                            }}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)

    qr2= [{"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
    #             {'COMMENT':{'$nin':['',' ',None]}},
               {'RATING':{'$ne':0}}
           ]}},


    {'$project':{'_id':'$USER._id', 'USER_NAME':'$USER.USER_NAME',
               'EMAIL':'$USER.EMAIL_ID',
                 'DEVICE_USED':'$DEVICE_USED',
               'SCHOOL':'$USER.schoolId.NAME',
               'CREATED_DATE':'$CREATED_DATE',
               'COMMENT':'$COMMENT', 'ACTION_DATE':'$MODIFIED_DATE',
         'RATING':'$RATING',
         'COMMENT':'$COMMENT'
        }} ,
    {'$sort':{'RATING':-1}}    ]  


    list2= list(collection2.aggregate(qr2))
    audio1= DataFrame(list2)
    if audio1.empty:
        
        temp = pd.DataFrame(index=[0], columns=['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'Program','COMMENT','CREATED_DATE','RATING','Language'])
        temp = temp.fillna('')
        temp={'data':temp.values.tolist()}        
        return json.dumps(temp)
#         return json.dumps({'data':[]})

    audio=pd.merge(audio1,df_atm1, on='_id', how='left')

    audio=audio.sort_values(by='COMMENT',ascending=False).reset_index(drop=True)
    audio['AUDIO_DAY']=audio['AUDIO_DAY'].fillna('')
    audio['PROGRAM_NAME']=audio['PROGRAM_NAME'].fillna('')
    audio['Program']=audio[['PROGRAM_NAME', 'AUDIO_DAY']].agg(' '.join, axis=1)
    audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'Program','COMMENT','CREATED_DATE','RATING','Language']]
    audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['RATING'].fillna('', inplace=True)
    audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
    audio2['Program'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    # audio2['RATING']=str(audio2['RATING'].iloc[0])
    audio2['RATING']=audio2['RATING'].replace(0, '')
    audio2['Language'].fillna('NO LANGUAGE FOUND', inplace=True)
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].fillna('')


    dates=[]
    for i in range(len(list(audio2['CREATED_DATE']))):
        if list(audio2['CREATED_DATE'])[i]=='':
            dates.append('')
        else:
            d=list(audio2['CREATED_DATE'])[i].strftime('%d %b %Y %H:%M:%S')
            dates.append(d)

    audio2['CREATED_DATE']=dates
    temp={'data':audio2.values.tolist()}


    return json.dumps(temp)

# Below api has been changed by 27 may 2021 by Anil

@app.route('/feedback_table_weekly_TEACHERS/<datestr>')
def weekly_feedback_tableTEACHERS___(datestr):
    username = urllib.parse.quote_plus('admin')

    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1 =db.audio_track_master
    collection2 = db.audio_feedback


    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime)+timedelta(hours=4)
    tod=mydatetime+ timedelta(hours=4)
    start= tod- timedelta(days=7)
    start_15day= start-timedelta(days=7)



    qr1= [{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
            {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
    ]}},
    {'$group':{'_id':'$USER_ID._id',
               'PRACTICE_COUNT':{'$sum':1},
           'SCHOOL_NAME':{'$first':'$USER_ID.schoolId.NAME'},
           'AUDIO_DAY':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_DAY'},
           'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
               'Audio_name':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_NAME'},
               'Audio_length':{'$first':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH'},
               'Language':{'$first':'$PROGRAM_AUDIO_ID.LANGUAGE'},

          'CITY':{'$first':'$USER_ID.schoolId.CITY'},
           'STATE':{'$first':'$USER_ID.schoolId.STATE'},
                'mindful_minutes':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}},
                    'PlayBack_Time_Percent':{'$sum':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}
                                            }}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)

    qr2= [{"$match":{
    '$and':[{ 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
           {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER.IS_DISABLED':{"$ne":'Y'}},
            {'USER.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'MODIFIED_DATE':{'$gte':start,
                             '$lt':yester
                             }},
    #             {'COMMENT':{'$nin':['',' ',None]}},
               {'RATING':{'$ne':0}}]}},


    {'$project':{'_id':'$USER._id', 'USER_NAME':'$USER.USER_NAME',
               'EMAIL':'$USER.EMAIL_ID',
                 'DEVICE_USED':'$DEVICE_USED',
               'SCHOOL':'$USER.schoolId.NAME',
               'CREATED_DATE':'$CREATED_DATE',
               'COMMENT':'$COMMENT', 'ACTION_DATE':'$MODIFIED_DATE',
         'RATING':'$RATING',
         'COMMENT':'$COMMENT'
        }} ,
    {'$sort':{'RATING':-1}}    ]  


    list2= list(collection2.aggregate(qr2))
    audio1= DataFrame(list2)
    if audio1.empty:
        
        temp = pd.DataFrame(index=[0], columns=['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'Program','COMMENT','CREATED_DATE','RATING','Language'])
        temp = temp.fillna('')
        temp={'data':temp.values.tolist()}        
        return json.dumps(temp)
#         return json.dumps({'data':[]})

    audio=pd.merge(audio1,df_atm1, on='_id', how='left')
    audio=audio.sort_values(by='COMMENT',ascending=False).reset_index(drop=True)
    audio['AUDIO_DAY']=audio['AUDIO_DAY'].fillna('')
    audio['PROGRAM_NAME']=audio['PROGRAM_NAME'].fillna('')

    audio['Program']=audio[['PROGRAM_NAME', 'AUDIO_DAY']].agg(' '.join, axis=1)
    audio2=audio[['SCHOOL_NAME', 'USER_NAME', 'EMAIL', 'Program','COMMENT','CREATED_DATE','RATING','Language']]
    audio2['SCHOOL_NAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['RATING'].fillna('', inplace=True)
    audio2['COMMENT'].fillna('NO COMMENT', inplace=True)
    audio2['Program'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    # audio2['RATING']=str(audio2['RATING'].iloc[0])
    audio2['RATING']=audio2['RATING'].replace(0, '')
    audio2['Language'].fillna('NO LANGUAGE FOUND', inplace=True)
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].fillna('')
    temp={'data':audio2.values.tolist()}
    return json.dumps(temp)

@app.route('/programPRACTICE_dailycomparsion/<datestr>')
def progpracticeDAY____(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1 = db.audio_track_master

    mydatetime= dateutil.parser.parse(datestr)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)
    

    qr111=[
    {'$match':{'USER_ID.schoolId':{'$exists':1}}},
    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
             {'MODIFIED_DATE':{'$gte':yester,
                                 '$lt':tod
                                 }},
                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME', 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'teacherspracticecount':'$practicecount'}},
        ]    


    qr222=   [

    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
             {'MODIFIED_DATE':{'$gte':yester,
                                 '$lt':tod
                                 }},

                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME', 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'parentspracticecount':'$practicecount'}},
        ]   
    
    
    qr44=[
    {'$match':{'USER_ID.schoolId':{'$exists':1}}},
    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
             {'MODIFIED_DATE':{'$gte':start_15day,
                                 '$lt':startend
                                 }},
                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME', 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'teacherspracticecount':'$practicecount'}},
        ]    


    qr33=   [

    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
             {'MODIFIED_DATE':{'$gte':start_15day,
                                 '$lt':startend
                                 }},

                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME', 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'parentspracticecount':'$practicecount'}},
        ]     
    

    list1= list(collection1.aggregate(qr111))
    df_atm1= DataFrame(list1)
    list2= list(collection1.aggregate(qr222))
    df_atm2= DataFrame(list2)
    join= pd.merge(df_atm1,df_atm2, how='left', on='_id')
    
    list3= list(collection1.aggregate(qr33))
    df_atm3= DataFrame(list3)
    list4= list(collection1.aggregate(qr44))
    df_atm4= DataFrame(list4)
    join_lastweek24hrs= pd.merge(df_atm3,df_atm4, how='left', on='_id')
    
    join.rename(columns = { '_id': 'progname'}, inplace = True)
    join['parentspracticecount'].fillna(0, inplace=True)
    join['teacherspracticecount'].fillna(0, inplace=True)
    
    parentspractice=join['parentspracticecount'].tolist()
    teacherspractice=join['teacherspracticecount'].tolist()
    progname=join['progname'].tolist()
        
    join_lastweek24hrs.rename(columns = { '_id': 'progname'}, inplace = True)
    join_lastweek24hrs['parentspracticecount'].fillna(0, inplace=True)
    join_lastweek24hrs['teacherspracticecount'].fillna(0, inplace=True)
    
    parentspractice_lastweek24hrs=join_lastweek24hrs['parentspracticecount'].tolist()
    teacherspractice_lastweek24hrs=join_lastweek24hrs['teacherspracticecount'].tolist()
    progname_lastweek24hrs=join_lastweek24hrs['progname'].tolist()
    
#     print(df)
    for i in range(len(progname)):
            progname[i] = progname[i]
    data={'parentspractice':parentspractice,'teacherspractice':teacherspractice,
          'parentspractice_lastweek24hrs':parentspractice_lastweek24hrs,
          'teacherspractice_lastweek24hrs':teacherspractice_lastweek24hrs,
          'progname':progname}
    
    return json.dumps(data)


#>>>>>>>>>>>>>>>>>>>----------PRACTICE BIFURCATION API----------------------

@app.route('/programPRACTICE_dailycomparsion/<datestr>/<charttype>')
def progpractice____DAY____(datestr,charttype):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1 = db.audio_track_master

    mydatetime= dateutil.parser.parse(datestr)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(tod)
    print(yester)
    print(start_15day)
    print(startend)
    dtf=DataFrame(list(db.program_master.aggregate([
        {"$match":{"$and":[
        #              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                        {"PROGRAM_ID":{"$nin":[5,6,7]}},]}},
        {'$project':{'_id':'$PROGRAM_ID','PROGRAM_NAME':'$PROGRAM_NAME'}},
    {'$sort':{'_id':1}}])))
    progname_=dtf['PROGRAM_NAME'].tolist()
                      
    charttype=str(charttype).title()
    if charttype=='Practice':
    #     threshold=int(threshold)/100
        threshold=.5
        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        
        qr111=[
#         {'$match':{'USER_ID.schoolId':{'$exists':1}}},
        {"$match":
             {'$and': [
                     {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
                 {'MODIFIED_DATE':{'$gte':yester,
                                     '$lte':tod
                                     }},
                    ]}},
                        practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
            {"$group":{'_id':'$PROGRAM_ID','PROGRAM_NAME':{'$first':'$PROGRAM_NAME'},'practicecount':{'$sum':1}}},
             {"$project":{'_id':1,'PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},
            ]    
        
        qr222=   [

        {"$match":
             {'$and': [
                     {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
                 {'MODIFIED_DATE':{'$gte':yester,
                                     '$lte':tod
                                     }},

                    ]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
            {"$group":{'_id':'$PROGRAM_ID','PROGRAM_NAME':{'$first':'$PROGRAM_NAME'}, 'practicecount':{'$sum':1}}},
             {"$project":{'_id':1,'PROGRAM_NAME':'$PROGRAM_NAME', 'parentspracticecount':'$practicecount'}},
            ]   


        qr44=[
#         {'$match':{'USER_ID.schoolId':{'$exists':1}}},
        {"$match":
             {'$and': [
                     {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
                 {'MODIFIED_DATE':{'$gte':start_15day,
                                     '$lte':startend
                                     }},
                    ]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
            {"$group":{'_id':'$PROGRAM_ID','PROGRAM_NAME':{'$first':'$PROGRAM_NAME'},  'practicecount':{'$sum':1}}},
             {"$project":{'_id':1,'PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},
            ]    


        qr33=   [

        {"$match":
             {'$and': [
                     {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                      {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
              
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
                 {'MODIFIED_DATE':{'$gte':start_15day,
                                     '$lte':startend
                                     }},

                    ]}},
            practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
            {"$group":{'_id':'$PROGRAM_ID', 'PROGRAM_NAME':{'$first':'$PROGRAM_NAME'}, 'practicecount':{'$sum':1}}},
             {"$project":{'_id':1,'PROGRAM_NAME':'$PROGRAM_NAME',  'parentspracticecount':'$practicecount'}},
            ]     

        list1= list(collection1.aggregate(qr111))
        df_atm1= DataFrame(list1)
        
        _id=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]
        if df_atm1.empty:
            df_atm1 = pd.DataFrame(index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16], columns=['_id','teacherspracticecount'])
            df_atm1['_id']=_id
            df_atm1 = df_atm1.fillna(0)

        list2= list(collection1.aggregate(qr222))
        df_atm2= DataFrame(list2)

        if df_atm2.empty:
            df_atm2 = pd.DataFrame(index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16], columns=['_id','parentspracticecount'])
            df_atm2['_id']=_id
            df_atm2 = df_atm2.fillna(0)

        df1= pd.merge(dtf,df_atm1, how='left', on='_id')
        join= pd.merge(df1,df_atm2, how='left', on='_id')

        list3= list(collection1.aggregate(qr33))
        df_atm3= DataFrame(list3)

        if df_atm3.empty:
            df_atm3 = pd.DataFrame(index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16], columns=['_id','parentspracticecount'])
            df_atm3['_id']=_id
            df_atm3 = df_atm3.fillna(0)

        list4= list(collection1.aggregate(qr44))
        df_atm4= DataFrame(list4)

        if df_atm4.empty:
            df_atm4 = pd.DataFrame(index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16], columns=['_id','teacherspracticecount'])
            df_atm4['_id']=_id
            df_atm4 = df_atm4.fillna(0)
        
        df2= pd.merge(dtf,df_atm3, how='left', on='_id')
        join_lastweek24hrs= pd.merge(df2,df_atm4, how='left', on='_id')

        join.rename(columns = { '_id': 'progname'}, inplace = True)
        join['parentspracticecount'].fillna(0, inplace=True)
        join['teacherspracticecount'].fillna(0, inplace=True)

        parentspractice=join['parentspracticecount'].tolist()
        teacherspractice=join['teacherspracticecount'].tolist()
        progname=join['progname'].tolist()
        
#         print(progname)

        join_lastweek24hrs.rename(columns = { '_id': 'progname'}, inplace = True)
        join_lastweek24hrs['parentspracticecount'].fillna(0, inplace=True)
        join_lastweek24hrs['teacherspracticecount'].fillna(0, inplace=True)
        
        join_lastweek24hrs['progname'].fillna("NO INFO",inplace=True)
#         print(join_lastweek24hrs)

        parentspractice_lastweek24hrs=join_lastweek24hrs['parentspracticecount'].tolist()
        teacherspractice_lastweek24hrs=join_lastweek24hrs['teacherspracticecount'].tolist()
        progname_lastweek24hrs=join_lastweek24hrs['progname'].tolist()

#         print(progname)
#         for i in range(len(progname)):
#                 progname[i] = progname[i]

        if len(progname) > len(progname_lastweek24hrs):
            progname=progname

        if len(progname_lastweek24hrs) > len(progname):
            progname=progname_lastweek24hrs
    
        data={'parentspractice':parentspractice,'teacherspractice':teacherspractice,
              'parentspractice_lastweek24hrs':parentspractice_lastweek24hrs,
              'teacherspractice_lastweek24hrs':teacherspractice_lastweek24hrs,
              'progname':progname}
        return json.dumps(data)
    else:
        
        
        
        
        
        qr111=[
#     {'$match':{'USER_ID.schoolId':{'$exists':1}}},
    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
            
             {'MODIFIED_DATE':{'$gte':yester,
                                 '$lte':tod
                                 }},
                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID','PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}, 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'teacherspracticecount':'$practicecount','PROGRAM_NAME':'$PROGRAM_NAME'}},
        ]    


    qr222=   [

    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
             {'MODIFIED_DATE':{'$gte':yester,
                                 '$lte':tod
                                 }},

                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID','PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}, 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'parentspracticecount':'$practicecount','PROGRAM_NAME':'$PROGRAM_NAME'}},
        ]   
    
    
    qr44=[
#     {'$match':{'USER_ID.schoolId':{'$exists':1}}},
    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#            
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
             {'MODIFIED_DATE':{'$gte':start_15day,
                                 '$lte':startend
                                 }},
                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID','PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}, 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'teacherspracticecount':'$practicecount','PROGRAM_NAME':'$PROGRAM_NAME'}},
        ]    


    qr33=   [

    {"$match":
         {'$and': [
                 {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
          {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$ne':None}},
             {'MODIFIED_DATE':{'$gte':start_15day,
                                 '$lte':startend
                                 }},

                ]}},
        {"$group":{'_id':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID','PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}, 'practicecount':{'$sum':1}}},
         {"$project":{'_id':1, 'parentspracticecount':'$practicecount','PROGRAM_NAME':'$PROGRAM_NAME'}},
        ]     
    

    list1= list(collection1.aggregate(qr111))
    df_atm1= DataFrame(list1)
    
    _id=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]
    if df_atm1.empty:
        df_atm1 = pd.DataFrame(index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16], columns=['_id','teacherspracticecount'])
        df_atm1['_id']=_id
        df_atm1 = df_atm1.fillna(0)

    list2= list(collection1.aggregate(qr222))
    df_atm2= DataFrame(list2)
    
    if df_atm2.empty:
        df_atm2 = pd.DataFrame(index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16], columns=['_id','parentspracticecount'])
        df_atm2['_id']=_id
        df_atm2 = df_atm2.fillna(0)

    df1= pd.merge(dtf,df_atm1, how='left', on='_id')
    join= pd.merge(df1,df_atm2, how='left', on='_id')

    list3= list(collection1.aggregate(qr33))
    df_atm3= DataFrame(list3)
    
    if df_atm3.empty:
        df_atm3 = pd.DataFrame(index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16], columns=['_id','parentspracticecount'])
        df_atm3['_id']=_id
        df_atm3 = df_atm3.fillna(0)

    list4= list(collection1.aggregate(qr44))
    df_atm4= DataFrame(list4)
    
    if df_atm4.empty:
        df_atm4 = pd.DataFrame(index=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16], columns=['_id','teacherspracticecount'])
        df_atm4['_id']=_id
        df_atm4 = df_atm4.fillna(0)
    df2= pd.merge(dtf,df_atm3, how='left', on='_id')
    join_lastweek24hrs= pd.merge(df2,df_atm4, how='left', on='_id')
    
    join.rename(columns = { '_id': 'progname'}, inplace = True)
    join['parentspracticecount'].fillna(0, inplace=True)
    join['teacherspracticecount'].fillna(0, inplace=True)
    
    parentspractice=join['parentspracticecount'].tolist()
    teacherspractice=join['teacherspracticecount'].tolist()
    progname=join['progname'].tolist()
#     progname_=join['PROGRAM_NAME'].tolist()
        
    join_lastweek24hrs.rename(columns = { '_id': 'progname'}, inplace = True)
    join_lastweek24hrs['parentspracticecount'].fillna(0, inplace=True)
    join_lastweek24hrs['teacherspracticecount'].fillna(0, inplace=True)
    
    join_lastweek24hrs['progname'].fillna("NO INFO",inplace=True)
    parentspractice_lastweek24hrs=join_lastweek24hrs['parentspracticecount'].tolist()
    teacherspractice_lastweek24hrs=join_lastweek24hrs['teacherspracticecount'].tolist()
    progname_lastweek24hrs=join_lastweek24hrs['progname'].tolist()
#     progname_lastweek24hrs=join_lastweek24hrs['PROGRAM_NAME'].tolist()
    
#     print(df)
#     for i in range(len(progname)):
#             progname[i] = progname[i]
    
    if len(progname) > len(progname_lastweek24hrs):
        progname=progname
        
    if len(progname_lastweek24hrs) > len(progname):
        progname=progname_lastweek24hrs
    
    data={'parentspractice':parentspractice,'teacherspractice':teacherspractice,
          'parentspractice_lastweek24hrs':parentspractice_lastweek24hrs,
          'teacherspractice_lastweek24hrs':teacherspractice_lastweek24hrs,
          'prognameid':progname,
         'progname':progname_
         }
    
    return json.dumps(data)


@app.route('/ratedaily/<datestr>')
def RATssy(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection=db.audio_feedback
    mydatetime= dateutil.parser.parse(datestr)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)
    index=[0]

    df1 = DataFrame(list(collection.aggregate([
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lte':tod}}    ,         
    {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
    'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
    'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},           
    
    }},
    {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3',
                'rating_2':'$rating_2', 'rating_1':'$rating_1'}},
    {'$sort':{'_id':1}}
    ])))
    df1.rename(columns = { '_id': 'week'}, inplace = True)
    if df1.empty:
        df1 = pd.DataFrame(index=index, columns=['week','rating_5','rating_4','rating_3','rating_2','rating_1'])
        df1 = df1.fillna(0)
    df1[['week','rating_5','rating_4','rating_3','rating_2','rating_1']]
    print(df1,"teachers_yes")
    df2 = DataFrame(list(collection.aggregate([
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':yester, '$lte':tod}}    ,         
    {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
    'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
    'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},              
    
    }},
    {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3',
                'rating_2':'$rating_2', 'rating_1':'$rating_1'}},
    {'$sort':{'_id':1}}
    ])))
    df2.rename(columns = {'_id': 'week'}, inplace = True)
    if df2.empty:
        df2 = pd.DataFrame(index=index, columns=['week','rating_5','rating_4','rating_3','rating_2','rating_1'])
        df2 = df2.fillna(0)
    df2[['week','rating_5','rating_4','rating_3','rating_2','rating_1']]
    print(df2,"par_yes")
    df10 = DataFrame(list(collection.aggregate([
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lte':startend}}    ,         
    {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
    'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
    'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},              
    
    }},
    {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3',
                'rating_2':'$rating_2', 'rating_1':'$rating_1'}},
    {'$sort':{'_id':1}}
    ])))
    df10.rename(columns = { '_id': 'week'}, inplace = True)
    if df10.empty:
        df10 = pd.DataFrame(index=index, columns=['week','rating_5','rating_4','rating_3','rating_2','rating_1'])
        df10 = df10.fillna(0)
    df10[['week','rating_5','rating_4','rating_3','rating_2','rating_1']]
    print(df10,"teach_lastweek")
    df20 = DataFrame(list(collection.aggregate([
     {"$match":{'$and':[
         {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER.IS_DISABLED":{"$ne":"Y"}},
         { "USER.IS_BLOCKED":{"$ne":"Y"}},
        { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
           {'MODIFIED_DATE':{'$gte':start_15day, '$lte':startend}}    ,         
        {'RATING':{'$ne':0}}]}},
    {'$group':{'_id':{'$dayOfWeek':'$MODIFIED_DATE'}, 'count':{'$sum':'$USER._id'},
    'rating_5':{'$sum':{'$cond':[{'$eq':['$RATING', 5]},1,0]}},
    'rating_4':{'$sum':{'$cond':[{'$eq':['$RATING', 4]},1,0]}},
    'rating_3':{'$sum':{'$cond':[{'$eq':['$RATING', 3]},1,0]}},
    'rating_2':{'$sum':{'$cond':[{'$eq':['$RATING', 2]},1,0]}},
    'rating_1':{'$sum':{'$cond':[{'$eq':['$RATING', 1]},1,0]}},              
   
    }},
    {'$project':{'_id':1, 'rating_5':'$rating_5','rating_4':'$rating_4', 'rating_3':'$rating_3',
                'rating_2':'$rating_2', 'rating_1':'$rating_1'}},
    {'$sort':{'_id':1}}
        ])))
    df20.rename(columns = { '_id': 'week'}, inplace = True)
    if df20.empty:
        df20 = pd.DataFrame(index=index, columns=['week','rating_5','rating_4','rating_3','rating_2','rating_1'])
        df20 = df20.fillna(0)
    df20[['week','rating_5','rating_4','rating_3','rating_2','rating_1']]
    print(df20,"par_lastweek")
    teachers_yes=df1.values.tolist()
    par_yes=df2.values.tolist()
    teach_lastweek=df10.values.tolist()
    par_lastweek=df20.values.tolist()
    weekdata={"rating":["5 STAR","4 STAR","3 STAR", "2 STAR", "1 STAR"],"teachers_yes":teachers_yes[0][1:],"par_yes":par_yes[0][1:],"teach_lastweek":teach_lastweek[0][1:],"par_lastweek":par_lastweek[0][1:]}
    
    temp={'weekdata':weekdata}
    return json.dumps(temp)


@app.route('/parents_signup_table_daily/<datestr>')
def signupdataparentDay______(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
    
    mydatetime= dateutil.parser.parse(datestr)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)
    

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte':yester , '$lt':tod
#     }},
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
     'PRACTICE_DATE':{'$first':'$MODIFIED_DATE'}, 
     'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
    }}, 

    {'$sort':{'_id':1}}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                    
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':yester
                , '$lte': tod}}
    ]}},
         {'$project':{'_id':'$_id','CREATED_DATE':'$CREATED_DATE', 'schoolNAME':'$schoolId.NAME',
                      'USER_NAME':'$USER_NAME','EMAIL':'$EMAIL_ID',
                     'COUNTRY':'$schoolId.COUNTRY', 'STATE':'$schoolId.STATE', 'CITY':'$schoolId.CITY',
                
                     }}
         

    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    if df_um.empty:
        return json.dumps({'data':"NO DATA AVAILABLE"})
    else:
        df_final= pd.merge(df_um,df_atm,how='left', on='_id')

        audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','PRACTICE_DATE','COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
        audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
        audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
        audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
        audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
        audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
        audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
        audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
        audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
        audio2['PRACTICE_DATE']=audio2['PRACTICE_DATE'].dt.strftime('%d %b %Y')
    #     audio2['PRACTICE_DATE']=pd.to_datetime(audio2['PRACTICE_DATE'], errors='coerce').dt.time
    #     audio2['PRACTICE_DATE']=pd.to_datetime(audio2['PRACTICE_DATE'], format = '%d%b%Y')
        audio2['PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)


        audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')


        temp={'data':audio2.values.tolist()}
        return json.dumps(temp)


@app.route('/teacher_signup_table_daily/<datestr>')
def teacher_signup_table_day__(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master

    mydatetime= dateutil.parser.parse(datestr)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    
    
#     yester= pd.to_datetime(mydatetime) - timedelta(days=1)
#     tod= mydatetime
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#     {'MODIFIED_DATE':{'$gte':yester , '$lt':tod
#     }},
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
     'PRACTICE_DATE':{'$first':'$MODIFIED_DATE'}, 
     'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
    }}, 

    {'$sort':{'_id':1}}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},                    
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':yester
                , '$lte': tod}}
    ]}},
         {'$project':{'_id':'$_id','CREATED_DATE':'$CREATED_DATE', 'schoolNAME':'$schoolId.NAME',
                      'USER_NAME':'$USER_NAME','EMAIL':'$EMAIL_ID',
                     'COUNTRY':'$schoolId.COUNTRY', 'STATE':'$schoolId.STATE', 'CITY':'$schoolId.CITY'
                     }}
    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    
    if df_um.empty:
        
        return json.dumps({'data':"NO DATA AVAILABLE"})
    else:
        df_final= pd.merge(df_um,df_atm,how='left', on='_id')

        audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','PRACTICE_DATE','COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
        audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
        audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
        audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
        audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
        audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
        audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
        audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
        audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
        audio2['PRACTICE_DATE']=audio2['PRACTICE_DATE'].dt.strftime('%d %b %Y')
    #     audio2['PRACTICE_DATE']=pd.to_datetime(audio2['PRACTICE_DATE'], errors='coerce').dt.time
    #     audio2['PRACTICE_DATE']=pd.to_datetime(audio2['PRACTICE_DATE'], format = '%d%b%Y')
        audio2['PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)


        audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')


        temp={'data':audio2.values.tolist()}
        return json.dumps(temp)


@app.route('/classroom_practice_table_DAILY/<datestr>')
def school_practice_table_DAILYY____(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master
    # datetime.datetime.now() - datetime.timedelta(days=7)
    # ar d = new Date();
      
    mydatetime= dateutil.parser.parse(datestr)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': yester, '$lte':tod
    }},
    ]}},


    {'$project':{'_id':'$USER_ID._id',
               'USER_NAME':'$USER_ID.USER_NAME',
                 'EMAIL_ID':'$USER_ID.EMAIL_ID',
    #                'PRACTICE_COUNT':{'$sum':1},
                   'LAST_PRACTICE_DATE':'$MODIFIED_DATE',
               'SCHOOL_NAME':'$USER_ID.schoolId.NAME',
               'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY',
               'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
               'COUNTRY':'$USER_ID.schoolId.COUNTRY',
               'CITY':'$USER_ID.schoolId.CITY',
               'STATE':'$USER_ID.schoolId.STATE',
                 'PHONE':'$USER_ID.CONTACT_NUMBER',
                 'IP':'$USER_ID.IP_ADDRESS','AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                 'AUDIO_LENGTH':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH',
    #        'Mindful_Minutes':{"$round":[{"$divide":
    #                     [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
    #                 'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
    #                     ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]},

         'CURSOR_START':"$cursorStart", 'CURSOR_END':'$CURSOR_END'
                }}
             ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    if df_atm1.empty:
        return json.dumps({'data':'NO DATA AVAILABLE'})
    else:
        
        if 'CURSOR_START' not in list(df_atm1.columns):
            df_atm1['CURSOR_START']=0
        else:
            df_atm1=df_atm1

            # df_atm1[['parents_playback_24hr', 'teachers_playback_24hr','total_playback_24hr']]


            df_atm1['CURSOR_START'].fillna(0, inplace=True)
            df_atm1['CITY'].fillna('NO INFO FOUND', inplace=True)
            df_atm1['STATE'].fillna('NO INFO FOUND', inplace=True)
            df_atm1['COUNTRY'].fillna('NO INFO FOUND', inplace=True)
            df_atm1['PHONE'].fillna('NO INFO FOUND', inplace=True)

            df_atm1['subtract']=df_atm1['CURSOR_END']-df_atm1['CURSOR_START']
            df_atm1['divide']=df_atm1['subtract']/60

            decimals = 2    

            df_atm1['Mindful_minutess']=df_atm1['divide'].round(decimals)


            df_atm1['playback']= df_atm1['subtract']/df_atm1['AUDIO_LENGTH']
            df_atm1['playback_time_percent']= df_atm1['playback'].round(0)
        #     df_atm1['playback_time_PERCENTAGE']=df_atm1['playback_time_round']*100

            df_atm1['LAST_PRACTICE_DATE']=df_atm1['LAST_PRACTICE_DATE'].dt.strftime("%m/%d/%Y")
            df_atm1=df_atm1.fillna('')


            table=df_atm1[['SCHOOL_NAME','USER_NAME','EMAIL_ID','LAST_PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY',
    #                        'PHONE',
#                        'AUDIO_LENGTH',
                       'Mindful_minutess',
                       'playback_time_percent',
#                        'CITY','STATE','COUNTRY'
                      ]]
            temp={'data':table.values.tolist()}
            return json.dumps(temp)


@app.route('/FAMILY_practice_table_DAILY/<datestr>')
def PARENTS_practice_table_DAY___(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master
    # datetime.datetime.now() - datetime.timedelta(days=7)
    # ar d = new Date();
  
    mydatetime= dateutil.parser.parse(datestr)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
#     print(start_15day)
#     print(startend)



    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': yester, '$lte':tod
    }},
    ]}},


    {'$project':{'_id':'$USER_ID._id',
               'USER_NAME':'$USER_ID.USER_NAME',
                 'EMAIL_ID':'$USER_ID.EMAIL_ID',
    #                'PRACTICE_COUNT':{'$sum':1},
                   'LAST_PRACTICE_DATE':'$MODIFIED_DATE',
               'SCHOOL_NAME':'$USER_ID.schoolId.NAME',
               'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY',
               'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
               'COUNTRY':'$USER_ID.schoolId.COUNTRY',
               'CITY':'$USER_ID.schoolId.CITY',
               'STATE':'$USER_ID.schoolId.STATE',
                 'PHONE':'$USER_ID.CONTACT_NUMBER',
                 'IP':'$USER_ID.IP_ADDRESS','AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                 'AUDIO_LENGTH':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH',
    #        'Mindful_Minutes':{"$round":[{"$divide":
    #                     [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
    #                 'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
    #                     ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]},

         'CURSOR_START':"$cursorStart", 'CURSOR_END':'$CURSOR_END'
                }}
             ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    if df_atm1.empty:
        return json.dumps({'data':'NO DATA AVAILABLE'})
    else:
        
        if 'CURSOR_START' not in list(df_atm1.columns):
            df_atm1['CURSOR_START']=0
        else:
            df_atm1=df_atm1

        df_atm1['CURSOR_START'].fillna(0, inplace=True)
        df_atm1['USER_NAME'].fillna('NO INFO FOUND', inplace=True)
        df_atm1['EMAIL_ID'].fillna('NO INFO FOUND', inplace=True)
        df_atm1['CITY'].fillna('NO INFO FOUND', inplace=True)
        df_atm1['STATE'].fillna('NO INFO FOUND', inplace=True)
        df_atm1['COUNTRY'].fillna('NO INFO FOUND', inplace=True)
        df_atm1['PHONE'].fillna('NO INFO FOUND', inplace=True)

        df_atm1['subtract']=df_atm1['CURSOR_END']-df_atm1['CURSOR_START']
        df_atm1['divide']=df_atm1['subtract']/60

        decimals = 2    

        df_atm1['Mindful_minutess']=df_atm1['divide'].round(decimals)


        df_atm1['playback']= df_atm1['subtract']/df_atm1['AUDIO_LENGTH']
        df_atm1['playback_time_percent']= df_atm1['playback'].round(0)
    #     df_atm1['playback_time_PERCENTAGE']=df_atm1['playback_time_round']*100


        df_atm1['LAST_PRACTICE_DATE']=df_atm1['LAST_PRACTICE_DATE'].dt.strftime("%m/%d/%Y")
        df_atm1=df_atm1.fillna('')
        

        table=df_atm1[['SCHOOL_NAME','USER_NAME','EMAIL_ID','LAST_PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY',
#                        'PHONE',
#                        'AUDIO_LENGTH',
                       'Mindful_minutess',
                       'playback_time_percent',
#                        'CITY','STATE','COUNTRY'
                      ]]

        temp={'data':table.values.tolist()}
        return json.dumps(temp)

@app.route('/parents_signup_table_weekly/<datestr>')
def signupparentweekLY_____(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master

    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    #     print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    #     print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    #     print(start_15day)

    

    qr1=[{"$match":{
    '$and':[
        {'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    ]}},
         
         
    {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
     'LAST_PRACTICE_DATE':{'$max':'$MODIFIED_DATE'}, 
     'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
    }}, 

    {'$sort':{'_id':1}}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
      
               
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},                    
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start
                , '$lt': yester}}
    ]}},
         {'$project':{'_id':'$_id','CREATED_DATE':'$CREATED_DATE', 'schoolNAME':'$schoolId.NAME',
                      'USER_NAME':'$USER_NAME','EMAIL':'$EMAIL_ID',
                     'COUNTRY':'$schoolId.COUNTRY', 'STATE':'$schoolId.STATE', 'CITY':'$schoolId.CITY',

                     }}


    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)

    df_final= pd.merge(df_um,df_atm,how='left', on='_id')

    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','LAST_PRACTICE_DATE','COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')
    audio2['LAST_PRACTICE_DATE']= audio2['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
    audio2['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
#     audio2=audio2[audio2['EMAIL']]
    
    temp={'data':audio2.values.tolist()}
    return json.dumps(temp)


# The below api has been changed by Anil 27 may 2021 
@app.route('/teacher_signup_table_weekly/<datestr>')
def signupteacherweeklyyy____(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.audio_track_master
    collection2= db.user_master
 
    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
#     print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
#     print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
#     print(start_15day)


    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},        
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'PRACTICE_COUNT':{'$sum':1},
     'LAST_PRACTICE_DATE':{'$max':'$MODIFIED_DATE'}, 
     'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},
    }}, 

    {'$sort':{'_id':1}}
    ]

    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)

    
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},                    
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start
                , '$lt': yester}}
    ]}},
         {'$project':{'_id':'$_id','CREATED_DATE':'$CREATED_DATE', 'schoolNAME':'$schoolId.NAME',
                      'USER_NAME':'$USER_NAME','EMAIL':'$EMAIL_ID',
                     'COUNTRY':'$schoolId.COUNTRY', 'STATE':'$schoolId.STATE', 'CITY':'$schoolId.CITY',
                
                     }}
         

    ]

    list2= list(collection2.aggregate(qr2))
    df_um= DataFrame(list2)
    
    df_final= pd.merge(df_um,df_atm,how='left', on='_id')
   
    audio2=df_final[['schoolNAME', 'USER_NAME', 'EMAIL','PRACTICE_COUNT','CREATED_DATE','LAST_PRACTICE_DATE','COUNTRY', 'STATE', 'CITY', 'PROGRAM_NAME']]
    audio2['schoolNAME'].fillna('NO SCHOOL', inplace=True)
    audio2['USER_NAME'].fillna('NO NAME FOUND', inplace=True)
    audio2['PRACTICE_COUNT'].fillna(0, inplace=True)
    audio2['EMAIL'].fillna('NO EMAIL FOUND', inplace=True)
    audio2['PROGRAM_NAME'].fillna('NO PROGRAM NAME FOUND', inplace=True)
    audio2['COUNTRY'].fillna('NO COUNTRY FOUND', inplace=True)
    audio2['STATE'].fillna('NO STATE FOUND', inplace=True)
    audio2['CITY'].fillna('NO CITY FOUND', inplace=True)
    audio2['CREATED_DATE']=audio2['CREATED_DATE'].dt.strftime('%d %b %Y')
    audio2['LAST_PRACTICE_DATE']=audio2['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
    audio2['LAST_PRACTICE_DATE'].fillna('NO PRACTICE', inplace=True)
    audio2=audio2[audio2['EMAIL']!='']
    temp={'data':audio2.values.tolist()}
    return json.dumps(temp)



@app.route('/PARENTS_practice_WEEKLY/<datestr>')
def family_practice_table_weekly____(datestr):
    username = urllib.parse.quote_plus('admin')

    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master
    # datetime.datetime.now() - datetime.timedelta(days=7)

    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    # print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    # print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    # print(start_15day)



    qr1=[
        {"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
            {'USER_ID.EMAIL_ID':{'$nin':['',' ',None]}},
    {'MODIFIED_DATE':{'$gte': start, '$lt':yester
    }},
    ]}},



    {'$project':{'_id':'$USER_ID._id',
               'USER_NAME':'$USER_ID.USER_NAME',
                 'EMAIL_ID':'$USER_ID.EMAIL_ID',
    #                'PRACTICE_COUNT':{'$sum':1},
                   'LAST_PRACTICE_DATE':'$MODIFIED_DATE',
               'SCHOOL_NAME':'$USER_ID.schoolId.NAME',
               'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY',
               'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
               'COUNTRY':'$USER_ID.schoolId.COUNTRY',
               'CITY':'$USER_ID.schoolId.CITY',
               'STATE':'$USER_ID.schoolId.STATE',
                 'PHONE':'$USER_ID.CONTACT_NUMBER',
                 'IP':'$USER_ID.IP_ADDRESS','AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                 'AUDIO_LENGTH':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH',

    #        'Mindful_Minutes':{"$round":[{"$divide":
    #                     [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
    #                 'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
    #                     ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]},

         'CURSOR_START':"$cursorStart", 'CURSOR_END':'$CURSOR_END'
                }}
             ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    # df_atm1[['parents_playback_24hr', 'teachers_playback_24hr','total_playback_24hr']]
    df_atm1.loc[(df_atm1['CURSOR_START']>df_atm1['CURSOR_END']),'CURSOR_END'] = df_atm1['CURSOR_START']
    df_atm1.loc[(df_atm1['CURSOR_END'].isnull()),'CURSOR_END'] = df_atm1['CURSOR_START']


    df_atm1['CURSOR_START'].fillna(0, inplace=True)
    df_atm1['CITY'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['STATE'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['COUNTRY'].fillna('NO INFO FOUND', inplace=True)

    df_atm1['subtract']=df_atm1['CURSOR_END']-df_atm1['CURSOR_START']
    df_atm1['divide']=df_atm1['subtract']/60

    df_atm1['CURSOR_START'].fillna(0, inplace=True)
    df_atm1['CITY'].fillna('NO INFO', inplace=True)
    df_atm1['STATE'].fillna('NO INFO', inplace=True)
    df_atm1['COUNTRY'].fillna('NO INFO', inplace=True)

    df_atm1['subtract']=df_atm1['CURSOR_END']-df_atm1['CURSOR_START']
    df_atm1['divide']=df_atm1['subtract']/60
    df_atm1['Mindful_minutess']=df_atm1['divide'].round(2)
    df_atm1['playback']= df_atm1['subtract']/df_atm1['AUDIO_LENGTH']
    df_atm1['playback_time_percent']= df_atm1['playback'].round(0)
    # df_atm1['playback_time_PERCENTAGE']=df_atm1['playback_time_round']*100


    df_atm1['LAST_PRACTICE_DATE']=df_atm1['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
    df_atm1['LAST_PRACTICE_DATE']=df_atm1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE')

    df_atm1['SCHOOL_NAME'].fillna('', inplace=True)
    df_atm1['USER_NAME'].fillna('', inplace=True)
    df_atm1['EMAIL_ID'].fillna('', inplace=True)
    df_atm1['LAST_PRACTICE_DATE'].fillna('', inplace=True)
    df_atm1['PROGRAM_NAME'].fillna('', inplace=True)
    df_atm1['AUDIO_DAY'].fillna('', inplace=True)
    df_atm1['Mindful_minutess'].fillna('', inplace=True)
    df_atm1['playback_time_percent'].fillna('', inplace=True)

    table=df_atm1[['SCHOOL_NAME','USER_NAME','EMAIL_ID','LAST_PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY',
#                        'PHONE',
#                        'AUDIO_LENGTH',
                       'Mindful_minutess',
                       'playback_time_percent',
#                        'CITY','STATE','COUNTRY'
                      ]]
    temp={'data':table.values.tolist()}
    return json.dumps(temp)


@app.route('/classroom_practice_WEEKLY/<datestr>')
def School_practice_table_WEEK___(datestr):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master
    # datetime.datetime.now() - datetime.timedelta(days=7)

    mydatetime= dateutil.parser.parse(datestr)
    yester= pd.to_datetime(mydatetime) +timedelta(hours=4)
    # print(yester)
    tod=mydatetime+ timedelta(hours=4)

    start= tod- timedelta(days=8)+timedelta(days=1)
    # print(start)
    start_15day= start-timedelta(days=8)+timedelta(days=1)
    # print(start_15day)



    qr1=[
        {"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': start, '$lt':yester
    }},
    ]}},



    {'$project':{'_id':'$USER_ID._id',
               'USER_NAME':'$USER_ID.USER_NAME',
                 'EMAIL_ID':'$USER_ID.EMAIL_ID',
    #                'PRACTICE_COUNT':{'$sum':1},
                   'LAST_PRACTICE_DATE':'$MODIFIED_DATE',
               'SCHOOL_NAME':'$USER_ID.schoolId.NAME',
               'AUDIO_DAY':'$PROGRAM_AUDIO_ID.AUDIO_DAY',
               'PROGRAM_NAME':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME',
               'COUNTRY':'$USER_ID.schoolId.COUNTRY',
               'CITY':'$USER_ID.schoolId.CITY',
               'STATE':'$USER_ID.schoolId.STATE',
                 'PHONE':'$USER_ID.CONTACT_NUMBER',
                 'IP':'$USER_ID.IP_ADDRESS','AGE_GROUP':'$PROGRAM_AUDIO_ID.PROGRAM_ID.AGE_GROUP',
                 'AUDIO_LENGTH':'$PROGRAM_AUDIO_ID.AUDIO_LENGTH',
    #        'Mindful_Minutes':{"$round":[{"$divide":
    #                     [{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]},
    #                 'PlayBack_Time_Percent':{"$round":[{"$divide":[{"$subtract":
    #                     ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]},

         'CURSOR_START':"$cursorStart", 'CURSOR_END':'$CURSOR_END'
                }}
             ]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    # df_atm1[['parents_playback_24hr', 'teachers_playback_24hr','total_playback_24hr']]
    df_atm1.loc[(df_atm1['CURSOR_START']>df_atm1['CURSOR_END']),'CURSOR_END'] = df_atm1['CURSOR_START']
    df_atm1.loc[(df_atm1['CURSOR_END'].isnull()),'CURSOR_END'] = df_atm1['CURSOR_START']


    df_atm1['CURSOR_START'].fillna(0, inplace=True)
    df_atm1['CITY'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['STATE'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['COUNTRY'].fillna('NO INFO FOUND', inplace=True)

    df_atm1['subtract']=df_atm1['CURSOR_END']-df_atm1['CURSOR_START']
    df_atm1['divide']=df_atm1['subtract']/60

    df_atm1['CURSOR_START'].fillna(0, inplace=True)
    df_atm1['CITY'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['STATE'].fillna('NO INFO FOUND', inplace=True)
    df_atm1['COUNTRY'].fillna('NO INFO FOUND', inplace=True)

    df_atm1['subtract']=df_atm1['CURSOR_END']-df_atm1['CURSOR_START']
    df_atm1['divide']=df_atm1['subtract']/60
    df_atm1['Mindful_minutess']=df_atm1['divide'].round(2)
    df_atm1['playback']= df_atm1['subtract']/df_atm1['AUDIO_LENGTH']
    df_atm1['playback_time_percent']= df_atm1['playback'].round(0)
    # df_atm1['playback_time_PERCENTAGE']=df_atm1['playback_time_round']*100


    df_atm1['LAST_PRACTICE_DATE']=df_atm1['LAST_PRACTICE_DATE'].dt.strftime('%d %b %Y')
    df_atm1['LAST_PRACTICE_DATE']=df_atm1['LAST_PRACTICE_DATE'].fillna('NO PRACTICE')

    df_atm1['SCHOOL_NAME'].fillna('', inplace=True)
    df_atm1['USER_NAME'].fillna('', inplace=True)
    df_atm1['EMAIL_ID'].fillna('', inplace=True)
    df_atm1['LAST_PRACTICE_DATE'].fillna('', inplace=True)
    df_atm1['PROGRAM_NAME'].fillna('', inplace=True)
    df_atm1['AUDIO_DAY'].fillna('', inplace=True)
    df_atm1['Mindful_minutess'].fillna('', inplace=True)
    df_atm1['playback_time_percent'].fillna('', inplace=True)


    table=df_atm1[['SCHOOL_NAME','USER_NAME','EMAIL_ID','LAST_PRACTICE_DATE','PROGRAM_NAME','AUDIO_DAY',
#                        'PHONE',
#                        'AUDIO_LENGTH',
                       'Mindful_minutess',
                       'playback_time_percent',
#                        'CITY','STATE','COUNTRY'
                      ]]
    temp={'data':table.values.tolist()}
    return json.dumps(temp)


@app.route("/spanish_narrator_usage_new")
def spanish_narrator_usage_new_detail():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    
    collection_home=db.user_master
    user= [
    {
        "$match":{"$and":
        [
        {"_id":{"$in": db.audio_track_master.distinct("USER_ID._id",
                                                      {"PROGRAM_AUDIO_ID.LANGUAGE":{"$regex":"spanish","$options":"i"}})}},
        {"DEVICE_USED" : "webApp"},
        {"EMAIL_ID":{"$not":{"$regex":"test","$options":"i"}}},
        {"EMAIL_ID":{"$not":{"$regex":"1gen","$options":"i"}}},
        {"USER_NAME":{"$not":{"$regex":"test","$options":"i"}}},
        {"USER_NAME":{"$not":{"$regex":"user","$options":"i"}}},
        {"DISTRICT_ID.DISTRICT_NAME":{"$not":{"$regex":"test","$options":"i"}}},
        {"DISTRICT_ID.DISTRICT_NAME":{"$not":{"$regex":"user","$options":"i"}}},
        {"IS_BLOCKED" :{"$ne":"Y"}},
        {"IS_DISABLED" : {"$ne":"Y"}},
        {"INCOMPLETE_SIGNUP" : {"$ne":"Y"}},
        ]}
    },
    {
    "$project":
    {
   
    "created date":"$CREATED_DATE",
    "time_month":"$CREATED_DATE",
    "time_hours":"$CREATED_DATE",
    "user name":"$USER_NAME",
    "EMAIL ID":"$EMAIL_ID",
    "ROLE_ID":"$ROLE_ID.ROLE_ID",
    "DISTRICT_NAME" :"$DISTRICT_ID.DISTRICT_NAME",
    "school id":"$schoolId._id",
    "school name":"$schoolId.NAME",
    "school address":"$schoolId.ADDRESS",
    "school city":"$schoolId.CITY",
    "school state":"$schoolId.STATE",      
    "school country":"$schoolId.COUNTRY"
    }
    }
    ]
    update=list(collection_home.aggregate(user))
    df_home=pd.DataFrame(update)
    df_home=df_home[(df_home['created date'] >= '2019-03-01')]

    list_names=df_home['_id'].tolist()

    collection_practice=db.audio_track_master
    user_practice=[
      {
    "$match":{"$and":
        [
        {"USER_ID._id":{"$in": list_names}},
        ]} 
    },
    {
        "$group":
        {
        "_id":"$USER_ID._id","USER_PRACTICE_COUNT":{"$sum":1},
        "USER_MINDFUL_MINUTES":{"$sum":{"$round":[{"$divide":[{"$subtract":['$CURSOR_END','$cursorStart']},60]},2]}},
        "LAST_PRACTICE_DATE":{"$first":"$MODIFIED_DATE"},
        "NARRATED_BY" :{"$first":"$PROGRAM_AUDIO_ID.NARRATEDBY"}
        }
    },
    {
    "$project":
    {
        "USER_PRACTICE_COUNT":1,
        "USER_MINDFUL_MINUTES":1,
        "LAST_PRACTICE_DATE":1,
        "NARRATED_BY" : 1
    } 
    }
     ]

    update_practice= list(collection_practice.aggregate(user_practice))
    df_practice=pd.DataFrame(update_practice)

    collection_feed=db.audio_feedback
    user_feed=[
    {
    "$match":{"$and":
        [
        {"USER._id":{"$in": list_names}},
        {"RATING":{"$exists":1}},
        {"RATING":{"$ne":0}}
        ]} 
    },
    {
        "$group":
        {
        "_id":"$USER._id",
        "RATING":{"$avg":"$RATING"}, 
        "RATING_count":{"$sum":"$RATING"}, 
        "AUDIO_NAME" : {"$first":"$AUDIO_ID.AUDIO_TITLE"}
        }
    },
    {
    "$project":
        {
            "RATING" : 1,
            "RATING_count":1,
            "AUDIO_NAME" : 1
        } 
    }
     ]
    update_feed= list(collection_feed.aggregate(user_feed))
    df_feed=pd.DataFrame(update_feed)

    df_merge=pd.merge(df_home,df_practice,on="_id",how="left")
    final_df=pd.merge(df_merge,df_feed,on="_id",how="inner")
    final_df['created date']=pd.to_datetime(final_df["created date"]).dt.strftime('%Y')
    final_df['time_hours']=pd.to_datetime(final_df["time_hours"]).dt.strftime('%H')
    final_df['RATING']=round(final_df['RATING'],1)
    
#     df_narrator = final_df.groupby(['NARRATED_BY','RATING',"AUDIO_NAME"])["MODIFIED_DATE"].agg(['max']).reset_index()
#     df_narrator.columns = ['NARRATED_BY','RATING',"AUDIO_NAME","MODIFIED_DATE"]

#     df_narrator_narrator=df_narrator['NARRATED_BY'].to_list()
#     df_narrator_audio=df_narrator['AUDIO_NAME'].to_list()
#     df_narrator_RATING=df_narrator['RATING'].to_list()
#     df_narrator_date=df_narrator['MODIFIED_DATE'].to_list()

#     dict_narrator={'total':
#                 {'df_narrator_narrator':df_narrator_narrator,
#                 'df_narrator_audio':df_narrator_audio,
#                 'df_narrator_RATING':df_narrator_RATING,
#                 'df_narrator_date':df_narrator_date}
#                 }


    df_narrator=final_df.groupby('NARRATED_BY').agg({'RATING':'mean','RATING_count':'sum'}).reset_index()
    df_narrator.columns = ['NARRATED_BY','RATING','RATING_count']
    
    df_narrator_audio = final_df.groupby(['NARRATED_BY',"AUDIO_NAME"])['RATING','RATING_count'].agg(['max']).reset_index()
    df_narrator_audio.columns = ['NARRATED_BY',"AUDIO_NAME",'RATING','RATING_count']
    
    dict_narrator={'total':
                   [
                        {'df_narrator_narrator':df_narrator['NARRATED_BY'].to_list()},
                        {'df_narrator_rating':round(df_narrator['RATING'],1).to_list()},
                        {'df_narrator_rating_count':df_narrator['RATING_count'].to_list()}
                   ]
                    }
    
    dict_narrator_audio={'total_1':
                [
                    {'df_narrator_narrator':df_narrator_audio['NARRATED_BY'].to_list()},
                    {'df_narrator_audio':df_narrator_audio['AUDIO_NAME'].to_list()},
                    {'df_narrator_rating':round(df_narrator_audio['RATING'],1).to_list()},
                    {'df_narrator_rating_count':df_narrator_audio['RATING_count'].to_list()}                  
               ]
                }
    dict_narrator.update(dict_narrator_audio)
    # print(dict_final)
        
    return json.dumps(dict_narrator)
@app.route('/enduser')
def end_user_slareport():
    googleSheetId = '1V50tiyckuiIM_dmBb2WFx_BMGFrHxZ60ajhmPUDLIv8'
    worksheetName1 = 'End_user_SLA'
    worksheetName2 = 'Application_Server_SLA'
    URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName1)
    end_user_sla=pd.read_csv(URL1)
    temp={'End_User':{
        'Month_Name':end_user_sla.Month_Name.tolist(),
        'page_views_in_thousands':end_user_sla["End user page views (thousands)"].tolist(),
        'end_user_load_time':end_user_sla['End user load time sec'].tolist()
    },
         'End_User_Stat':{
             'Month_Name':end_user_sla.Month_Name.tolist(),
             'satisfying_rate':end_user_sla['End user % satisfied'].tolist(),
             'tolerating_rate':end_user_sla['End user % tolerating'].tolist(),
             'frustrating_rate':end_user_sla['End user % frustrated'].tolist()
         }}
    return json.dumps({'data':temp})
# Application server SLA report.
@app.route('/appserverslareport')
def app_server_slareport():
    googleSheetId = '1V50tiyckuiIM_dmBb2WFx_BMGFrHxZ60ajhmPUDLIv8'
    worksheetName = 'Application_Server_SLA'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    app_server_sla=pd.read_csv(URL)
    temp={'App_Server':{
        'Month_Name':app_server_sla.Month_Name.tolist(),
        'app_server_in_millions':app_server_sla["App server requests (millions)"].tolist(),
        'app_server_response_time':app_server_sla['App server response time sec'].tolist()
    },
         'App_Server_Stat':{
             'Month_Name':app_server_sla.Month_Name.tolist(),
             'satisfying_rate':app_server_sla['App server % satisfied'].tolist(),
             'tolerating_rate':app_server_sla['App server % tolerating'].tolist(),
             'frustrating_rate':app_server_sla['App server % frustrated'].tolist()
         }
         }
    return json.dumps({'data':temp})

@app.route('/awscostoptimisation')
def db_performance():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.user_master
    query=[{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'CREATED_DATE':{'$gte':datetime.datetime(2020,3,1)}}    
              ]}},
       {'$group':{
           '_id': {
            'month': {'$month': "$CREATED_DATE" },
            'year': {'$year': "$CREATED_DATE" }
          },
          'User_Count':{'$addToSet':'$_id'}}},
          {'$project':{
              '_id':0,
              'month':'$_id.month',
              'year':'$_id.year',
              'User_Count':{'$size':'$User_Count'}
              }}]
    usercount=list(collection.aggregate(query))
    user_count_mar2020_onwards=pd.DataFrame(usercount)
    collection2=db.audio_track_master
    query2=[{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,3,1)}}
              ]}}
        ,            
       {'$group':{
           '_id': {
            'month': {'$month': "$MODIFIED_DATE" },
            'year': {'$year': "$MODIFIED_DATE" }
          },
          'Practice_Sessions':{'$sum':1}}},      
          {'$project':{
              '_id':0,
              'month':'$_id.month',
              'year':'$_id.year',
              'Practice_Sessions':'$Practice_Sessions'
              }}]
    atm_user=list(collection2.aggregate(query2))
    atm_user_mar2020_onwards=pd.DataFrame(atm_user)
    googleSheetId = '1V50tiyckuiIM_dmBb2WFx_BMGFrHxZ60ajhmPUDLIv8'
    worksheetName1 = 'AWS_Cost_before'
    worksheetName2 = 'AWS_Cost_after'
    worksheetName3 = 'Month'
    URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName1)
    URL2 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName2)
    URL3 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName3)
    aws_before=pd.read_csv(URL1)
    aws_after=pd.read_csv(URL2)
    month=pd.read_csv(URL3)
    df1=month.merge(aws_before,on=['Month_Name','year'],how='left').fillna(0)
    df2=df1.merge(aws_after,on=['Month_Name','year'],how='left').fillna(0)
    user_count_mar2020_onwards['Month_Name']=user_count_mar2020_onwards['month'].apply(lambda x: calendar.month_name[x])
    atm_user_mar2020_onwards['Month_Name']=atm_user_mar2020_onwards['month'].apply(lambda x: calendar.month_name[x])
    df3=df2.merge(user_count_mar2020_onwards,on=['Month_Name','year'],how='left').fillna(0)
    df4=df3.merge(atm_user_mar2020_onwards,on=['Month_Name','year'],how='left').fillna(0)
    df5=df4.drop(['month_x','month_y'],axis=1)
    df5['year']=df5['year'].astype('str')
    df5['User_Count_Cumulative']=df5['User_Count'].cumsum()
    df5['time_period']=df5[['Month_Name', 'year']].apply(lambda x: ' '.join(x), axis = 1)
    df5['TotaL_Cost']=df5.Total_Cost_Before+df5.Total_Cost_After
    temp={'Month_Name':df5.time_period.tolist(),
          'TotaL_Cost':df5.TotaL_Cost.tolist(),
          'Practice_Sessions':df5.Practice_Sessions.tolist(),
          'User_Growth':df5.User_Count_Cumulative.tolist()
         }
    return json.dumps({'data':temp})

# @app.route('/mongomosttimeconquery')
# def mongo_most_timeconsuming():
#     googleSheetId = '1V50tiyckuiIM_dmBb2WFx_BMGFrHxZ60ajhmPUDLIv8'
#     worksheetName1 = 'query_fetch'
#     URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName1)
#     top_ten_time_consuming=pd.read_csv(URL1)
#     top_ten_time_consuming['Mongo_fetch_time']=round(top_ten_time_consuming['Mongo_fetch_time'],3)
#     top_ten_time_consuming['Average']=round(top_ten_time_consuming.Mongo_fetch_time.mean(),3)
#     temp={
#         'Collection_Name':top_ten_time_consuming.mongodb.tolist(),
#         'Operation_Time':top_ten_time_consuming.Mongo_fetch_time.tolist(),
#         'Average_Time':top_ten_time_consuming.Average.tolist()
#     }
    
#     return json.dumps({'data':temp})
# @app.route('/mysqlmosttimeconquery')
# def mysql_most_timeconsuming():
#     googleSheetId = '1V50tiyckuiIM_dmBb2WFx_BMGFrHxZ60ajhmPUDLIv8'
#     worksheetName1 = 'query_fetch'
#     URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName1)
#     top_ten_time_consuming=pd.read_csv(URL1)
#     top_ten_time_consuming['Mysql_fetch_time']=round(top_ten_time_consuming['Mysql_fetch_time'],3)
#     top_ten_time_consuming['Average']=round(top_ten_time_consuming.Mysql_fetch_time.mean(),3)
#     temp={
#         'Collection_Name':top_ten_time_consuming.Mysql.tolist(),
#         'Operation_Time':top_ten_time_consuming.Mysql_fetch_time.tolist(),
#         'Average_Time':top_ten_time_consuming.Average.tolist()
#     }
#     return json.dumps({'data':temp})

@app.route('/mongovssqlquery')
def query_comparison():
    googleSheetId = '1V50tiyckuiIM_dmBb2WFx_BMGFrHxZ60ajhmPUDLIv8'
    worksheetName1 = 'query_fetch'
    URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName1)
    query_execution=pd.read_csv(URL1)
    query_execution[['Mongo_fetch_time','Mysql_fetch_time']]=round(query_execution[['Mongo_fetch_time','Mysql_fetch_time']],3)
    temp={'table_name':query_execution['Data_Source'].tolist(),
         'mongodb':query_execution['Mongo_fetch_time'].tolist(),
          'mysql':query_execution['Mysql_fetch_time'].tolist()
         }
    return json.dumps({'data':temp})

    
# @app.route('/awschart')
# def AWS():
#     googleSheetId1 = '1Syk9Xqvvz07phGrC52Xsy7JlyBEfkBIAUonQwgkMDh8'
#     worksheetName1 = 'aws_relaeses1'
#     URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
#     googleSheetId1,
#     worksheetName1
#     )
#     df = pd.read_csv(URL1)

#     #Cost vs User growth
#     googleSheetId3 = '1Syk9Xqvvz07phGrC52Xsy7JlyBEfkBIAUonQwgkMDh8'
#     worksheetName3= 'Cost_vs_User_Growth'
#     URL3= 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
#     googleSheetId3,
#     worksheetName3
#     )
#     df1= pd.read_csv(URL3)

#     #Cost_vs_Playbacks
#     googleSheetId4 = '1Syk9Xqvvz07phGrC52Xsy7JlyBEfkBIAUonQwgkMDh8'
#     worksheetName4= 'Cost_vs_Playbacks'
#     URL4 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
#     googleSheetId4,
#     worksheetName4
#     )
#     df2 = pd.read_csv(URL4)
#     df['date'] = pd.to_datetime(df['date'])
#     df['date'] = df['date'].astype(np.int64) / int(1e6)
#     df4=df[['date','count of AWS features']].fillna(0)  
#     AWS_FeaTures = df4.values.tolist()
#     df1['Date'] = pd.to_datetime(df1['Date'])
#     df1['Date'] = df1['Date'].astype(np.int64) / int(1e6)
#     df5=df1[['Date','School Users']].fillna(0) 
#     df6=df1[['Date','Family Users']].fillna(0) 
#     df7=df1[['Date','Cost($)']].fillna(0)  
#     School_Users = df5.values.tolist()
#     Family_Users = df6.values.tolist()
#     Cost = df7.values.tolist()
#     df2['Date'] = pd.to_datetime(df2['Date'])
#     df2[(df2.Date>= '2017-01-01')]
#     df2['Date'] = df2['Date'].astype(np.int64) / int(1e6)
#     df8=df2[['Date','Users Playback']].fillna(0)
#     df9=df2[['Date','Family Playback']].fillna(0) 
#     df10=df2[['Date','Cost per Playback(Cents)']].fillna(0)    
#     Users_Playback = df8.values.tolist()
#     Family_Playback = df9.values.tolist()
#     cost_per_playback = df10.values.tolist()
#     temp={"releases":{"AWS_FEATURES":AWS_FeaTures},"growth":{"School_Users":School_Users,"Family_Users":Family_Users,"Cost":Cost},"playback":{"Users_Playback":Users_Playback,"Family_Playback":Family_Playback,"cost_per_playback":cost_per_playback}}


#     return(json.dumps(temp))


@app.route('/awschart')
def AWS():

    googleSheetId1 = '1Syk9Xqvvz07phGrC52Xsy7JlyBEfkBIAUonQwgkMDh8'
    worksheetName1 = 'aws_relaeses1'
    URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId1,
    worksheetName1
    )
    df = pd.read_csv(URL1)
    #Cost vs User growth
    googleSheetId3 = '1Syk9Xqvvz07phGrC52Xsy7JlyBEfkBIAUonQwgkMDh8'
    worksheetName3= 'Cost_vs_User_Growth'
    URL3= 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId3,
    worksheetName3
    )
    df1= pd.read_csv(URL3)
    #Cost_vs_Playbacks
    googleSheetId4 = '1Syk9Xqvvz07phGrC52Xsy7JlyBEfkBIAUonQwgkMDh8'
    worksheetName4= 'Cost_vs_Playbacks'
    URL4 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(
    googleSheetId4,
    worksheetName4
    )
    df2 = pd.read_csv(URL4)
    df['date'] = pd.to_datetime(df['date'])
    df['date'] = df['date'].astype(np.int64) / int(1e6)
    df4=df[['date','count of AWS features']].fillna(0)
    AWS_FeaTures = df4.values.tolist()
    df1['Date'] = pd.to_datetime(df1['Date'])
    df1['Date'] = df1['Date'].astype(np.int64) / int(1e6)
    df5=df1[['Date','Classroom']].fillna(0)
    df6=df1[['Date','Home']].fillna(0)
    df7=df1[['Date','Cost($)']].fillna(0)
    df77=df1[['Date','Clever']].fillna(0)
    df88=df1[['Date','Schoology']].fillna(0)
    df99=df1[['Date','Canvas']].fillna(0)
    School_Users = df5.values.tolist()
    Family_Users = df6.values.tolist()
    Clever_users=df77.values.tolist()
    Schoology_users=df88.values.tolist()
    Canvas_users=df99.values.tolist()
    Cost = df7.values.tolist()
    df2['Date'] = pd.to_datetime(df2['Date'])
    df2[(df2.Date>= '2017-01-01')]
    df2['Date'] = df2['Date'].astype(np.int64) / int(1e6)
    df8=df2[['Date','Classroom']].fillna(0)
    df9=df2[['Date','Home']].fillna(0)
    df10=df2[['Date','Cost per Playback(Cents)']].fillna(0)
    df777=df1[['Date','Clever']].fillna(0)
    df888=df1[['Date','Schoology']].fillna(0)
    df999=df1[['Date','Canvas']].fillna(0)
    Users_Playback = df8.values.tolist()
    Family_Playback = df9.values.tolist()
    Clever_Playback=df777.values.tolist()
    Schoology_Playback=df888.values.tolist()
    Canvas_Playback=df999.values.tolist()
    cost_per_Playback = df10.values.tolist()
    temp={"releases":{"AWS_FEATURES":AWS_FeaTures},"growth":{"School_Users":School_Users,"Family_Users":Family_Users,"Cost":Cost,
                       "Clever_users":Clever_users,'Schoology_users':Schoology_users,'Canvas_users':Canvas_users},
          "playback":{"Users_Playback":Users_Playback,"Family_Playback":Family_Playback,"cost_per_playback":cost_per_Playback,
            "Clever_Playback":Clever_Playback,'Schoology_Playback':Schoology_Playback,'Canvas_Playback':Canvas_Playback
                     }}
    return(json.dumps(temp))







@app.route('/AWSTABLE/<date>')
def AWS_TABLE(date):

    googleSheetId2 = '1Syk9Xqvvz07phGrC52Xsy7JlyBEfkBIAUonQwgkMDh8'
    worksheetName2 = 'release_dashboard'
    URL2 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId2,worksheetName2)
    df2 = pd.read_csv(URL2) 
    df2['Dates']=pd.to_datetime(df2['Dates'])
    df2['Dates']=df2['Dates'].astype(str)
    df3 = df2[df2.Dates.str.contains("" + date + "",case=False)]
    df4=df3.values.tolist()
    temp={'data':df4}
    return json.dumps(temp)

@app.route('/relicweeklyresponse')
def relic_weekly_response():
    googleSheetId = '1V50tiyckuiIM_dmBb2WFx_BMGFrHxZ60ajhmPUDLIv8'
    worksheetName1 = 'Average_response_relic_weekly'
    URL1 = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName1)
    response_weekly_average=pd.read_csv(URL1)
    df1=response_weekly_average.groupby('Days')['Practice_sessions',"Average Response time"].mean().reset_index()
    df1.Practice_sessions=df1.Practice_sessions.round(0)
    df1['Average Response time']=df1['Average Response time'].round(2)
    temp={
        'Days':df1.Days.tolist(),
        'average_practice_sessions':df1.Practice_sessions.tolist(),
        'average_response_time':df1['Average Response time'].tolist()}
    return json.dumps({'data':temp})

@app.route('/districtescore/<disid>')
def districtescore(disid):
    disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
        '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
        '5f2609807a1c0000950bb475':'Agawam School district',
        '5f2609807a1c0000950bb481':'Alameda Unified School District',
        '5f2609807a1c0000950bb47a':'Alpine School District',
        '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
        '5f2609807a1c0000950bb463':'Austin Independent School District',
        '5f59e4836451a9089d7d4007':'Belleville School District',
        '5f2609807a1c0000950bb46d':'Broward County Public Schools',
        '5f2609807a1c0000950bb46c':'Chico Unified School District',
        '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
        '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
        '5f2609807a1c0000950bb45c':'Comox Valley School District(sd71)',
        '5f2609807a1c0000950bb480':'Dell Texas',
        '5f7413ef9387fd71ce6387cb':'Douglas County School District',
        '5f895191609e08b76029f641':'Early learning Sarasota',
        '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
        '5f2609807a1c0000950bb461':'Englewood Public School District',
        '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
        '5f2609807a1c0000950bb47d':'Flint Public Schools',
        '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
        '5f2609807a1c0000950bb450':'Goleta District',
        '5f2609807a1c0000950bb474':'Greenburgh-North Castle (GNC) Union Free School District',
        '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
        '5f2609807a1c0000950bb476':'Hillsborough County',
        '5f2609807a1c0000950bb455':'Krum Independent School District',
        '5f2609807a1c0000950bb47e':'La Joya School District',
        '5f2609807a1c0000950bb467':'Lincolnshire Schools',
        '5f2609807a1c0000950bb45a':'LAUSD',
        '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
        '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
        '5fbcdf0ba84e48a64412a798':'Needham School District',
        '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
        '5f6994386451a9089d7d4009':'Ogden school district',
        '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
        '5fd704da04a848e368de5dc6':'Oakland Unified School District',
        '5f8fcd33609e08b76029f644':'Paradise Unified School District',
        '5f2609807a1c0000950bb466':'Pinellas County Schools',
        '5f2609807a1c0000950bb471':'Racine Unified Schools',
        '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
        '5f2609807a1c0000950bb478':'San Diego Unified School District',
        '5f2609807a1c0000950bb470':'San Leandro Unified School District',
        '5f2609807a1c0000950bb477':'Sarasota County',
        '5f2609807a1c0000950bb473':'Skillman Foundation',
        '5f2609807a1c0000950bb46a':'Springfield Public Schools',
        '5f2609807a1c0000950bb468':'Utah Board of Education',
        '5f698b826451a9089d7d4008':'Wayne Metro',
        '5f2609807a1c0000950bb45b':'Westfield Public School District',
        '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
        '5f2609807a1c0000950bb45d':'Youngstown',
        '5f2609807a1c0000950bb464':'Equity Education',
        '5f2609807a1c0000950bb469':'LSF -  Head Start',
        '5f2609807a1c0000950bb46e':'District 25 New York Schools',
        '5f2609807a1c0000950bb46f':'Paradise Schools',
        '5f2609807a1c0000950bb479':'Panorama Education',
        '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
        '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
        '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
        '5fe2e25d4d0ca68d7baf889d':'BGCA',
        '5fe318b14d0ca68d7baf889e':'BLUE',
        '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
        '6017ab3043ca9c39151838d4':'Oswego School District',
        '60239a84e57dc27613699d57':'Austin Independent School District',
        '6023a6d79e8e623753fc305c':'Boulder Valley School District',
        '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
        '6023a7269e8e623753fc305e':'Fulton County School System',
        '6023a7499e8e623753fc305f':'Manatee County School District',
        '6023a76f9e8e623753fc3060':'San Jose Unified School District',
        '6023a7949e8e623753fc3061':'Wasatch County School District'}
    district=disdic[disid]
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    
    def csy_first_date():
        date_today =datetime.date.today()
    #     print(date_today)
    #     date_today='2024-07-01'
    #     day_end=datetime.datetime.strptime(date_today, '%Y-%m-%d').date()
        initial_date='2020-08-01'
        day1=datetime.datetime.strptime(initial_date, '%Y-%m-%d').date()
        # Check if leap year in the calculation
        if ((day1.year+1) % 4) == 0:
            if ((day1.year+1) % 100) == 0:
                if ((day1.year+1) % 400) == 0:
                    days_diff=1
                else:
                    days_diff=1
            else:
                days_diff=1
        else:
            days_diff=0
        if ((date_today-day1).days<(365+days_diff)):
            day_1=day1
        else:
            day1=day1+timedelta(days=(365+days_diff))
            day_1=day1

        csy_date=datetime.datetime.strptime((day_1.strftime('%Y-%m-%d')), '%Y-%m-%d')

        return csy_date
        # LSY logic:
    LSY_Date=csy_first_date()-relativedelta(years=1)
    #     print("LSY", LSY_Date)
    #     print("CSY",csy_first_date())
    
    collection = db.user_master.aggregate([
    {"$match":{"schoolId":{"$exists":1}}},
    {"$match":
        {"$and":[
    {"schoolId._id":{"$in":db.school_master.distinct( "_id", {"CATEGORY":{'$regex':district, '$options':'i'} } )}},
            {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
    ,
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME","USER_NAME":"$USER_NAME",
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME","CREATED_DATE":{ "$dateToString": { "format": "%Y-%m-%d", "date":"$CREATED_DATE"}}}}

    ])
    df1= DataFrame(list(collection)).fillna(0)
    user_list=df1["USER_ID"].tolist()
    total_school=df1.groupby(["ID","school_name"])["USER_ID"].count().reset_index()
    total_users=len(user_list)
    collection2 = db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                        "$in":user_list

                    }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
    #            {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}        
            ]}},
            {'$group':{
                    
                '_id':{"USER_ID":"$USER_ID._id","SCHOOLiD":'$USER_ID.schoolId._id'},
                'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                'Active_User':{'$addToSet':'$USER_ID._id'},
                'Practice_Sessions':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':
                    [{'$divide':[{'$subtract':
                        ['$CURSOR_END','$cursorStart']},60]},0]}}  
                }},
            {'$project':{'_id':0,
                        "USER_ID":"$_id.USER_ID",
                        "USER_ID":"$_id.USER_ID",
                'SCHOOL_ID':'$_id.SCHOOLiD',
                'LAST_PRACTICE_DATE':{ "$dateToString": { "format": "%Y-%m-%d", "date":'$Last_Prac_Date'}},
                'PRACTICE_COUNT':'$Practice_Sessions',
                'MINDFUL_MINUTES':'$Mindful_Minutes'
                }
                }])
    df3= DataFrame(list(collection2)).fillna(0)
    final=pd.merge(df1, df3, on='USER_ID',how='left').fillna(0)
    total_users_school=final.groupby(["ID","school_name"])["USER_ID"].count().reset_index()
    ######################### percentage_of_active_users ############################
    final1 = final[final.PRACTICE_COUNT != 0]
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    final1["TODAY_DATE"]=d1
    final1['LAST_PRACTICE_DATE'] = pd.to_datetime(final1['LAST_PRACTICE_DATE'])
    final1['CREATED_DATE'] = pd.to_datetime(final1['CREATED_DATE'])
    final1["TODAY_DATE"] = pd.to_datetime(final1["TODAY_DATE"])
    final1['DAYS'] = (final1["TODAY_DATE"] - final1['CREATED_DATE']).dt.days
    final1['DAYS'] = pd.to_numeric(final1['DAYS'])
    final1["PRACTICE_COUNT"] = pd.to_numeric(final1["PRACTICE_COUNT"])
    final1.loc[(final1['DAYS'] > 60) & (final1["PRACTICE_COUNT"] >= 20), 'STATUS'] = 'ACTIVE'  #ACTIVE
    final1.loc[(final1['DAYS'] <= 60), 'THRESHOLD'] = (final1['DAYS']/60)*20
    final1.loc[((final1["THRESHOLD"]!=0) & (final1["PRACTICE_COUNT"]>final1["THRESHOLD"])), 'STATUS'] = 'ACTIVE'  #ACTIVE
    final1=final1.fillna(0)    
    active_users=final1[final1["STATUS"]=="ACTIVE"]
    active_users_school=active_users.groupby(["ID","school_name"])["_id"].count().reset_index()
    active_users_final=pd.merge(active_users_school, total_users_school, on='ID',how='left').fillna(0)
    active_users_final["p_of_active_users"]=round((active_users_final["_id"]/active_users_final["USER_ID"])*100)
    p_of_active_users=round(active_users_final["p_of_active_users"].mean())
    AUSW=active_users_final[["ID","school_name_x","p_of_active_users"]]
    AUSW0=pd.merge(AUSW, total_school, on='ID',how='right').fillna(0)
    AUSW1=AUSW0[["school_name","p_of_active_users"]]
    AUSW1.loc[(AUSW1["p_of_active_users"] > 100), 'p_of_active_users'] = 100  
    AUSW1["NAME"]="ACTIVE USER"
    AUSW1=AUSW1.round()
    links0 = AUSW1.rename(columns={'school_name' : 'y', 'NAME' : 'x','p_of_active_users':'heat'}).to_dict('r')
    ###################################################################################
    ##################### PERCENTAGE_ACTIVE_USAGE ################################
    collection3 = db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                        "$in":user_list

                    }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
            {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
    #           {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}      
            ]}},
            # {'$project':{
            #             "USER_ID":"$USER_ID._id",
            #     'MODIFIED_DATE':{ "$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}},
            #     'CURSOR_END':'$CURSOR_END',
            #     'cursorStart':'$cursorStart'
            #     }
            #     },
            {'$group':{
                    
                '_id':{"USER_ID":"$USER_ID._id",'MODIFIED_DATE':'$MODIFIED_DATE'},
                'First_Prac_Date':{'$min':'$MODIFIED_DATE'},
                'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                'Practice_Sessions':{'$sum':1}
                }},
            {'$project':{'_id':0,
                        "USER_ID":"$_id.USER_ID",
                'LAST_PRACTICE_DATE':'$Last_Prac_Date',
                'FIRST_PRACTICE_DATE':'$First_Prac_Date',
                'PRACTICE_DAYS':'$Practice_Sessions'
                }
            }
                ,
                {'$group':{
                    
                '_id':{"USER_ID":"$USER_ID"},
                'First_Prac_Date':{'$min':'$FIRST_PRACTICE_DATE'},
                'Last_Prac_Date':{'$max':'$LAST_PRACTICE_DATE'},
                'Practice_Sessions':{'$sum':'$PRACTICE_DAYS'}
                }},
                {'$project':{'_id':0,
                "USER_ID":"$_id.USER_ID",
                'LAST_PRACTICE_DATE':{ "$dateToString": { "format": "%Y-%m-%d", "date":'$Last_Prac_Date'}},
                'FIRST_PRACTICE_DATE':{ "$dateToString": { "format": "%Y-%m-%d", "date":'$First_Prac_Date'}},
                'PRACTICE_DAYS':'$Practice_Sessions'
                }
                },
        
                ])
    df4= DataFrame(list(collection3)).fillna(0)
    usage=pd.merge(df1, df4, on='USER_ID',how='left').fillna(0)
    usage1 = usage[usage.PRACTICE_DAYS != 0].reset_index()
    usage1["TODAY_DATE"]=d1
    usage1['FIRST_PRACTICE_DATE'] = pd.to_datetime(usage1['FIRST_PRACTICE_DATE'])
    usage1["LAST_PRACTICE_DATE"] = pd.to_datetime(usage1["LAST_PRACTICE_DATE"])
    usage1["TODAY_DATE"] = pd.to_datetime(usage1["TODAY_DATE"])
    usage1["DAYSKIP"]=0
    for i in range(len(usage1.index)):
        skip_count = 0
        start = usage1['FIRST_PRACTICE_DATE'][i]
        end = today
        dates_to_skip = [Timestamp('2018-01-01 00:00:00'), Timestamp('2018-01-30 00:00:00'), Timestamp('2018-01-31 00:00:00'), Timestamp('2018-04-05 00:00:00'), Timestamp('2018-04-06 00:00:00'),
            Timestamp('2018-04-07 00:00:00'), Timestamp('2018-04-08 00:00:00'), Timestamp('2018-04-09 00:00:00'), Timestamp('2018-06-16 00:00:00'), Timestamp('2018-06-17 00:00:00'), Timestamp('2018-06-18 00:00:00'),
            Timestamp('2018-06-19 00:00:00'), Timestamp('2018-06-20 00:00:00'), Timestamp('2018-06-21 00:00:00'), Timestamp('2018-06-22 00:00:00'), Timestamp('2018-06-23 00:00:00'), Timestamp('2018-06-24 00:00:00'),
            Timestamp('2018-06-25 00:00:00'), Timestamp('2018-06-26 00:00:00'), Timestamp('2018-06-27 00:00:00'), Timestamp('2018-06-28 00:00:00'), Timestamp('2018-06-29 00:00:00'), Timestamp('2018-06-30 00:00:00'),
            Timestamp('2018-07-01 00:00:00'), Timestamp('2018-07-02 00:00:00'), Timestamp('2018-07-03 00:00:00'), Timestamp('2018-07-04 00:00:00'), Timestamp('2018-07-05 00:00:00'), Timestamp('2018-07-06 00:00:00'),
            Timestamp('2018-07-07 00:00:00'), Timestamp('2018-07-08 00:00:00'), Timestamp('2018-07-09 00:00:00'), Timestamp('2018-07-10 00:00:00'), Timestamp('2018-07-11 00:00:00'), Timestamp('2018-07-12 00:00:00'),
            Timestamp('2018-07-13 00:00:00'), Timestamp('2018-07-14 00:00:00'), Timestamp('2018-07-15 00:00:00'), Timestamp('2018-07-16 00:00:00'), Timestamp('2018-07-17 00:00:00'), Timestamp('2018-07-18 00:00:00'),
            Timestamp('2018-07-19 00:00:00'), Timestamp('2018-07-20 00:00:00'), Timestamp('2018-07-21 00:00:00'), Timestamp('2018-07-22 00:00:00'), Timestamp('2018-07-23 00:00:00'), Timestamp('2018-07-24 00:00:00'),
            Timestamp('2018-07-25 00:00:00'), Timestamp('2018-07-26 00:00:00'), Timestamp('2018-07-27 00:00:00'), Timestamp('2018-07-28 00:00:00'), Timestamp('2018-07-29 00:00:00'), Timestamp('2018-07-30 00:00:00'),
            Timestamp('2018-07-31 00:00:00'), Timestamp('2018-08-01 00:00:00'), Timestamp('2018-08-02 00:00:00'), Timestamp('2018-08-03 00:00:00'), Timestamp('2018-08-04 00:00:00'), Timestamp('2018-08-05 00:00:00'),
            Timestamp('2018-08-06 00:00:00'), Timestamp('2018-08-07 00:00:00'), Timestamp('2018-08-08 00:00:00'), Timestamp('2018-08-09 00:00:00'), Timestamp('2018-08-10 00:00:00'), Timestamp('2018-08-11 00:00:00'),
            Timestamp('2018-08-12 00:00:00'), Timestamp('2018-08-13 00:00:00'), Timestamp('2018-08-14 00:00:00'), Timestamp('2018-09-18 00:00:00'), Timestamp('2018-11-26 00:00:00'), Timestamp('2018-11-27 00:00:00'),
            Timestamp('2018-11-28 00:00:00'), Timestamp('2018-12-21 00:00:00'), Timestamp('2018-12-22 00:00:00'), Timestamp('2018-12-23 00:00:00'), Timestamp('2018-12-24 00:00:00'), Timestamp('2018-12-25 00:00:00'),
            Timestamp('2018-12-26 00:00:00'), Timestamp('2018-12-27 00:00:00'), Timestamp('2018-12-28 00:00:00'), Timestamp('2018-12-29 00:00:00'), Timestamp('2018-12-30 00:00:00'), Timestamp('2018-12-31 00:00:00'),
            Timestamp('2019-01-01 00:00:00'), Timestamp('2019-01-30 00:00:00'), Timestamp('2019-01-31 00:00:00'), Timestamp('2019-04-05 00:00:00'), Timestamp('2019-04-06 00:00:00'), Timestamp('2019-04-07 00:00:00'),
            Timestamp('2019-04-08 00:00:00'), Timestamp('2019-04-09 00:00:00'), Timestamp('2019-06-16 00:00:00'), Timestamp('2019-06-17 00:00:00'), Timestamp('2019-06-18 00:00:00'), Timestamp('2019-06-19 00:00:00'),
            Timestamp('2019-06-20 00:00:00'), Timestamp('2019-06-21 00:00:00'), Timestamp('2019-06-22 00:00:00'), Timestamp('2019-06-23 00:00:00'), Timestamp('2019-06-24 00:00:00'), Timestamp('2019-06-25 00:00:00'),
            Timestamp('2019-06-26 00:00:00'), Timestamp('2019-06-27 00:00:00'), Timestamp('2019-06-28 00:00:00'), Timestamp('2019-06-29 00:00:00'), Timestamp('2019-06-30 00:00:00'), Timestamp('2019-07-01 00:00:00'),
            Timestamp('2019-07-02 00:00:00'), Timestamp('2019-07-03 00:00:00'), Timestamp('2019-07-04 00:00:00'), Timestamp('2019-07-05 00:00:00'), Timestamp('2019-07-06 00:00:00'), Timestamp('2019-07-07 00:00:00'),
            Timestamp('2019-07-08 00:00:00'), Timestamp('2019-07-09 00:00:00'), Timestamp('2019-07-10 00:00:00'), Timestamp('2019-07-11 00:00:00'), Timestamp('2019-07-12 00:00:00'), Timestamp('2019-07-13 00:00:00'),
            Timestamp('2019-07-14 00:00:00'), Timestamp('2019-07-15 00:00:00'), Timestamp('2019-07-16 00:00:00'), Timestamp('2019-07-17 00:00:00'), Timestamp('2019-07-18 00:00:00'), Timestamp('2019-07-19 00:00:00'),
            Timestamp('2019-07-20 00:00:00'), Timestamp('2019-07-21 00:00:00'), Timestamp('2019-07-22 00:00:00'), Timestamp('2019-07-23 00:00:00'), Timestamp('2019-07-24 00:00:00'), Timestamp('2019-07-25 00:00:00'),
            Timestamp('2019-07-26 00:00:00'), Timestamp('2019-07-27 00:00:00'), Timestamp('2019-07-28 00:00:00'), Timestamp('2019-07-29 00:00:00'), Timestamp('2019-07-30 00:00:00'), Timestamp('2019-07-31 00:00:00'),
            Timestamp('2019-08-01 00:00:00'), Timestamp('2019-08-02 00:00:00'), Timestamp('2019-08-03 00:00:00'), Timestamp('2019-08-04 00:00:00'), Timestamp('2019-08-05 00:00:00'), Timestamp('2019-08-06 00:00:00'),
            Timestamp('2019-08-07 00:00:00'), Timestamp('2019-08-08 00:00:00'), Timestamp('2019-08-09 00:00:00'), Timestamp('2019-08-10 00:00:00'), Timestamp('2019-08-11 00:00:00'), Timestamp('2019-08-12 00:00:00'),
            Timestamp('2019-08-13 00:00:00'), Timestamp('2019-08-14 00:00:00'), Timestamp('2019-09-18 00:00:00'), Timestamp('2019-11-26 00:00:00'), Timestamp('2019-11-27 00:00:00'), Timestamp('2019-11-28 00:00:00'),
            Timestamp('2019-12-21 00:00:00'), Timestamp('2019-12-22 00:00:00'), Timestamp('2019-12-23 00:00:00'), Timestamp('2019-12-24 00:00:00'), Timestamp('2019-12-25 00:00:00'), Timestamp('2019-12-26 00:00:00'),
            Timestamp('2019-12-27 00:00:00'), Timestamp('2019-12-28 00:00:00'), Timestamp('2019-12-29 00:00:00'), Timestamp('2019-12-30 00:00:00'), Timestamp('2019-12-31 00:00:00'), Timestamp('2020-01-01 00:00:00'),
            Timestamp('2020-01-30 00:00:00'), Timestamp('2020-01-31 00:00:00'), Timestamp('2020-04-05 00:00:00'), Timestamp('2020-04-06 00:00:00'), Timestamp('2020-04-07 00:00:00'), Timestamp('2020-04-08 00:00:00'),
            Timestamp('2020-04-09 00:00:00'), Timestamp('2020-06-16 00:00:00'), Timestamp('2020-06-17 00:00:00'), Timestamp('2020-06-18 00:00:00'), Timestamp('2020-06-19 00:00:00'), Timestamp('2020-06-20 00:00:00'),
            Timestamp('2020-06-21 00:00:00'), Timestamp('2020-06-22 00:00:00'), Timestamp('2020-06-23 00:00:00'), Timestamp('2020-06-24 00:00:00'), Timestamp('2020-06-25 00:00:00'), Timestamp('2020-06-26 00:00:00'),
            Timestamp('2020-06-27 00:00:00'), Timestamp('2020-06-28 00:00:00'), Timestamp('2020-06-29 00:00:00'), Timestamp('2020-06-30 00:00:00'), Timestamp('2020-07-01 00:00:00'), Timestamp('2020-07-02 00:00:00'),
            Timestamp('2020-07-03 00:00:00'), Timestamp('2020-07-04 00:00:00'), Timestamp('2020-07-05 00:00:00'), Timestamp('2020-07-06 00:00:00'), Timestamp('2020-07-07 00:00:00'), Timestamp('2020-07-08 00:00:00'),
            Timestamp('2020-07-09 00:00:00'), Timestamp('2020-07-10 00:00:00'), Timestamp('2020-07-11 00:00:00'), Timestamp('2020-07-12 00:00:00'), Timestamp('2020-07-13 00:00:00'), Timestamp('2020-07-14 00:00:00'),
            Timestamp('2020-07-15 00:00:00'), Timestamp('2020-07-16 00:00:00'), Timestamp('2020-07-17 00:00:00'), Timestamp('2020-07-18 00:00:00'), Timestamp('2020-07-19 00:00:00'), Timestamp('2020-07-20 00:00:00'),
            Timestamp('2020-07-21 00:00:00'), Timestamp('2020-07-22 00:00:00'), Timestamp('2020-07-23 00:00:00'), Timestamp('2020-07-24 00:00:00'), Timestamp('2020-07-25 00:00:00'), Timestamp('2020-07-26 00:00:00'),
            Timestamp('2020-07-27 00:00:00'), Timestamp('2020-07-28 00:00:00'), Timestamp('2020-07-29 00:00:00'), Timestamp('2020-07-30 00:00:00'), Timestamp('2020-07-31 00:00:00'), Timestamp('2020-08-01 00:00:00'),
            Timestamp('2020-08-02 00:00:00'), Timestamp('2020-08-03 00:00:00'), Timestamp('2020-08-04 00:00:00'), Timestamp('2020-08-05 00:00:00'), Timestamp('2020-08-06 00:00:00'), Timestamp('2020-08-07 00:00:00'),
            Timestamp('2020-08-08 00:00:00'), Timestamp('2020-08-09 00:00:00'), Timestamp('2020-08-10 00:00:00'), Timestamp('2020-08-11 00:00:00'), Timestamp('2020-08-12 00:00:00'), Timestamp('2020-08-13 00:00:00'),
            Timestamp('2020-08-14 00:00:00'), Timestamp('2020-09-18 00:00:00'), Timestamp('2020-11-26 00:00:00'), Timestamp('2020-11-27 00:00:00'), Timestamp('2020-11-28 00:00:00'), Timestamp('2020-12-21 00:00:00'),
            Timestamp('2020-12-22 00:00:00'), Timestamp('2020-12-23 00:00:00'), Timestamp('2020-12-24 00:00:00'), Timestamp('2020-12-25 00:00:00'), Timestamp('2020-12-26 00:00:00'), Timestamp('2020-12-27 00:00:00'),
            Timestamp('2020-12-28 00:00:00'), Timestamp('2020-12-29 00:00:00'), Timestamp('2020-12-30 00:00:00'), Timestamp('2020-12-31 00:00:00'), Timestamp('2021-01-01 00:00:00'), Timestamp('2021-01-30 00:00:00'),
            Timestamp('2021-01-31 00:00:00'), Timestamp('2021-04-05 00:00:00'), Timestamp('2021-04-06 00:00:00'), Timestamp('2021-04-07 00:00:00'), Timestamp('2021-04-08 00:00:00'), Timestamp('2021-04-09 00:00:00'),
            Timestamp('2021-06-16 00:00:00'), Timestamp('2021-06-17 00:00:00'), Timestamp('2021-06-18 00:00:00'), Timestamp('2021-06-19 00:00:00'), Timestamp('2021-06-20 00:00:00'), Timestamp('2021-06-21 00:00:00'),
            Timestamp('2021-06-22 00:00:00'), Timestamp('2021-06-23 00:00:00'), Timestamp('2021-06-24 00:00:00'), Timestamp('2021-06-25 00:00:00'), Timestamp('2021-06-26 00:00:00'), Timestamp('2021-06-27 00:00:00'),
            Timestamp('2021-06-28 00:00:00'), Timestamp('2021-06-29 00:00:00'), Timestamp('2021-06-30 00:00:00'), Timestamp('2021-07-01 00:00:00'), Timestamp('2021-07-02 00:00:00'), Timestamp('2021-07-03 00:00:00'),
            Timestamp('2021-07-04 00:00:00'), Timestamp('2021-07-05 00:00:00'), Timestamp('2021-07-06 00:00:00'), Timestamp('2021-07-07 00:00:00'), Timestamp('2021-07-08 00:00:00'), Timestamp('2021-07-09 00:00:00'),
            Timestamp('2021-07-10 00:00:00'), Timestamp('2021-07-11 00:00:00'), Timestamp('2021-07-12 00:00:00'), Timestamp('2021-07-13 00:00:00'), Timestamp('2021-07-14 00:00:00'), Timestamp('2021-07-15 00:00:00'),
            Timestamp('2021-07-16 00:00:00'), Timestamp('2021-07-17 00:00:00'), Timestamp('2021-07-18 00:00:00'), Timestamp('2021-07-19 00:00:00'), Timestamp('2021-07-20 00:00:00'), Timestamp('2021-07-21 00:00:00'),
            Timestamp('2021-07-22 00:00:00'), Timestamp('2021-07-23 00:00:00'), Timestamp('2021-07-24 00:00:00'), Timestamp('2021-07-25 00:00:00'), Timestamp('2021-07-26 00:00:00'), Timestamp('2021-07-27 00:00:00'),
            Timestamp('2021-07-28 00:00:00'), Timestamp('2021-07-29 00:00:00'), Timestamp('2021-07-30 00:00:00'), Timestamp('2021-07-31 00:00:00'), Timestamp('2021-08-01 00:00:00'), Timestamp('2021-08-02 00:00:00'),
            Timestamp('2021-08-03 00:00:00'), Timestamp('2021-08-04 00:00:00'), Timestamp('2021-08-05 00:00:00'), Timestamp('2021-08-06 00:00:00'), Timestamp('2021-08-07 00:00:00'), Timestamp('2021-08-08 00:00:00'),
            Timestamp('2021-08-09 00:00:00'), Timestamp('2021-08-10 00:00:00'), Timestamp('2021-08-11 00:00:00'), Timestamp('2021-08-12 00:00:00'), Timestamp('2021-08-13 00:00:00'), Timestamp('2021-08-14 00:00:00'),
            Timestamp('2021-09-18 00:00:00'), Timestamp('2021-11-26 00:00:00'), Timestamp('2021-11-27 00:00:00'), Timestamp('2021-11-28 00:00:00'), Timestamp('2021-12-21 00:00:00'), Timestamp('2021-12-22 00:00:00'),
            Timestamp('2021-12-23 00:00:00'), Timestamp('2021-12-24 00:00:00'), Timestamp('2021-12-25 00:00:00'), Timestamp('2021-12-26 00:00:00'), Timestamp('2021-12-27 00:00:00'), Timestamp('2021-12-28 00:00:00'),
            Timestamp('2021-12-29 00:00:00'), Timestamp('2021-12-30 00:00:00'), Timestamp('2021-12-31 00:00:00'),
            ]
        for to_skip in dates_to_skip:
            if start <= to_skip < end:
                skip_count += 1
        datestoskip=[]
        

        for to_skip in dates_to_skip:
            if start <= to_skip < end:
                    datestoskip.append(to_skip)
        usage1["DAYSKIP"][i]=len(datestoskip)
    usage1['TOTAL_DAYS'] = (usage1["TODAY_DATE"]-usage1['FIRST_PRACTICE_DATE'] ).dt.days
    usage1['TOTAL_DAYS'] = pd.to_numeric(usage1['TOTAL_DAYS'])
    usage1["DAYS"]=usage1["TOTAL_DAYS"]-usage1['DAYSKIP']
    usage1['PRACTICE_DAYS'] = pd.to_numeric(usage1['PRACTICE_DAYS'])
    usage1.loc[(usage1['DAYS'] == 0), 'DAYS'] =1
    usage1['THRESHOLD'] = usage1['PRACTICE_DAYS']/usage1['DAYS']
    usage1['THRESHOLD'] = pd.to_numeric(usage1['THRESHOLD'])
    mean=usage1['THRESHOLD'].mean()
    std=usage1['THRESHOLD'].std()
    usage1['NORMALIZED']=(usage1['THRESHOLD']-mean)/std
    MAX_THRESHOLD=usage1['NORMALIZED'].max()
    MIN_THRESHOLD=usage1['NORMALIZED'].min()
    usage1.loc[(usage1['NORMALIZED'] >= 0), 'ACTIVE_USAGE'] = (0.5+((usage1['NORMALIZED']/MAX_THRESHOLD)/2))*100
    usage1.loc[(usage1['NORMALIZED'] < 0), 'ACTIVE_USAGE'] = ((1-(usage1['NORMALIZED']/MIN_THRESHOLD))/2)*100
    active_usage=round(usage1["ACTIVE_USAGE"].mean())
    new= usage1.groupby(["ID","school_name"])['ACTIVE_USAGE'].mean().reset_index()
    AUESW=new[["ID","school_name","ACTIVE_USAGE"]]
    AUESW0=pd.merge(AUESW, total_school, on='ID',how='right').fillna(0)
    AUESW1=AUESW0[["school_name_y","ACTIVE_USAGE"]]
    AUESW1["NAME"]="ACTIVE USAGE"
    AUESW1=AUESW1.round()
    activepusage=usage1[["USER_ID","ACTIVE_USAGE"]]
    activepusage.loc[(activepusage["ACTIVE_USAGE"] > 100), "ACTIVE_USAGE"] = 100  
    links1 = AUESW1.rename(columns={'school_name_y' : 'y', 'NAME' : 'x','ACTIVE_USAGE':'heat'}).to_dict('r')
    ##############################################################################################
    #################################RECENT_ENGAGMENT############################################
    collection4 = db.audio_track_master.aggregate([
        {"$match":{"USER_ID._id":{
                        "$in":user_list

                    }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    #           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},  
    #         {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}  
            ]}},
            {'$group':{
                    
                '_id':{"USER_ID":"$USER_ID._id","SCHOOLiD":'$USER_ID.schoolId._id'},
                'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                'Active_User':{'$addToSet':'$USER_ID._id'},
                'Practice_Sessions':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':
                    [{'$divide':[{'$subtract':
                        ['$CURSOR_END','$cursorStart']},60]},0]}}  
                }},
            {'$project':{'_id':0,
                        "USER_ID":"$_id.USER_ID",
                        "USER_ID":"$_id.USER_ID",
                'SCHOOL_ID':'$_id.SCHOOLiD',
                'LAST_PRACTICE_DATE':{ "$dateToString": { "format": "%Y-%m-%d", "date":'$Last_Prac_Date'}},
                'PRACTICE_COUNT':'$Practice_Sessions',
                'MINDFUL_MINUTES':'$Mindful_Minutes'
                }
                }])
    dfe= DataFrame(list(collection4)).fillna(0)
    final1e=pd.merge(df1, dfe, on='USER_ID',how='left').fillna(0)
    final1e = final1e[final1e.PRACTICE_COUNT != 0]
    final1e["TODAY_DATE"]=d1
    final1e['LAST_PRACTICE_DATE'] = pd.to_datetime(final1e['LAST_PRACTICE_DATE'])
    final1e['CREATED_DATE'] = pd.to_datetime(final1e['CREATED_DATE'])
    final1e["TODAY_DATE"] = pd.to_datetime(final1e["TODAY_DATE"])
    final1e['DAYS'] = (final1e["TODAY_DATE"] - final1e['CREATED_DATE']).dt.days
    final1e['PRACTICE_DAYS'] = (final1e["TODAY_DATE"] - final1e['LAST_PRACTICE_DATE']).dt.days
    final1e['DAYS'] = pd.to_numeric(final1e['DAYS'])
    final1e["PRACTICE_COUNT"] = pd.to_numeric(final1e["PRACTICE_COUNT"])
    engagment=final1e[["_id","USER_ID","ID","school_name","USER_NAME","email_id","district_name","CREATED_DATE","SCHOOL_ID","LAST_PRACTICE_DATE","PRACTICE_COUNT","MINDFUL_MINUTES","TODAY_DATE","DAYS",'PRACTICE_DAYS']]
    engagment=pd.merge(engagment, activepusage, on='USER_ID',how='left').fillna(0)
    ################ 30_DAYS #########
    days_30=engagment[(engagment["DAYS"]<=30)|(engagment["PRACTICE_DAYS"]<=30)]
    if days_30.empty == True:
    #     days_30_score=0
        days_30["ID"]=0
        days_30["school_name"]="NO SCHOOL"
        days_30["SCORE"]=0
        days_30["POSSIBLE_SCORE"]=0
    else:
        days_30.loc[(days_30['PRACTICE_COUNT'] >=5), 'SCORE'] = 2
        days_30.loc[(days_30['PRACTICE_COUNT'] < 5), 'SCORE'] = 1
        days_30['POSSIBLE_SCORE']=2
    #     days_30_score= (sum(days_30['SCORE'])/sum(days_30['POSSIBLE_SCORE']))*100
    ###################################

    ################ 60_DAYS ##########
    days_60=engagment[(engagment["DAYS"]<=60) |(engagment["PRACTICE_DAYS"]<=60)]
    if days_60.empty == True:
    #     days_60_score=0
        days_60["ID"]=0
        days_60["school_name"]="NO SCHOOL"
        days_60["SCORE"]=0
        days_60["POSSIBLE_SCORE"]=0
    else:
        days_60.loc[(days_60['PRACTICE_COUNT'] >=10), 'SCORE'] = 2
        days_60.loc[(days_60['PRACTICE_COUNT'] < 10), 'SCORE'] = 1
        days_60['POSSIBLE_SCORE']=2
    #     days_60_score= (sum(days_60['SCORE'])/sum(days_60['POSSIBLE_SCORE']))*100
    ###################################

    ################ 180_DAYS ##########
    days_180=engagment[(engagment["DAYS"]<=180)|(engagment["PRACTICE_DAYS"]<=180)]
    if days_180.empty == True:
    #     days_180_score=0
        days_180["ID"]=0
        days_180["school_name"]="NO SCHOOL"
        days_180["SCORE"]=0
        days_180["POSSIBLE_SCORE"]=0
    else:
        days_180.loc[(days_180['PRACTICE_COUNT'] >=30), 'SCORE'] = 2
        days_180.loc[(days_180['PRACTICE_COUNT'] < 30), 'SCORE'] = 1
        days_180['POSSIBLE_SCORE']=2
    #     days_180_score= (sum(days_180['SCORE'])/sum(days_180['POSSIBLE_SCORE']))*100
    ###################################

    ################ 365_DAYS ##########
    days_365=engagment[(engagment["DAYS"]<=365)|(engagment["PRACTICE_DAYS"]<=365)]
    if days_365.empty == True:
    #     days_365_score=0
        days_365["ID"]=0
        days_365["school_name"]="NO SCHOOL"
        days_365["SCORE"]=0
        days_365["POSSIBLE_SCORE"]=0
    else:
        days_365.loc[(days_365['PRACTICE_COUNT'] >= 60), 'SCORE'] = 2
        days_365.loc[(days_365['PRACTICE_COUNT'] < 60), 'SCORE'] = 1
        days_365['POSSIBLE_SCORE']=2
    #     days_365_score= (sum(days_365['SCORE'])/sum(days_365['POSSIBLE_SCORE']))*100
    ###################################

    ################ THIS_SCHOOL_YEAR ##########
    this_school_year=engagment[(engagment["CREATED_DATE"]>=str(csy_first_date()))|(engagment["LAST_PRACTICE_DATE"]<=str(csy_first_date()))]
    if this_school_year.empty == True:
    #     this_school_year_score=0
        this_school_year["ID"]=0
        this_school_year["school_name"]="NO SCHOOL"
        this_school_year["SCORE"]=0
        this_school_year["POSSIBLE_SCORE"]=0  

    else:
        a_date = str(csy_first_date())
        this_school_days = round((( pd.to_datetime(d1) -  pd.to_datetime(a_date)).days)/6)
        this_school_year.loc[(this_school_year['PRACTICE_COUNT'] >= this_school_days), 'SCORE'] = 2
        this_school_year.loc[(this_school_year['PRACTICE_COUNT'] < this_school_days), 'SCORE'] = 1
        this_school_year['POSSIBLE_SCORE']=2
    #     this_school_year_score= (sum(this_school_year['SCORE'])/sum(this_school_year['POSSIBLE_SCORE']))*100
    ###################################

    ################ LIFETIME ##########
    lifetime=engagment[engagment["PRACTICE_COUNT"]>0]
    if lifetime.empty == True:
    #     lifetime_score=0
        lifetime["ID"]=0
        lifetime["school_name"]="NO SCHOOL"
        lifetime["SCORE"]=0
        lifetime["POSSIBLE_SCORE"]=0  
    else:
        this_school_days1 = 1/6
        lifetime.loc[(lifetime['ACTIVE_USAGE'] >= this_school_days1), 'SCORE'] = 2
        lifetime.loc[(lifetime['ACTIVE_USAGE'] < this_school_days1), 'SCORE'] = 1
        lifetime['POSSIBLE_SCORE']=2
    #     lifetime_score= (sum(this_school_year['SCORE'])/sum(this_school_year['POSSIBLE_SCORE']))*100
    ###################################
    a=days_30[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
    b=days_60[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
    c=days_180[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
    d=days_365[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
    e=this_school_year[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
    f=lifetime[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
    engagmentfinaldf=pd.concat([a,b,c,d,e,f], axis=0)
    engagment_school_final=engagmentfinaldf.groupby(["ID","school_name"]).sum().reset_index()
    engagment_school_final["RECENT_ENGAGMENT"]= (engagment_school_final['SCORE']/engagment_school_final['POSSIBLE_SCORE'])*100
    percentage_recent_engagment=round(engagment_school_final["RECENT_ENGAGMENT"]).mean()
    RESW=engagment_school_final[["ID","school_name","RECENT_ENGAGMENT"]]
    RESW0=pd.merge(RESW, total_school, on='ID',how='right').fillna(0)
    RESW1=RESW0[["school_name_y","RECENT_ENGAGMENT"]]
    RESW1.loc[(RESW1["RECENT_ENGAGMENT"] > 100), "RECENT_ENGAGMENT"] = 100  
    RESW1["NAME"]="RECENT ENGAGEMENT"
    RESW1=RESW1.round()
    links2 = RESW1.rename(columns={'school_name_y' : 'y', 'NAME' : 'x','RECENT_ENGAGMENT':'heat'}).to_dict('r')
    ########################################################################################
    ###############################Consistent Weekly Practice#######################
    collection5 = db.audio_track_master
    query5=[ {"$match":{"USER_ID._id":{
                        "$in":user_list

                    }    ,"USER_ID.schoolId":{"$exists":1}}},
        {"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    #            {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}
                    ]}},
    #           {'$project':{
    #               '_id':0,
    #               'USER_ID':'$USER_ID._id',
    #               'PRACTICE_DATE':{'$dateToString':{'format':"%Y-%m-%d",'date': "$MODIFIED_DATE"}}
                
    #               }},
            
            {'$group':{
                '_id':{
                    'USER_ID':'$USER_ID._id',
                    'PRACTICE_DATE':"$MODIFIED_DATE"
                    }
                }},
                {'$project':{
                    '_id':0,
                    'USER_ID':'$_id.USER_ID',
                    'PRACTICE_DATE':'$_id.PRACTICE_DATE'
                    }}]
    atmaster=list(collection5.aggregate(query5))
    audio_track_master=pd.DataFrame(atmaster)
    df1['CREATED_DATE']=pd.to_datetime(df1['CREATED_DATE'])
    df1['week_since_signup']=np.ceil(round((datetime.datetime.today()-df1.CREATED_DATE)/np.timedelta64(1,'W'),3))
    dfw1=audio_track_master.merge(df1,on='USER_ID',how='left')
    dfw1['PRACTICE_DATE']=pd.to_datetime(dfw1['PRACTICE_DATE'])
    dfw1['practicing_week']=np.ceil(round((dfw1.PRACTICE_DATE-dfw1.CREATED_DATE)/np.timedelta64(1,'W'),3))
    dfw1.sort_values(['USER_ID', 'week_since_signup','practicing_week'], ascending=[True, True,True])
    dfw2=dfw1.sort_values(['USER_ID', 'week_since_signup','practicing_week'], ascending=[True, True,True]).reset_index(drop=True)
    dfw2.loc[dfw2['PRACTICE_DATE']<dfw2['CREATED_DATE'], 'PRACTICE_DATE'] = dfw2['CREATED_DATE']
    dfw2.loc[dfw2['PRACTICE_DATE']==dfw2['CREATED_DATE'], 'practicing_week'] = 1
    dfw3=dfw2.groupby(['USER_ID','practicing_week'])['practicing_week'].count().to_frame(name = 'practice_count').reset_index()
    prac_count_of_week=dfw3.practice_count.tolist()
    points=[]
    for i in range(len(prac_count_of_week)):
        if prac_count_of_week[i]==1:
            points.append(1)
        elif prac_count_of_week[i]==2:
            points.append(3)
        elif prac_count_of_week[i]==3:
            points.append(10)
        elif prac_count_of_week[i]==4:        
            points.append(15)
        else:
            points.append(20)
            
    dfw3['Earned_Points']=points
    dfw4=dfw3.groupby('USER_ID')['Earned_Points'].sum().to_frame(name = 'Total_Points_Earned').reset_index()
    dfw5=df1.merge(dfw4,how='left',on='USER_ID').fillna(0)
    dfw5['CWP_Score']=round((dfw5['Total_Points_Earned']/(dfw5['week_since_signup']*10))*100,0)
    dfw6=dfw5.groupby('ID')['CWP_Score'].mean().reset_index()

    ##################################################################
    FESCORE=pd.merge(AUSW, AUESW, on='ID',how='left').fillna(0)
    FESCORE1=pd.merge(FESCORE, RESW, on='ID',how='left').fillna(0)
    FESCORE2=pd.merge(FESCORE1, dfw6, on='ID',how='left').fillna(0)
    FINAL_ESCORE=FESCORE2[["ID","school_name_y","p_of_active_users","ACTIVE_USAGE","RECENT_ENGAGMENT","CWP_Score"]]
    FINAL_ESCORE0=pd.merge(FINAL_ESCORE, total_school, on='ID',how='right').fillna(0)
    CWPSW=FINAL_ESCORE0[["school_name","CWP_Score"]]
    CWPSW.loc[(CWPSW["CWP_Score"] > 100), "CWP_Score"] = 100 
    CWPSW["NAME"]="CONSISTENT WEEKLY PRACTICE"
    CWPSW=CWPSW.round()
    links3 = CWPSW.rename(columns={'school_name' : 'y', 'NAME' : 'x','CWP_Score':'heat'}).to_dict('r')
    links0.extend(links1)
    links0.extend(links2)
    links0.extend(links3)
    FINAL_ESCORE0['mean'] = FINAL_ESCORE0.mean(axis=1)
    FINAL_ESCORE_SCHOOL=FINAL_ESCORE0[["school_name","mean"]]
    FINAL_ESCORE_SCHOOL["NAME"]="SCHOOL ENGAGEMENT SCORE"
    FINAL_ESCORE_SCHOOL=FINAL_ESCORE_SCHOOL.round()
    links_school = FINAL_ESCORE_SCHOOL.rename(columns={'school_name' : 'y', 'NAME' : 'x','mean':'heat'}).to_dict('r')
    links0.extend(links_school)
    District_Averages= FINAL_ESCORE.mean(axis=0)

    temp={"chart1":links0,"chart2":links_school,"cards":{"p_of_Active_Users":round(District_Averages.p_of_active_users),
        "Active_Usage":round(District_Averages.ACTIVE_USAGE),"Recent_Engagement":round(District_Averages.RECENT_ENGAGMENT),
        "Consistent_Weekly_Practice":round(District_Averages.CWP_Score),"District_Engagement_Score":round(District_Averages.mean())}}
    return json.dumps(temp)


@app.route('/dis_streak_report/<districtid>')
def dis_streak_report(districtid):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass

    disdic={'6045e4d007ead7744b125848':'Adams 12 Five Star Schools',
    '6045e4d707ead7744b125854':'Adams County School District 14',
    '5f2609807a1c0000950bb475':'Agawam School district',
    '5f2609807a1c0000950bb481':'Alameda Unified School District',
    '5f2609807a1c0000950bb47a':'Alpine School District',
    '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
    '6045e4c907ead7744b12583d':'Apple Valley Unified School District',
    '789':'Attendance works',
    '6045e4d707ead7744b125855':'Aurora Public Schools',
    '5f2609807a1c0000950bb463':'Austin Independent School District',
    '5f59e4836451a9089d7d4007':'Belleville School District',
    '6045e4d107ead7744b125849':'Berkeley Public Schools',
    '5fe2e25d4d0ca68d7baf889d':'BGCA',
    '6045e4ca07ead7744b12583e':'Bishop Unified School District',
    '6045e4d107ead7744b12584a':'Bismarck Public Schools',
    '5fe318b14d0ca68d7baf889e':'BLUE',
    '6045e4c807ead7744b12583b':'Boston Public Schools',
    '6023a6d79e8e623753fc305c':'Boulder Valley School District',
    '60f7bf747cc8db72d772e465':'Bright Horizons Early Learning Centers',
    '5f2609807a1c0000950bb46d':'Broward County Public Schools',
    '6045e4ca07ead7744b12583f':'Canyons School District',
    '60473f8823e88e242074ebd2':'Champlain Valley School District',
    '6045e4d907ead7744b125858':'Chicago Public Schools',
    '5f2609807a1c0000950bb46c':'Chico Unified School District',
    '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
    '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
    '6045e4d907ead7744b125857':'Colton Joint Unified School District',
    '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
    '5f2609807a1c0000950bb45c':'Comox Valley School District',
    '5f2609807a1c0000950bb480':'Dell Texas',
    '6045e4da07ead7744b125859':'Dennis-Yarmouth Regional School District',
    '6045e4cb07ead7744b125840':'Denver Public Schools',
    '5f2609807a1c0000950bb46e':'District 25 New York Schools',
    '5f7413ef9387fd71ce6387cb':'Douglas County School District',
    '6045e4c707ead7744b12583a':'Durham Public Schools',
    '5f895191609e08b76029f641':'Early learning Sarasota',
    '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
    '5f2609807a1c0000950bb461':'Englewood Public School District',
    '5f2609807a1c0000950bb464':'Equity Education',
    '6045e4cc07ead7744b125841':'Fairfax County Public Schools',
    '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
    '6045e4cd07ead7744b125843':'Falmouth Public Schools',
    '6045e4da07ead7744b12585a':'FITCHBURG PUBLIC SCHOOLS',
    '5f2609807a1c0000950bb47d':'Flint Public Schools',
    '6023a7269e8e623753fc305e':'Fulton County School System',
    '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
    '6045e4d207ead7744b12584b':'Glenbard District 87',
    '5f2609807a1c0000950bb450':'Goleta District',
    '6045e4cd07ead7744b125844':'Granite School District',
    '5f2609807a1c0000950bb474':'Greenburgh North Castle Union Free School District',
    '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
    '60cb8971c5b0e89ed7ac0aa1':'Hall County School District',
    '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
    '6045e4c707ead7744b125839':'Hartford Public Schools',
    '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
    '6045e4ce07ead7744b125845':'Helena Public Schools',
    '6045e4db07ead7744b12585b':'HidalgoIndependent School district',
    '5f2609807a1c0000950bb476':'Hillsborough County',
    '6045e4db07ead7744b12585c':'Hopedale Public Schools',
    '6045e4cc07ead7744b125842':'Houston Independent School District',
    '60b872ce826cab06ebdf044e':'Kalamazoo Public Schools',
    '6045e4dc07ead7744b12585d':'Kearsarge Regional School District',
    '6045e4d307ead7744b12584d':'KIPP Public Schools',
    '5f2609807a1c0000950bb455':'Krum Independent School District',
    '5f2609807a1c0000950bb47e':'La Joya School District',
    '6045e4cf07ead7744b125846':'Lamar Consolidated Independent School District',
    '5f2609807a1c0000950bb45a':'LAUSD',
    '5f2609807a1c0000950bb467':'Lincolnshire Schools',
    '6045e4dc07ead7744b12585e':'Littleton Public Schools',
    '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
    '6023a7499e8e623753fc305f':'Manatee County School District',
    '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
    '6077e1b5eaa8bae0e2e04a64':'Medfield School District',
    '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
    '5f2609807a1c0000950bb465':'Middleton-Cross Plains Area School District',
    '6045e4d407ead7744b12584f':'Mill Valley School District',
    '6045e4d307ead7744b12584e':'Millard School District',
    '610d0837931db8cfdf500fef':'Mission Consolidated Independent School District',
    '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
    '6045e4cf07ead7744b125847':'Muscatine Community School District',
    '5fbcdf0ba84e48a64412a798':'Needham School District',
    '5f2609807a1c0000950bb459':'North Special School District',
    '6045e4c907ead7744b12583c':'Northside Independent School District',
    '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
    '5fd704da04a848e368de5dc6':'Oakland Unified School District',
    '5f6994386451a9089d7d4009':'Ogden school district',
    '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
    '6017ab3043ca9c39151838d4':'Oswego School District',
    '6045e4dd07ead7744b12585f':'Palm Beach County School District',
    '60913aaea5fd4b56a4bafa70':'Palm Springs Unified',
    '5f2609807a1c0000950bb479':'Panorama Education',
    '5f2609807a1c0000950bb46f':'Paradise Schools',
    '5f8fcd33609e08b76029f644':'Paradise Unified School District',
    '6045e4de07ead7744b125860':'Paterson School District',
    '5f2609807a1c0000950bb466':'Pinellas County Schools',
    '5f2609807a1c0000950bb471':'Racine Unified Schools',
    '6045e4d507ead7744b125850':'Rich School District',
    '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
    '5f2609807a1c0000950bb478':'San Diego Unified School District',
    '6045e4d507ead7744b125851':'San Francisco Unified School District',
    '6023a76f9e8e623753fc3060':'San Jose Unified School District',
    '5f2609807a1c0000950bb470':'San Leandro Unified School District',
    '6045e4df07ead7744b125862':'San Marcos Unified School District',
    '6045e4df07ead7744b125863':'San Marino Unified School District',
    '5f2609807a1c0000950bb477':'Sarasota County',
    '602e60e567d3e6c0a4eb4d99':'School District of Palm Beach County',
    '6045e4d807ead7744b125856':'School District of the Chathams',
    '6045e4de07ead7744b125861':'Sevier School District',
    '5f2609807a1c0000950bb473':'Skillman Foundation',
    '123':'Skillman',
    '6045e4e007ead7744b125864':'South Summit School District',
    '60eea965ae7de54f57abf234':'Southfield Public Schools',
    '5f2609807a1c0000950bb46a':'Springfield Public School',
    '5f2609807a1c0000950bb46a':'Springfield Public Schools',
    '6045e4e007ead7744b125865':'Sudbury Public Schools',
    '6045e4e107ead7744b125866':'Tooele County School District',
    '60a7b03831afdba383052726':'United Way Of Santa Barbara',
    '6045e4d607ead7744b125852':'Upland Unified School District',
    '5f2609807a1c0000950bb468':'Utah Board of Education',
    '456':'UWBA',
    '6023a7949e8e623753fc3061':'Wasatch County School District',
    '6045e4e207ead7744b125867':'Washoe County School District',
    '5f698b826451a9089d7d4008':'Wayne Metro',
    '6045e4d607ead7744b125853':'West Contra Costa Unified School District',
    '5f2609807a1c0000950bb45b':'Westfield Public School District',
    '6045e4e207ead7744b125868':'Westford Public Schools',
    '6045e4d207ead7744b12584c':'White River School District',
    '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
    '5f2609807a1c0000950bb45d':'Youngstown'}
    district=disdic[districtid]
#     collection = db.school_master.aggregate([
#     {"$match":
#         {"$and":[
#     {'IS_PORTAL':'Y'},
#     {'CATEGORY':{'$regex':district,'$options':'i'}}
#     ]}},
#     {"$project":{"ID":"$_id","school_name":"$NAME","district_name":"$CATEGORY"}}

#     ])
#     df67= DataFrame(list(collection)).fillna(0)
#     school_list=df67["ID"].tolist()
    collection1 = db.user_master.aggregate([
    {"$match":
        {"$and":[
#         {"schoolId._id":{"$in":school_list}},
            {"IS_QUEST_OBTAINED":"Y"},
       {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

             {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}},
    {"$project":{"USER_ID":"$_id","USER_NAME":"$USER_NAME","USER_EMAIL":"$EMAIL_ID","USER_CREATED_DATE":{ "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE"}},"ID":"$schoolId._id","school_name":"$schoolId.NAME","USER_NAME":"$USER_NAME",
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME","STATE":"$schoolId.STATE"}}

    ])
    df1= DataFrame(list(collection1)).fillna(0)
    if df1.empty == True:
        dataa=pd.DataFrame([{"USER_NAME":'NO USER',"USER_EMAIL":0,"USER_CREATED_DATE":0,
                     "school_name":0,"STATE":0,"PRACTICE_SESSIONS":0,"MINDFUL_MINUTES":0,"LAST_PRACTICE_DATE":0,
                  "LAST_LOGIN":0,"renewable_date":0,"QUEST_OBTAINED_DATE":0,"STREAK":0}])
        temp={"data":dataa.values.tolist()}
    else:
        user_list=df1["USER_ID"].tolist()

        collection2 = db.audio_track_master.aggregate([{"$match":{
                 '$and':[{"USER_ID._id":{"$in":user_list}},  
                     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
                  {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}       
                  ]}},
                  {'$group':{

                      '_id':{"USER_ID":"$USER_ID._id","SCHOOLiD":'$USER_ID.schoolId._id'},
                      'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                      'Active_User':{'$addToSet':'$USER_ID._id'},
        #               "EMAIL_ID":{"$first":"$USER_ID.EMAIL_ID"},
                      'Practice_Sessions':{'$sum':1},
                      'Mindful_Minutes':{'$sum':{'$round':
                          [{'$divide':[{'$subtract':
                              ['$CURSOR_END','$cursorStart']},60]},0]}}  
                      }},
                 {'$project':{'_id':0,
                            "USER_ID":"$_id.USER_ID",
                               "USER_ID":"$_id.USER_ID",
                     'SCHOOL_ID':'$_id.SCHOOLiD',
                     'LAST_PRACTICE_DATE':{ "$dateToString": { "format": "%Y-%m-%d", "date":'$Last_Prac_Date'}},
                     'PRACTICE_SESSIONS':'$Practice_Sessions',
                     'MINDFUL_MINUTES':'$Mindful_Minutes'
                     }
                     }])
        df2=pd.DataFrame(list(collection2))

        collection3=db.login_logs.aggregate([{"$match":{"USER_ID._id":{
                                "$in":user_list

                            }    ,"USER_ID.schoolId":{"$exists":1}}},
            {"$group":{"_id":"$USER_ID._id",
                       "LAST_LOGIN":{"$max":"$LAST_LOGGED_IN"},
                    "count":{"$sum":1},
                    }},
            {"$project":{"_id":0,"USER_ID":"$_id",
                         "LAST_LOGIN":{ "$dateToString": { "format": "%Y-%m-%d", "date":"$LAST_LOGIN"}}}}
                    ])
        df3= DataFrame(list(collection3)).fillna(0)

        df4 = pd.merge(df1, df2, on="USER_ID", how='left').fillna(0)
        df5 = pd.merge(df4, df3, on="USER_ID", how='left').fillna(0)

        collection4 =db.subscription_master.aggregate([
            {"$match":{"USER_ID._id":{
                                "$in":user_list

                            }    ,"USER_ID.schoolId":{"$exists":1}}},
            {"$match":
                {"$and":[
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
            {"$match":
            {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
            ,
            {"$project":{"_id":0,"USER_ID":"$USER_ID._id","renewable_date":{ "$dateToString": {"format": "%Y-%m-%d", "date": "$SUBSCRIPTION_EXPIRE_DATE"} }}}

            ])
        df6= DataFrame(list(collection4)).fillna(0)
        df7=pd.merge(df5, df6, on='USER_ID',how='left').fillna(0)

        ######################streak############################
        collection5 = db.user_master.aggregate([
        {"$match":
            {"$and":[ 
               {"IS_QUEST_OBTAINED":"Y"},
            {'IS_DISABLED':{"$ne":'Y'}},
        {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
        {"$match":
        {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
        {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
        ,
        {"$project":{"_id":0,"USER_ID":"$_id",
                    "QUEST_OBTAINED_DATE":{"$dateToString": { "format": "%Y-%m-%d", "date": "$QUEST_OBTAINED_DATE"}}}}

        ])
        df8= DataFrame(list(collection5)).fillna(0)
        user_list1=df8["USER_ID"].tolist()
        collection6 =db.audio_track_master.aggregate([
            {"$match":{"USER_ID._id":{
                                "$in":user_list1

                            }}},
            {"$match":
                {"$and":[
                {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'MODIFIED_DATE':{"$gt":datetime.datetime(2021,1,14)}},
            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
            {"$match":
            {"$and":[{'USER_ID.USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
            {'USER_ID.USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
            ,
            {"$group":{"_id":{"USER_ID":"$USER_ID._id",'MODIFIED_DATE':'$MODIFIED_DATE'},
                    "NEW":{"$addToSet":"$USER_ID._id"},
                    "count":{"$sum":1},
                    "USER_NAME": { "$first": "$USER_ID.USER_NAME" }
                    }},
                {"$project":{"_id":0,"USER_ID":"$_id.USER_ID","MODIFIED_DATE":{ "$dateToString": { "format": "%Y-%m-%d", "date":"$_id.MODIFIED_DATE"}},"practice_count12":"$count"}}

            ])
        df9= DataFrame(list(collection6)).fillna(0)
        df10=pd.merge(df8, df9, on='USER_ID',how='right').fillna(0)
        df10.loc[(df10['MODIFIED_DATE'] >= df10['QUEST_OBTAINED_DATE']) & (df10['USER_ID'] == df10['USER_ID']), 'hex'] = '#00a651'  #ACTIVE
        df10.drop(df10[df10['hex'] != "#00a651"].index, inplace = True) 
        df11=df10.groupby(["USER_ID","MODIFIED_DATE"])["practice_count12"].count().reset_index()
        df11['Dates'] = pd.to_datetime(df11["MODIFIED_DATE"]).dt.day
        df11['MODIFIED_DATE'] = pd.to_datetime(df11["MODIFIED_DATE"])
        s = df11.groupby('USER_ID').MODIFIED_DATE.diff().dt.days.ne(1).cumsum()
        df12=df11.groupby(['USER_ID', s]).size().reset_index(level=1, drop=True)
        streak=df12.reset_index()
        streak.columns=["USER_ID","STREAK"]
        user_streak=streak.groupby(["USER_ID"])["STREAK"].max().reset_index()
        df13=pd.merge(df8, user_streak, on='USER_ID',how='left').fillna(0)
        df14=pd.merge(df7, df13, on='USER_ID',how='left').fillna(0)
        df15=df14[["USER_NAME","USER_EMAIL","USER_CREATED_DATE","school_name","STATE","PRACTICE_SESSIONS","MINDFUL_MINUTES","LAST_PRACTICE_DATE",
                  "LAST_LOGIN","renewable_date","QUEST_OBTAINED_DATE","STREAK"]]
        temp={"data":df15.values.tolist()}
#         print(temp)
    return json.dumps(temp)






@app.route('/familysearchid/<name>')
def familysearch_em_id(name):
    if "@" in name:
        print( "Found!")
#         def school_search_email_d1_mongo1(emaail):
        from bson.regex import Regex
        from pymongo import MongoClient
        from flask import Flask,json

        import urllib 
        import pandas as pd
        mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
        client = pymongo.MongoClient(mongo_uri)
        # db = client.compass
        # client = MongoClient("mongodb://host:port/")
        database = client["compass"]
        collection = database["user_master"]
        query = {}
        query["EMAIL_ID"] = Regex(name, "i")
        projection = {}
        projection["schoolId._id"] = 1.0

        cursor1 = collection.find(query, projection = projection)
        dfum1=(list(cursor1))
        dfm2=pd.json_normalize(dfum1, max_level=1)
        xvbnm=dfm2["schoolId._id"][0]
        print(xvbnm)
        # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com
        query = {}
    #     query["schoolId.NAME"] = name1
        query["schoolId._id"] = ObjectId(xvbnm)
    #     query["EMAIL_ID"] = Regex(u".*"""+emaail+""".*", "i")
        query["USER_NAME"] = {
            u"$not": Regex(u".*TEST.*", "i")
        }

        query["IS_BLOCKED"] = {
            u"$ne": u"Y"
        }
        

        query["INCOMPLETE_SIGNUP"] = {
            u"$ne": u"Y"
        }

        # query["DEVICE_USED"] = Regex(u".*webapp.*", "i")

        projection = {}
        projection["USER_ID.USER_ID"] = 1.0
        projection["EMAIL_ID"] = 1.0
        projection["CREATED_DATE"] = 1.0

        projection["USER_NAME"] = 1.0
        projection["IS_ADMIN"] = 1.0
        projection["schoolId.ADDRESS"] = 1.0
        projection["schoolId.CITY"] = 1.0
        projection["schoolId.STATE"] = 1.0
        projection["schoolId.COUNTRY"] = 1.0
        projection["schoolId.NAME"] = 1.0

        cursor = collection.find(query, projection = projection)
        dfum=(list(cursor))
        dfum=pd.json_normalize(dfum, max_level=1)
        schoolname=dfum["schoolId.NAME"][0]
        country=dfum["schoolId.COUNTRY"][0]
        city=dfum["schoolId.CITY"][0]
        state=dfum["schoolId.STATE"][0]
        address=dfum["schoolId.ADDRESS"][0]

        admin1=dfum[dfum['IS_ADMIN']=='Y']

        admin2=admin1['USER_NAME']
        admin3=list(admin2)
        admin=admin3[0]
        adminemail1=admin1['EMAIL_ID']
        admine=list(adminemail1)
        # adminemail=[dfum['EMAIL_ID'][dfum['IS_ADMIN']=='Y']][0]
        adminemail=admine[0]
    #     print(adminemail)
        email=list(dfum['EMAIL_ID'])
    #     print(email)
        totaluser=len(email)
        collection = database["audio_track_master"]

    #     Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

        pipeline = [
            {
                u"$match": {
                    u"USER_ID.EMAIL_ID": {
                        u"$in": email
                    },
                    u"USER_ID.EMAIL_ID" :Regex(u".*PRESENT.*", "i")
                }

            }, 
            {
                u"$group": {
                    u"_id": {
                        u"USER_ID\u1390_id": u"$USER_ID._id"
                    },
                    u"MAX(MODIFIED_DATE)": {
                        u"$max": u"$MODIFIED_DATE"
                    },
                    u"COUNT(USER_ID\u1390_id)": {
                        u"$sum": 1
                    }
                }
            }, 
            {
                u"$project": {
                    u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                    u"MAX(MODIFIED_DATE)": u"$MAX(MODIFIED_DATE)",
                    u"COUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
                    u"_id": 0
                }
            }
        ]

        cursor = collection.aggregate(
            pipeline, 
            allowDiskUse = True
        )
        dfatd=list(cursor)
        dfatd=pd.json_normalize(dfatd, max_level=1)
    #     print(dfatd)
        collection = database["subscription_master"]

        # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

        pipeline = [
            {
                u"$match": {
                    u"USER_ID.EMAIL_ID": {
                        u"$in": email
                    },
                    u"USER_ID.EMAIL_ID" :Regex(u".*PRESENT.*", "i")
                }
            }, 
            {
                u"$group": {
                    u"_id": {
                        u"USER_ID\u1390_id": u"$USER_ID._id"
                    },
                    u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                        u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                    }
                }
            }, 
            {
                u"$project": {
                    u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                    u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                    u"_id": 0
                }
            }
        ]

        cursor = collection.aggregate(
            pipeline, 
            allowDiskUse = True
        )
        dfsbm=list(cursor)
        dfsbm=pd.json_normalize(dfsbm, max_level=1)
        
    #     print(dfatd,"atd")
    ############################################################
        collection = database["audio_track_master"]

    #     Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

        pipeline = [
            {
                u"$match": {
                    u"USER_ID.EMAIL_ID": {
                        u"$in": email
                    },
                    u"USER_ID.EMAIL_ID" :Regex(u".*PRESENT.*", "i"),
                     
             u"MODIFIED_DATE" : { 
                u"$gte" : datetime.datetime(2020,8,1)
            
            }
                }

            }, 
            {
                u"$group": {
                    u"_id": {
                        u"USER_ID\u1390_id": u"$USER_ID._id"
                    },
                    u"MAX(MODIFIED_DATE)": {
                        u"$max": u"$MODIFIED_DATE"
                    },
                    u"COUNT(USER_ID\u1390_id)": {
                        u"$sum": 1
                    }
                }
            }, 
            {
                u"$project": {
                    u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                    u"MAX(MODIFIED_DATE)": u"$MAX(MODIFIED_DATE)",
                    u"COUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
                    u"_id": 0
                }
            }
        ]

        cursor = collection.aggregate(
            pipeline, 
            allowDiskUse = True
        )
        dfatdcsy=list(cursor)
        dfatdcsy=pd.json_normalize(dfatdcsy, max_level=1)
        ####################################################################

        try:
            dffinal=pd.merge(dfum,dfatd,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
            dffinal1=pd.merge(dffinal,dfatdcsy1,left_on='_id',right_on='CSYUSER_ID._id',how='left',suffixes=('_',''))
            dffinalnew=pd.merge(dffinal1,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
        except:
            # dfum['MAX(MODIFIED_DATE)']='NO PRACTICE'
            # dfum['COUNT(USER_ID᎐_id)']=0
            # dffinal=dfum
            # dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
            dfum['MAX(MODIFIED_DATE)']='NO PRACTICE'
            dfum['COUNT(USER_ID᎐_id)']=0
            dffinal=dfum
            dffinal1=dffinal
            dffinal1['CSYCOUNT(USER_ID᎐_id)']=0
            dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))



    #     schoolname=dfum["schoolId.NAME"][0]
        country=dfum["schoolId.COUNTRY"][0]
        city=dfum["schoolId.CITY"][0]
        state=dfum["schoolId.STATE"][0]
        address=dfum["schoolId.ADDRESS"][0]
    #     admin=[dfum['USER_NAME'][dfum['IS_ADMIN']=='Y']][0]
    #     admin=admin[0]
    #     adminemail=[dfum['EMAIL_ID'][dfum['IS_ADMIN']=='Y']][0]
    #     adminemail=adminemail[0]
        email=list(dfum['EMAIL_ID'])
        totaluser=len(email)
        dffinalnew['MAX(MODIFIED_DATE)'].fillna("NO PRACTICE", inplace=True)
        dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)'].fillna(" ", inplace=True)
        dffinalnew['COUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
        dffinalnew['CSYCOUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
        pracsum=sum(list(dffinalnew['COUNT(USER_ID᎐_id)']))
        dffinalnew.fillna(value=pd.np.nan, inplace=True)

        MAX=[]
        for i in dffinalnew['MAX(MODIFIED_DATE)']:
            if  i != 'NO PRACTICE' :
                MAX.append(i.strftime("%d %b %Y "))
            else:
                MAX.append("NO PRACTICE")
        SUBSCRIPTION_EXPIRE_DATE=[]
        for i in dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)']:
            if  i != ' ' :
                SUBSCRIPTION_EXPIRE_DATE.append(i.strftime("%d %b %Y "))
            else:
                SUBSCRIPTION_EXPIRE_DATE.append(" ")        
        CREATED_DATE=[]
        for i in dffinalnew['CREATED_DATE']:
            if  i != ' ' :
                CREATED_DATE.append(i.strftime("%d %b %Y "))
            else: 
                CREATED_DATE.append(" ")
        data=[]

        for T,k,l,m,o,p,q in zip(dffinalnew['USER_NAME'].tolist(),dffinalnew['EMAIL_ID'].tolist(),CREATED_DATE,MAX,SUBSCRIPTION_EXPIRE_DATE,dffinalnew['COUNT(USER_ID᎐_id)'].tolist(),dffinalnew['CSYCOUNT(USER_ID᎐_id)'].tolist()):
            #print(p,q,r)
            data.append([T,k,l,m,o,p,q])
        database = client["compass"]
        collection = database["subscription_master"]
        query = {}
        query["USER_ID.EMAIL_ID"] = {
            u"$in": [
                adminemail
            ]
        }
        projection = {}
        projection["PLAN_ID.PLAN_NAME"] = 1.0
        cursor = collection.find(query, projection = projection)
        plandf=list(cursor)
        plandf=pd.json_normalize(plandf, max_level=1)
        plannameadmin=plandf["PLAN_ID.PLAN_NAME"][0]
        temp={"data":data,"school_practice_count":str(pracsum),"school_name":schoolname,"country":country,"state":state,"city":city,"address":address,"admin_name":admin,"admin_email":adminemail,"plan_name":plannameadmin,"user_count":totaluser}
    #     ,"school_practice_count":str(card_detail['school_practice_count1'][0])
    #     temp={"data":data}
        return json.dumps(temp)
    else:
        print ("Not found!")
#         def school_searchid_mongo1(name):
        name1=name.replace("%20"," ")
        print(name1,"hola")
        from bson.regex import Regex
        from pymongo import MongoClient
        from flask import Flask,json

        import urllib 
        import pandas as pd
        mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
        client = pymongo.MongoClient(mongo_uri)
        # client = MongoClient("mongodb://host:port/")
        database = client["compass"]
        collection = database["user_master"]

        # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com
        query = {}
    #     query["schoolId.NAME"] = name1
        query["schoolId._id"] = ObjectId(name)
        #     query["EMAIL_ID"] = Regex(u".*amorgan@methacton\\.org.*", "i")
        query["USER_NAME"] = {
            u"$not": Regex(u".*TEST.*", "i")
        }

        query["IS_BLOCKED"] = {
            u"$ne": u"Y"
        }
        

        query["INCOMPLETE_SIGNUP"] = {
            u"$ne": u"Y"
        }

        # query["DEVICE_USED"] = Regex(u".*webapp.*", "i")

        projection = {}
        projection["USER_ID.USER_ID"] = 1.0
        projection["EMAIL_ID"] = 1.0
        projection["CREATED_DATE"] = 1.0

        projection["USER_NAME"] = 1.0
        projection["IS_ADMIN"] = 1.0
        projection["schoolId.ADDRESS"] = 1.0
        projection["schoolId.CITY"] = 1.0
        projection["schoolId.STATE"] = 1.0
        projection["schoolId.COUNTRY"] = 1.0
        projection["schoolId.NAME"] = 1.0

        cursor = collection.find(query, projection = projection)
        dfum=(list(cursor))
        dfum=pd.json_normalize(dfum, max_level=1)
        schoolname=dfum["schoolId.NAME"][0]
        country=dfum["schoolId.COUNTRY"][0]
        city=dfum["schoolId.CITY"][0]
        state=dfum["schoolId.STATE"][0]
        address=dfum["schoolId.ADDRESS"][0]

        admin1=dfum[dfum['IS_ADMIN']=='Y']

        admin2=admin1['USER_NAME']
        admin3=list(admin2)
        admin=admin3[0]
        adminemail1=admin1['EMAIL_ID']
        admine=list(adminemail1)
        # adminemail=[dfum['EMAIL_ID'][dfum['IS_ADMIN']=='Y']][0]
        adminemail=admine[0]
    #     print(adminemail)
        email=list(dfum['EMAIL_ID'])
    #     print(email)
        totaluser=len(email)
        collection = database["audio_track_master"]

    #     Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

        pipeline = [
            {
                u"$match": {
                    u"USER_ID.EMAIL_ID": {
                        u"$in": email
                    },
                    u"USER_ID.EMAIL_ID":Regex(u".*PRESENT.*", "i")
                }

            }, 
            {
                u"$group": {
                    u"_id": {
                        u"USER_ID\u1390_id": u"$USER_ID._id"
                    },
                    u"MAX(MODIFIED_DATE)": {
                        u"$max": u"$MODIFIED_DATE"
                    },
                    u"COUNT(USER_ID\u1390_id)": {
                        u"$sum": 1
                    }
                }
            }, 
            {
                u"$project": {
                    u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                    u"MAX(MODIFIED_DATE)": u"$MAX(MODIFIED_DATE)",
                    u"COUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
                    u"_id": 0
                }
            }
        ]

        cursor = collection.aggregate(
            pipeline, 
            allowDiskUse = True
        )
        dfatd=list(cursor)
        dfatd=pd.json_normalize(dfatd, max_level=1)
    #     print(dfatd)
        collection = database["subscription_master"]

        # Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

        pipeline = [
            {
                u"$match": {
                    u"USER_ID.EMAIL_ID": {
                        u"$in": email
                    },
                    u"USER_ID.EMAIL_ID":Regex(u".*PRESENT.*", "i")
                }
            }, 
            {
                u"$group": {
                    u"_id": {
                        u"USER_ID\u1390_id": u"$USER_ID._id"
                    },
                    u"MAX(SUBSCRIPTION_EXPIRE_DATE)": {
                        u"$max": u"$SUBSCRIPTION_EXPIRE_DATE"
                    }
                }
            }, 
            {
                u"$project": {
                    u"MAX(SUBSCRIPTION_EXPIRE_DATE)": u"$MAX(SUBSCRIPTION_EXPIRE_DATE)",
                    u"USER_ID._id": u"$_id.USER_ID\u1390_id",
                    u"_id": 0
                }
            }
        ]

        cursor = collection.aggregate(
            pipeline, 
            allowDiskUse = True
        )
        dfsbm=list(cursor)
        dfsbm=pd.json_normalize(dfsbm, max_level=1)
    #     print(dfatd,"atd")
        ############################################################
        collection = database["audio_track_master"]

    #     Created with Studio 3T, the IDE for MongoDB - https://studio3t.com/

        pipeline = [
            {
                u"$match": {
                    u"USER_ID.EMAIL_ID": {
                        u"$in": email
                    },
                    u"USER_ID.EMAIL_ID" :Regex(u".*PRESENT.*", "i"),
                     
             u"MODIFIED_DATE" : { 
                 u"$gte" :  datetime.datetime(2020,8,1)
            
        }
                }

            }, 
            {
                u"$group": {
                    u"_id": {
                        u"USER_ID\u1390_id": u"$USER_ID._id"
                    },
                    u"MAX(MODIFIED_DATE)": {
                        u"$max": u"$MODIFIED_DATE"
                    },
                    u"COUNT(USER_ID\u1390_id)": {
                        u"$sum": 1
                    }
                }
            }, 
            {
                u"$project": {
                    u"CSYUSER_ID._id": u"$_id.USER_ID\u1390_id",
                    u"CSYCOUNT(USER_ID\u1390_id)": u"$COUNT(USER_ID\u1390_id)",
                    u"_id": 0
                }
            }
        ]

        cursor1 = collection.aggregate(
            pipeline, 
            allowDiskUse = True
        )
        dfatdcsy=list(cursor1)
        dfatdcsy1=pd.json_normalize(dfatdcsy, max_level=1)
        ####################################################################

        try:
            dffinal=pd.merge(dfum,dfatd,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
            dffinal1=pd.merge(dffinal,dfatdcsy1,left_on='_id',right_on='CSYUSER_ID._id',how='left',suffixes=('_',''))
            dffinalnew=pd.merge(dffinal1,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))
        except:
            dfum['MAX(MODIFIED_DATE)']='NO PRACTICE'
            dfum['COUNT(USER_ID᎐_id)']=0
            dffinal=dfum
            dffinal1=dffinal
            dffinal1['CSYCOUNT(USER_ID᎐_id)']=0
            dffinalnew=pd.merge(dffinal,dfsbm,left_on='_id',right_on='USER_ID._id',how='left',suffixes=('_',''))



    #     schoolname=dfum["schoolId.NAME"][0]
        country=dfum["schoolId.COUNTRY"][0]
        city=dfum["schoolId.CITY"][0]
        state=dfum["schoolId.STATE"][0]
        address=dfum["schoolId.ADDRESS"][0]
    #     admin=[dfum['USER_NAME'][dfum['IS_ADMIN']=='Y']][0]
    #     admin=admin[0]
    #     adminemail=[dfum['EMAIL_ID'][dfum['IS_ADMIN']=='Y']][0]
    #     adminemail=adminemail[0]
        email=list(dfum['EMAIL_ID'])
        totaluser=len(email)
        dffinalnew['MAX(MODIFIED_DATE)'].fillna("NO PRACTICE", inplace=True)
        dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)'].fillna(" ", inplace=True)
        dffinalnew['COUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
        dffinalnew['CSYCOUNT(USER_ID᎐_id)'].fillna(0, inplace=True)
        pracsum=sum(list(dffinalnew['COUNT(USER_ID᎐_id)']))
        dffinalnew.fillna(value=pd.np.nan, inplace=True)
        

        MAX=[]
        for i in dffinalnew['MAX(MODIFIED_DATE)']:
            if  i != 'NO PRACTICE' :
                MAX.append(i.strftime("%d %b %Y "))
            else:
                MAX.append("NO PRACTICE")
        SUBSCRIPTION_EXPIRE_DATE=[]
        for i in dffinalnew['MAX(SUBSCRIPTION_EXPIRE_DATE)']:
            if  i != ' ' :
                SUBSCRIPTION_EXPIRE_DATE.append(i.strftime("%d %b %Y "))
            else:
                SUBSCRIPTION_EXPIRE_DATE.append(" ")        
        CREATED_DATE=[]
        for i in dffinalnew['CREATED_DATE']:
            if  i != ' ' :
                CREATED_DATE.append(i.strftime("%d %b %Y "))
            else: 
                CREATED_DATE.append(" ")
        data=[]

        for T,k,l,m,o,p,q in zip(dffinalnew['USER_NAME'].tolist(),dffinalnew['EMAIL_ID'].tolist(),CREATED_DATE,MAX,SUBSCRIPTION_EXPIRE_DATE,dffinalnew['COUNT(USER_ID᎐_id)'].tolist(),dffinalnew['CSYCOUNT(USER_ID᎐_id)'].tolist()):
            #print(p,q,r)
            data.append([T,k,l,m,o,p,q])
        database = client["compass"]
        collection = database["subscription_master"]
        query = {}
        query["USER_ID.EMAIL_ID"] = {
            u"$in": [
                adminemail
            ]
        }
        projection = {}
        projection["PLAN_ID.PLAN_NAME"] = 1.0
        cursor = collection.find(query, projection = projection)
        plandf=list(cursor)
        plandf=pd.json_normalize(plandf, max_level=1)
        plannameadmin=plandf["PLAN_ID.PLAN_NAME"][0]
        temp={"data":data,"school_practice_count":str(pracsum),"school_name":schoolname,"country":country,"state":state,"city":city,"address":address,"admin_name":admin,"admin_email":adminemail,"plan":plannameadmin,"user_count":totaluser}
        return json.dumps(temp)


@app.route('/microdisrenewable/')
def micro_dis_renewable():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    portal=['Adams 12 Five Star Schools',
    'Adams County School District 14',
    'Apple Valley Unified School District',
    'Aurora Public Schools',
    'Berkeley Public Schools',
    'Bishop Unified School District',
    'Bismarck Public Schools',
    'Boston Public Schools',
    'Canyons School District',
    'Chicago Public Schools',
    'Colton Joint Unified School District',
    'Dennis-Yarmouth Regional School District',
    'Denver Public Schools',
    'Durham Public Schools',
    'FITCHBURG PUBLIC SCHOOLS',
    'Fairfax County Public Schools',
    'Falmouth Public Schools',
    'Glenbard District 87',
    'Granite School District',
    'Greenburgh North Castle Union Free School District',
    'Hartford Public Schools',
    'Helena Public Schools',
    'HidalgoIndependent School district',
    'Hopedale Public Schools',
    'Houston Independent School District',
    'KIPP Public Schools',
    'Kearsarge Regional School District',
    'Lamar Consolidated Independent School District',
    'Lincolnshire Schools',
    'Littleton Public Schools',
    'Middleton-Cross Plains Area School District',
    'Mill Valley School District',
    'Millard School District',
    'Muscatine Community School District',
    'Northside Independent School District',
    'Paterson School District',
    'Rich School District',
    'San Francisco Unified School District',
    'San Marcos Unified School District',
    'San Marino Unified School District',
    'School District of Palm Beach County',
    'School District of the Chathams',
    'Sevier School District',
    'South Summit School District',
    'Sudbury Public Schools',
    'Tooele County School District',
    'Washoe County School District',
    'West Contra Costa Unified School District',
    'Westford Public Schools',
    'White River School District',
    'Upland Unified School District',
    'Ann Arbor Public Schools',
    'Manatee County School District',
    'Wasatch County School District',
    'Fulton County School System',
    'Miami-Dade County Public Schools',
    'San Jose Unified School District',
    'Boulder Valley School District',
    'Griffin-Spalding County School System',
    'Austin Independent School District',
    ]
    collection1 = db.school_master.aggregate([
    {"$match":
        {"$and":[
    {'IS_PORTAL':'Y'},
    {'CATEGORY':{"$in":portal}}]}},
    {"$project":{"ID":"$_id","school_name":"$NAME","district_name":"$CATEGORY"}}

    ])
    df67= DataFrame(list(collection1)).fillna(0)
    school_list=df67["ID"].tolist()
    collection = db.user_master.aggregate([
    {"$match":
        {"$and":[
        {"schoolId._id":{"$in":school_list}},
            {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}},
    {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME","USER_NAME":"$USER_NAME",
                "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME"}}

    ])
    df1= DataFrame(list(collection)).fillna(0)
    collection2 = db.user_master.aggregate([
    {"$match":
        {"$and":[
        {"schoolId._id":{"$in":school_list}},
            {'IS_DISABLED':{"$ne":'Y'}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}]}},
        {"$match":{"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}},
    {"$project":{"USER_IDf":"$_id","ID":"$schoolId._id"}}

    ])
    df12= DataFrame(list(collection2)).fillna(0)
    user_list=df1["USER_ID"].tolist()
    collection3d = db.audio_track_master
    query6d=[
        {"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    # //           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    # //           {'USER_ID.DEVICE_USED':{"$regex":'webapp','$options':'i'}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
            {'MODIFIED_DATE':{'$gte':datetime.datetime(2020,8,1)}}       
            ]}},
            {'$group':{
                '_id':'$USER_ID.schoolId._id',
                'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                'Active_User':{'$addToSet':'$USER_ID._id'},
                'Practice_Sessions':{'$sum':1},
                'Mindful_Minutes':{'$sum':{'$round':
                    [{'$divide':[{'$subtract':
                        ['$CURSOR_END','$cursorStart']},60]},0]}}  
                }},
            {'$project':{'_id':0,
                'SCHOOL_ID':'$_id',
                'Active_User':{'$size':'$Active_User'},
                'Last_Practice_Date':'$Last_Prac_Date',
                'Practice_Sessions':'$Practice_Sessions',
                'Mindful_Minutes':'$Mindful_Minutes'
                }
                }]
    school_prac_active_csy=list(collection3d.aggregate(query6d))
    school_prac_active_csy_df=pd.DataFrame(school_prac_active_csy)
    df34= pd.merge(school_prac_active_csy_df, df67,left_on='SCHOOL_ID', right_on='ID', how='right').fillna(0)
    df34=df34.groupby(["district_name","ID","school_name"])["Active_User","Practice_Sessions","Mindful_Minutes"].sum().reset_index()
    final2 = pd.merge(df1, df67, on="ID", how='right').fillna(0)
    final23 = pd.merge(df12, df67, on="ID", how='right').fillna(0)
    df243=final23.groupby(["district_name","ID","school_name"])["USER_IDf"].count().reset_index()
    df2=final2.groupby(["district_name_y","ID","school_name_y"])["USER_ID"].count().reset_index()
    df3=df2.groupby(['district_name_y',"ID",'school_name_y']).agg({'USER_ID': 'sum'}).reset_index()
    final345 = pd.merge(df3, df243,left_on='ID', right_on='ID', how='left').fillna(0)
    final_to_final=final345[["ID","district_name_y","school_name_y","USER_ID","USER_IDf"]]
    final_to_final.columns=["ID","DISTRICT_NAME","SCHOOL_COUNT","USER_COUNT","PARENT"]
    final24524 = pd.merge(final_to_final, df34,left_on='ID', right_on='ID', how='left').fillna(0)
    collection134 = db.school_master.aggregate([
    {"$match":
        {"$and":[
    {'IS_PORTAL':'Y'},
    {'CATEGORY':{"$in":portal}}]}},
    {"$project":{"ID":"$_id","STATE":"$STATE","CITY":"$CITY","CREATED_DATE": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } }}}

    ])
    df6734= DataFrame(list(collection134)).fillna(0)
    D1_SCHOOL_REPORT = pd.merge(final24524, df6734,left_on='ID', right_on='ID', how='left').fillna(0)
    collection2345 = db.school_master.aggregate([
    {"$match":
        {"$and":[
    {'IS_PORTAL':'Y'},
    {'CATEGORY':{"$in":portal}}]}},
    {"$project":{"ID":"$_id","school_name":"$NAME","district_name":"$CATEGORY"}}

    ])
    dfmy= DataFrame(list(collection2345)).fillna(0)
    school_list=df67["ID"].tolist()
    collection234 = db.user_master.aggregate([
    {"$match":
        {"$and":[
        {"schoolId._id":{"$in":school_list}},
        {'IS_DISABLED':{"$ne":'Y'}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
        {"IS_ADMIN":"Y"},
    {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
    {"$match":
    {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}},
    {"$group":{"_id":"$schoolId._id",
            "USER_ID":{"$first":"$_id"},
                "school_name":{"$first":"$schoolId.NAME"},
                "USER_NAME":{"$first":"$USER_NAME"},
                "EMAIL_ID":{"$first":"$EMAIL_ID"},
            
            }},
    {"$project":{"USER_ID":"$USER_ID","ID":"$_id","school_name":"$school_name","USER_NAME":"$USER_NAME",
                "email_id":"$EMAIL_ID"}}

    ])
    dfu= DataFrame(list(collection234)).fillna(0)
    dfuu=dfu[["ID","USER_ID","USER_NAME","email_id"]]
    D1_SCHOOL_REPORT2 = pd.merge(D1_SCHOOL_REPORT, dfuu,left_on='ID', right_on='ID', how='left').fillna(0)
    subuser=D1_SCHOOL_REPORT2["USER_ID"].tolist()
    collectionsub = db.subscription_master.aggregate([
    {"$match":
        {"$and":[
        {"USER_ID._id":{"$in":subuser}},
            ]}},
        {"$match":{
            '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
            {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
            {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
            {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},    
            ]}},
        {"$project":{"_id":0,"USER_ID":"$USER_ID._id",
            "SUBSCRIPTION_EXPIRE_DATE" : { "$dateToString": { "format": "%Y-%m-%d", "date": "$SUBSCRIPTION_EXPIRE_DATE" } }}},
        ])
    dfsub1= DataFrame(list(collectionsub)).fillna(0)
    D1_SCHOOL_REPORT3 = pd.merge(D1_SCHOOL_REPORT2, dfsub1,left_on='USER_ID', right_on='USER_ID', how='left').fillna(0)
    dfsub=D1_SCHOOL_REPORT3[["SUBSCRIPTION_EXPIRE_DATE","USER_ID","Active_User"]]
    dfsub.loc[(dfsub["Active_User"] >1),"Active_User"]=1
    dfsub["SUBSCRIPTION_EXPIRE_DATE"]=dfsub["SUBSCRIPTION_EXPIRE_DATE"].astype(str)
    year2020= dfsub.loc[(dfsub["SUBSCRIPTION_EXPIRE_DATE"] <"2021-01-01")]
    year2021= dfsub.loc[(dfsub["SUBSCRIPTION_EXPIRE_DATE"] >"2020-12-31")&(dfsub["SUBSCRIPTION_EXPIRE_DATE"]<"2022-01-01")]
    year2022= dfsub.loc[(dfsub["SUBSCRIPTION_EXPIRE_DATE"] >"2021-12-31")&(dfsub["SUBSCRIPTION_EXPIRE_DATE"]<"2023-01-01")]
    year2020["SUBSCRIPTION_EXPIRE_DATE"]=pd.to_datetime(year2020["SUBSCRIPTION_EXPIRE_DATE"], format='%Y-%m-%d', errors='coerce')
    year2021["SUBSCRIPTION_EXPIRE_DATE"]=pd.to_datetime(year2021["SUBSCRIPTION_EXPIRE_DATE"], format='%Y-%m-%d', errors='coerce')
    year2022["SUBSCRIPTION_EXPIRE_DATE"]=pd.to_datetime(year2022["SUBSCRIPTION_EXPIRE_DATE"], format='%Y-%m-%d', errors='coerce')
    GByear2020=year2020.groupby(year2020["SUBSCRIPTION_EXPIRE_DATE"].dt.strftime('%b')).agg({"USER_ID":'count',"Active_User":'sum'}).sort_values(by="SUBSCRIPTION_EXPIRE_DATE").reset_index()
    GByear2021=year2021.groupby(year2021["SUBSCRIPTION_EXPIRE_DATE"].dt.strftime('%b')).agg({"USER_ID":'count',"Active_User":'sum'}).sort_values(by="SUBSCRIPTION_EXPIRE_DATE").reset_index()
    GByear2022=year2022.groupby(year2022["SUBSCRIPTION_EXPIRE_DATE"].dt.strftime('%b')).agg({"USER_ID":'count',"Active_User":'sum'}).sort_values(by="SUBSCRIPTION_EXPIRE_DATE").reset_index()
    Month_Name = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

    month_df=pd.DataFrame({'SUBSCRIPTION_EXPIRE_DATE':Month_Name})
    y2020=pd.merge(month_df,GByear2020,on='SUBSCRIPTION_EXPIRE_DATE',how='left').fillna(0)
    y2021=pd.merge(month_df,GByear2021,on='SUBSCRIPTION_EXPIRE_DATE',how='left').fillna(0)
    y2022=pd.merge(month_df,GByear2022,on='SUBSCRIPTION_EXPIRE_DATE',how='left').fillna(0)
    temp={'Data_2020':{'Month_Name':Month_Name,
            'Expiring_Schools':y2020.USER_ID.to_list(),
            'Active_Schools_csy':y2020.Active_User.to_list()
            },
            'Data_2021':{
            'Month_Name':Month_Name,
            'Expiring_Schools':y2021.USER_ID.to_list(),
            'Active_Schools_csy':y2021.Active_User.to_list()
            },
            'Data_2022':{
            'Month_Name':Month_Name,
            'Expiring_Schools':y2022.USER_ID.to_list(),
            'Active_Schools_csy':y2022.Active_User.to_list()   
            }}
    return json.dumps(temp)

@app.route('/weeklyrevanue/<enddate>')
def weekly_revanue(enddate):
    from datetime import datetime, timedelta,date
    date2=datetime.strptime(enddate, "%Y-%m-%d")
    date1=date2 - timedelta(days=7)
    date1=date1.strftime("%Y-%m-%d")
    today = date.today()
    startdate1=date1
    enddate1=date2
    googleSheetId = '1ydZC5Q5cNBlPb2rI_lzcdL0lh7r7rvuSzDYxCDNseyw'
    worksheetName = 'Payment'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    mongo_uri = "mongodb://admin:" + urllib.parse.quote("F5tMazRj47cYqm33e") + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    datestr7 = "2021-04-19T20:12:46.000Z"
    myDatetim0 = dateutil.parser.parse(datestr7)
    collection1 = db.campaign_data.aggregate([ {"$match":{"$and":[{"EMAIL":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"EMAIL":{"$not":{ "$regex":"TEST",'$options':'i'}}},
            {"FIRST_NAME":{"$not":{ "$regex":"Rajbir Kaur",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"1gen",'$options':'i'}}},
                {"FIRST_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
                {"IS_PAYMENT_SUCCESS" :{"$eq":"Y"}},
                {"CREATED_DATE":{"$gt":myDatetim0}},
                { "CAMPAIGN_ID._id":{"$ne":ObjectId("5f5933f122a9de32555fceb4")}}
            
            ]
        }}
    ,{"$project":{"_id":1,"FIRST_NAME":1,"LAST_NAME":1,"EMAIL_ID":"$EMAIL","PHONE_NO":1,"IP_ADDRESS":1,
        "Payment_Amount":"$AMOUNT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$CREATED_DATE" } },"Total_Amount":"$AMOUNT"}}
    ] )
    dfd= DataFrame(list(collection1))
    dfd["TYPE_OF_PAYMENT"]="DONATION"
    dfd["DEVICE_USED"]="COMPASS"
    dfd["MODE_OF_PAYMENT"]="ONLINE"
    # dfd["IP_ADDRESS"]=dfd["IP_ADDRESS"].fillna("NO INFO.")
    # IP_ADDRESS=dfd["IP_ADDRESS"].tolist()
    # IP_ADDRESS="100.15.128.147"
    # STATE1=[]

    # for i in IP_ADDRESS:
    #     url = 'http://ipinfo.io/'+i+'/json'
    #     response = urlopen(url)
    #     data = json.load(response)

    #     IP=data['ip']
    #     org=data['org']
    #     city = data['city']
    #     country=data['country']
    #     region=data['region']
    #     # print ('IP : {4} \nState : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP))
    #     STATE1.append(region)

    # dfd["STATE"]=STATE1
    # us_state_shot = {
    #     'Alabama': 'AL',
    #     'Alaska': 'AK',
    #     'American Samoa': 'AS',
    #     'Arizona': 'AZ',
    #     'Arkansas': 'AR',
    #     'California': 'CA',
    #     'Colorado': 'CO',
    #     'Connecticut': 'CT',
    #     'Delaware': 'DE',
    #     'District of Columbia': 'DC',
    #     'Florida': 'FL',
    #     'Georgia': 'GA',
    #     'Guam': 'GU',
    #     'Hawaii': 'HI',
    #     'Idaho': 'ID',
    #     'Illinois': 'IL',
    #     'Indiana': 'IN',
    #     'Iowa': 'IA',
    #     'Kansas': 'KS',
    #     'Kentucky': 'KY',
    #     'Louisiana': 'LA',
    #     'Maine': 'ME',
    #     'Maryland': 'MD',
    #     'Massachusetts': 'MA',
    #     'Michigan': 'MI',
    #     'Minnesota': 'MN',
    #     'Mississippi': 'MS',
    #     'Missouri': 'MO',
    #     'Montana': 'MT',
    #     'Nebraska': 'NE',
    #     'Nevada': 'NV',
    #     'New Hampshire': 'NH',
    #     'New Jersey': 'NJ',
    #     'New Mexico': 'NM',
    #     'New York': 'NY',
    #     'North Carolina': 'NC',
    #     'North Dakota': 'ND',
    #     'Northern Mariana Islands':'MP',
    #     'Ohio': 'OH',
    #     'Oklahoma': 'OK',
    #     'Oregon': 'OR',
    #     'Pennsylvania': 'PA',
    #     'Puerto Rico': 'PR',
    #     'Rhode Island': 'RI',
    #     'South Carolina': 'SC',
    #     'South Dakota': 'SD',
    #     'Tennessee': 'TN',
    #     'Texas': 'TX',
    #     'Utah': 'UT',
    #     'Vermont': 'VT',
    #     'Virgin Islands': 'VI',
    #     'Virginia': 'VA',
    #     'Washington': 'WA',
    #     'West Virginia': 'WV',
    #     'Wisconsin': 'WI',
    #     'Wyoming': 'WY'
    # }
    # dfd["STATE_SHOT"] = dfd["STATE"].map(us_state_shot) 
    dfd['USER_NAME'] = dfd['FIRST_NAME'].str.cat(dfd['LAST_NAME'], sep =" ") 
    dfd['USER_NAME'] = dfd['USER_NAME'].str.upper()
    dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","Total_Amount"]]
    
    # dfd1=dfd[["USER_NAME","DEVICE_USED","TYPE_OF_PAYMENT","Last_Payment_Date","Payment_Amount","EMAIL_ID","MODE_OF_PAYMENT","STATE","STATE_SHOT","Total_Amount"]]
    dateStr = "2020-07-01T00:00:00.000Z"
    myDatetime = dateutil.parser.parse(dateStr)
    mydoc = db.subscription_master.aggregate([
    {"$match":{"$and":[{"USER_ID.USER_NAME":{"$not":{ "$regex":"Test",'$options':'i'}}},
        {"USER_ID.USER_NAME":{"$not":{ "$regex":"test",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"1gen",'$options':'i'}}},
            {"USER_ID.EMAIL_ID":{"$not":{ "$regex":"test",'$options':'i'}}},
                    
            {"LAST_PAYMENT_DATE":{"$gte":myDatetime}},
            {"IS_PAYMENT_SUCCESS" : "Y"},
            {"LAST_PAYMENT_AMOUNT":{"$ne":0}}]
    }},
    {"$project":{"_id":0,"USER_NAME":"$USER_ID.USER_NAME","DEVICE_USED":"$USER_ID.DEVICE_USED","SCHOOL":"$USER_ID.schoolId.NAME",
    "MODE_OF_PAYMENT":"$MODE_OF_PAYMENT","Last_Payment_Date": { "$dateToString": { "format": "%Y-%m-%d", "date": "$LAST_PAYMENT_DATE"}},"Payment_Amount":"$LAST_PAYMENT_AMOUNT",
    "EMAIL_ID":"$USER_ID.EMAIL_ID"}}
    ,{"$unwind":"$Last_Payment_Date"}
    ])
    payment_df1= DataFrame(list(mydoc))
    payment_df1['Payment_Amount']= payment_df1['Payment_Amount'].fillna(0)
    payment_df1= payment_df1.fillna('')
    payment_df1.replace(to_replace="NULL",value="NO INFO",inplace=True)
    SCHOOL_LIST=['LYDIKSEN ELEMENTARY SCHOOOL',
        'MONTGOMERY UPPER MIDDLE SCHOOL',
        'RIVER VALLEY ELEMENTARY',
        'ALTURA PREPARATORY SCHOOL',
        'TWO BUNCH PALMS ELEMENTARY',
        'MELISSA MIDDLE SCHOOL',
        'MONTGOMERY LOWER MID SCH',
        'HATTIE DYER ELEMENTARY SCHOOL',
        'STOCKDALE JUNIOR HIGH',
        'INYO COUNTY COMMUNITY SCHOOL',
        'DESERT HOT SPRINGS HIGH',
        'SEMINOLE HIGH SCHOOL',
        'FRANKLIN WOODS INTERMEDIATE SCHOOL',
        'MARY B. LEWIS ELEMENTARY',
        'MCMILLIN (CORKY) ELEMENTARY',
        'ELGIN MIDDLE',
        'MACFARLANE PARK ELEMENTARY MAGNET SCHOOL',
        'ODYSSEY ELEMENTARY',
        'FORT MEADOW ECC',
        'NO INFO',
        'BRAWLEY ELEMENTARY SCHOOL DISTRICVT',
        'BRIGHTON HIGH',
        'MARY M WALSH',
        'THE CAPITOL SCHOOL',
        'DR. DANIEL BRIGHT SCHOOL',
        'ROCK POINT COMMUNITY SCHOOL',
        'MURNIN ES',
        'SUNNY SANDS ELEMENTARY',
        'THOMAS JEFFERSON MIDDLE SCHOOL',
        'BENJAMIN FRANKLIN MIDDLE SCHOOL',
        'FAIRMONT CHARTER ELEMENTARY',
        'BLAIR ELEMENTARY SCHOOL',
        'L.A. MORGAN ELEMENTARY',
        'KRUM EARLY EDUCATION CENTER',
        'AMANDA HOPE RAINBOW ANGLES(NPO)',
        'STONY BROOK ELEMENTARY',
        'ROSE SPRINGS ELEMENTARY',
        'MT. BALDY JOINT ELEMENTARY',
        'LIBERTY HILLS ELEMENTARY',
        'WEST ZONE ELC']
    payment_df1 = payment_df1[~payment_df1['SCHOOL'].isin(SCHOOL_LIST)]
    payment_df1['TYPE_OF_PAYMENT'] = 'SCHOOL'
    payment_df1= payment_df1[payment_df1['MODE_OF_PAYMENT']!='payLater']
    payment_df1= payment_df1[payment_df1['DEVICE_USED']!='OTHERS']
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "ios"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1.loc[(payment_df1['DEVICE_USED'] == "android"), 'TYPE_OF_PAYMENT'] = 'MOBILE'
    payment_df1['DEVICE_USED'] = payment_df1['DEVICE_USED'].str.upper()
    payment_df3=payment_df1.drop(payment_df1[(payment_df1['Payment_Amount'] < 100) & (payment_df1['DEVICE_USED'] == "WEBAPP")].index)
    payment_df1=payment_df3.append(dfd1)
    payment_df=payment_df1.append(payment_df2)

    # payment_df.Payment_Amount = payment_df.Payment_Amount.round()
    payment_df['DEVICE_USED'] = payment_df['DEVICE_USED'].str.upper() 
    payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.upper()
    payment_df['DEVICE_USED'] = payment_df['DEVICE_USED'].str.upper()
    payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("POMOCODE", "PROMOCODE")
    payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("SQUAREPAYMENT", "SQUARE PAYMENT")
    payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("INVITED_USER", "INVITED USER")
    payment_df['MODE_OF_PAYMENT'] = payment_df['MODE_OF_PAYMENT'].str.replace("INVITEDUSER", "INVITED USER")
    payment_df['Last_Payment_Date'] =  pd.to_datetime(payment_df['Last_Payment_Date'])
    newdf1=payment_df[(payment_df.Last_Payment_Date >= startdate1) & (payment_df.Last_Payment_Date <= enddate1)]
    df1web=newdf1[['USER_NAME',"EMAIL_ID",'DEVICE_USED','MODE_OF_PAYMENT','TYPE_OF_PAYMENT','Last_Payment_Date','Payment_Amount']]
    df1web['Last_Payment_Date'] = pd.to_datetime(df1web['Last_Payment_Date'])
    df2web= df1web.groupby(['TYPE_OF_PAYMENT'])['Payment_Amount'].sum().reset_index()
    df3web= df1web.groupby(['TYPE_OF_PAYMENT'])['Payment_Amount'].count().reset_index()
    df3web.sort_values(by=['Payment_Amount'], inplace=True, ascending=False)
    df2web.sort_values(by=['Payment_Amount'], inplace=True, ascending=False)
    df2web.Payment_Amount = df2web.Payment_Amount.round()
    if df2web['TYPE_OF_PAYMENT'].all() != "SCHOOL":
        df2web.loc[len(df2web.index)] = ['SCHOOL', 0]
    elif df2web['TYPE_OF_PAYMENT'].all() != "DONATION":
        df2web.loc[len(df2web.index)] = ["DONATION", 0] 
    else:
        pass
    Payment_Mode_amount=df2web['TYPE_OF_PAYMENT'].values.tolist()
    Payment_Mode_user=df3web['TYPE_OF_PAYMENT'].values.tolist()
    Payment_Mode_Amount=df2web['Payment_Amount'].values.tolist()
    Payment_Mode_User=df3web['Payment_Amount'].values.tolist()
    temp={"amount":{"Payment_Mode":Payment_Mode_amount,"Payment_Mode_Amount":Payment_Mode_Amount},"user": {"Payment_Mode":Payment_Mode_user,"Payment_Mode_User":Payment_Mode_User}}
    return(json.dumps(temp))

@app.route("/insights")
def insights():     
    googleSheetId = '1HIm2Z9t6IDckB8WCrAv1NPVNiZK_zIUGpl8_G2JjGAk'
    worksheetName = 'INSIGHTS'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)

    insight = payment_df2.INSIGHTS.to_list()
#     l1 = insight[0].split(',')
#     l2 = insight[1].split(',')
#     l3 = insight[2].split(',')
#     l4 = insight[3].split(',')
#     l5 = insight[4].split(',')

    temp = {"INSIGHTS" : insight}
    return json.dumps(temp)

@app.route('/districtlogoupdates')
def district_logo_updates():
    googleSheetId = '1rS2iEjlfRyljeZI7U7wKo0VLwnGaL9L4Ebapq3QY76w'
    # googleSheetId = '1y0nF64mOFuIJ7WUotPVt4IBM7GySaSoXr3UlkuSgQNo'
    worksheetName = 'District_logo_sheet'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    # print(payment_df2)
    payment_df2=payment_df2.sort_values(by='DISTRICT_NAME')
    data1 = payment_df2.to_numpy().tolist()
    data2={"data":data1}
    data2
    return json.dumps(data2)


# district_logo_updates()
    
#>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> DASHBOARD LINKS API'S >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
@app.route("/cap_apis")
def capapis():     
    googleSheetId = '1UmU9f3wRnF-BLmq_-NsSQsgku3J7PtNOR9BaeKnmBsg'
    worksheetName = "API'S"
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)
    dff = payment_df2[["Dashboard Name","Dashboard Description","Dashboard Link"]].to_dict('records')
    #     print(payment_df2)
#     df1 = payment_df2[payment_df2["Main Dashboard"] == "EXECUTIVE SUMMARY"][["Dashboard Name","Dashboard Description", "Dashboard Link"]].to_dict('records')
#     df2 = payment_df2[payment_df2["Main Dashboard"] == "ENGAGEMENT DASHBOARDS"][["Dashboard Name","Dashboard Description", "Dashboard Link"]].to_dict('records')
#     df3 = payment_df2[payment_df2["Main Dashboard"] == "PLAYBACK ANALYTICS"][["Dashboard Name","Dashboard Description", "Dashboard Link"]].to_dict('records')
#     df4 = payment_df2[payment_df2["Main Dashboard"] == "REVENUE DASHBOARDS"][["Dashboard Name","Dashboard Description", "Dashboard Link"]].to_dict('records')
#     df5 = payment_df2[payment_df2["Main Dashboard"] == "FEEDBACK AND SURVEY"][["Dashboard Name","Dashboard Description", "Dashboard Link"]].to_dict('records')
#     df6 = payment_df2[payment_df2["Main Dashboard"] == "SUBSCRIPTION DASHBOARDS"][["Dashboard Name","Dashboard Description", "Dashboard Link"]].to_dict('records')
#     df7 = payment_df2[payment_df2["Main Dashboard"] == "APP ANALYTICS"][["Dashboard Name","Dashboard Description", "Dashboard Link"]].to_dict('records')

#     temp = {"EXECUTIVE SUMMARY" : df1, "ENGAGEMENT DASHBOARDS" : df2, "PLAYBACK ANALYTICS" : df3, "REVENUE DASHBOARDS" : df4, "FEEDBACK AND SURVEY" : df5, "SUBSCRIPTION DASHBOARDS" : df6, "APP ANALYTICS" :df7}
    temp1 = {"DATA" : dff}
    return json.dumps(temp1)

######################################################
@app.route("/oldescores")
def old_escores():
    dict2=[]
    dict1=[]
    datelist=["2021-01-30","2021-02-28","2021-03-31","2021-04-30","2021-05-31","2021-06-30","2021-07-31"]
    disdic=["Agawam School district","Belleville School District","Broward County Public Schools","Champlain Valley School District","Chico Unified School District","Chula Vista Elementary School District","Clarksville-Montgomery County School System","Community Consolidated School District 89","Comox Valley School District","Douglas County School District","Early learning Sarasota","Englewood Public School District","Fairfield-Suisun Unified School District","Flint Public Schools","Goleta District","Hillsborough County","Krum Independent School District","LAUSD","LSF-Head Start","La Joya School District","Mt. Lebanon School District","NYC - Queens South","Needham School District","Oakland Unified School District","Ogden school district","Oroville City Elementary School District","Oswego School District","Paradise Unified School District","Pinellas County Schools","Racine Unified Schools","Salt Lake City School District","San Diego Unified School District","San Leandro Unified School District","Sarasota County","Springfield Public School","Wayne Metro","Westfield Public School District","Wichita Falls Independent School District","Youngstown","Adams 12 Five Star Schools","Adams County School District 14","Ann Arbor Public Schools","Apple Valley Unified School District","Aurora Public Schools","Austin Independent School District","Berkeley Public Schools","Bishop Unified School District","Bismarck Public Schools","Boston Public Schools","Boulder Valley School District","Canyons School District","Chicago Public Schools","Colton Joint Unified School District","Dennis-Yarmouth Regional School District","Denver Public Schools","Durham Public Schools","FITCHBURG PUBLIC SCHOOLS","Fairfax County Public Schools","Falmouth Public Schools","Fulton County School System","Glenbard District 87","Granite School District","Greenburgh North Castle Union Free School District","Griffin-Spalding County School System","Hartford Public Schools","Helena Public Schools","HidalgoIndependent School district","Hopedale Public Schools","Houston Independent School District","KIPP Public Schools","Kearsarge Regional School District","Lamar Consolidated Independent School District","Lincolnshire Schools","Littleton Public Schools","Manatee County School District","Miami-Dade County Public Schools","Middleton-Cross Plains Area School District","Mill Valley School District","Millard School District","Muscatine Community School District","Northside Independent School District","Paterson School District","Rich School District","San Francisco Unified School District","San Jose Unified School District","San Marcos Unified School District","San Marino Unified School District","School District of Palm Beach County","School District of the Chathams","Sevier School District","South Summit School District","Sudbury Public Schools","Tooele County School District","Upland Unified School District","Wasatch County School District","Washoe County School District","West Contra Costa Unified School District","Westford Public Schools","White River School District"]
    for j in disdic: 
        print(j)
        for i in datelist:
            print(i)
            try:   
                username = urllib.parse.quote_plus('admin')
                password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
                client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
                db=client.compass
                today = date.today()
                d1 = str(i)
                d2=pd.to_datetime(d1)
                datestr7 = d1+"T00:00:00.000Z"
                myDatetime = dateutil.parser.parse(datestr7)
                print(d1,d2)
                collection = db.user_master.aggregate([
                {"$match":{"schoolId":{"$exists":1}}},
                {"$match":
                    {"$and":[
                {"schoolId._id":{"$in":db.school_master.distinct( "_id", {"CATEGORY":{'$regex':j, '$options':'i'} } )}},
                        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                    {'IS_DISABLED':{"$ne":'Y'}},
                {'IS_BLOCKED':{"$ne":'Y'}},
                {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'schoolId.NAME':{"$not":{"$regex":'Blocked', '$options':'i'}}}]}},
                {"$match":
                {"$and":[{'USER_NAME':{"$not":{"$regex":"Test",'$options':'i'}}},
                {'USER_NAME':{"$not":{"$regex":'1gen','$options':'i'}}}]}}
                ,
                {"$project":{"USER_ID":"$_id","ID":"$schoolId._id","school_name":"$schoolId.NAME","USER_NAME":"$USER_NAME",
                            "email_id":"$EMAIL_ID","district_name":"$DISTRICT_ID.DISTRICT_NAME","CREATED_DATE":{ "$dateToString": { "format": "%Y-%m-%d", "date":"$CREATED_DATE"}}}}

                ])
                df1= DataFrame(list(collection)).fillna(0)
                user_list=df1["USER_ID"].tolist()
                total_school=df1.groupby(["ID","school_name"])["USER_ID"].count().reset_index()
                total_users=len(user_list)
                collection2 = db.audio_track_master.aggregate([
                    {"$match":{"USER_ID._id":{
                                    "$in":user_list

                                }    ,"USER_ID.schoolId":{"$exists":1}}},
                    {"$match":{
                        '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
                        {'MODIFIED_DATE':{'$lte':myDatetime}}        
                        ]}},
                        {'$group':{

                            '_id':{"USER_ID":"$USER_ID._id","SCHOOLiD":'$USER_ID.schoolId._id'},
                            'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                            'Active_User':{'$addToSet':'$USER_ID._id'},
                            'Practice_Sessions':{'$sum':1},
                            'Mindful_Minutes':{'$sum':{'$round':
                                [{'$divide':[{'$subtract':
                                    ['$CURSOR_END','$cursorStart']},60]},0]}}  
                            }},
                        {'$project':{'_id':0,
                                    "USER_ID":"$_id.USER_ID",
                                    "USER_ID":"$_id.USER_ID",
                            'SCHOOL_ID':'$_id.SCHOOLiD',
                            'LAST_PRACTICE_DATE':{ "$dateToString": { "format": "%Y-%m-%d", "date":'$Last_Prac_Date'}},
                            'PRACTICE_COUNT':'$Practice_Sessions',
                            'MINDFUL_MINUTES':'$Mindful_Minutes'
                            }
                            }])
                df3= DataFrame(list(collection2)).fillna(0)
                final=pd.merge(df1, df3, on='USER_ID',how='left').fillna(0)
                total_users_school=final.groupby(["ID","school_name"])["USER_ID"].count().reset_index()
                ######################### percentage_of_active_users ############################
                final1 = final[final.PRACTICE_COUNT != 0]

                final1["TODAY_DATE"]=d1
                final1['LAST_PRACTICE_DATE'] = pd.to_datetime(final1['LAST_PRACTICE_DATE'])
                final1['CREATED_DATE'] = pd.to_datetime(final1['CREATED_DATE'])
                final1["TODAY_DATE"] = pd.to_datetime(final1["TODAY_DATE"])
                final1['DAYS'] = (final1["TODAY_DATE"] - final1['CREATED_DATE']).dt.days
                final1['DAYS'] = pd.to_numeric(final1['DAYS'])
                final1["PRACTICE_COUNT"] = pd.to_numeric(final1["PRACTICE_COUNT"])
                final1.loc[(final1['DAYS'] > 60) & (final1["PRACTICE_COUNT"] >= 20), 'STATUS'] = 'ACTIVE'  #ACTIVE
                final1.loc[(final1['DAYS'] <= 60), 'THRESHOLD'] = (final1['DAYS']/60)*20
                final1.loc[((final1["THRESHOLD"]!=0) & (final1["PRACTICE_COUNT"]>final1["THRESHOLD"])), 'STATUS'] = 'ACTIVE'  #ACTIVE
                final1=final1.fillna(0)    
                active_users=final1[final1["STATUS"]=="ACTIVE"]
                active_users_school=active_users.groupby(["ID","school_name"])["_id"].count().reset_index()
                active_users_final=pd.merge(active_users_school, total_users_school, on='ID',how='left').fillna(0)
                active_users_final["p_of_active_users"]=round((active_users_final["_id"]/active_users_final["USER_ID"])*100)
                p_of_active_users=round(active_users_final["p_of_active_users"].mean())
                AUSW=active_users_final[["ID","school_name_x","p_of_active_users"]]
                AUSW0=pd.merge(AUSW, total_school, on='ID',how='right').fillna(0)
                AUSW1=AUSW0[["school_name","p_of_active_users"]]
                AUSW1.loc[(AUSW1["p_of_active_users"] > 100), 'p_of_active_users'] = 100  
                AUSW1["NAME"]="ACTIVE USER"
                AUSW1=AUSW1.round()
                links0 = AUSW1.rename(columns={'school_name' : 'x', 'NAME' : 'y','p_of_active_users':'heat'}).to_dict('r')
                ###################################################################################
                ##################### PERCENTAGE_ACTIVE_USAGE ################################
                collection3 = db.audio_track_master.aggregate([
                    {"$match":{"USER_ID._id":{
                                    "$in":user_list
                                }    ,"USER_ID.schoolId":{"$exists":1}}},
                    {"$match":{
                        '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},
                            {'MODIFIED_DATE':{'$lte':myDatetime}}       
                        ]}},
                #            {'$project':{
                #                     "USER_ID":"$USER_ID._id",
                #              'MODIFIED_DATE':{ "$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}},
                #              'CURSOR_END':'$CURSOR_END',
                #              'cursorStart':'$cursorStart'
                #              }
                #              },
                        {'$group':{

                            '_id':{"USER_ID":"$USER_ID._id",'MODIFIED_DATE':'$MODIFIED_DATE'},
                            'First_Prac_Date':{'$min':'$MODIFIED_DATE'},
                            'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                            'Practice_Sessions':{'$sum':1}
                            }},
                        {'$project':{'_id':0,
                                    "USER_ID":"$_id.USER_ID",
                            'LAST_PRACTICE_DATE':'$Last_Prac_Date',
                            'FIRST_PRACTICE_DATE':'$First_Prac_Date',
                            'PRACTICE_DAYS':'$Practice_Sessions'
                            }
                        }
                            ,
                            {'$group':{

                            '_id':{"USER_ID":"$USER_ID"},
                            'First_Prac_Date':{'$min':'$FIRST_PRACTICE_DATE'},
                            'Last_Prac_Date':{'$max':'$LAST_PRACTICE_DATE'},
                            'Practice_Sessions':{'$sum':'$PRACTICE_DAYS'}
                            }},
                            {'$project':{'_id':0,
                                    "USER_ID":"$_id.USER_ID",
                            'LAST_PRACTICE_DATE':{ "$dateToString": { "format": "%Y-%m-%d", "date":'$Last_Prac_Date'}},
                            'FIRST_PRACTICE_DATE':{ "$dateToString": { "format": "%Y-%m-%d", "date":'$First_Prac_Date'}},
                            'PRACTICE_DAYS':'$Practice_Sessions'
                            }
                            }
                            ])
                df4= DataFrame(list(collection3)).fillna(0)
                usage=pd.merge(df1, df4, on='USER_ID',how='left').fillna(0)
                usage1 = usage[usage.PRACTICE_DAYS != 0].reset_index()
                usage1["TODAY_DATE"]=d1
                usage1['FIRST_PRACTICE_DATE'] = pd.to_datetime(usage1['FIRST_PRACTICE_DATE'])
                usage1["LAST_PRACTICE_DATE"] = pd.to_datetime(usage1["LAST_PRACTICE_DATE"])
                usage1["TODAY_DATE"] = pd.to_datetime(usage1["TODAY_DATE"])
                dfhello=pd.read_csv("Holiday_List.csv")
                dfhello["date"]= pd.to_datetime(dfhello["date"])
                list1=dfhello["date"].tolist()
                usage1["DAYSKIP"]=0
                from datetime import timedelta
                from datetime import date
                from pandas import Timestamp
                for i in range(len(usage1.index)):
                    skip_count = 0
                    start = usage1['FIRST_PRACTICE_DATE'][i]
                    end = today
                    dates_to_skip = [Timestamp('2018-01-01 00:00:00'), Timestamp('2018-01-30 00:00:00'), Timestamp('2018-01-31 00:00:00'), Timestamp('2018-04-05 00:00:00'), Timestamp('2018-04-06 00:00:00'),
                Timestamp('2018-04-07 00:00:00'), Timestamp('2018-04-08 00:00:00'), Timestamp('2018-04-09 00:00:00'), Timestamp('2018-06-16 00:00:00'), Timestamp('2018-06-17 00:00:00'), Timestamp('2018-06-18 00:00:00'),
                Timestamp('2018-06-19 00:00:00'), Timestamp('2018-06-20 00:00:00'), Timestamp('2018-06-21 00:00:00'), Timestamp('2018-06-22 00:00:00'), Timestamp('2018-06-23 00:00:00'), Timestamp('2018-06-24 00:00:00'),
                Timestamp('2018-06-25 00:00:00'), Timestamp('2018-06-26 00:00:00'), Timestamp('2018-06-27 00:00:00'), Timestamp('2018-06-28 00:00:00'), Timestamp('2018-06-29 00:00:00'), Timestamp('2018-06-30 00:00:00'),
                Timestamp('2018-07-01 00:00:00'), Timestamp('2018-07-02 00:00:00'), Timestamp('2018-07-03 00:00:00'), Timestamp('2018-07-04 00:00:00'), Timestamp('2018-07-05 00:00:00'), Timestamp('2018-07-06 00:00:00'),
                Timestamp('2018-07-07 00:00:00'), Timestamp('2018-07-08 00:00:00'), Timestamp('2018-07-09 00:00:00'), Timestamp('2018-07-10 00:00:00'), Timestamp('2018-07-11 00:00:00'), Timestamp('2018-07-12 00:00:00'),
                Timestamp('2018-07-13 00:00:00'), Timestamp('2018-07-14 00:00:00'), Timestamp('2018-07-15 00:00:00'), Timestamp('2018-07-16 00:00:00'), Timestamp('2018-07-17 00:00:00'), Timestamp('2018-07-18 00:00:00'),
                Timestamp('2018-07-19 00:00:00'), Timestamp('2018-07-20 00:00:00'), Timestamp('2018-07-21 00:00:00'), Timestamp('2018-07-22 00:00:00'), Timestamp('2018-07-23 00:00:00'), Timestamp('2018-07-24 00:00:00'),
                Timestamp('2018-07-25 00:00:00'), Timestamp('2018-07-26 00:00:00'), Timestamp('2018-07-27 00:00:00'), Timestamp('2018-07-28 00:00:00'), Timestamp('2018-07-29 00:00:00'), Timestamp('2018-07-30 00:00:00'),
                Timestamp('2018-07-31 00:00:00'), Timestamp('2018-08-01 00:00:00'), Timestamp('2018-08-02 00:00:00'), Timestamp('2018-08-03 00:00:00'), Timestamp('2018-08-04 00:00:00'), Timestamp('2018-08-05 00:00:00'),
                Timestamp('2018-08-06 00:00:00'), Timestamp('2018-08-07 00:00:00'), Timestamp('2018-08-08 00:00:00'), Timestamp('2018-08-09 00:00:00'), Timestamp('2018-08-10 00:00:00'), Timestamp('2018-08-11 00:00:00'),
                Timestamp('2018-08-12 00:00:00'), Timestamp('2018-08-13 00:00:00'), Timestamp('2018-08-14 00:00:00'), Timestamp('2018-09-18 00:00:00'), Timestamp('2018-11-26 00:00:00'), Timestamp('2018-11-27 00:00:00'),
                Timestamp('2018-11-28 00:00:00'), Timestamp('2018-12-21 00:00:00'), Timestamp('2018-12-22 00:00:00'), Timestamp('2018-12-23 00:00:00'), Timestamp('2018-12-24 00:00:00'), Timestamp('2018-12-25 00:00:00'),
                Timestamp('2018-12-26 00:00:00'), Timestamp('2018-12-27 00:00:00'), Timestamp('2018-12-28 00:00:00'), Timestamp('2018-12-29 00:00:00'), Timestamp('2018-12-30 00:00:00'), Timestamp('2018-12-31 00:00:00'),
                Timestamp('2019-01-01 00:00:00'), Timestamp('2019-01-30 00:00:00'), Timestamp('2019-01-31 00:00:00'), Timestamp('2019-04-05 00:00:00'), Timestamp('2019-04-06 00:00:00'), Timestamp('2019-04-07 00:00:00'),
                Timestamp('2019-04-08 00:00:00'), Timestamp('2019-04-09 00:00:00'), Timestamp('2019-06-16 00:00:00'), Timestamp('2019-06-17 00:00:00'), Timestamp('2019-06-18 00:00:00'), Timestamp('2019-06-19 00:00:00'),
                Timestamp('2019-06-20 00:00:00'), Timestamp('2019-06-21 00:00:00'), Timestamp('2019-06-22 00:00:00'), Timestamp('2019-06-23 00:00:00'), Timestamp('2019-06-24 00:00:00'), Timestamp('2019-06-25 00:00:00'),
                Timestamp('2019-06-26 00:00:00'), Timestamp('2019-06-27 00:00:00'), Timestamp('2019-06-28 00:00:00'), Timestamp('2019-06-29 00:00:00'), Timestamp('2019-06-30 00:00:00'), Timestamp('2019-07-01 00:00:00'),
                Timestamp('2019-07-02 00:00:00'), Timestamp('2019-07-03 00:00:00'), Timestamp('2019-07-04 00:00:00'), Timestamp('2019-07-05 00:00:00'), Timestamp('2019-07-06 00:00:00'), Timestamp('2019-07-07 00:00:00'),
                Timestamp('2019-07-08 00:00:00'), Timestamp('2019-07-09 00:00:00'), Timestamp('2019-07-10 00:00:00'), Timestamp('2019-07-11 00:00:00'), Timestamp('2019-07-12 00:00:00'), Timestamp('2019-07-13 00:00:00'),
                Timestamp('2019-07-14 00:00:00'), Timestamp('2019-07-15 00:00:00'), Timestamp('2019-07-16 00:00:00'), Timestamp('2019-07-17 00:00:00'), Timestamp('2019-07-18 00:00:00'), Timestamp('2019-07-19 00:00:00'),
                Timestamp('2019-07-20 00:00:00'), Timestamp('2019-07-21 00:00:00'), Timestamp('2019-07-22 00:00:00'), Timestamp('2019-07-23 00:00:00'), Timestamp('2019-07-24 00:00:00'), Timestamp('2019-07-25 00:00:00'),
                Timestamp('2019-07-26 00:00:00'), Timestamp('2019-07-27 00:00:00'), Timestamp('2019-07-28 00:00:00'), Timestamp('2019-07-29 00:00:00'), Timestamp('2019-07-30 00:00:00'), Timestamp('2019-07-31 00:00:00'),
                Timestamp('2019-08-01 00:00:00'), Timestamp('2019-08-02 00:00:00'), Timestamp('2019-08-03 00:00:00'), Timestamp('2019-08-04 00:00:00'), Timestamp('2019-08-05 00:00:00'), Timestamp('2019-08-06 00:00:00'),
                Timestamp('2019-08-07 00:00:00'), Timestamp('2019-08-08 00:00:00'), Timestamp('2019-08-09 00:00:00'), Timestamp('2019-08-10 00:00:00'), Timestamp('2019-08-11 00:00:00'), Timestamp('2019-08-12 00:00:00'),
                Timestamp('2019-08-13 00:00:00'), Timestamp('2019-08-14 00:00:00'), Timestamp('2019-09-18 00:00:00'), Timestamp('2019-11-26 00:00:00'), Timestamp('2019-11-27 00:00:00'), Timestamp('2019-11-28 00:00:00'),
                Timestamp('2019-12-21 00:00:00'), Timestamp('2019-12-22 00:00:00'), Timestamp('2019-12-23 00:00:00'), Timestamp('2019-12-24 00:00:00'), Timestamp('2019-12-25 00:00:00'), Timestamp('2019-12-26 00:00:00'),
                Timestamp('2019-12-27 00:00:00'), Timestamp('2019-12-28 00:00:00'), Timestamp('2019-12-29 00:00:00'), Timestamp('2019-12-30 00:00:00'), Timestamp('2019-12-31 00:00:00'), Timestamp('2020-01-01 00:00:00'),
                Timestamp('2020-01-30 00:00:00'), Timestamp('2020-01-31 00:00:00'), Timestamp('2020-04-05 00:00:00'), Timestamp('2020-04-06 00:00:00'), Timestamp('2020-04-07 00:00:00'), Timestamp('2020-04-08 00:00:00'),
                Timestamp('2020-04-09 00:00:00'), Timestamp('2020-06-16 00:00:00'), Timestamp('2020-06-17 00:00:00'), Timestamp('2020-06-18 00:00:00'), Timestamp('2020-06-19 00:00:00'), Timestamp('2020-06-20 00:00:00'),
                Timestamp('2020-06-21 00:00:00'), Timestamp('2020-06-22 00:00:00'), Timestamp('2020-06-23 00:00:00'), Timestamp('2020-06-24 00:00:00'), Timestamp('2020-06-25 00:00:00'), Timestamp('2020-06-26 00:00:00'),
                Timestamp('2020-06-27 00:00:00'), Timestamp('2020-06-28 00:00:00'), Timestamp('2020-06-29 00:00:00'), Timestamp('2020-06-30 00:00:00'), Timestamp('2020-07-01 00:00:00'), Timestamp('2020-07-02 00:00:00'),
                Timestamp('2020-07-03 00:00:00'), Timestamp('2020-07-04 00:00:00'), Timestamp('2020-07-05 00:00:00'), Timestamp('2020-07-06 00:00:00'), Timestamp('2020-07-07 00:00:00'), Timestamp('2020-07-08 00:00:00'),
                Timestamp('2020-07-09 00:00:00'), Timestamp('2020-07-10 00:00:00'), Timestamp('2020-07-11 00:00:00'), Timestamp('2020-07-12 00:00:00'), Timestamp('2020-07-13 00:00:00'), Timestamp('2020-07-14 00:00:00'),
                Timestamp('2020-07-15 00:00:00'), Timestamp('2020-07-16 00:00:00'), Timestamp('2020-07-17 00:00:00'), Timestamp('2020-07-18 00:00:00'), Timestamp('2020-07-19 00:00:00'), Timestamp('2020-07-20 00:00:00'),
                Timestamp('2020-07-21 00:00:00'), Timestamp('2020-07-22 00:00:00'), Timestamp('2020-07-23 00:00:00'), Timestamp('2020-07-24 00:00:00'), Timestamp('2020-07-25 00:00:00'), Timestamp('2020-07-26 00:00:00'),
                Timestamp('2020-07-27 00:00:00'), Timestamp('2020-07-28 00:00:00'), Timestamp('2020-07-29 00:00:00'), Timestamp('2020-07-30 00:00:00'), Timestamp('2020-07-31 00:00:00'), Timestamp('2020-08-01 00:00:00'),
                Timestamp('2020-08-02 00:00:00'), Timestamp('2020-08-03 00:00:00'), Timestamp('2020-08-04 00:00:00'), Timestamp('2020-08-05 00:00:00'), Timestamp('2020-08-06 00:00:00'), Timestamp('2020-08-07 00:00:00'),
                Timestamp('2020-08-08 00:00:00'), Timestamp('2020-08-09 00:00:00'), Timestamp('2020-08-10 00:00:00'), Timestamp('2020-08-11 00:00:00'), Timestamp('2020-08-12 00:00:00'), Timestamp('2020-08-13 00:00:00'),
                Timestamp('2020-08-14 00:00:00'), Timestamp('2020-09-18 00:00:00'), Timestamp('2020-11-26 00:00:00'), Timestamp('2020-11-27 00:00:00'), Timestamp('2020-11-28 00:00:00'), Timestamp('2020-12-21 00:00:00'),
                Timestamp('2020-12-22 00:00:00'), Timestamp('2020-12-23 00:00:00'), Timestamp('2020-12-24 00:00:00'), Timestamp('2020-12-25 00:00:00'), Timestamp('2020-12-26 00:00:00'), Timestamp('2020-12-27 00:00:00'),
                Timestamp('2020-12-28 00:00:00'), Timestamp('2020-12-29 00:00:00'), Timestamp('2020-12-30 00:00:00'), Timestamp('2020-12-31 00:00:00'), Timestamp('2021-01-01 00:00:00'), Timestamp('2021-01-30 00:00:00'),
                Timestamp('2021-01-31 00:00:00'), Timestamp('2021-04-05 00:00:00'), Timestamp('2021-04-06 00:00:00'), Timestamp('2021-04-07 00:00:00'), Timestamp('2021-04-08 00:00:00'), Timestamp('2021-04-09 00:00:00'),
                Timestamp('2021-06-16 00:00:00'), Timestamp('2021-06-17 00:00:00'), Timestamp('2021-06-18 00:00:00'), Timestamp('2021-06-19 00:00:00'), Timestamp('2021-06-20 00:00:00'), Timestamp('2021-06-21 00:00:00'),
                Timestamp('2021-06-22 00:00:00'), Timestamp('2021-06-23 00:00:00'), Timestamp('2021-06-24 00:00:00'), Timestamp('2021-06-25 00:00:00'), Timestamp('2021-06-26 00:00:00'), Timestamp('2021-06-27 00:00:00'),
                Timestamp('2021-06-28 00:00:00'), Timestamp('2021-06-29 00:00:00'), Timestamp('2021-06-30 00:00:00'), Timestamp('2021-07-01 00:00:00'), Timestamp('2021-07-02 00:00:00'), Timestamp('2021-07-03 00:00:00'),
                Timestamp('2021-07-04 00:00:00'), Timestamp('2021-07-05 00:00:00'), Timestamp('2021-07-06 00:00:00'), Timestamp('2021-07-07 00:00:00'), Timestamp('2021-07-08 00:00:00'), Timestamp('2021-07-09 00:00:00'),
                Timestamp('2021-07-10 00:00:00'), Timestamp('2021-07-11 00:00:00'), Timestamp('2021-07-12 00:00:00'), Timestamp('2021-07-13 00:00:00'), Timestamp('2021-07-14 00:00:00'), Timestamp('2021-07-15 00:00:00'),
                Timestamp('2021-07-16 00:00:00'), Timestamp('2021-07-17 00:00:00'), Timestamp('2021-07-18 00:00:00'), Timestamp('2021-07-19 00:00:00'), Timestamp('2021-07-20 00:00:00'), Timestamp('2021-07-21 00:00:00'),
                Timestamp('2021-07-22 00:00:00'), Timestamp('2021-07-23 00:00:00'), Timestamp('2021-07-24 00:00:00'), Timestamp('2021-07-25 00:00:00'), Timestamp('2021-07-26 00:00:00'), Timestamp('2021-07-27 00:00:00'),
                Timestamp('2021-07-28 00:00:00'), Timestamp('2021-07-29 00:00:00'), Timestamp('2021-07-30 00:00:00'), Timestamp('2021-07-31 00:00:00'), Timestamp('2021-08-01 00:00:00'), Timestamp('2021-08-02 00:00:00'),
                Timestamp('2021-08-03 00:00:00'), Timestamp('2021-08-04 00:00:00'), Timestamp('2021-08-05 00:00:00'), Timestamp('2021-08-06 00:00:00'), Timestamp('2021-08-07 00:00:00'), Timestamp('2021-08-08 00:00:00'),
                Timestamp('2021-08-09 00:00:00'), Timestamp('2021-08-10 00:00:00'), Timestamp('2021-08-11 00:00:00'), Timestamp('2021-08-12 00:00:00'), Timestamp('2021-08-13 00:00:00'), Timestamp('2021-08-14 00:00:00'),
                Timestamp('2021-09-18 00:00:00'), Timestamp('2021-11-26 00:00:00'), Timestamp('2021-11-27 00:00:00'), Timestamp('2021-11-28 00:00:00'), Timestamp('2021-12-21 00:00:00'), Timestamp('2021-12-22 00:00:00'),
                Timestamp('2021-12-23 00:00:00'), Timestamp('2021-12-24 00:00:00'), Timestamp('2021-12-25 00:00:00'), Timestamp('2021-12-26 00:00:00'), Timestamp('2021-12-27 00:00:00'), Timestamp('2021-12-28 00:00:00'),
                Timestamp('2021-12-29 00:00:00'), Timestamp('2021-12-30 00:00:00'), Timestamp('2021-12-31 00:00:00'),
                ]
                    for to_skip in dates_to_skip:
                        if start <= to_skip < end:
                            skip_count += 1
                    datestoskip=[]



                    for to_skip in dates_to_skip:
                        if start <= to_skip < end:
                                datestoskip.append(to_skip)
                    usage1["DAYSKIP"][i]=len(datestoskip)
                usage1['TOTAL_DAYS'] = (usage1["TODAY_DATE"]-usage1['FIRST_PRACTICE_DATE'] ).dt.days
                usage1['TOTAL_DAYS'] = pd.to_numeric(usage1['TOTAL_DAYS'])
                usage1["DAYS"]=usage1["TOTAL_DAYS"]-usage1['DAYSKIP']
                usage1['PRACTICE_DAYS'] = pd.to_numeric(usage1['PRACTICE_DAYS'])
                usage1.loc[(usage1['DAYS'] == 0), 'DAYS'] =1
                usage1['THRESHOLD'] = usage1['PRACTICE_DAYS']/usage1['DAYS']
                usage1['THRESHOLD'] = pd.to_numeric(usage1['THRESHOLD'])
                mean=usage1['THRESHOLD'].mean()
                std=usage1['THRESHOLD'].std()
                usage1['NORMALIZED']=(usage1['THRESHOLD']-mean)/std
                MAX_THRESHOLD=usage1['NORMALIZED'].max()
                MIN_THRESHOLD=usage1['NORMALIZED'].min()
                usage1.loc[(usage1['NORMALIZED'] >= 0), 'ACTIVE_USAGE'] = (0.5+((usage1['NORMALIZED']/MAX_THRESHOLD)/2))*100
                usage1.loc[(usage1['NORMALIZED'] < 0), 'ACTIVE_USAGE'] = ((1-(usage1['NORMALIZED']/MIN_THRESHOLD))/2)*100
                active_usage=round(usage1["ACTIVE_USAGE"].mean())
                new= usage1.groupby(["ID","school_name"])['ACTIVE_USAGE'].mean().reset_index()
                AUESW=new[["ID","school_name","ACTIVE_USAGE"]]
                AUESW0=pd.merge(AUESW, total_school, on='ID',how='right').fillna(0)
                AUESW1=AUESW0[["school_name_y","ACTIVE_USAGE"]]
                AUESW1["NAME"]="ACTIVE USAGE"
                AUESW1=AUESW1.round()
                activepusage=usage1[["USER_ID","ACTIVE_USAGE"]]
                activepusage.loc[(activepusage["ACTIVE_USAGE"] > 100), "ACTIVE_USAGE"] = 100  
                links1 = AUESW1.rename(columns={'school_name_y' : 'x', 'NAME' : 'y','ACTIVE_USAGE':'heat'}).to_dict('r')
                ##############################################################################################
                #################################RECENT_ENGAGMENT############################################
                collection4 = db.audio_track_master.aggregate([
                    {"$match":{"USER_ID._id":{
                                    "$in":user_list

                                }    ,"USER_ID.schoolId":{"$exists":1}}},
                    {"$match":{
                        '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                #           {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'test','$options':'i'}}},  
                            {'MODIFIED_DATE':{'$lte':myDatetime}}   
                        ]}},
                        {'$group':{

                            '_id':{"USER_ID":"$USER_ID._id","SCHOOLiD":'$USER_ID.schoolId._id'},
                            'Last_Prac_Date':{'$max':'$MODIFIED_DATE'},
                            'Active_User':{'$addToSet':'$USER_ID._id'},
                            'Practice_Sessions':{'$sum':1},
                            'Mindful_Minutes':{'$sum':{'$round':
                                [{'$divide':[{'$subtract':
                                    ['$CURSOR_END','$cursorStart']},60]},0]}}  
                            }},
                        {'$project':{'_id':0,
                                    "USER_ID":"$_id.USER_ID",
                                    "USER_ID":"$_id.USER_ID",
                            'SCHOOL_ID':'$_id.SCHOOLiD',
                            'LAST_PRACTICE_DATE':{ "$dateToString": { "format": "%Y-%m-%d", "date":'$Last_Prac_Date'}},
                            'PRACTICE_COUNT':'$Practice_Sessions',
                            'MINDFUL_MINUTES':'$Mindful_Minutes'
                            }
                            }])
                dfe= DataFrame(list(collection4)).fillna(0)
                final1e=pd.merge(df1, dfe, on='USER_ID',how='left').fillna(0)
                final1e = final1e[final1e.PRACTICE_COUNT != 0]
                final1e["TODAY_DATE"]=d1
                final1e['LAST_PRACTICE_DATE'] = pd.to_datetime(final1e['LAST_PRACTICE_DATE'])
                final1e['CREATED_DATE'] = pd.to_datetime(final1e['CREATED_DATE'])
                final1e["TODAY_DATE"] = pd.to_datetime(final1e["TODAY_DATE"])
                final1e['DAYS'] = (final1e["TODAY_DATE"] - final1e['CREATED_DATE']).dt.days
                final1e['PRACTICE_DAYS'] = (final1e["TODAY_DATE"] - final1e['LAST_PRACTICE_DATE']).dt.days
                final1e['DAYS'] = pd.to_numeric(final1e['DAYS'])
                final1e["PRACTICE_COUNT"] = pd.to_numeric(final1e["PRACTICE_COUNT"])
                engagment=final1e[["_id","USER_ID","ID","school_name","USER_NAME","email_id","district_name","CREATED_DATE","SCHOOL_ID","LAST_PRACTICE_DATE","PRACTICE_COUNT","MINDFUL_MINUTES","TODAY_DATE","DAYS",'PRACTICE_DAYS']]
                engagment=pd.merge(engagment, activepusage, on='USER_ID',how='left').fillna(0)
                ################ 30_DAYS #########
                days_30=engagment[(engagment["DAYS"]<=30)|(engagment["PRACTICE_DAYS"]<=30)]
                if days_30.empty == True:
                #     days_30_score=0
                    days_30["ID"]=0
                    days_30["school_name"]="NO SCHOOL"
                    days_30["SCORE"]=0
                    days_30["POSSIBLE_SCORE"]=0
                else:
                    days_30.loc[(days_30['PRACTICE_COUNT'] >=5), 'SCORE'] = 2
                    days_30.loc[(days_30['PRACTICE_COUNT'] < 5), 'SCORE'] = 1
                    days_30['POSSIBLE_SCORE']=2
                #     days_30_score= (sum(days_30['SCORE'])/sum(days_30['POSSIBLE_SCORE']))*100
                ###################################

                ################ 60_DAYS ##########
                days_60=engagment[(engagment["DAYS"]<=60) |(engagment["PRACTICE_DAYS"]<=60)]
                if days_60.empty == True:
                #     days_60_score=0
                    days_60["ID"]=0
                    days_60["school_name"]="NO SCHOOL"
                    days_60["SCORE"]=0
                    days_60["POSSIBLE_SCORE"]=0
                else:
                    days_60.loc[(days_60['PRACTICE_COUNT'] >=10), 'SCORE'] = 2
                    days_60.loc[(days_60['PRACTICE_COUNT'] < 10), 'SCORE'] = 1
                    days_60['POSSIBLE_SCORE']=2
                #     days_60_score= (sum(days_60['SCORE'])/sum(days_60['POSSIBLE_SCORE']))*100
                ###################################

                ################ 180_DAYS ##########
                days_180=engagment[(engagment["DAYS"]<=180)|(engagment["PRACTICE_DAYS"]<=180)]
                if days_180.empty == True:
                #     days_180_score=0
                    days_180["ID"]=0
                    days_180["school_name"]="NO SCHOOL"
                    days_180["SCORE"]=0
                    days_180["POSSIBLE_SCORE"]=0
                else:
                    days_180.loc[(days_180['PRACTICE_COUNT'] >=30), 'SCORE'] = 2
                    days_180.loc[(days_180['PRACTICE_COUNT'] < 30), 'SCORE'] = 1
                    days_180['POSSIBLE_SCORE']=2
                #     days_180_score= (sum(days_180['SCORE'])/sum(days_180['POSSIBLE_SCORE']))*100
                ###################################

                ################ 365_DAYS ##########
                days_365=engagment[(engagment["DAYS"]<=365)|(engagment["PRACTICE_DAYS"]<=365)]
                if days_365.empty == True:
                #     days_365_score=0
                    days_365["ID"]=0
                    days_365["school_name"]="NO SCHOOL"
                    days_365["SCORE"]=0
                    days_365["POSSIBLE_SCORE"]=0
                else:
                    days_365.loc[(days_365['PRACTICE_COUNT'] >= 60), 'SCORE'] = 2
                    days_365.loc[(days_365['PRACTICE_COUNT'] < 60), 'SCORE'] = 1
                    days_365['POSSIBLE_SCORE']=2
                #     days_365_score= (sum(days_365['SCORE'])/sum(days_365['POSSIBLE_SCORE']))*100
                ###################################

                ################ THIS_SCHOOL_YEAR ##########
                this_school_year=engagment[(engagment["CREATED_DATE"]>="2021-08-01")|(engagment["LAST_PRACTICE_DATE"]<="2021-08-01")]
                if this_school_year.empty == True:
                #     this_school_year_score=0
                    this_school_year["ID"]=0
                    this_school_year["school_name"]="NO SCHOOL"
                    this_school_year["SCORE"]=0
                    this_school_year["POSSIBLE_SCORE"]=0  

                else:
                    a_date = "2021-08-01"
                    this_school_days = round((( pd.to_datetime(d1) -  pd.to_datetime(a_date)).days)/6)
                    this_school_year.loc[(this_school_year['PRACTICE_COUNT'] >= this_school_days), 'SCORE'] = 2
                    this_school_year.loc[(this_school_year['PRACTICE_COUNT'] < this_school_days), 'SCORE'] = 1
                    this_school_year['POSSIBLE_SCORE']=2
                #     this_school_year_score= (sum(this_school_year['SCORE'])/sum(this_school_year['POSSIBLE_SCORE']))*100
                ###################################

                ################ LIFETIME ##########
                lifetime=engagment[engagment["PRACTICE_COUNT"]>0]
                if lifetime.empty == True:
                #     lifetime_score=0
                    lifetime["ID"]=0
                    lifetime["school_name"]="NO SCHOOL"
                    lifetime["SCORE"]=0
                    lifetime["POSSIBLE_SCORE"]=0  
                else:
                    this_school_days1 = 1/6
                    lifetime.loc[(lifetime['ACTIVE_USAGE'] >= this_school_days1), 'SCORE'] = 2
                    lifetime.loc[(lifetime['ACTIVE_USAGE'] < this_school_days1), 'SCORE'] = 1
                    lifetime['POSSIBLE_SCORE']=2
                #     lifetime_score= (sum(this_school_year['SCORE'])/sum(this_school_year['POSSIBLE_SCORE']))*100
                ###################################
                a=days_30[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
                b=days_60[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
                c=days_180[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
                d=days_365[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
                e=this_school_year[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
                f=lifetime[["ID","school_name","SCORE","POSSIBLE_SCORE"]]
                engagmentfinaldf=pd.concat([a,b,c,d,e,f], axis=0)
                engagment_school_final=engagmentfinaldf.groupby(["ID","school_name"]).sum().reset_index()
                engagment_school_final["RECENT_ENGAGMENT"]= (engagment_school_final['SCORE']/engagment_school_final['POSSIBLE_SCORE'])*100
                percentage_recent_engagment=round(engagment_school_final["RECENT_ENGAGMENT"]).mean()
                RESW=engagment_school_final[["ID","school_name","RECENT_ENGAGMENT"]]
                RESW0=pd.merge(RESW, total_school, on='ID',how='right').fillna(0)
                RESW1=RESW0[["school_name_y","RECENT_ENGAGMENT"]]
                RESW1.loc[(RESW1["RECENT_ENGAGMENT"] > 100), "RECENT_ENGAGMENT"] = 100  
                RESW1["NAME"]="RECENT ENGAGMENT"
                RESW1=RESW1.round()
                links2 = RESW1.rename(columns={'school_name_y' : 'x', 'NAME' : 'y','RECENT_ENGAGMENT':'heat'}).to_dict('r')
                ########################################################################################
                ###############################Consistent Weekly Practice#######################
                collection5 = db.audio_track_master
                query5=[ {"$match":{"USER_ID._id":{
                                    "$in":user_list

                                }    ,"USER_ID.schoolId":{"$exists":1}}},
                    {"$match":{
                        '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                                {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                        {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                        {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                        {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                                    {'MODIFIED_DATE':{'$lte':myDatetime}} 
                                ]}},
                #           {'$project':{
                #               '_id':0,
                #               'USER_ID':'$USER_ID._id',
                #               'PRACTICE_DATE':{'$dateToString':{'format':"%Y-%m-%d",'date': "$MODIFIED_DATE"}}

                #               }},

                        {'$group':{
                            '_id':{
                                'USER_ID':'$USER_ID._id',
                                'PRACTICE_DATE':"$MODIFIED_DATE"
                                }
                            }},
                            {'$project':{
                                '_id':0,
                                'USER_ID':'$_id.USER_ID',
                                'PRACTICE_DATE':'$_id.PRACTICE_DATE'
                                }}]
                atmaster=list(collection5.aggregate(query5))
                audio_track_master=pd.DataFrame(atmaster)
                df1['CREATED_DATE']=pd.to_datetime(df1['CREATED_DATE'])
                df1['week_since_signup']=np.ceil(round((d2-df1.CREATED_DATE)/np.timedelta64(1,'W'),3))
                dfw1=audio_track_master.merge(df1,on='USER_ID',how='left')
                dfw1['PRACTICE_DATE']=pd.to_datetime(dfw1['PRACTICE_DATE'])
                dfw1['practicing_week']=np.ceil(round((dfw1.PRACTICE_DATE-dfw1.CREATED_DATE)/np.timedelta64(1,'W'),3))
                dfw1.sort_values(['USER_ID', 'week_since_signup','practicing_week'], ascending=[True, True,True])
                dfw2=dfw1.sort_values(['USER_ID', 'week_since_signup','practicing_week'], ascending=[True, True,True]).reset_index(drop=True)
                dfw2.loc[dfw2['PRACTICE_DATE']<dfw2['CREATED_DATE'], 'PRACTICE_DATE'] = dfw2['CREATED_DATE']
                dfw2.loc[dfw2['PRACTICE_DATE']==dfw2['CREATED_DATE'], 'practicing_week'] = 1
                dfw3=dfw2.groupby(['USER_ID','practicing_week'])['practicing_week'].count().to_frame(name = 'practice_count').reset_index()
                prac_count_of_week=dfw3.practice_count.tolist()
                points=[]
                for i in range(len(prac_count_of_week)):
                    if prac_count_of_week[i]==1:
                        points.append(1)
                    elif prac_count_of_week[i]==2:
                        points.append(3)
                    elif prac_count_of_week[i]==3:
                        points.append(10)
                    elif prac_count_of_week[i]==4:        
                        points.append(15)
                    else:
                        points.append(20)

                dfw3['Earned_Points']=points
                dfw4=dfw3.groupby('USER_ID')['Earned_Points'].sum().to_frame(name = 'Total_Points_Earned').reset_index()
                dfw5=df1.merge(dfw4,how='left',on='USER_ID').fillna(0)
                dfw5['CWP_Score']=round((dfw5['Total_Points_Earned']/(dfw5['week_since_signup']*10))*100,0)
                dfw6=dfw5.groupby('ID')['CWP_Score'].mean().reset_index()

                ##################################################################
                FESCORE=pd.merge(AUSW, AUESW, on='ID',how='left').fillna(0)
                FESCORE1=pd.merge(FESCORE, RESW, on='ID',how='left').fillna(0)
                FESCORE2=pd.merge(FESCORE1, dfw6, on='ID',how='left').fillna(0)
                FINAL_ESCORE=FESCORE2[["ID","school_name_y","p_of_active_users","ACTIVE_USAGE","RECENT_ENGAGMENT","CWP_Score"]]
                FINAL_ESCORE0=pd.merge(FINAL_ESCORE, total_school, on='ID',how='right').fillna(0)
                CWPSW=FINAL_ESCORE0[["school_name","CWP_Score"]]
                CWPSW.loc[(CWPSW["CWP_Score"] > 100), "CWP_Score"] = 100 
                CWPSW["NAME"]="CONSTENT WEEKLY PRAC"
                CWPSW=CWPSW.round()
                links3 = CWPSW.rename(columns={'school_name' : 'x', 'NAME' : 'y','CWP_Score':'heat'}).to_dict('r')
                links0.extend(links1)
                links0.extend(links2)
                links0.extend(links3)
                FINAL_ESCORE0['mean'] = FINAL_ESCORE0.mean(axis=1)
                FINAL_ESCORE_SCHOOL=FINAL_ESCORE0[["school_name","mean"]]
                FINAL_ESCORE_SCHOOL["NAME"]="SCHOOL ENGAGMENT SCORE"
                FINAL_ESCORE_SCHOOL=FINAL_ESCORE_SCHOOL.round()
                links_school = FINAL_ESCORE_SCHOOL.rename(columns={'school_name_y' : 'x', 'NAME' : 'y','mean':'heat'}).to_dict('r')
                District_Averages= FINAL_ESCORE.mean(axis=0)
                temp={"District":j,"p_of_Active_Users":round(District_Averages.p_of_active_users),
                    "Active_Usage":round(District_Averages.ACTIVE_USAGE),"Recent_Engagement":round(District_Averages.RECENT_ENGAGMENT),
                    "Consistent_Weekly_Practice":round(District_Averages.CWP_Score),"District_Engagement_Score":round(District_Averages.mean()),"Month":d2.strftime("%B")}
                dict1.append(temp)
            except:
                dict2.append(j)
            dfdd=pd.DataFrame(dict1)
            # dfdd.to_csv("templates/newescore.csv")
            return jsonify("code run sucsessfully")  

@app.route('/escoreinsites/<disid>')
def escore_insites(disid):
    disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
        '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
        '5f2609807a1c0000950bb475':'Agawam School district',
        '5f2609807a1c0000950bb481':'Alameda Unified School District',
        '5f2609807a1c0000950bb47a':'Alpine School District',
        '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
        '5f2609807a1c0000950bb463':'Austin Independent School District',
        '5f59e4836451a9089d7d4007':'Belleville School District',
        '5f2609807a1c0000950bb46d':'Broward County Public Schools',
        '5f2609807a1c0000950bb46c':'Chico Unified School District',
        '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
        '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
        '5f2609807a1c0000950bb45c':'Comox Valley School District(sd71)',
        '5f2609807a1c0000950bb480':'Dell Texas',
        '5f7413ef9387fd71ce6387cb':'Douglas County School District',
        '5f895191609e08b76029f641':'Early learning Sarasota',
        '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
        '5f2609807a1c0000950bb461':'Englewood Public School District',
        '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
        '5f2609807a1c0000950bb47d':'Flint Public Schools',
        '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
        '5f2609807a1c0000950bb450':'Goleta District',
        '5f2609807a1c0000950bb474':'Greenburgh-North Castle (GNC) Union Free School District',
        '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
        '5f2609807a1c0000950bb476':'Hillsborough County',
        '5f2609807a1c0000950bb455':'Krum Independent School District',
        '5f2609807a1c0000950bb47e':'La Joya School District',
        '5f2609807a1c0000950bb467':'Lincolnshire Schools',
        '5f2609807a1c0000950bb45a':'LAUSD',
        '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
        '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
        '5fbcdf0ba84e48a64412a798':'Needham School District',
        '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
        '5f6994386451a9089d7d4009':'Ogden school district',
        '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
        '5fd704da04a848e368de5dc6':'Oakland Unified School District',
        '5f8fcd33609e08b76029f644':'Paradise Unified School District',
        '5f2609807a1c0000950bb466':'Pinellas County Schools',
        '5f2609807a1c0000950bb471':'Racine Unified Schools',
        '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
        '5f2609807a1c0000950bb478':'San Diego Unified School District',
        '5f2609807a1c0000950bb470':'San Leandro Unified School District',
        '5f2609807a1c0000950bb477':'Sarasota County',
        '5f2609807a1c0000950bb473':'Skillman Foundation',
        '5f2609807a1c0000950bb46a':'Springfield Public Schools',
        '5f2609807a1c0000950bb468':'Utah Board of Education',
        '5f698b826451a9089d7d4008':'Wayne Metro',
        '5f2609807a1c0000950bb45b':'Westfield Public School District',
        '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
        '5f2609807a1c0000950bb45d':'Youngstown',
        '5f2609807a1c0000950bb464':'Equity Education',
        '5f2609807a1c0000950bb469':'LSF -  Head Start',
        '5f2609807a1c0000950bb46e':'District 25 New York Schools',
        '5f2609807a1c0000950bb46f':'Paradise Schools',
        '5f2609807a1c0000950bb479':'Panorama Education',
        '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
        '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
        '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
        '5fe2e25d4d0ca68d7baf889d':'BGCA',
        '5fe318b14d0ca68d7baf889e':'BLUE',
        '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
        '6017ab3043ca9c39151838d4':'Oswego School District',
        '60239a84e57dc27613699d57':'Austin Independent School District',
        '6023a6d79e8e623753fc305c':'Boulder Valley School District',
        '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
        '6023a7269e8e623753fc305e':'Fulton County School System',
        '6023a7499e8e623753fc305f':'Manatee County School District',
        '6023a76f9e8e623753fc3060':'San Jose Unified School District',
        '6023a7949e8e623753fc3061':'Wasatch County School District'}
    district=disdic[disid]
    googleSheetId = '1gs1CqiYPAMhHWbelBU7o3GRAk7o3QeqYY-OJz_MUYZw'
    worksheetName = 'newescore'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    df=pd.read_csv(URL)
    dfdr=df[df["District"]==district]
    link =dfdr[["Month","p_of_Active_Users"]].assign(x = 'Active Users').rename(columns={'Month' : 'y','p_of_Active_Users':'heat'}).to_dict('r')
    link1 =dfdr[["Month","Active_Usage"]].assign(x = 'Active Usage').rename(columns={'Month' : 'y','Active_Usage':'heat'}).to_dict('r')
    link2 =dfdr[["Month","Recent_Engagement"]].assign(x = 'Recent Engagement').rename(columns={'Month' : 'y','Recent_Engagement':'heat'}).to_dict('r')
    link3 =dfdr[["Month","Consistent_Weekly_Practice"]].assign(x = 'Consistent Weekly Practice').rename(columns={'Month' : 'y','Consistent_Weekly_Practice':'heat'}).to_dict('r')
    link4 =dfdr[["Month","District_Engagement_Score"]].assign(x = 'District Engagement Score').rename(columns={'Month' : 'y','District_Engagement_Score':'heat'}).to_dict('r')
    link.extend(link1)
    link.extend(link2)
    link.extend(link3)
    link.extend(link4)
    return json.dumps(link)

@app.route('/escorepolar/<disid>')
def escore_polar(disid):
    disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
        '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
        '5f2609807a1c0000950bb475':'Agawam School district',
        '5f2609807a1c0000950bb481':'Alameda Unified School District',
        '5f2609807a1c0000950bb47a':'Alpine School District',
        '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
        '5f2609807a1c0000950bb463':'Austin Independent School District',
        '5f59e4836451a9089d7d4007':'Belleville School District',
        '5f2609807a1c0000950bb46d':'Broward County Public Schools',
        '5f2609807a1c0000950bb46c':'Chico Unified School District',
        '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
        '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
        '5f2609807a1c0000950bb45c':'Comox Valley School District(sd71)',
        '5f2609807a1c0000950bb480':'Dell Texas',
        '5f7413ef9387fd71ce6387cb':'Douglas County School District',
        '5f895191609e08b76029f641':'Early learning Sarasota',
        '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
        '5f2609807a1c0000950bb461':'Englewood Public School District',
        '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
        '5f2609807a1c0000950bb47d':'Flint Public Schools',
        '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
        '5f2609807a1c0000950bb450':'Goleta District',
        '5f2609807a1c0000950bb474':'Greenburgh-North Castle (GNC) Union Free School District',
        '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
        '5f2609807a1c0000950bb476':'Hillsborough County',
        '5f2609807a1c0000950bb455':'Krum Independent School District',
        '5f2609807a1c0000950bb47e':'La Joya School District',
        '5f2609807a1c0000950bb467':'Lincolnshire Schools',
        '5f2609807a1c0000950bb45a':'LAUSD',
        '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
        '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
        '5fbcdf0ba84e48a64412a798':'Needham School District',
        '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
        '5f6994386451a9089d7d4009':'Ogden school district',
        '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
        '5fd704da04a848e368de5dc6':'Oakland Unified School District',
        '5f8fcd33609e08b76029f644':'Paradise Unified School District',
        '5f2609807a1c0000950bb466':'Pinellas County Schools',
        '5f2609807a1c0000950bb471':'Racine Unified Schools',
        '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
        '5f2609807a1c0000950bb478':'San Diego Unified School District',
        '5f2609807a1c0000950bb470':'San Leandro Unified School District',
        '5f2609807a1c0000950bb477':'Sarasota County',
        '5f2609807a1c0000950bb473':'Skillman Foundation',
        '5f2609807a1c0000950bb46a':'Springfield Public Schools',
        '5f2609807a1c0000950bb468':'Utah Board of Education',
        '5f698b826451a9089d7d4008':'Wayne Metro',
        '5f2609807a1c0000950bb45b':'Westfield Public School District',
        '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
        '5f2609807a1c0000950bb45d':'Youngstown',
        '5f2609807a1c0000950bb464':'Equity Education',
        '5f2609807a1c0000950bb469':'LSF -  Head Start',
        '5f2609807a1c0000950bb46e':'District 25 New York Schools',
        '5f2609807a1c0000950bb46f':'Paradise Schools',
        '5f2609807a1c0000950bb479':'Panorama Education',
        '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
        '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
        '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
        '5fe2e25d4d0ca68d7baf889d':'BGCA',
        '5fe318b14d0ca68d7baf889e':'BLUE',
        '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
        '6017ab3043ca9c39151838d4':'Oswego School District',
        '60239a84e57dc27613699d57':'Austin Independent School District',
        '6023a6d79e8e623753fc305c':'Boulder Valley School District',
        '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
        '6023a7269e8e623753fc305e':'Fulton County School System',
        '6023a7499e8e623753fc305f':'Manatee County School District',
        '6023a76f9e8e623753fc3060':'San Jose Unified School District',
        '6023a7949e8e623753fc3061':'Wasatch County School District'}
    district=disdic[disid]
    googleSheetId = '1gs1CqiYPAMhHWbelBU7o3GRAk7o3QeqYY-OJz_MUYZw'
    worksheetName = 'newescore'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    df=pd.read_csv(URL)
    df1=df[df["District"]==district]
    month=['January', 'February', 'March', 'April', 'May', 'June', 'July','August', 'September', 'October', 'November', 'December']
    df2 = pd.DataFrame(month,columns =['Month'])
    df3= pd.merge(df2, df1, on="Month", how='left').fillna(0)
    df4=df3[["Month","p_of_Active_Users","Active_Usage","Recent_Engagement","Consistent_Weekly_Practice"]].values.tolist()
    return json.dumps({"data":df4})

@app.route('/escorestack/<disid>')
def escore_stack(disid):
    disdic={'60a7b03831afdba383052726' : "United Way Of Santa Barbara",
        '5f2609807a1c0000950bb465':'Middleton - Cross Plains Area School District',
        '5f2609807a1c0000950bb475':'Agawam School district',
        '5f2609807a1c0000950bb481':'Alameda Unified School District',
        '5f2609807a1c0000950bb47a':'Alpine School District',
        '5f2609807a1c0000950bb47b':'Ann Arbor Public Schools',
        '5f2609807a1c0000950bb463':'Austin Independent School District',
        '5f59e4836451a9089d7d4007':'Belleville School District',
        '5f2609807a1c0000950bb46d':'Broward County Public Schools',
        '5f2609807a1c0000950bb46c':'Chico Unified School District',
        '5f2609807a1c0000950bb460':'Clarksville-Montgomery County School System',
        '5f2609807a1c0000950bb47f':'Community Consolidated School District 89',
        '5f2609807a1c0000950bb45c':'Comox Valley School District(sd71)',
        '5f2609807a1c0000950bb480':'Dell Texas',
        '5f7413ef9387fd71ce6387cb':'Douglas County School District',
        '5f895191609e08b76029f641':'Early learning Sarasota',
        '5f2609807a1c0000950bb462':'Englewood Cliffs Public Schools',
        '5f2609807a1c0000950bb461':'Englewood Public School District',
        '5f2609807a1c0000950bb45e':'Fairfield-Suisun Unified School District',
        '5f2609807a1c0000950bb47d':'Flint Public Schools',
        '5f2609807a1c0000950bb46b':'FundaciÃ³n La Puerta',
        '5f2609807a1c0000950bb450':'Goleta District',
        '5f2609807a1c0000950bb474':'Greenburgh-North Castle (GNC) Union Free School District',
        '5f2609807a1c0000950bb45f':'Griffin-Spalding County School System',
        '5f2609807a1c0000950bb476':'Hillsborough County',
        '5f2609807a1c0000950bb455':'Krum Independent School District',
        '5f2609807a1c0000950bb47e':'La Joya School District',
        '5f2609807a1c0000950bb467':'Lincolnshire Schools',
        '5f2609807a1c0000950bb45a':'LAUSD',
        '5f2609807a1c0000950bb482':'Massachusetts Institute of Technology',
        '5fb4efce4139b9d4c5a86a69':'Mt. Lebanon School District',
        '5fbcdf0ba84e48a64412a798':'Needham School District',
        '5f7c01fa9387fd71ce6387cc':'NYC - Queens South',
        '5f6994386451a9089d7d4009':'Ogden school district',
        '5f2609807a1c0000950bb472':'Oroville City Elementary School District',
        '5fd704da04a848e368de5dc6':'Oakland Unified School District',
        '5f8fcd33609e08b76029f644':'Paradise Unified School District',
        '5f2609807a1c0000950bb466':'Pinellas County Schools',
        '5f2609807a1c0000950bb471':'Racine Unified Schools',
        '5f6d7cbce6452eb06384db20':'Salt Lake City School District',
        '5f2609807a1c0000950bb478':'San Diego Unified School District',
        '5f2609807a1c0000950bb470':'San Leandro Unified School District',
        '5f2609807a1c0000950bb477':'Sarasota County',
        '5f2609807a1c0000950bb473':'Skillman Foundation',
        '5f2609807a1c0000950bb46a':'Springfield Public Schools',
        '5f2609807a1c0000950bb468':'Utah Board of Education',
        '5f698b826451a9089d7d4008':'Wayne Metro',
        '5f2609807a1c0000950bb45b':'Westfield Public School District',
        '5f2609807a1c0000950bb368':'Wichita Falls Independent School District',
        '5f2609807a1c0000950bb45d':'Youngstown',
        '5f2609807a1c0000950bb464':'Equity Education',
        '5f2609807a1c0000950bb469':'LSF -  Head Start',
        '5f2609807a1c0000950bb46e':'District 25 New York Schools',
        '5f2609807a1c0000950bb46f':'Paradise Schools',
        '5f2609807a1c0000950bb479':'Panorama Education',
        '5f2609807a1c0000950bb47c':'Hawaii Public Schools',
        '5f9aa5e526edbed399d56c92':'Hamilton-Wenham Regional School District',
        '5fe2e1ee4d0ca68d7baf889c':'LSF-Head Start',
        '5fe2e25d4d0ca68d7baf889d':'BGCA',
        '5fe318b14d0ca68d7baf889e':'BLUE',
        '5ffd8176469a86e28635f512':'Chula Vista Elementary School District',
        '6017ab3043ca9c39151838d4':'Oswego School District',
        '60239a84e57dc27613699d57':'Austin Independent School District',
        '6023a6d79e8e623753fc305c':'Boulder Valley School District',
        '6023a7019e8e623753fc305d':'Miami-Dade County Public Schools',
        '6023a7269e8e623753fc305e':'Fulton County School System',
        '6023a7499e8e623753fc305f':'Manatee County School District',
        '6023a76f9e8e623753fc3060':'San Jose Unified School District',
        '6023a7949e8e623753fc3061':'Wasatch County School District'}
    district=disdic[disid]
    googleSheetId = '1gs1CqiYPAMhHWbelBU7o3GRAk7o3QeqYY-OJz_MUYZw'
    worksheetName = 'newescore'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    df=pd.read_csv(URL)
    df1=df[df["District"]==district]
    month=['January', 'February', 'March', 'April', 'May', 'June', 'July','August', 'September', 'October', 'November', 'December']
    df2 = pd.DataFrame(month,columns =['Month'])
    df3= pd.merge(df2, df1, on="Month", how='left').fillna(0)
    active_user=df3["p_of_Active_Users"].tolist()
    Active_Usage=df3["Active_Usage"].tolist()
    Recent_Engagement=df3["Recent_Engagement"].tolist()
    Consistent_Weekly_Practice=df3["Consistent_Weekly_Practice"].tolist()
    District_Engagement_Score=df3["District_Engagement_Score"].tolist()
    temp={"active_user":active_user,"Active_Usage":Active_Usage,"Recent_Engagement":Recent_Engagement,"Consistent_Weekly_Practice":Consistent_Weekly_Practice,
        "District_Engagement_Score":District_Engagement_Score}
    return json.dumps(temp)

#>>>>>>>>>>-----------JIRA REQUEST API's--------------------->>>>>>>>>>>>>>>>>
@app.route("/jiratickets/<datestr>")
def jira_tickets(datestr):
    googleSheetId = '1dMLQzJn-fMvWBz4ui1fY_xnouMI4lVH6Gl77CWiToSU'
    worksheetName = 'CAP_JIRA'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    df=pd.read_csv(URL)

    date= dateutil.parser.parse(datestr)

    #     datestr = "2021-08-19"
    df1 = df[['Date', 'Requests Received','Done','Escalted']].fillna(0)
    df1 = df1.replace("-", 0)
    df1['Date'] = pd.to_datetime(df1['Date'])

    df1["Requests Received"] = df1["Requests Received"].astype(int)
    df1["Done"] = df1["Done"].astype(int)
    df1["Escalted"] = df1["Escalted"].astype(int)


    dff = df1[(df1['Date'] == datestr)]

    dff.astype(str)
    d1 = dff.Date.iloc[0].strftime('%Y-%m-%d')
    d2 = dff["Requests Received"].iloc[0].astype(str)
    d3 = dff["Done"].iloc[0].astype(str)
    d4 = dff["Escalted"].iloc[0].astype(str)
    dict1 = dff.to_numpy().tolist()
    temp = {"date" : d1,"total_tickets" : d2,"done" : d3,"escalated" : d4}

    return json.dumps(temp,default=str)



#>>>>>>>>>>-----------JIRA REQUEST API's 2--------------------->>>>>>>>>>>>>>>>>
@app.route("/jiratype/<datestr>")
def jira_type(datestr):
    googleSheetId = '1dMLQzJn-fMvWBz4ui1fY_xnouMI4lVH6Gl77CWiToSU'
    worksheetName = 'CAP_JIRA'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    df=pd.read_csv(URL)
    date= dateutil.parser.parse(datestr)


    df2 = df[['Lisa Cahill', 'Laurie','Lisa Grady', 'Laura', 'Tabitha','Paul', 'Harsh', 'Victoria', 'Iris','Joan', 
              'Nina']].fillna(0)
    df3 = df[['Date','Login', 'Subscription Extend','Align Admin/ Teacher','Forgot Email', 'Others','Waiting for Customer']].fillna(0)

    df3['Date'] = pd.to_datetime(df3['Date'])
    df2 = df2.replace("-", 0)
    df3 = df3.replace("-", 0)

    df2["Tabitha"]=df2["Tabitha"].astype(int)
    df2["Harsh"]=df2["Harsh"].astype(int)
    df2["Paul"]=df2["Paul"].astype(int)
    df2["Joan"]=df2["Joan"].astype(int)
    df2["Laurie"]=df2["Laurie"].astype(int)
    df2["Lisa Grady"]=df2["Lisa Grady"].astype(int)
    df2["Nina"]=df2["Nina"].astype(int)
    df2["Lisa Cahill"]=df2["Lisa Cahill"].astype(int)
    df2["Laura"]=df2["Laura"].astype(int)
    df2["Victoria"]=df2["Victoria"].astype(int)


    df3['Login']=df3["Login"].astype(int)
    df3["Subscription Extend"]=df3["Subscription Extend"].astype(int)
    df3["Align Admin/ Teacher"]=df3["Align Admin/ Teacher"].astype(int)
    df3["Forgot Email"]=df3["Forgot Email"].astype(int)
    df3["Others"]=df3["Others"].astype(int)
    df3["Waiting for Customer"]=df3["Waiting for Customer"].astype(int)


    df3["IE_Team_Raised"] =df2.sum(axis = 1)
    dff = df3[(df3['Date'] == datestr)]
    #     dff.T
    d1 = dff.Date.iloc[0].strftime('%Y-%m-%d')
    d2 = dff["Login"].to_list()
    d3 = dff["Subscription Extend"].to_list()
    d4 = dff["Align Admin/ Teacher"].to_list()
    d5 = dff["Forgot Email"].to_list()
    d6 = dff["Others"].to_list()
    d7 = dff["Waiting for Customer"].to_list()
    d8 = dff["IE_Team_Raised"].to_list()
    temp = {"data" :dff}
    temp = {"Date" : d1,"Login" : d2,"Subscription Extend" : d3,"Align Admin/Teacher" : d4,"Forgot Email" : d5, "Others" : d6, 
            "Waiting For Customer" : d7, "IE Team Raised" : d8 }

    dftry = pd.DataFrame.from_dict(temp).fillna(0)
    temp = {"data":dftry.values.astype(str).tolist()}
    return json.dumps(temp) 

####################################################################################################################

@app.route('/Dashboard_Insights/<dashtype>')
def dashboard_insights(dashtype):

    googleSheetId = '18Z4L6-1p4DUyFDQ8PoIA5rYc0_Xk7OnU7pbPCfVvzV4'
    worksheetName = 'Executive_Summary'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df1=pd.read_csv(URL)

    googleSheetId = '18Z4L6-1p4DUyFDQ8PoIA5rYc0_Xk7OnU7pbPCfVvzV4'
    worksheetName = 'Engagement_Dashboard'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df2=pd.read_csv(URL)

    googleSheetId = '18Z4L6-1p4DUyFDQ8PoIA5rYc0_Xk7OnU7pbPCfVvzV4'
    worksheetName = 'Playback_Analytics'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df3=pd.read_csv(URL)

    googleSheetId = '18Z4L6-1p4DUyFDQ8PoIA5rYc0_Xk7OnU7pbPCfVvzV4'
    worksheetName = 'Revenue_Dashboards'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df4=pd.read_csv(URL)

    googleSheetId = '18Z4L6-1p4DUyFDQ8PoIA5rYc0_Xk7OnU7pbPCfVvzV4'
    worksheetName = 'Feedback_Survey'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df5=pd.read_csv(URL)

    googleSheetId = '18Z4L6-1p4DUyFDQ8PoIA5rYc0_Xk7OnU7pbPCfVvzV4'
    worksheetName = 'Subscription_Dashboard'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df6=pd.read_csv(URL)

    googleSheetId = '18Z4L6-1p4DUyFDQ8PoIA5rYc0_Xk7OnU7pbPCfVvzV4'
    worksheetName = 'App_Analytics'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    payment_df7=pd.read_csv(URL)

    payment_df1=payment_df1[['Name_of_the_dashboard','Chart_Card_Name','Insights']]
    dash_name1=payment_df1['Name_of_the_dashboard'].unique()
    dash_desc1=[]
    for i in np.arange(0,len(dash_name1)):
        b1=[]    
        data1 = payment_df1[payment_df1['Name_of_the_dashboard']==dash_name1[i]]
#         b1.append(data1[['Chart/ Card Name','Insights']].to_numpy().tolist())
        b1.append([dict(zip(data1.Chart_Card_Name, data1.Insights))]) 
        dash_desc1.append(b1[0])
    data1 = dict(zip(dash_name1, dash_desc1))
    print(data1)

    payment_df2=payment_df2[['Name_of_the_dashboard','Chart_Card_Name','Insights']]
    dash_name2=payment_df2['Name_of_the_dashboard'].unique()
    dash_desc2=[]
    for i in np.arange(0,len(dash_name2)):
        b2=[]    
        data2 = payment_df2[payment_df2['Name_of_the_dashboard']==dash_name2[i]]
#         b2.append(data2[['Chart/ Card Name','Insights']].to_numpy().tolist())
        b2.append([dict(zip(data2.Chart_Card_Name, data2.Insights))])
        dash_desc2.append(b2[0])
    data2 = dict(zip(dash_name2, dash_desc2))

    payment_df3=payment_df3[['Name_of_the_dashboard','Chart_Card_Name','Insights']]
    dash_name3=payment_df3['Name_of_the_dashboard'].unique()
    dash_desc3=[]
    for i in np.arange(0,len(dash_name3)):
        b3=[]    
        data3 = payment_df3[payment_df3['Name_of_the_dashboard']==dash_name3[i]]
#         b3.append(data3[['Chart/ Card Name','Insights']].to_numpy().tolist())
        b3.append([dict(zip(data3.Chart_Card_Name, data3.Insights))])
        dash_desc3.append(b3[0])
    data3 = dict(zip(dash_name3, dash_desc3))

    payment_df4=payment_df4[['Name_of_the_dashboard','Chart_Card_Name','Insights']]
    dash_name4=payment_df4['Name_of_the_dashboard'].unique()
    dash_desc4=[]
    for i in np.arange(0,len(dash_name4)):
        b4=[]    
        data4 = payment_df4[payment_df4['Name_of_the_dashboard']==dash_name4[i]]
#         b4.append(data4[['Chart/ Card Name','Insights']].to_numpy().tolist())
        b4.append([dict(zip(data4.Chart_Card_Name, data4.Insights))])
        dash_desc4.append(b4[0])
    data4 = dict(zip(dash_name4, dash_desc4))

    payment_df5=payment_df5[['Name_of_the_dashboard','Chart_Card_Name','Insights']]
    dash_name5=payment_df5['Name_of_the_dashboard'].unique()
    dash_desc5=[]
    for i in np.arange(0,len(dash_name5)):
        b5=[]    
        data5 = payment_df5[payment_df5['Name_of_the_dashboard']==dash_name5[i]]
#         b5.append(data5[['Chart/ Card Name','Insights']].to_numpy().tolist())
        b5.append([dict(zip(data5.Chart_Card_Name, data5.Insights))])
        dash_desc5.append(b5[0])
    data5 = dict(zip(dash_name5, dash_desc5))

    payment_df6=payment_df6[['Name_of_the_dashboard','Chart_Card_Name','Insights']]
    dash_name6=payment_df6['Name_of_the_dashboard'].unique()
    dash_desc6=[]
    for i in np.arange(0,len(dash_name6)):
        b6=[]    
        data6 = payment_df6[payment_df6['Name_of_the_dashboard']==dash_name6[i]]
#         b6.append(data6[['Chart/ Card Name','Insights']].to_numpy().tolist())
        b6.append([dict(zip(data6.Chart_Card_Name, data6.Insights))])
        dash_desc6.append(b6[0])
    data6 = dict(zip(dash_name6, dash_desc6))

    payment_df7=payment_df7[['Name_of_the_dashboard','Chart_Card_Name','Insights']]
    dash_name7=payment_df7['Name_of_the_dashboard'].unique()
    dash_desc7=[]
    for i in np.arange(0,len(dash_name7)):
        b7=[]    
        data7 = payment_df7[payment_df7['Name_of_the_dashboard']==dash_name7[i]]
#         b7.append(data7[['Chart/ Card Name','Insights']].to_numpy().tolist())
        b7.append([dict(zip(data7.Chart_Card_Name, data7.Insights))])
        dash_desc7.append(b7[0])
    data7 = dict(zip(dash_name7, dash_desc7))

    #     dataf={"Executive_Summary":data1,"Engagement_Dashboard":data2,"Practice_Analytics":data3,"Revenue_Dashboards":data4,
    #           "Feedback_Survey":data5,"Subscription_Dashboard":data6,"App_Analytics":data7}
    
    if dashtype=='Executive_Summary':
        dataf={"Executive_Summary":data1}
    if dashtype=='Engagement_Dashboard':
        dataf={"Engagement_Dashboard":data2}
    if dashtype=='Practice_Analytics':
        dataf={"Practice_Analytics":data3}
    if dashtype=='Revenue_Dashboards':
        dataf={"Revenue_Dashboards":data4}
    if dashtype=='Feedback_Survey':
        dataf={"Feedback_Survey":data5}
    if dashtype=='Subscription_Dashboard':
        dataf={"Subscription_Dashboard":data6}
    if dashtype=='App_Analytics':
        dataf={"App_Analytics":data7}

    return json.dumps(dataf)

# dashboard_insights('Executive_Summary')

# @app.route('/Lead_Generation')
# def lead_generation():

#     googleSheetId = '1PqiSqaWA4Gj8e8rTnMHq_WnKlOakdEps_RIKpdSrtHk'
#     worksheetName = 'Lead_Requests'
#     URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
#     payment=pd.read_csv(URL)

#     payment=payment[['S_No','Sub_title','Description','Date','Lead_Type','Conversion','Renewal_Date','Last_Payment_Amount']]
#     payment.fillna(0)

#     Total_lead_count=payment['Lead_Type'].count()
#     Total_conversion_count=payment['Conversion'].count()
#     Total_conversion_all_count=payment['Sub_title'].count()
#     Total_conversion_remaining_count=Total_conversion_all_count-Total_conversion_count

#     payment_lead=payment.groupby(['Lead_Type'])["S_No"].count().reset_index()
#     payment_date=payment.groupby(['Date'])["S_No"].count().reset_index()

#     Lead_Type_name=payment_lead['Lead_Type'].tolist()
#     Lead_Type_count=payment_lead['S_No'].tolist()

#     payment_date_date=payment_date['Date'].tolist()
#     payment_date_count=payment_date['S_No'].tolist()

#     data={'Total_lead_count':str(Total_lead_count),'Total_conversion_count':str(Total_conversion_count),
#           'Total_conversion_remaining_count':str(Total_conversion_remaining_count),
#           'Lead_Type_name':Lead_Type_name,'Lead_Type_count':Lead_Type_count,
#           'payment_date_date':payment_date_date,'payment_date_count':payment_date_count
#          }
#     return json.dumps(data)
# lead_generation()

# @app.route('/Lead_Generation_Table')
# def lead_generation_table():
    
#     googleSheetId = '1PqiSqaWA4Gj8e8rTnMHq_WnKlOakdEps_RIKpdSrtHk'
#     worksheetName = 'Lead_Requests'
#     URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
#     payment=pd.read_csv(URL)

    # payment=payment[['Sub_title','Description','Date','Lead_Type','Conversion','Renewal_Date','Last_Payment_Amount']]
    # payment=payment.fillna(0)

    # temp={'data':payment.values.tolist()}
    
    # return json.dumps(temp)
# lead_generation_table()


#<<<<<<<<<<<<<-----new code for E_score----------------->>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>

@app.route('/escores/<trackid>')


def escore_overall(trackid):
    # live server credentials    
    client_live= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@54.202.61.130:27017/')
    db_live=client_live.compass   
    pd.options.mode.chained_assignment = None
    def escore_school(trackid):
        schoolcond_um={'schoolId._id':ObjectId(trackid)}
        school_name_list=list(db_live.school_master.find({'_id':ObjectId(trackid)}))
        school_name=school_name_list[0].get('NAME')

        user_master_df=pd.DataFrame(list(db_live.user_master.aggregate(
        [{"$match":{'$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'IS_DISABLED':{"$ne":'Y'}},
                  {'IS_BLOCKED':{"$ne":'Y'}},
                  {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                  {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                            schoolcond_um
                           ]}},
            {'$project':{
                '_id':0,
                'USER_ID':'$_id',
                'USER_NAME':'$USER_NAME',
                'EMAIL_ID':'$EMAIL_ID',
                'SIGNUP_DATE':'$CREATED_DATE',
                'SCHOOL_ID':'$schoolId._id',
                'SCHOOL_NAME':'$schoolId.NAME',
                'ROLE_ID':'$ROLE_ID.ROLE_ID'
                }}

            ])))

        if user_master_df.empty:
            score_output={
            'SCHOOL_ID':trackid,
            'SCHOOL_NAME':school_name,        
            'ACTIVE_USER_SCORE_SCHOOL':float(0),
                     'USAGE_SCORE_SCHOOL':float(0),
                      'CWP_SCORE_SCHOOL':float(0),
                      'RE_SCORE_SCHOOL':float(0),
                      'E_SCORE_SCHOOL':float(0),
                      'ACTIVE_SCHOOL':float(0)
            }

            return score_output

        audio_track_master_df=pd.DataFrame(list(db_live.audio_track_master.aggregate(
        [{"$match":{
                 '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                  {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                  {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
                  {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                  {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
                  {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
                  {'cursorStart':{'$exists':1}},
                  {'CURSOR_END':{'$exists':1}},
                  {'USER_ID._id':{'$in':user_master_df['USER_ID'].tolist()}}       
                  ]}},          
                  {'$project':{
                      '_id':0,
                      'USER_ID':'$USER_ID._id',
                      'PRACTICE_DATE':'$MODIFIED_DATE',
                      'CURSOR_START':'$cursorStart',
                      'CURSOR_END':'$CURSOR_END'
                      }}             

                  ])))

        

        # <<<<<<<<<<<<<<<<<<<<<<-----------------------------USAGE SCORE----------------->>>>>>>>>>>>>>>>>>>>>>>>>>

        if audio_track_master_df.empty:
            score_output={
            'SCHOOL_ID':trackid,
            'SCHOOL_NAME':school_name,        
            'ACTIVE_USER_SCORE_SCHOOL':float(0),
                     'USAGE_SCORE_SCHOOL':float(0),
                      'CWP_SCORE_SCHOOL':float(0),
                      'RE_SCORE_SCHOOL':float(0),
                      'E_SCORE_SCHOOL':float(0),
                      'ACTIVE_SCHOOL':float(0)
            }

            return score_output

        audio_track_master_df['PRACTICE_DATE']=pd.to_datetime(audio_track_master_df['PRACTICE_DATE']).dt.date

        practising_dates=audio_track_master_df.groupby('USER_ID')['PRACTICE_DATE'].apply(list).reset_index().rename(columns={'PRACTICE_DATE':'DATES_OF_PRACTICING'})

        audio_track_master_df1=audio_track_master_df.groupby(['USER_ID']).agg({'PRACTICE_DATE':['min','max']
                                                                              }).rename(columns={'min':'FIRST_PRAC_DATE','max':'LAST_PRAC_DATE'}).droplevel(axis=1, level=0).reset_index()



        audio_track_master_df2=audio_track_master_df1.merge(practising_dates,how='left',on='USER_ID')

        for i in range(len(audio_track_master_df2)):
            new_value=list(set(audio_track_master_df2['DATES_OF_PRACTICING'][i]))
            audio_track_master_df2['DATES_OF_PRACTICING'][i]=new_value

        us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())

        BUSINESS_DAYS=[]
        for i in range(len(audio_track_master_df2['FIRST_PRAC_DATE'])):
            business_days=list(pd.date_range(start=audio_track_master_df2['FIRST_PRAC_DATE'][i],end=datetime.datetime.now().date(), freq=us_bd))
            bd=[]
            for j in range(len(business_days)):
                bd.append(business_days[j].date())
            BUSINESS_DAYS.append(bd)



        audio_track_master_df2['BUSINESS_DAYS']=BUSINESS_DAYS

        audio_track_master_df2['POSSIBLE_PRACTISING_DAYS']=''
        for k in range(len(audio_track_master_df2['BUSINESS_DAYS'])):
            possible_prac_dates=len(audio_track_master_df2['BUSINESS_DAYS'][k])
            audio_track_master_df2['POSSIBLE_PRACTISING_DAYS'][k]=possible_prac_dates

        audio_track_master_df2['TOTAL_PRACTICE_DAYS']=''
        for l in range(len(audio_track_master_df2['DATES_OF_PRACTICING'])):
            dys=len(list(set(audio_track_master_df2['DATES_OF_PRACTICING'][l]).intersection(audio_track_master_df2['BUSINESS_DAYS'][l])))
            audio_track_master_df2['TOTAL_PRACTICE_DAYS'][l]=dys


        final_data1=audio_track_master_df2 
        
        final_data1['USAGE_METRIC']=''
        for i in range(len(final_data1)):
            if final_data1['POSSIBLE_PRACTISING_DAYS'][i]==0:
                final_data1['USAGE_METRIC'][i]=0
            else:
                final_data1['USAGE_METRIC'][i]=final_data1['TOTAL_PRACTICE_DAYS'][i]/final_data1['POSSIBLE_PRACTISING_DAYS'][i]
                
                

#         final_data1['USAGE_METRIC']=final_data1['TOTAL_PRACTICE_DAYS']/final_data1['POSSIBLE_PRACTISING_DAYS']
        
        final_data1['USAGE_METRIC_STANDARDISATION']=''
        for kk in range(len(final_data1['USAGE_METRIC'])):
            if math.isnan(final_data1['USAGE_METRIC'].std()):                    
                svalue=0
            else:                    
                svalue=(final_data1['USAGE_METRIC'][kk] - final_data1['USAGE_METRIC'].mean())/final_data1['USAGE_METRIC'].std()
            
            final_data1['USAGE_METRIC_STANDARDISATION'][kk]=svalue
            


#         final_data1['USAGE_METRIC_STANDARDISATION'] = StandardScaler().fit_transform(final_data1['USAGE_METRIC'])

        final_data1['USAGE_SCORE']=''
        for i in range(len(final_data1['USAGE_METRIC_STANDARDISATION'])):
            if final_data1['USAGE_METRIC_STANDARDISATION'][i]>0:                                
                uscore=(0.5+(final_data1['USAGE_METRIC_STANDARDISATION'][i]/max(final_data1['USAGE_METRIC_STANDARDISATION'])))/2*100
                final_data1['USAGE_SCORE'][i]=round(uscore,0)

            elif (final_data1['USAGE_METRIC_STANDARDISATION'][i]==0):                                
                final_data1['USAGE_SCORE'][i]=0
            else:                    
                uscore=((1-final_data1['USAGE_METRIC_STANDARDISATION'][i]/min(final_data1['USAGE_METRIC_STANDARDISATION']))/2)*100
                final_data1['USAGE_SCORE'][i]=round(uscore,0)


        # <<<<<<<<<<<<<<<<<<<<<<<<------------------CONSISTENT WEEKLY PRACTICE SCORE---------------------->>>>>>>>>>>>>>>>>>>>>>>>>

        final_data2=final_data1

        final_data2['WEEK_SINCE_FIRST_PRACTICE']=np.ceil(round((datetime.datetime.now().date()-final_data2['FIRST_PRAC_DATE'])/np.timedelta64(1,'W'),3))

        PRACTISING_WEEK=[]
        for i in range(len(final_data2)):
            pw=[]
            for j in range(len(final_data2['DATES_OF_PRACTICING'][i])):
                week=np.ceil(round((final_data2['DATES_OF_PRACTICING'][i][j]-final_data2['FIRST_PRAC_DATE'][i])/datetime.timedelta(days=7),3))
                if week==0:
                    week=week+1
                else:
                    week=week
                pw.append(week)
            PRACTISING_WEEK.append(pw)


        WEEK_PRAC_FREQ=[]
        UNIQUE_WEEK_PRACTISED=[]
        for i in range(len(PRACTISING_WEEK)):
            WEEK_PRAC_FREQ.append(list(collections.Counter(PRACTISING_WEEK[i]).values()))
            UNIQUE_WEEK_PRACTISED.append(list(collections.Counter(PRACTISING_WEEK[i]).keys()))


        GAINED_POINTS=[]
        for i in range(len(WEEK_PRAC_FREQ)):
            points=[]
            for j in range(len(WEEK_PRAC_FREQ[i])):
                if WEEK_PRAC_FREQ[i][j]==1:
                    point=1*WEEK_PRAC_FREQ[i][j]
                elif WEEK_PRAC_FREQ[i][j]==2:
                    point=3*WEEK_PRAC_FREQ[i][j]
                elif WEEK_PRAC_FREQ[i][j]==3:
                    point=10*WEEK_PRAC_FREQ[i][j]
                elif WEEK_PRAC_FREQ[i][j]==4:
                    point=15*WEEK_PRAC_FREQ[i][j]
                else:
                    point=20*WEEK_PRAC_FREQ[i][j]
                points.append(point)
            GAINED_POINTS.append(sum(points))


        final_data2['PRACTISING_WEEK']=PRACTISING_WEEK
        final_data2['UNIQUE_WEEK_PRACTISED']=UNIQUE_WEEK_PRACTISED
        final_data2['WEEK_PRAC_FREQ']=WEEK_PRAC_FREQ
        final_data2['GAINED_POINTS']=GAINED_POINTS
        final_data2['CWP_SCORE']=round((final_data2['GAINED_POINTS']/(20*final_data2['WEEK_SINCE_FIRST_PRACTICE']))*100,0)
        final_data2.loc[(final_data2['CWP_SCORE']>100),'CWP_SCORE'] = 100



        # <<<<<<<<<<<<<<<<<<<<-------------------RECENT ENGAGEMENT SCORE------------------->>>>>>>>>>>>>>>>>>>>>>>>>>>>

        final_data3=final_data2

        user_master_df['SIGNUP_DATE']=pd.to_datetime(user_master_df['SIGNUP_DATE']).dt.date

        final_data3=user_master_df[['USER_ID','SIGNUP_DATE']].merge(final_data3,how='inner',on='USER_ID').reset_index(drop=True)

        _30_day_data=[]
        points_30_day=[]

        _60_day_data=[]
        points_60_day=[]

        _180_day_data=[]
        points_180_day=[]

        _365_day_data=[]
        points_365_day=[]

        CSY_data=[]
        points_csy_day=[]

        Lifetime=[]
        points_Lifetime=[]


        for i in range(len(final_data3)):
            if (datetime.datetime.now().date()-final_data3['SIGNUP_DATE'][i]).days>=30:
                dates30=list(pd.date_range(start=datetime.datetime.now().date()-timedelta(days=30),end=datetime.datetime.now().date(), freq=us_bd))
                dates30=[j.date() for j in dates30]
                _30_days=len(list(set(final_data3['DATES_OF_PRACTICING'][i]).intersection(dates30)))
                if (_30_days>0) and (_30_days<len(dates30)/6):
                    points30=1
                elif (_30_days==0):
                    points30=0
                else:
                    points30=2
            else:
                _30_days='not eligible'
                points30='not eligible'
            _30_day_data.append(_30_days)
            points_30_day.append(points30)



        for i in range(len(final_data3)):
            if (datetime.datetime.now().date()-final_data3['SIGNUP_DATE'][i]).days>=60:
                dates60=list(pd.date_range(start=datetime.datetime.now().date()-timedelta(days=60),end=datetime.datetime.now().date(), freq=us_bd))
                dates60=[j.date() for j in dates60]
                _60_days=len(list(set(final_data3['DATES_OF_PRACTICING'][i]).intersection(dates60)))
                if (_60_days>0) and (_60_days<len(dates60)/6):
                    points60=1
                elif (_60_days==0):
                    points60=0
                else:
                    points60=2
            else:
                _60_days='not eligible'
                points60='not eligible'        
            _60_day_data.append(_60_days)
            points_60_day.append(points60)



        for i in range(len(final_data3)):
            if (datetime.datetime.now().date()-final_data3['SIGNUP_DATE'][i]).days>=180:
                dates180=list(pd.date_range(start=datetime.datetime.now().date()-timedelta(days=180),end=datetime.datetime.now().date(), freq=us_bd))
                dates180=[j.date() for j in dates180]
                _180_days=len(list(set(final_data3['DATES_OF_PRACTICING'][i]).intersection(dates180)))
                if (_180_days>0) and (_180_days<len(dates180)/6):
                    points180=1
                elif (_180_days==0):
                    points180=0
                else:
                    points180=2

            else:
                _180_days='not eligible'
                points180='not eligible'

            _180_day_data.append(_180_days)
            points_180_day.append(points180)



        for i in range(len(final_data3)):
            if (datetime.datetime.now().date()-final_data3['SIGNUP_DATE'][i]).days>=365:
                dates365=list(pd.date_range(start=datetime.datetime.now().date()-timedelta(days=365),end=datetime.datetime.now().date(), freq=us_bd))
                dates365=[j.date() for j in dates365]
                _365_days=len(list(set(final_data3['DATES_OF_PRACTICING'][i]).intersection(dates365)))
                if (_365_days>0) and (_365_days<len(dates365)/6):
                    points365=1
                elif (_365_days==0):
                    points365=0
                else:
                    points365=2
            else:
                _365_days='not eligible'
                points365='not eligible'

            _365_day_data.append(_365_days)
            points_365_day.append(points365)


        for i in range(len(final_data3)):
            dates_csy=list(pd.date_range(start=csy_first_date().date(),end=datetime.datetime.now().date(), freq=us_bd))
            dates_csy=[j.date() for j in dates_csy]
            csy_days=len(list(set(final_data3['DATES_OF_PRACTICING'][i]).intersection(dates_csy)))
            if (csy_days>0) and (csy_days<len(dates_csy)/6):
                points_csy=1
            elif (csy_days==0):
                points_csy=0
            else:
                points_csy=2
            CSY_data.append(csy_days)
            points_csy_day.append(points_csy)





        for i in range(len(final_data3)):
            dates_lifetime=list(pd.date_range(start=final_data3['SIGNUP_DATE'][i],end=datetime.datetime.now().date(), freq=us_bd))
            dates_lifetime=[j.date() for j in dates_lifetime]
            lifetime_days=len(list(set(final_data3['DATES_OF_PRACTICING'][i]).intersection(dates_lifetime)))
            if (lifetime_days>0) and (lifetime_days<len(dates_lifetime)/6):
                points_lifetime=1
            elif (lifetime_days==0):
                points_lifetime=0
            else:
                points_lifetime=2

            Lifetime.append(lifetime_days)
            points_Lifetime.append(points_lifetime)




        mergedata=[]
        for m,n,o,p,q,r in zip(points_30_day,points_60_day,points_180_day,points_365_day,points_csy_day,points_Lifetime):
            mergedata.append([m,n,o,p,q,r])


        final_data3['RE_SCORE']=''
        for i in range(len(mergedata)):
            xs=[s for s,val in enumerate(mergedata[i]) if val!='not eligible']
            check=len(xs)
            if check>0:
                re_score=(sum([mergedata[i][q] for q in xs])/(2*check))*100
            else:
                re_score=0
            final_data3['RE_SCORE'][i]=round(re_score,0)


        # <<<<<<<<<<<<<<<<------------------------------ACTIVE USER SCORE------------------------>>>>>>>>>>>>>>>>>>>>>>>>>

        days_since_signup=[]
        for i in range(len(final_data3)):
            d_snup=(datetime.datetime.now().date()-final_data3['SIGNUP_DATE'][i]).days
            days_since_signup.append(d_snup)


        ACTIVE_USER=[]
        for i in range(len(days_since_signup)):
            p_days=len(final_data3['DATES_OF_PRACTICING'][i])
            if days_since_signup[i]>60:        
                if p_days>=20:
                    active_user=1
                else:
                    active_user=0
            else:
                if p_days>=round((days_since_signup[i]/60)*20,0):
                    active_user=1
                else:
                    active_user=0

            ACTIVE_USER.append(active_user)


        final_data3['ACTIVE_USER']=ACTIVE_USER


        ACTIVE_USER_SCORE_SCHOOL=round((len(final_data3[final_data3['ACTIVE_USER']>0])/len(user_master_df))*100,0)

        USAGE_SCORE_SCHOOL=round(final_data3['USAGE_SCORE'].mean(),0)

        CWP_SCORE_SCHOOL=round(final_data3['CWP_SCORE'].mean(),0)

        RE_SCORE_SCHOOL=round(final_data3['RE_SCORE'].mean(),0)

        E_SCORE_SCHOOL=round((ACTIVE_USER_SCORE_SCHOOL+USAGE_SCORE_SCHOOL+CWP_SCORE_SCHOOL+RE_SCORE_SCHOOL)/4,0)

        if len(audio_track_master_df)>=5*len(user_master_df):

            ACTIVE_SCHOOL=1
        else:
            ACTIVE_SCHOOL=0

        score_output={
            'SCHOOL_ID':trackid,
            'SCHOOL_NAME':school_name,        
            'ACTIVE_USER_SCORE_SCHOOL':ACTIVE_USER_SCORE_SCHOOL*10,
                     'USAGE_SCORE_SCHOOL':USAGE_SCORE_SCHOOL*10,
                      'CWP_SCORE_SCHOOL':CWP_SCORE_SCHOOL*10,
                      'RE_SCORE_SCHOOL':RE_SCORE_SCHOOL*10,
                      'E_SCORE_SCHOOL':E_SCORE_SCHOOL*10,
                      'ACTIVE_SCHOOL':ACTIVE_SCHOOL*10  


                     }

        return score_output

    if len(list(db_live.district_master.find({'_id':ObjectId(str(trackid))})))>0:
        district_id=trackid
        districtinfo={
            '5f2609807a1c0000950bb45a':'LAUSD',
            '5f2609807a1c0000950bb45c':'Comox Valley School District'
        }
        
        if district_id in list(districtinfo):
            district_name=districtinfo[district_id]
        
#         if district_id=='5f2609807a1c0000950bb45a':
#             district_name='LAUSD'
        else:
            districtname=list(db_live.district_master.find({'_id':ObjectId(district_id)}))
            district_name=districtname[0].get('DISTRICT_NAME')
            
#         districtname=list(db_live.district_master.find({'_id':ObjectId(district_id)}))
        
        schoolids=db_live.user_master.distinct('schoolId._id',
                                               
                                               {'schoolId._id':{'$in':db_live.school_master.distinct('_id',                                               
                                               {'CATEGORY':{'$regex':district_name,'$options':'i'}})}
                                               })
        df_s=[]
        for ii in range(len(schoolids)):
            schls= escore_school(str(schoolids[ii]))
            df_s.append(schls)
        schools_df=pd.DataFrame(df_s)
        
        schools_df['SCORE_TYPE']=''

        for i in range(len(schools_df)):
            if schools_df['E_SCORE_SCHOOL'][i]<=250:
                schools_df['SCORE_TYPE'][i]='0-250'
            elif schools_df['E_SCORE_SCHOOL'][i]<=500:
                schools_df['SCORE_TYPE'][i]='251-500'
            elif schools_df['E_SCORE_SCHOOL'][i]<=750:
                schools_df['SCORE_TYPE'][i]='501-750'
            else:
                schools_df['SCORE_TYPE'][i]='751-1000'
                
                
        
        import os
        file_name = str(trackid)+'_school_e_scores.csv'

        if(os.path.exists(file_name) and os.path.isfile(file_name)):
            os.remove(file_name)
                
        schools_df.to_csv(str(trackid)+'_school_e_scores.csv',index=False)
                
    
                
        new_schools_df=schools_df.groupby('SCORE_TYPE')['SCHOOL_ID'].count().reset_index().rename(columns={'SCHOOL_ID':'School_Count'})

        score_type=pd.DataFrame({'SCORE_TYPE':[
            '0-250','251-500','501-750','751-1000'
        ]})
        
        
        
        
        new_schools_df1=score_type.merge(new_schools_df,how='left',on='SCORE_TYPE').fillna(0)
        
        
        ACTIVE_SCHOOL_SCORE=round(sum(schools_df['ACTIVE_SCHOOL'])/len(set(schoolids))*100,0)
        E_SCORE=round((schools_df['ACTIVE_USER_SCORE_SCHOOL'].mean()+schools_df['USAGE_SCORE_SCHOOL'].mean()+schools_df['CWP_SCORE_SCHOOL'].mean()+schools_df['RE_SCORE_SCHOOL'].mean()+ACTIVE_SCHOOL_SCORE)/5)

        temp={'ACTIVE_USER_SCORE':round(schools_df['ACTIVE_USER_SCORE_SCHOOL'].mean(),0),
             'USAGE_SCORE':round(schools_df['USAGE_SCORE_SCHOOL'].mean(),0),
              'CWP_SCORE':round(schools_df['CWP_SCORE_SCHOOL'].mean(),0),
              'RE_SCORE':round(schools_df['RE_SCORE_SCHOOL'].mean(),0),
              'ACTIVE_SCHOOL_SCORE':ACTIVE_SCHOOL_SCORE,
              'E_SCORE':E_SCORE,
              'columchart':{'axis':new_schools_df1['SCORE_TYPE'].tolist(),
                           'schoolcount':new_schools_df1['School_Count'].tolist()
#               '0-25':new_schools_df1[new_schools_df1['SCORE_TYPE']=='0-25'].reset_index()['School_Count'][0],
#               '26-50':new_schools_df1[new_schools_df1['SCORE_TYPE']=='26-50'].reset_index()['School_Count'][0],
#               '51-75':new_schools_df1[new_schools_df1['SCORE_TYPE']=='51-75'].reset_index()['School_Count'][0],
#               '76-100':new_schools_df1[new_schools_df1['SCORE_TYPE']=='76-100'].reset_index()['School_Count'][0],
              
                            }}
        
        return json.dumps(temp)
#         return new_schools_df1   
    else:
        df_single_s=[]        
        schls= escore_school(trackid)
        df_single_s.append(schls)
        schools_df=pd.DataFrame(df_single_s)
        temp={'ACTIVE_USER_SCORE':schools_df['ACTIVE_USER_SCORE_SCHOOL'][0],
             'USAGE_SCORE':schools_df['USAGE_SCORE_SCHOOL'][0],
              'CWP_SCORE':schools_df['CWP_SCORE_SCHOOL'][0],
              'RE_SCORE':schools_df['RE_SCORE_SCHOOL'][0],
              'E_SCORE':schools_df['E_SCORE_SCHOOL'][0]
             }
        
        
    return json.dumps(temp)



@app.route('/escores/<trackid>/<scoretype>')
def schoolscores(trackid,scoretype):
    df=pd.read_csv(r"/root/" + str(trackid)+'_school_e_scores.csv',sep=',')
    new_df=df[df['SCORE_TYPE']==scoretype][['SCHOOL_NAME', 'ACTIVE_USER_SCORE_SCHOOL',
       'USAGE_SCORE_SCHOOL', 'CWP_SCORE_SCHOOL', 'RE_SCORE_SCHOOL',
       'E_SCORE_SCHOOL']]   
    
    if new_df.empty:
        return json.dumps({'data':'No Data Available'})
    
    return json.dumps({'data':new_df.values.tolist()})


@app.route('/escoresnew/<trackid>/<scoretype>')


def schoolscoresnew(trackid,scoretype):
    df=pd.read_csv(r"/root/" + str(trackid)+'_school_e_scores.csv',sep=',')
    new_df=df[df['SCORE_TYPE']==scoretype][['SCHOOL_NAME', 'ACTIVE_USER_SCORE_SCHOOL',
       'USAGE_SCORE_SCHOOL', 'CWP_SCORE_SCHOOL', 'RE_SCORE_SCHOOL',
       'E_SCORE_SCHOOL']]   
    
    if new_df.empty:
        return json.dumps({'data':'No Data Available'})
    
    return json.dumps({'data':new_df.values.tolist()})

    
@app.route('/escoresnew/<trackid>/')

def dis_escore(trackid):
    df=pd.read_csv(r"/root/" + trackid+'_E_SCORE_DATA.csv',sep=",")
    df1=df[['DISTRICT_NAME', 'ACTIVE_USER_SCORE',
           'USAGE_SCORE', 'CWP_SCORE', 'RE_SCORE', 'ACTIVE_SCHOOL_SCORE',
           'E_SCORE']]
    
    
    df_table=pd.read_csv(r"/root/" + str(trackid)+'_school_e_scores.csv',sep=',')


    new_df_table=df_table.groupby('SCORE_TYPE')['SCHOOL_ID'].count().reset_index().rename(columns={'SCHOOL_ID':'School_Count'})

    score_type=pd.DataFrame({'SCORE_TYPE':[
        '0-250','251-500','501-750','751-1000'
    ]})
    new_df1=score_type.merge(new_df_table,how='left',on='SCORE_TYPE').fillna(0)    
    p=df1.to_dict('records')[0]    
    
    df_monthwise=pd.read_csv(r"/root/" + str(trackid)+'_school_e_scores.csv',sep=',')
    
    p['columchart']={'axis':new_df1['SCORE_TYPE'].tolist(),
                           'schoolcount':new_df1['School_Count'].tolist()}
    
    df_monthwise=pd.read_csv(r"/root/" + str(trackid)+'_monthwise_e_score.csv',sep=',')
    
    
    p['mothwise_col_chart']={'months':df_monthwise['TIME_PERIOD'].tolist(),
                            'monthvalues_escore':df_monthwise['E_SCORE'].tolist(),
                            'monthvalues_active_user_score':df_monthwise['ACTIVE_USER_SCORE'].tolist(),
                            'monthvalues_usage_score':df_monthwise['USAGE_SCORE'].tolist(),
                            'monthvalues_cwp_score':df_monthwise['CWP_SCORE'].tolist(),
                            'monthvalues_re_score':df_monthwise['RE_SCORE'].tolist(),
                             'monthvalues_active_school_score':df_monthwise['ACTIVE_SCHOOL_SCORE'].tolist(),
                            }

    return json.dumps(p)

# E-Score Heatmap api:

@app.route('/escoreheatmap/<trackid>')
def escore_heatmap(trackid):
    school_level=pd.read_csv(r"/root/" + str(trackid)+'_school_e_scores.csv',sep=",")
    school_level=school_level.drop(columns=['SCHOOL_NAME'],axis=1)
    if len(list(db_live.district_master.find({'_id':ObjectId(str(trackid))})))>0:
        district_id=trackid
        districtinfo={
            '5f2609807a1c0000950bb45a':'LAUSD',
            '5f2609807a1c0000950bb45c':'Comox Valley School District'
        }

        if district_id in list(districtinfo):
            district_name=districtinfo[district_id]

#         if district_id=='5f2609807a1c0000950bb45a':
#             district_name='LAUSD'
        else:
            districtname=list(db_live.district_master.find({'_id':ObjectId(district_id)}))
            district_name=districtname[0].get('DISTRICT_NAME')

#         districtname=list(db_live.district_master.find({'_id':ObjectId(district_id)}))

        all_schools=pd.DataFrame(list(db_live.school_master.aggregate([{'$match':{'$and':[
                                        {'CATEGORY':{'$regex':district_name,'$options':'i'}},
            {'IS_PORTAL':'Y'}]}},
                                {'$project':{
                                        '_id':0,
                                        'SCHOOL_ID':'$_id',
                                        'SCHOOL_NAME':'$NAME'
                                    }}
                                    ])))
    


    all_schools['SCHOOL_ID']=all_schools['SCHOOL_ID'].astype('str')

    final_df=all_schools.merge(school_level,how='left',on='SCHOOL_ID')

    final_df[[ 'ACTIVE_USER_SCORE_SCHOOL',
           'USAGE_SCORE_SCHOOL', 'CWP_SCORE_SCHOOL', 'RE_SCORE_SCHOOL',
           'E_SCORE_SCHOOL', 'ACTIVE_SCHOOL']]=final_df[[ 'ACTIVE_USER_SCORE_SCHOOL',
           'USAGE_SCORE_SCHOOL', 'CWP_SCORE_SCHOOL', 'RE_SCORE_SCHOOL',
           'E_SCORE_SCHOOL', 'ACTIVE_SCHOOL']].fillna(0)

    final_df['SCORE_TYPE']=final_df['SCORE_TYPE'].fillna('0-250')

    final_df=final_df.sort_values(by='E_SCORE_SCHOOL',ascending=False).reset_index(drop=True)

    temp={}
    for i in range(len(final_df)):
        x={str(final_df['SCHOOL_NAME'][i]):final_df[['ACTIVE_USER_SCORE_SCHOOL',
           'USAGE_SCORE_SCHOOL', 'CWP_SCORE_SCHOOL', 'RE_SCORE_SCHOOL',
           'E_SCORE_SCHOOL']].values.tolist()[i]}
        temp.update(x)


    final_temp={'heatmap':temp,
               'fieldnames':['Active User Score',
           'Usage Score', 'CWP Score', 'RE Score',
           'E Score']

               }
    return json.dumps(final_temp)


# DAILD
@app.route('/Playback_Chart_daild')
def day_playbacks_():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass

    mydatetime=datetime.datetime.utcnow()
    # +timedelta(hours=4)
    today_min=datetime.datetime.combine(mydatetime,datetime.time.min)
    # +timedelta(hours=4)
    today_max=datetime.datetime.combine(mydatetime, datetime.time.max)
    # +timedelta(hours=4)
    
#     week before
    week_before=datetime.datetime.utcnow()-timedelta(days=7)
    # +timedelta(hours=4)
    week_before_min=datetime.datetime.combine(week_before,datetime.time.min)
    # +timedelta(hours=4)
    week_before_max=datetime.datetime.combine(week_before, datetime.time.max)
    # +timedelta(hours=4)


    collection= db.audio_track_master
    df_playback= DataFrame(list(collection.aggregate([{"$match":{
    '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'MODIFIED_DATE': {'$gte':today_min, '$lt':today_max}}
    ]}},
    {'$group':{'_id':{'$hour':{'date':'$MODIFIED_DATE'}}, 'Playbacks':{'$sum':1}
    }}, {'$sort':{'_id':1}}
    ])))

    
    playback_week_before= DataFrame(list(collection.aggregate([{"$match":{
    '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'MODIFIED_DATE': {'$gte': week_before_min, '$lt':week_before_max}}
    ]}},
    {'$group':{'_id':{'$hour':{'date':'$MODIFIED_DATE'}}, 'Playbacks':{'$sum':1}
    }}, {'$sort':{'_id':1}}
    ])))


    
    if df_playback.empty:
        df= pd.DataFrame(columns=['Hour', 'Playbacks'])
        for i in range(1):
            df.loc[i]= ['None'],['No Practice happened till now']
            hr= df['Hour'].tolist()
            rating=df['Playbacks'].tolist()
            temp={"Hour":hr,"Playbacks":playback}

    else:
        hour=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]

        count=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]

        df_hour=pd.DataFrame({'hour':hour,'count':count})

        df_merge=pd.merge(df_hour,df_playback, left_on='hour',right_on='_id', how='left')

        df_fillna=df_merge.fillna(0)

        df_fillna['Playbacks']=df_fillna['Playbacks'].astype(int)

        df_final=df_fillna[['hour','Playbacks']]

        df_final=df_final.sort_values(["hour","Playbacks"], ascending=(True,False))

        hr= df_final['hour'].tolist()
        playback=df_final['Playbacks'].tolist()

        
        #week_before
        df_merge_wb=pd.merge(df_hour,playback_week_before, left_on='hour',right_on='_id', how='left')

        df_fillna_wb=df_merge_wb.fillna(0)

        df_fillna_wb['Playbacks']=df_fillna_wb['Playbacks'].astype(int)

        df_final_wb=df_fillna_wb[['hour','Playbacks']]

        df_final_wb=df_final_wb.sort_values(["hour","Playbacks"], ascending=(True,False))

        hr_wb= df_final_wb['hour'].tolist()
        playback_wb=df_final_wb['Playbacks'].tolist()


        temp={"Hour":hr,"Playbacks":playback, "Playback_last_week":playback_wb}

        return json.dumps(temp)
    




@app.route('/Feedback_Chart_daild')
def day_hourly_feed_():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass

    mydatetime=datetime.datetime.utcnow()
    # +timedelta(hours=4)
    today_min=datetime.datetime.combine(mydatetime,datetime.time.min)
    # +timedelta(hours=4)
    today_max=datetime.datetime.combine(mydatetime, datetime.time.max)
    # +timedelta(hours=4)

#     week before
    week_before=datetime.datetime.utcnow()-timedelta(days=7)
    # +timedelta(hours=4)
    week_before_min=datetime.datetime.combine(week_before,datetime.time.min)
    # +timedelta(hours=4)
    week_before_max=datetime.datetime.combine(week_before, datetime.time.max)
    # +timedelta(hours=4)

    
    collections= db.audio_feedback
    df_feed=DataFrame(list(collections.aggregate([
        {"$match":{'$and':[
        {"USER.IS_DISABLED":{"$ne":"Y"}},     { "USER.IS_BLOCKED":{"$ne":"Y"}},
        { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'MODIFIED_DATE': {'$gte':  today_min, '$lt':today_max}}, {'RATING':{'$ne':0}}
            #         {'COMMENT':{'$nin':['',' ',None]}},

    #         }]
        ]}},
    {'$group':{'_id':{'$hour':{'date':'$MODIFIED_DATE'}},'rating':{'$sum':1}}}, 
        {'$sort':{'_id':1}}
    ])))

    df_feed_week_beofre=DataFrame(list(collections.aggregate([
        {"$match":{'$and':[
        {"USER.IS_DISABLED":{"$ne":"Y"}},     { "USER.IS_BLOCKED":{"$ne":"Y"}},
        { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'MODIFIED_DATE': {'$gte':  week_before_min, '$lt':week_before_max}}, {'RATING':{'$ne':0}}
            #         {'COMMENT':{'$nin':['',' ',None]}},

    #         }]
        ]}},
    {'$group':{'_id':{'$hour':{'date':'$MODIFIED_DATE'}},'rating':{'$sum':1}}}, 
        {'$sort':{'_id':1}}
    ])))



    if df_feed.empty:
        df= pd.DataFrame(columns=['Hour', 'Rating'])
        for i in range(1):
            df.loc[i]= ['None'],['No Ratings were given today']
            hr= df['Hour'].tolist()
            rating=df['Rating'].tolist()
            temp={"Hour":hr,"Rating":rating}
        return json.dumps(temp)

    else:
        hour=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]

        count=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]

        df_hour=pd.DataFrame({'hour':hour,'count':count})

        df_merge=pd.merge(df_hour,df_feed, left_on='hour',right_on='_id', how='left')

        df_fillna=df_merge.fillna(0)
        df_fillna['rating']=df_fillna['rating'].astype(int)

        df_final=df_fillna[['hour','rating']]

        df_final=df_final.sort_values(["hour","rating"], ascending=(True,False))


        hr= df_final['hour'].tolist()
        rating=df_final['rating'].tolist()
        
#         week_before
        df_merge_wb=pd.merge(df_hour,df_feed_week_beofre, left_on='hour',right_on='_id', how='left')
        df_fillna_wb=df_merge_wb.fillna(0)
        df_fillna_wb['rating']=df_fillna_wb['rating'].astype(int)

        df_final_wb=df_fillna_wb[['hour','rating']]

        df_final_wb=df_final_wb.sort_values(["hour","rating"], ascending=(True,False))
        hr_wb= df_final_wb['hour'].tolist()
        rating_wb=df_final_wb['rating'].tolist()


        
        temp={"Hour":hr,"Rating":rating,"Ratings_last_week":rating_wb}
    return json.dumps(temp)


# Sentiment Analysis
from nltk.tokenize import word_tokenize
from nltk.probability import FreqDist
from nltk.corpus import stopwords
from textblob import TextBlob, Word, Blobber    


@app.route('/Sentiment_donut_dild')
def donut_chart_():
    
    clean_list=[]
    news_headlines_senti = []
    news_headlines_dict = {}
    pnews_headlines=0
    nnews_headlines=0
    nenews_headlines = 0

    mydatetime=datetime.datetime.utcnow()
    # +timedelta(hours=4)
    today_min=datetime.datetime.combine(mydatetime,datetime.time.min)
    # +timedelta(hours=4)
    today_max=datetime.datetime.combine(mydatetime, datetime.time.max)
    # +timedelta(hours=4)


    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback
    user_feed=[
    {"$match":{'$and':[ {"USER.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
    {"USER.USER_NAME":{ "$ne": ""}},
    {"USER.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
    {"USER.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
    {'USER.EMAIL_ID':{ "$not": { "$regex": "tech@innerexplorer.org",'$options':'i'}}},
    {"USER.EMAIL_ID":{ "$ne": ""}},{'USER.IS_BLOCKED':{"$ne":'Y'}}, {'USER.IS_DISABLED':{"$ne":'Y'}},
       {'MODIFIED_DATE':{'$gte': today_min, '$lt':today_max}}, 
    #                        {'RATING':{'$in':rating}},     
    {'USER.INCOMPLETE_SIGNUP':{"$ne":'Y'}}
    ]}},
    { "$project": { "_id": "$USER._id", "USER_NAME": "$USER.USER_NAME","EMAIL": "$USER.EMAIL_ID", "RATING":1,
    "LAST_COMMENT_DATE": "$MODIFIED_DATE", "AUDIO_NAME": "$AUDIO_ID.AUDIO_NAME", "NARRATOR_NAME": "$AUDIO_ID.NARRATEDBY",
    "COMMENT":1, "PROGRAM_NAME": "$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME"}}
    ]
    update_feed=list(collection.aggregate(user_feed))
    df_feed=pd.DataFrame(update_feed).fillna("no info")

    # list_of_names=df_feed["_id"].tolist()

    collection1 = db.user_master
    user_master=[
    {"$match":{'$and':[ {"USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_NAME":{ "$ne": ""}},
    {"EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
    {"EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
    {"EMAIL_ID":{ "$ne": ""}},  {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}
    # ,{"_id":{"$in":list_of_names}}   
    ]}},
    { "$project": {"_id":"$_id",
        "SCHOOL_NAME":"$schoolId.NAME", 'District_name':'$DISTRICT_ID.DISTRICT_NAME',
    "CITY":"$schoolId.CITY","STATE":"$schoolId.STATE"}}
    ]
    update_user=list(collection1.aggregate(user_master))
    df_user=pd.DataFrame(update_user).fillna("no info")

    df01=pd.merge(df_feed,df_user,on="_id",how="left")

    collection2 = db.subscription_master
    user_sub=[
    {"$match":{'$and':[{"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_ID.USER_NAME":{ "$ne": ""}},
    {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
    {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
    {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    # {"USER_ID._id":{"$in":list_of_names}}
    ]}},
    { "$project": {"_id":"$USER_ID._id","RENEWAL_DATE":"$SUBSCRIPTION_EXPIRE_DATE","PLAN_NAME":"$PLAN_ID.PLAN_NAME"}}]

    update_sub=list(collection2.aggregate(user_sub))
    df2_sub=pd.DataFrame(update_sub).fillna("no info")

    df12=pd.merge(df01,df2_sub,on="_id",how="left")

    collection_atm = db.audio_track_master
    atm=[
    {"$match":{'$and':[ {"USER_ID.USER_NAME": { "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_ID.USER_NAME":{ "$ne": ""}},
    {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "test",'$options':'i'}}},
    {"USER_ID.EMAIL_ID":{ "$not": { "$regex": "1gen",'$options':'i'}}},
    {"USER_ID.EMAIL_ID":{ "$ne": ""}},  
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, 
    {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    # { "USER_ID._id":{"$in":list_of_names}},
    ]}},
    {"$group":{"_id": "$USER_ID._id","PRACTICE_COUNT":{"$sum":1}, 
    "LAST_PRACTICE_DATE": {"$last": "$MODIFIED_DATE"},
    }}
    # { "$project": {"_id":"$USER_ID._id","PRACTICE_COUNT":1,"LAST_PRACTICE_DATE":1}}
    ]
    update_atm=list(collection_atm.aggregate(atm))
    df3=pd.DataFrame(update_atm)


    df123=pd.merge(df12,df3,on="_id",how="left")

#     def average(listt):
#         return sum(listt)/len(listt) 
#     df_rating=df123[df123['RATING']!=0]
#     listt=df_rating['RATING'].tolist()
#     Avg= round(average(listt),1)

    xx=df123[df123["COMMENT"]!="no info"]
    df_comments=xx[xx["COMMENT"]!=""]

    comment_list=df_comments["COMMENT"].to_list()

    # df_comments


    newtexttoken=[]
    for i in comment_list:
        text_tokens= word_tokenize(i)
        newtexttoken.append(text_tokens)
    # newtexttoken    

    newlist=[]
    for i in newtexttoken:
        for z in i:
            newlist.append(z.lower())

    # newlist 

    st_words=stopwords.words('english')
    st_words_spanish=stopwords.words('spanish')
    tokens_without_sw= [word for word in newlist if not word in st_words]

    # tokens_without_sw


    token5=[]
    for sentence in tokens_without_sw:
        text3 = sentence.split('ing')

        for i in text3:
            token5.append(i)

    words = [w.replace('liked', 'like') for w in token5]
    words2 = [w.replace('relaxed', 'relax') for w in words]
    words3 = [w.replace('relaxing', 'relax') for w in words2]
    words4 = [w.replace('excitinging', 'excited') for w in words3]
    # words

    zxc=""
    name=""
    count=""

    try:
        xxx=[x for x in words4 if len(x)>3]
        fdist=FreqDist(xxx)
        df_fdist = pd.DataFrame.from_dict(fdist, orient='index')
        df_fdist.columns = ['Frequency']
        df_fdist.index.name = 'Term'
        xc=df_fdist.sort_values(by='Frequency', ascending=False, na_position='first')
        cc=xc[0:10]
        name=cc.index.to_list()
        count=cc["Frequency"].to_list()
        zxc=' '.join(word for word in xxx)
    except:
        pass

    for item in comment_list:
        # trim
        item = item.strip()
        # Removing RT
        item = item.replace('RT', '')
        # Removing new line character
        item = item.replace('\\n', '')
        # Replace #word with word
        news_headlines = re.sub(r'#([^\s]+)', r'\1', item)
        # Convert @username to username
        news_headlines = re.sub(r'@([^\s]+)', r'\1', item)
        item = " ".join(re.findall("[a-zA-Z]+", item))
        tmp_var = re.sub(r'^\S*\s', '', item)
        clean_list.append(tmp_var)

    for item in clean_list:
        #print(item)
        # create TextBlob object of passed news_headlines text
        analysis = TextBlob(item)
        # set sentiment
        if analysis.sentiment.polarity > 0:
            # saving sentiment of news_headlines
            news_headlines_score = 'positive'
            pnews_headlines = pnews_headlines + 1
            news_headlines_dict[item] = news_headlines_score
        elif analysis.sentiment.polarity == 0:
            # saving sentiment of news_headlines
            news_headlines_score = 'neutral'
            nenews_headlines = nenews_headlines + 1
            news_headlines_dict[item] = news_headlines_score
        else:
            # saving sentiment of news_headlines
            news_headlines_score = 'negative'
            nnews_headlines = nnews_headlines + 1
            news_headlines_dict[item] = news_headlines_score


    newssentiment=[]
    for k, v in news_headlines_dict.items():
        if v == "positive":
            newssentiment.append({"sentiment":int(1),"text":k})
        elif v == "negative":
            newssentiment.append({"sentiment":int(-1),"text":k})
        else:
            newssentiment.append({"sentiment":int(0),"text":k})


    newssentiment_dataframe=pd.DataFrame.from_dict(newssentiment)

    neg = 100 * (nnews_headlines) / ((nnews_headlines) + (pnews_headlines))
    pos = 100 * (pnews_headlines) / ((nnews_headlines) + (pnews_headlines))


    donut={"donut":{"pos":round(pos, 2),"neg":round(neg, 2)}}

    return json.dumps(donut)



@app.route('/Feedback_card_dild')
def day_feedback_card():
    import datetime
    import math
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection2=db.audio_feedback

    mydatetime=datetime.datetime.utcnow()
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)

    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)

    #TEACHERS COMMENT PER FEEDBACK LAST WEEK
    query1=[
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lte':tod}}    ,    
    #         {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed=list(collection2.aggregate(query1))
    if len(commentsonfeed)>0:
        commentsonfeedback=pd.DataFrame(commentsonfeed)
        comments_per_feedback_teacher=commentsonfeedback[['rating']]
    else:
        comments_per_feedback_teacher=pd.DataFrame({'rating':[0]})


    #PARENTS COMMENT PER FEEDBACK LAST WEEK
    querya=[
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lte':tod}}    ,    
    #        {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}}]}},


    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed2=list(collection2.aggregate(querya))
    if len(commentsonfeed2)>0:
        commentsonfeedback2=pd.DataFrame(commentsonfeed2)
        comments_per_feedback_parents=commentsonfeedback2[['rating']]
    else:
        comments_per_feedback_parents=pd.DataFrame({'rating':[0]})



    #TEACHERS COMMENT PER FEEDBACK before LAST WEEK
    query4=[
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lte':startend}}    ,   
    #        {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}}]}},

    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed11=list(collection2.aggregate(query4))
    if len(commentsonfeed11)>0:
        commentsonfeedback11=pd.DataFrame(commentsonfeed11)
        comments_per_feedback_before_last_week_teachers=commentsonfeedback11[['rating']]
    else:
        comments_per_feedback_before_last_week_teachers=pd.DataFrame({'rating':[0]})



    #  PARENTS COMMENT PER FEEDBACK before LAST WEEK
    queryB=[
    {"$match":{'$and':[
     {'USER.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lt':startend}},    
    #         {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}}]}},


    {'$group':{'_id':'null', 'rating':{'$sum':1}
    }}
    ]

    commentsonfeed200=list(collection2.aggregate(queryB))
    if len(commentsonfeed200)>0:
        commentsonfeedback20=pd.DataFrame(commentsonfeed200)
        comments_per_feedback_before_last_week_parents=commentsonfeedback20[['rating']]
    else:
        comments_per_feedback_before_last_week_parents=pd.DataFrame({'rating':[0]})



    # AVERAGE FEEDBACK RATING LAST WEEK
    query6=[
    {"$match":{'$and':[
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':yester, '$lt':tod}}    ,    
    #         {'COMMENT':{'$nin':['',' ',None]}},
    {'RATING':{'$ne':0}}]}},
    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rating=list(collection2.aggregate(query6))
    if len(avg_rating)>0:
        avg_ratings=pd.DataFrame(avg_rating)
        avg_ratings_lastweek=avg_ratings[['RATING']]
        avg_ratings_last_week=pd.DataFrame({'avg_ratings_lastweek':round(avg_ratings_lastweek[avg_ratings_lastweek['RATING']!=0]['RATING'].mean(),1)}, index=[0])
    else:
        avg_ratings_lastweek=pd.DataFrame({'RATING':[0]})
        avg_ratings_last_week=pd.DataFrame({'avg_ratings_lastweek':[0]})


    query60=[
    {"$match":{'$and':[
    {"USER.IS_DISABLED":{"$ne":"Y"}},
     { "USER.IS_BLOCKED":{"$ne":"Y"}},
    { "USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
       {'MODIFIED_DATE':{'$gte':start_15day, '$lt':startend}}    ,   
    #         {'COMMENT':{'$nin':['',' ',None]}},

    {'RATING':{'$ne':0}}]}},

    {'$project':{'_id':0, 'RATING':'$RATING'
    }}
    ]

    avg_rate=list(collection2.aggregate(query60))
    if len(avg_rate)>0:
        avg_ratin=pd.DataFrame(avg_rate)
        avg_ratings_before_lastweek=avg_ratin[['RATING']]
        avg_ratings_beforee_last_week=pd.DataFrame({'avg_ratings_before_lastweek':round(avg_ratings_before_lastweek[avg_ratings_before_lastweek['RATING']!=0]['RATING'].mean(),1)}, index=[0])
    else:
        avg_ratings_before_lastweek=pd.DataFrame({'RATING':[0]})
        avg_ratings_beforee_last_week=pd.DataFrame({'avg_ratings_before_lastweek':[0]})



    TEACHER_Comment_per_feedbackchange=[]
    teacher_PERCENTAGE_change=[]
    if comments_per_feedback_before_last_week_teachers['rating'].iloc[0]> comments_per_feedback_teacher['rating'].iloc[0]:
        xx=comments_per_feedback_before_last_week_teachers['rating'].iloc[0]-comments_per_feedback_teacher['rating'].iloc[0]
        if comments_per_feedback_before_last_week_teachers['rating'].iloc[0]==0:
            yy= round(xx/1*100,2)
        else:
            yy=xx/comments_per_feedback_before_last_week_teachers['rating'].iloc[0]


    #     if math.isnan(yy):
    #         yy=0
    #     else:
    #         yy=yy
    #     zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('-1')
        teacher_PERCENTAGE_change.append(yy)

    elif comments_per_feedback_teacher['rating'].iloc[0] == comments_per_feedback_before_last_week_teachers['rating'].iloc[0]:
        xx=comments_per_feedback_teacher['rating'].iloc[0]-comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        yy= xx/comments_per_feedback_teacher['rating'].iloc[0]
    #     if math.isnan(yy):
    #         yy=0
    #     else:
    #         yy=yy
    #     zz= round(yy*100,2)
        TEACHER_Comment_per_feedbackchange.append('0')
        teacher_PERCENTAGE_change.append(yy)

    else:
        pp=comments_per_feedback_teacher['rating'].iloc[0]-comments_per_feedback_before_last_week_teachers['rating'].iloc[0]
        if comments_per_feedback_before_last_week_teachers['rating'].iloc[0]==0:
            qq= round(pp/1*100,2)
        else:
            qq= pp/comments_per_feedback_before_last_week_teachers['rating'].iloc[0]


    #     if math.isnan(qq):
    #         qq=0
    #     else:
    #         qq=qq 
    #     rr=round(qq*100,2)
        TEACHER_Comment_per_feedbackchange.append('1')
        teacher_PERCENTAGE_change.append(qq)

    import math
    teacher_PERCENTAGE_change=[0 if math.isnan(i) else i for i in teacher_PERCENTAGE_change] 


    PARENT_Comment_per_feedbackchange=[]
    parent_PERCENTAGE_change=[]
    if comments_per_feedback_before_last_week_parents['rating'].iloc[0]> comments_per_feedback_parents['rating'].iloc[0]:
        pp=comments_per_feedback_before_last_week_parents['rating'].iloc[0]- comments_per_feedback_parents['rating'].iloc[0]
        if comments_per_feedback_before_last_week_parents['rating'].iloc[0]==0:
            qq=round(pp/1*100,2)
        else:
            qq= pp/comments_per_feedback_before_last_week_parents['rating'].iloc[0]
    #     if math.isnan(qq):
    #         qq=0
    #     else:
    #         qq=qq 
    #     rr=round(qq*100,2)
        PARENT_Comment_per_feedbackchange.append('-1')
        parent_PERCENTAGE_change.append(qq)

    elif comments_per_feedback_parents['rating'].iloc[0] == comments_per_feedback_before_last_week_parents['rating'].iloc[0]:
        pp=comments_per_feedback_parents['rating'].iloc[0]-comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        qq= pp/comments_per_feedback_parents['rating'].iloc[0]
    #     if math.isnan(qq):
    #         qq=0
    #     else:
    #         qq=qq 
    #     rr=round(qq*100,2)
        PARENT_Comment_per_feedbackchange.append('0')
        parent_PERCENTAGE_change.append(qq)

    else:
        pp=comments_per_feedback_parents['rating'].iloc[0]-comments_per_feedback_before_last_week_parents['rating'].iloc[0]
        if comments_per_feedback_before_last_week_parents['rating'].iloc[0]==0:
            qq= round(pp/1*100,2)
        else:
            qq= pp/comments_per_feedback_before_last_week_parents['rating'].iloc[0]


    #     if math.isnan(qq):
    #         qq=0
    #     else:
    #         qq=qq 
    #     rr=round(qq*100,2)
        PARENT_Comment_per_feedbackchange.append('1')
        parent_PERCENTAGE_change.append(qq)

    import math
    parent_PERCENTAGE_change=[0 if math.isnan(i) else i for i in parent_PERCENTAGE_change] 



    Average_FEEDBACK_Rating_change=[]
    Average_feedback_PERCENTAGE=[]
    if avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]> avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]:
        aa=avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]- avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
        if avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]==0:
            bb= round(aa/1*100,2)
        else:
            bb= aa/avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]


    #     if math.isnan(bb):
    #         bb=0
    #     else:
    #         bb=bb            
    #     cc= round(bb*100,2)
        Average_FEEDBACK_Rating_change.append('-1')
        Average_feedback_PERCENTAGE.append(bb)


    elif avg_ratings_last_week['avg_ratings_lastweek'].iloc[0] == avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]:
        aa=avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]-avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        bb= aa/avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]
    #     if math.isnan(bb):
    #         bb=0
    #     else:
    #         bb=bb            
    #     cc= round(bb*100,2)
        Average_FEEDBACK_Rating_change.append('0')
        Average_feedback_PERCENTAGE.append(bb)

    else:
        aa=avg_ratings_last_week['avg_ratings_lastweek'].iloc[0]-avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]
        if avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]==0:
            bb= round(aa/1*100,2)
        else:
            bb= aa/avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].iloc[0]


    #     if math.isnan(bb):
    #         bb=0
    #     else:
    #         bb=bb            
    #     cc= round(bb*100,2)

        Average_FEEDBACK_Rating_change.append('1')
        Average_feedback_PERCENTAGE.append(bb)



    data_final=pd.DataFrame({'TEACHER_FEEDBACK_RATING_LAST_WEEK':comments_per_feedback_teacher['rating'].tolist(),
                             'TEACHER_FEEDBACK_RATING_BEFORE_LAST_WEEK':comments_per_feedback_before_last_week_teachers['rating'].tolist(),

    'PARENT_FEEDBACK_RATING_LAST_WEEK':comments_per_feedback_parents['rating'].tolist(),
    'PARENT_FEEDBACK_RATING_BEFORE_LAST_WEEK':comments_per_feedback_before_last_week_parents['rating'].tolist(),

     'avg_ratings_before_lastweek':avg_ratings_beforee_last_week['avg_ratings_before_lastweek'].tolist(),
     'Average_Rating_lastweek':avg_ratings_last_week['avg_ratings_lastweek'].tolist(),

      'TEACHER_Comment_per_feedbackchange':TEACHER_Comment_per_feedbackchange,
       'teacher_PERCENTAGE_change':teacher_PERCENTAGE_change,                      
      'PARENT_Comment_per_feedbackchange':PARENT_Comment_per_feedbackchange,
       'parent_PERCENTAGE_change':parent_PERCENTAGE_change,                      
      'Average_FEEDBACK_Rating_change':Average_FEEDBACK_Rating_change,
       'Average_feedback_PERCENTAGE':Average_feedback_PERCENTAGE                   
                                })   


    temp={}
    for j in range(len(data_final.columns)):
        key = data_final.columns[j]
        value = [str(data_final[data_final.columns[j]].iloc[0])]
        temp.update({key:value})
        #     print(temp)
    return json.dumps(temp)


@app.route('/active_user_dild')
def active_userss_s():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass

    mydatetime=datetime.datetime.utcnow()

    today_min=datetime.datetime.combine(mydatetime,datetime.time.min)
    # +timedelta(hours=4)
    today_max=datetime.datetime.combine(mydatetime, datetime.time.max)
    # +timedelta(hours=4)

    collection= db.audio_track_master
    df_playback= DataFrame(list(collection.aggregate([{"$match":{
    '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'MODIFIED_DATE': {'$gte':datetime.datetime.utcnow()-datetime.timedelta(minutes=5)}}
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'practice':{'$sum':1}}}
    ])))

    if df_playback.empty:
        data= {'active_users':str(0),'web_users':str(0),'mobile_users':str(0),'lms_users':str(0)}
#         temp={"data":data.values.tolist()}
        temp={"data":[data]}
    else: 
        list_of_users=df_playback['_id'].tolist()
        active_users=str(len(df_playback))

        collection2= db.user_master
        df_web=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#             {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}, 
                    {'DEVICE_USED':{'$regex':'webApp', '$options':'i'}},
        {'_id':{'$in':list_of_users}}
               ]}},
        {'$group':{'_id':'$_id', 'device':{'$first':'$DEVICE_USED'}}}])))

        web_users=len(df_web)



        df_home=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}, 
                {'_id':{'$in':list_of_users}}
        ]}},
        {'$group':{'_id':'$_id'}}])))


        df_classroom=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}, 
        {'_id':{'$nin':db.schoology_master.distinct("USER_ID._id")}},
        {'_id':{'$nin':db.clever_master.distinct("USER_ID._id")}},
        {'DEVICE_USED':{'$not':{'$regex':'webapp', '$options':'i'}}} , 
        {'DEVICE_USED':{'$not':{'$regex':'clever', '$options':'i'}}},
                {'DEVICE_USED':{'$not':{'$regex':'schoology', '$options':'i'}}},
        {'_id':{'$in':list_of_users}}]}},
        {'$group':{'_id':'$_id', 'device':{'$first':'$DEVICE_USED'}}}])))


        mobile=pd.concat([df_home,df_classroom]).reset_index(drop=True)
        mobile_users=len(mobile)

        df_clever=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
                    {'_id':{'$nin':db.schoology_master.distinct('USER_ID._id')}},
                    {'_id':{'$in':db.clever_master.distinct('USER_ID._id')}},
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'_id':{'$in':list_of_users}},
                  {'DEVICE_USED':{'$regex':'clever', '$options':'i'}},
        ]}},

        {'$group':{'_id':'$_id'}}])))

        clever_users=len(df_clever)

        df_schoology=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
                    {'_id':{'$in':db.schoology_master.distinct('USER_ID._id')}},
                    {'_id':{'$nin':db.clever_master.distinct('USER_ID._id')}},
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'_id':{'$in':list_of_users}},

                {'DEVICE_USED':{'$regex':'schoology', '$options':'i'}}
        ]}},
        {'$group':{'_id':'$_id'}}])))


        schoology_users=len(df_schoology)

        lms=pd.concat([df_clever,df_schoology]).reset_index(drop=True)
        lms_users=len(lms)


        data1= {'active_users':str(active_users),'web_users':str(web_users),'mobile_users':str(mobile_users),'lms_users':str(lms_users)}
        temp={'data':[data1]} 
    return json.dumps(temp)





@app.route('/Playback_card_dild')
def day_practice_card():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass
    collection1= db.audio_track_master
    mydatetime=datetime.datetime.utcnow()
    #     -timedelta(hours=24)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)
    print(start_15day)
    print(startend)

    qr1=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte': yester, '$lt':tod
    }},
    ]}},

    {'$group':{'_id':'null', 

    'parents_playback_24hr': {'$sum':{'$cond':[{'$eq':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_24hr': {'$sum':{'$cond':[{'$ne':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_24hr': {'$sum':1}            
    }}]

    list1= list(collection1.aggregate(qr1))
    df_atm1= DataFrame(list1)
    df_atm1[['parents_playback_24hr', 'teachers_playback_24hr','total_playback_24hr']]




    qr2=[{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}}, 
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}}, {'USER_ID.schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'MODIFIED_DATE':{'$gte':start_15day
                , '$lte': startend
    }},
    ]}},

    {'$group':{'_id':'null', 

    'parents_playback_48hrs': {'$sum':{'$cond':[{'$eq':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_playback_48hrs': {'$sum':{'$cond':[{'$ne':['$USER_ID.ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_playback_48hrs': {'$sum':1}            
    }}]

    list2= list(collection1.aggregate(qr2))
    df_atm2= DataFrame(list2)
    df_atm2[['parents_playback_48hrs', 'teachers_playback_48hrs','total_playback_48hrs']]




    PARENTSCHANGE=[]
    PARENT_percentagechange=[]
    if df_atm2['parents_playback_48hrs'].iloc[0] > df_atm1['parents_playback_24hr'].iloc[0]:
        xx=df_atm2['parents_playback_48hrs'].iloc[0]-df_atm1['parents_playback_24hr'].iloc[0]
        if df_atm2['parents_playback_48hrs'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:
            yy=xx/df_atm2['parents_playback_48hrs'].iloc[0]

    #         if math.isnan(yy):
    #             yy=0
    #         else:
    #             yy=yy
    #         zz= round(yy*100,2)
        PARENTSCHANGE.append('-1')
        PARENT_percentagechange.append(yy)

    elif df_atm2['parents_playback_48hrs'].iloc[0] == df_atm1['parents_playback_24hr'].iloc[0]:
        xx=df_atm2['parents_playback_48hrs'].iloc[0]-df_atm1['parents_playback_24hr'].iloc[0]
        yy= xx/df_atm2['parents_playback_48hrs'].iloc[0]
        if math.isnan(yy):
            yy=0
        else:
            yy=yy
        zz= round(yy*100,2)
        PARENTSCHANGE.append('0')
        PARENT_percentagechange.append(zz)

    else:
        xx=df_atm1['parents_playback_24hr'].iloc[0]-df_atm2['parents_playback_48hrs'].iloc[0]
        if df_atm2['parents_playback_48hrs'].iloc[0]==0:
            yy= round(xx/1*100,2)
        else:
            yy= xx/df_atm2['parents_playback_48hrs'].iloc[0]

    #         if math.isnan(yy):
    #             yy=0
    #         else:
    #             yy=yy
    #         zz= round(yy*100,2)
        PARENTSCHANGE.append('1')
        PARENT_percentagechange.append(yy)



    TEACHERSCHANGE=[]
    TEACHER_percentagechange=[]
    if df_atm2['teachers_playback_48hrs'].iloc[0] > df_atm1['teachers_playback_24hr'].iloc[0]:
        aa=df_atm2['teachers_playback_48hrs'].iloc[0]-df_atm1['teachers_playback_24hr'].iloc[0]
        if df_atm2['teachers_playback_48hrs'].iloc[0]==0:
            bb=round(aa/1*100,2)
        else:            
            bb= aa/df_atm2['teachers_playback_48hrs'].iloc[0]   
    #         if math.isnan(bb):
    #             bb=0
    #         else:
    #             bb=bb
    #         cc= round(bb*100,2)
        TEACHERSCHANGE.append('-1')
        TEACHER_percentagechange.append(bb)

    elif df_atm2['teachers_playback_48hrs'].iloc[0] == df_atm1['teachers_playback_24hr'].iloc[0]:
        aa=df_atm2['teachers_playback_48hrs'].iloc[0]-df_atm1['teachers_playback_24hr'].iloc[0]
        bb= aa/df_atm2['teachers_playback_48hrs'].iloc[0]
        if math.isnan(bb):
            bb=0
        else:
            bb=bb
        cc= round(bb*100,2)
        TEACHERSCHANGE.append('0')
        TEACHER_percentagechange.append(cc)


    else:
        aa=df_atm1['teachers_playback_24hr'].iloc[0]-df_atm2['teachers_playback_48hrs'].iloc[0]
        if df_atm2['teachers_playback_48hrs'].iloc[0]==0:
            bb= round(aa/1*100,2)
        else:

            bb= aa/df_atm2['teachers_playback_48hrs'].iloc[0]
    #         if math.isnan(bb):
    #             bb=0
    #         else:
    #             bb=bb
    #         cc= round(bb*100,2)
        TEACHERSCHANGE.append('1')
        TEACHER_percentagechange.append(bb)


    TOTALCHANGE=[]
    TOTAL_percentagechange=[]
    if df_atm2['total_playback_48hrs'].iloc[0] > df_atm1['total_playback_24hr'].iloc[0]:
        pp=df_atm2['total_playback_48hrs'].iloc[0]-df_atm1['total_playback_24hr'].iloc[0]
        if df_atm2['total_playback_48hrs'].iloc[0]==0:
            qq= round(pp/1*100,2)
        else:

            qq= pp/df_atm2['total_playback_48hrs'].iloc[0]
    #         if math.isnan(qq):
    #             qq=0
    #         else:
    #             qq=qq
    #         rr= round(qq*100,2)
        TOTALCHANGE.append('-1')
        TOTAL_percentagechange.append(qq)


    elif df_atm2['total_playback_48hrs'].iloc[0] == df_atm1['total_playback_24hr'].iloc[0]:
        pp=df_atm2['total_playback_48hrs'].iloc[0]-df_atm1['total_playback_24hr'].iloc[0]
        qq= pp/df_atm2['total_playback_48hrs'].iloc[0]
        if math.isnan(qq):
            qq=0
        else:
            qq=qq
        rr= round(qq*100,2)
        TOTALCHANGE.append('0')
        TOTAL_percentagechange.append(rr)


    else: 
        pp=df_atm1['total_playback_24hr'].iloc[0]-df_atm2['total_playback_48hrs'].iloc[0]
        if df_atm2['total_playback_48hrs'].iloc[0]==0:
            qq= round(pp/1*100,2)
        else:

            qq= pp/df_atm2['total_playback_48hrs'].iloc[0]
    #         if math.isnan(qq):
    #             qq=0
    #         else:
    #             qq=qq
    #         rr= round(qq*100,2)
        TOTALCHANGE.append('1')
        TOTAL_percentagechange.append(qq)


    parents_playback_24hr=df_atm1['parents_playback_24hr'].tolist()
    teachers_playback_24hr=df_atm1['teachers_playback_24hr'].tolist()
    total_playback_24hr=df_atm1['total_playback_24hr'].tolist()
    parents_playback_48hrs =df_atm2['parents_playback_48hrs'].tolist()
    teachers_playback_48hrs= df_atm2['teachers_playback_48hrs'].tolist()
    total_playback_48hrs= df_atm2['total_playback_48hrs'].tolist()


    temp={'parents_playback_24hr':parents_playback_24hr, 'PARENTSCHANGE':PARENTSCHANGE, 'PARENT_percentagechange':PARENT_percentagechange,
          'teachers_playback_24hr':teachers_playback_24hr, 'TEACHERSCHANGE':TEACHERSCHANGE, 'TEACHER_percentagechange':TEACHER_percentagechange,
          'total_playback_24hr':total_playback_24hr, 'TOTALCHANGE':TOTALCHANGE, 'TOTAL_percentagechange':TOTAL_percentagechange,
          'parents_playback_48hrs':parents_playback_48hrs, 'teachers_playback_48hrs':teachers_playback_48hrs,
          'total_playback_48hrs':total_playback_48hrs
         }

    return json.dumps(temp)


@app.route('/Signup_card_dild')
def day_signup_card():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection1= db.user_master

    mydatetime=datetime.datetime.utcnow()
    #     -timedelta(hours=24)
    yester= datetime.datetime.combine(mydatetime,datetime.time.min)
    #     - timedelta(days=1)
    tod= datetime.datetime.combine(mydatetime,datetime.time.max)
    start_15day=yester- timedelta(days=7)
    startend= tod- timedelta(days=7)

    qr1=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gt':yester , '$lte':tod}}
    ]}},
    {'$group':{'_id':'null', 
    'parents_signup_last_week': {'$sum':{'$cond':[{'$eq':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_signup_last_week': {'$sum':{'$cond':[{'$ne':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_signup_last_week': {'$sum':1}            
    }}]
    list1= list(collection1.aggregate(qr1))
    df_atm= DataFrame(list1)
    df_atm1=df_atm[['parents_signup_last_week', 'teachers_signup_last_week','total_signup_last_week']]
    qr2=[{"$match":{
    '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
    {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
    {'IS_BLOCKED':{"$ne":'Y'}}, 
    {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
    {'CREATED_DATE':{'$gte':start_15day
                , '$lt': startend}}
    ]}},
    {'$group':{'_id':'null', 
    'parents_signup_last_to_lastweek': {'$sum':{'$cond':[{'$eq':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'teachers_signup_last_to_lastweek': {'$sum':{'$cond':[{'$ne':['$ROLE_ID._id', ObjectId("5f155b8a3b6800007900da2b")]}, 1,0]}},
    'total_signup_last_to_lastweek': {'$sum':1}            
    }}]
    list2= list(collection1.aggregate(qr2))
    df_atm= DataFrame(list2)

    df_atm2=df_atm[['parents_signup_last_to_lastweek', 'teachers_signup_last_to_lastweek','total_signup_last_to_lastweek']]


    parentschange=[]
    parents_Percentage_Change=[]
    if df_atm2['parents_signup_last_to_lastweek'].iloc[0] > df_atm1['parents_signup_last_week'].iloc[0]:
        xx=df_atm2['parents_signup_last_to_lastweek'].iloc[0]-df_atm1['parents_signup_last_week'].iloc[0]
        if df_atm2['parents_signup_last_to_lastweek'].iloc[0]==0:
            yy= round(xx/1*100,2)
        else:        
            yy= xx/df_atm2['parents_signup_last_to_lastweek'].iloc[0]
    #         zz= round(yy*100,2)
        parentschange.append('-1')
        parents_Percentage_Change.append(yy)

    elif df_atm2['parents_signup_last_to_lastweek'].iloc[0] == df_atm1['parents_signup_last_week'].iloc[0]:
        xx=df_atm2['parents_signup_last_to_lastweek'].iloc[0]-df_atm1['parents_signup_last_week'].iloc[0]
        if df_atm2['parents_signup_last_to_lastweek'].iloc[0] & df_atm1['parents_signup_last_week'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:

            yy= xx/df_atm2['parents_signup_last_to_lastweek'].iloc[0]

    #         zz= round(yy*100,2)
        parentschange.append('0')
        parents_Percentage_Change.append(yy)

    else:
        xx=df_atm1['parents_signup_last_week'].iloc[0]-df_atm2['parents_signup_last_to_lastweek'].iloc[0]
        if df_atm2['parents_signup_last_to_lastweek'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:

            yy= xx/df_atm2['parents_signup_last_to_lastweek'].iloc[0]
    #         zz= round(yy*100,2)
        parentschange.append('1')
        parents_Percentage_Change.append(yy)


    teacherschange=[]
    Teacher_percentage_change=[]
    if df_atm2['teachers_signup_last_to_lastweek'].iloc[0] > df_atm1['teachers_signup_last_week'].iloc[0]:
        xx=df_atm2['teachers_signup_last_to_lastweek'].iloc[0]-df_atm1['teachers_signup_last_week'].iloc[0]
        yy= xx/df_atm2['teachers_signup_last_to_lastweek'].iloc[0]
        zz= round(yy*100,2)
        teacherschange.append('-1')
        Teacher_percentage_change.append(zz)

    elif df_atm2['teachers_signup_last_to_lastweek'].iloc[0] == df_atm1['teachers_signup_last_week'].iloc[0]:
        xx=df_atm2['teachers_signup_last_to_lastweek'].iloc[0]-df_atm1['teachers_signup_last_week'].iloc[0]
        if df_atm2['teachers_signup_last_to_lastweek'].iloc[0] &df_atm1['teachers_signup_last_week'].iloc[0]==0:
            yy= round(xx/1*100,2)
        else:
            yy= xx/df_atm2['teachers_signup_last_to_lastweek'].iloc[0]
    #         zz= round(yy*100,2)

        teacherschange.append('0')
        Teacher_percentage_change.append(yy)

    else:
        xx=df_atm1['teachers_signup_last_week'].iloc[0]-df_atm2['teachers_signup_last_to_lastweek'].iloc[0]
        if df_atm2['teachers_signup_last_to_lastweek'].iloc[0]==0:
            yy= round(xx/1*100,2)
        else:
            yy= xx/df_atm2['teachers_signup_last_to_lastweek'].iloc[0]

    #         zz= round(yy*100,2)
        teacherschange.append('1')
        Teacher_percentage_change.append(yy)


    totalchange=[]
    Total_percentage_change=[]
    if df_atm2['total_signup_last_to_lastweek'].iloc[0] > df_atm1['total_signup_last_week'].iloc[0]:
        xx=df_atm2['total_signup_last_to_lastweek'].iloc[0]-df_atm1['total_signup_last_week'].iloc[0]

        if df_atm2['total_signup_last_to_lastweek'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:

            yy= xx/df_atm2['total_signup_last_to_lastweek'].iloc[0]
    #         zz= round(yy*100,2)
        totalchange.append('-1')
        Total_percentage_change.append(yy)

    elif df_atm2['total_signup_last_to_lastweek'].iloc[0] == df_atm1['total_signup_last_week'].iloc[0]:        
        xx=df_atm2['total_signup_last_to_lastweek'].iloc[0]-df_atm1['total_signup_last_week'].iloc[0]
        if df_atm2['total_signup_last_to_lastweek'].iloc[0] & df_atm1['total_signup_last_week'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:
            yy= xx/df_atm2['total_signup_last_to_lastweek'].iloc[0]
    #         zz= round(yy*100,2)
        totalchange.append('0')
        Total_percentage_change.append(yy)
    else:
        xx=df_atm1['total_signup_last_week'].iloc[0]-df_atm2['total_signup_last_to_lastweek'].iloc[0]
        if df_atm2['total_signup_last_to_lastweek'].iloc[0]==0:
            yy=round(xx/1*100,2)
        else:
            yy= xx/df_atm2['total_signup_last_to_lastweek'].iloc[0]
    #         zz= round(yy*100,2)
        totalchange.append('1')
        Total_percentage_change.append(yy)


    data=pd.DataFrame({'parents_signup_yesterday':df_atm1['parents_signup_last_week'].tolist(),
                       'teachers_signup_yesterday':df_atm1['teachers_signup_last_week'].tolist(),
    'total_signup_yesterday':df_atm1['total_signup_last_week'].tolist(),
                       'parentschanged':parentschange, 'parents_Percentage_Change':parents_Percentage_Change,
                       'teacherschanged':teacherschange, 'Teacher_percentage_change':Teacher_percentage_change,
          'totalchanged':totalchange, 'Total_percentage_change':Total_percentage_change,
               'parents_signup_lastweek':df_atm2['parents_signup_last_to_lastweek'].tolist(),
                     'teachers_signup_lastweek':  df_atm2['teachers_signup_last_to_lastweek'].tolist(),
                'total_signup_lastweek':       df_atm2['total_signup_last_to_lastweek'].tolist()

                      })  
    temp2={}

    for j in range(len(data.columns)):
        key= data.columns[j]
        value=[str(data[data.columns[j]].iloc[0])]
        temp2.update({key:value})
        
    return json.dumps(temp2)

@app.route('/totalactive_users_dild_')
def active_users_todayy():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass

    mydatetime=datetime.datetime.utcnow()

    today_min=datetime.datetime.combine(mydatetime,datetime.time.min)
    # +timedelta(hours=4)
    today_max=datetime.datetime.combine(mydatetime, datetime.time.max)
    # +timedelta(hours=4)

    collection= db.audio_track_master
    df_playback= DataFrame(list(collection.aggregate([{"$match":{
    '$and':[{'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'MODIFIED_DATE': {'$gte':today_min, '$lte':today_max}}
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'users':{'$addToSet':'$USER_ID._id'}}},
    {'$project':{'_id':1, 'users':{'$size':'$users'}}}
    ])))

    if df_playback.empty:
        data= {'active_users':str(0),'web_users':str(0),'mobile_users':str(0),'lms_users':str(0)}
#         temp={"data":data.values.tolist()}
        temp={"data":[data]}

    else: 
        list_of_users=df_playback['_id'].tolist()
        active_users=str(len(df_playback))

        collection2= db.user_master
        df_web=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
#         {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}, 
                {'DEVICE_USED':{'$regex':'webapp', '$options':'i'}},
        {'_id':{'$in':list_of_users}}
               ]}},
        {'$group':{'_id':'$_id', 'device':{'$first':'$DEVICE_USED'}}}])))

        web_users=len(df_web)

        df_home=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}, 
                {'_id':{'$in':list_of_users}}
        ]}},
        {'$group':{'_id':'$_id'}}])))


        df_classroom=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}, 
        {'_id':{'$nin':db.schoology_master.distinct("USER_ID._id")}},
        {'_id':{'$nin':db.clever_master.distinct("USER_ID._id")}},
        {'DEVICE_USED':{'$not':{'$regex':'webapp', '$options':'i'}}} , 
        {'DEVICE_USED':{'$not':{'$regex':'clever', '$options':'i'}}},
                {'DEVICE_USED':{'$not':{'$regex':'schoology', '$options':'i'}}},
        {'_id':{'$in':list_of_users}}]}},
        {'$group':{'_id':'$_id', 'device':{'$first':'$DEVICE_USED'}}}])))


        mobile=pd.concat([df_home,df_classroom]).reset_index(drop=True)
        mobile_users=len(mobile)

        df_clever=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
                    {'_id':{'$nin':db.schoology_master.distinct('USER_ID._id')}},
                    {'_id':{'$in':db.clever_master.distinct('USER_ID._id')}},
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'_id':{'$in':list_of_users}},
                  {'DEVICE_USED':{'$regex':'clever', '$options':'i'}},
        ]}},

        {'$group':{'_id':'$_id'}}])))

        clever_users=len(df_clever)

        df_schoology=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
                    {'_id':{'$in':db.schoology_master.distinct('USER_ID._id')}},
                    {'_id':{'$nin':db.clever_master.distinct('USER_ID._id')}},
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'_id':{'$in':list_of_users}},

                {'DEVICE_USED':{'$regex':'schoology', '$options':'i'}}
        ]}},
        {'$group':{'_id':'$_id'}}])))


        schoology_users=len(df_schoology)

        lms=pd.concat([df_clever,df_schoology]).reset_index(drop=True)
        lms_users=len(lms)


        data1= {'active_users':str(active_users),'web_users':str(web_users),'mobile_users':str(mobile_users),'lms_users':str(lms_users)}
        temp={'data':[data1]} 
    return json.dumps(temp)




@app.route('/active_users_on_day_dild')
def active_userss_day():
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username,password))
    db=client.compass

    mydatetime=datetime.datetime.utcnow()

    today_min=datetime.datetime.combine(mydatetime,datetime.time.min)
    # +timedelta(hours=4)
    today_max=datetime.datetime.combine(mydatetime, datetime.time.max)
    # +timedelta(hours=4)

    collection= db.audio_track_master
    df_playback= DataFrame(list(collection.aggregate([{"$match":{
    '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
    {'USER_ID.IS_DISABLED':{"$ne":'Y'}},{'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
    {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}},
    {'MODIFIED_DATE': {'$gte':today_min, '$lt':today_max}}
    ]}},
    {'$group':{'_id':'$USER_ID._id', 'practice':{'$sum':1}}}
    ])))

    if df_playback.empty:
        data= {'active_users':str(0),'web_users':str(0),'mobile_users':str(0),'lms_users':str(0)}
        temp={"data":data.values.tolist()}
    else: 
        list_of_users=df_playback['_id'].tolist()
        active_users=str(len(df_playback))

        collection2= db.user_master
        df_web=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2a")}}, {'DEVICE_USED':{'$regex':'webapp', '$options':'i'}},
        {'_id':{'$in':list_of_users}}
               ]}},
        {'$group':{'_id':'$_id'}}])))

        web_users=len(df_web)


        df_home=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}, 
                {'_id':{'$in':list_of_users}}
        ]}},
        {'$group':{'_id':'$_id'}}])))


        df_classroom=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2a")}}, 
        {'_id':{'$nin':db.schoology_master.distinct("USER_ID._id")}},
        {'_id':{'$nin':db.clever_master.distinct("USER_ID._id")}},
        {'DEVICE_USED':{'$not':{'$regex':'webapp', '$options':'i'}}} , 
        {'DEVICE_USED':{'$not':{'$regex':'clever', '$options':'i'}}},
                {'DEVICE_USED':{'$not':{'$regex':'schoology', '$options':'i'}}},
        {'_id':{'$in':list_of_users}}]}},
        {'$group':{'_id':'$_id'}}])))


        mobile=pd.concat([df_home,df_classroom]).reset_index(drop=True)
        mobile_users=len(mobile)

        df_lms=DataFrame(list(collection2.aggregate([{"$match":{
        '$and':[{'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},{'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_NAME':{'$not':{'$regex':'1gen', '$options':'i'}}},
        {'INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {'IS_BLOCKED':{"$ne":'Y'}}, 
        {'IS_DISABLED':{"$ne":'Y'}}, {'schoolId.NAME':{'$not':{'$regex':'test', '$options':'i'}}},
        {'_id':{'$in':list_of_users}}
        ]}},
        {"$match":{'$or':[{'DEVICE_USED':{'$regex':'clever', '$options':'i'}},{'DEVICE_USED':{'$regex':'schoology', '$options':'i'}}
        ]}},
        {'$group':{'_id':'$_id'}}])))

        lms_users=len(df_lms)

        data1= {'active_users':str(active_users),'web_users':str(web_users),'mobile_users':str(mobile_users),'lms_users':str(lms_users)}
    temp={'data':[data1]} 
    return json.dumps(temp)

@app.route('/Practice_per_minute_dild/<charttype>')
def practice_per_minutee_(charttype):
    mongo_uri = "mongodb://admin:" + urllib.parse.quote('F5tMazRj47cYqm33e') + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection = db.audio_track_master_all
    collection2 = db.audio_track_master

    mydatetime=datetime.datetime.utcnow()
    today_min=datetime.datetime.combine(mydatetime,datetime.time.min)
    today_max=datetime.datetime.combine(mydatetime, datetime.time.max)

    start_today=today_min.strftime('%Y-%m-%d %H:%M:%S')
    end_today=today_max.strftime('%Y-%m-%d %H:%M:%S')

    charttype=str(charttype).title()

    if charttype=='Practice':
        threshold=.5


        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        ######################  USER PRACTICE 2019-2020(LSY) ############################################
        df1 = DataFrame(list(collection2.aggregate([
            {"$match":
            {"$and" :[
                {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{'$ne':""}},

                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                    {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"MODIFIED_DATE":{"$gte": today_min
                                             ,"$lte" : today_max
                                    }},
                {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},


                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
        practice_cond_dictonary_list[0],
                    practice_cond_dictonary_list[1],
                     threshcond[0],

            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Users_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                        'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))

        df2 = DataFrame(list(collection2.aggregate([{"$match":
            {"$and" :[
                {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{'$ne':""}},

                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                    {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"MODIFIED_DATE":{"$gte": today_min
                                             ,"$lte" : today_max
                                    }},
                {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},


                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}},                
            ]}},
                                                practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],

                {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                                    'month':{'$month':'$MODIFIED_DATE'}},
                            'date':{'$first':'$MODIFIED_DATE'}, 
                            'Parents_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                                'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))

        schoology = DataFrame(list(collection2.aggregate([
                    {"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                             { "USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                           {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": today_min
                                                 ,"$lte" : today_max
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},

        practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],

                    {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                                    'month':{'$month':'$MODIFIED_DATE'}},
                            'date':{'$first':'$MODIFIED_DATE'}, 
                            'Parents_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                                'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))
            #     print(schoology,"schoology")
                                      ########clever################################

        clever = DataFrame(list(collection2.aggregate([{"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                             { "USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.schoology_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": today_min
                                                 ,"$lte" : today_min
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},
        practice_cond_dictonary_list[0],
                    practice_cond_dictonary_list[1],
                     threshcond[0],
            {'$group':{'_id':{'day':{'$dayOfMonth':'$MODIFIED_DATE'}, 
                            'month':{'$month':'$MODIFIED_DATE'}},
                    'date':{'$first':'$MODIFIED_DATE'}, 
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))

        df1['Practice_date']=pd.to_datetime(df1['Practice_date'], format="%Y-%m-%d %H:%M")
        df5=df1.sort_values(by='Practice_date')
        time_range=[]
        # start = '2021-10-12 00:00:00'
        # end = "2021-10-12 23:59:59"
        delta = datetime.timedelta(seconds=60)
        start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
        end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
        t = start
        while t <= end :
            x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
            t += delta
            time_range.append(x)

        df9 = pd.DataFrame(time_range,columns = ["Practice_date"])
        df9['Practice_date']=pd.to_datetime(df9['Practice_date'])

        df10=pd.merge(df5,df9, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

        df10['Practice_date']=df10['Practice_date'].astype(np.int64)/int(1e6)

        csy_users_list=df10[['Practice_date','Users_Practice_CSY']].values.astype(int).tolist()   

        # Clever

        if 'Practice_date' in list(clever.columns):
            clever['Practice_date']=pd.to_datetime(clever['Practice_date'])
            clever_sort=clever.sort_values(by='Practice_date')
        else:
            time_range=[]
        #     start = '2021-10-12 00:00:00'
        #     end = "2021-10-12 23:59:59"
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)
            clever=pd.DataFrame(time_range, columns=['Practice_date'])
            clever['Parents_Practice_CSY'] = 0
            clever_sort=clever.sort_values(by='Practice_date')

        # Schoology

        if 'Practice_date' in list(schoology.columns):
            schoology['Practice_date']=pd.to_datetime(schoology['Practice_date'], format='%Y-%m-%d %H:%M')
            schoology_sort=schoology.sort_values(by='Practice_date')
        else:
            time_range=[]
        #     start = '2021-10-12 00:00:00'
        #     end = "2021-10-12 23:59:59"
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)
            schoology=pd.DataFrame(time_range, columns=['Practice_date'])
            schoology['Parents_Practice_CSY'] = 0
            schoology_sort=schoology.sort_values(by='Practice_date')

        # Parents 
        df2['Practice_date'] = pd.to_datetime(df2['Practice_date'])
        df6=df2.sort_values(by='Practice_date')

        time_range=[]
        # start = '2021-10-12 00:00:00'
        # end = "2021-10-12 23:59:59"
        delta = datetime.timedelta(seconds=60)
        start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
        end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
        t = start
        while t <= end :
            x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
            t += delta
            time_range.append(x)

        df_parents=pd.DataFrame(time_range, columns=['Practice_date'])
        # # df_parents['value']=0
        parents_datetime=pd.to_datetime(df_parents['Practice_date'])

        parents=pd.merge(df6,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')
        parents['Practice_date']=parents['Practice_date'].astype(np.int64)/int(1e6)
        parents_final=parents[['Practice_date','Parents_Practice_CSY']].values.astype(int).tolist()


        # cleverr
        clever['Practice_date']=pd.to_datetime(clever['Practice_date'])
        clever_csy1=pd.merge(clever,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')


        clever_csy1['Practice_date']=clever_csy1['Practice_date'].astype(np.int64)/int(1e6)
        clever_parents_users=clever_csy1[["Practice_date","Parents_Practice_CSY"]].values.astype(int).tolist()


        # schoologyyy
        schoology_sort['Practice_date']=pd.to_datetime(schoology_sort['Practice_date'])
        schoology_csy1= pd.merge(schoology_sort,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')


        schoology_csy1['Practice_date']=schoology_csy1['Practice_date'].astype(np.int64)/int(1e6)
        schoology_parents_users=schoology_csy1[["Practice_date","Parents_Practice_CSY"]].values.astype(int).tolist()


        temp={'data':{'teachers_practices':csy_users_list, 'Parents_practices':parents_final, 'Clever':clever_parents_users, 'schoology':schoology_parents_users}}

        return json.dumps(temp)


    else:
        ######################  USER PRACTICE 2019-2020(LSY) ############################################
        df1 = DataFrame(list(collection2.aggregate([{
                '$match':{'$and':[{'USER_ID.IS_DISABLED':{'$ne':'Y'}}, {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {'USER_ID.EMAIL_ID':{'$ne':""}},{"MODIFIED_DATE":{"$gte": today_min ,"$lte" : today_max}},
                        {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}}]}},

                {"$match":{"$and" :[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},

                {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},'Users_Practice_CSY':{'$sum':1}}},
                {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                            'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
                {"$sort":{'Practice_date':1}}])))

        ##################### PARENTS ##########################################
        df2 = DataFrame(list(collection2.aggregate([{
                '$match':{'$and':[{'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                       {'USER_ID.EMAIL_ID':{'$ne':""}},
                          {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                           {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}},                  
                        {"MODIFIED_DATE":{"$gte": today_min ,"$lte" : today_max}},                    
                        {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}}
                                  ]}},
                {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  'Parents_Practice_CSY':{'$sum':1}}},
                {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
                            'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                {"$sort":{'Practice_date':1}}])))

        ########schoology################################
        schoology = DataFrame(list(collection2.aggregate([{
                '$match':{'$and':[{'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                        {'USER_ID.EMAIL_ID':{'$ne':""}},
                          {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                       {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                       {"MODIFIED_DATE":{"$gte": today_min ,"$lte" : today_max}},
        #                     'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}
                                 ]}},
                {"$match":
                {"$and" :[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},

             {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  'Parents_Practice_CSY':{'$sum':1}}},
                {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
                            'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                {"$sort":{'Practice_date':1}}])))

        ########clever################################
        clever = DataFrame(list(collection2.aggregate([{
                '$match':{'$and':[{'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                        {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                        {'USER_ID.EMAIL_ID':{'$ne':""}},
                          {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                       {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                       {"MODIFIED_DATE":{"$gte": today_min ,"$lte" : today_max}},

        #                     'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}
                                   ]}},
                {"$match":
                {"$and" :[{'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                        {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                        {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
                 {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  'Parents_Practice_CSY':{'$sum':1}}},
                {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
                            'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                {"$sort":{'Practice_date':1}}])))

        df1['Practice_date']=pd.to_datetime(df1['Practice_date'], format="%Y-%m-%d %H:%M")

        df5=df1.sort_values(by='Practice_date')
        time_range=[]
        # start = '2021-10-12 00:00:00'
        # end = "2021-10-12 23:59:59"
        delta = datetime.timedelta(seconds=60)
        start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
        end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
        t = start
        while t <= end :
            x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
            t += delta
            time_range.append(x)

        df9 = pd.DataFrame(time_range,columns = ["Practice_date"])
        df9['Practice_date']=pd.to_datetime(df9['Practice_date'])

        df10=pd.merge(df5,df9, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

        df10['Practice_date']=df10['Practice_date'].astype(np.int64)/int(1e6)

        csy_users_list=df10[['Practice_date','Users_Practice_CSY']].values.astype(int).tolist()   

        # Clever

        if 'Practice_date' in list(clever.columns):
            clever['Practice_date']=pd.to_datetime(clever['Practice_date'])
            clever_sort=clever.sort_values(by='Practice_date')
        else:
            time_range=[]
        #     start = '2021-10-12 00:00:00'
        #     end = "2021-10-12 23:59:59"
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)
            clever=pd.DataFrame(time_range, columns=['Practice_date'])
            clever['Parents_Practice_CSY'] = 0
            clever_sort=clever.sort_values(by='Practice_date')

        # Schoology

        if 'Practice_date' in list(schoology.columns):
            schoology['Practice_date']=pd.to_datetime(schoology['Practice_date'])
            schoology_sort=schoology.sort_values(by='Practice_date')
        else:
            time_range=[]
        #     start = '2021-10-12 00:00:00'
        #     end = "2021-10-12 23:59:59"
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)
            schoology=pd.DataFrame(time_range, columns=['Practice_date'])
            schoology['Parents_Practice_CSY'] = 0
            schoology_sort=schoology.sort_values(by='Practice_date')

        # Parents 
        df2['Practice_date'] = pd.to_datetime(df2['Practice_date'])
        df6=df2.sort_values(by='Practice_date')

        time_range=[]
        # start = '2021-10-12 00:00:00'
        # end = "2021-10-12 23:59:59"
        delta = datetime.timedelta(seconds=60)
        start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
        end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
        t = start
        while t <= end :
            x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
            t += delta
            time_range.append(x)

        df_parents=pd.DataFrame(time_range, columns=['Practice_date'])
        # # df_parents['value']=0
        parents_datetime=pd.to_datetime(df_parents['Practice_date'])

        parents=pd.merge(df6,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')
        parents['Practice_date']=parents['Practice_date'].astype(np.int64)/int(1e6)
        parents_final=parents[['Practice_date','Parents_Practice_CSY']].values.astype(int).tolist()


        # cleverr
        clever['Practice_date']=pd.to_datetime(clever['Practice_date'])
        clever_csy1=pd.merge(clever,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')


        clever_csy1['Practice_date']=clever_csy1['Practice_date'].astype(np.int64)/int(1e6)
        clever_parents_users=clever_csy1[["Practice_date","Parents_Practice_CSY"]].values.astype(int).tolist()


        # schoologyyy
        schoology_sort['Practice_date']=pd.to_datetime(schoology_sort['Practice_date'])
        schoology_csy1= pd.merge(schoology_sort,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')


        schoology_csy1['Practice_date']=schoology_csy1['Practice_date'].astype(np.int64)/int(1e6)
        schoology_parents_users=schoology_csy1[["Practice_date","Parents_Practice_CSY"]].values.astype(int).tolist()


        temp={'data':{'teachers_practices':csy_users_list, 'Parents_practices':parents_final, 'Clever':clever_parents_users, 'schoology':schoology_parents_users}}

        return json.dumps(temp)


@app.route('/Practice_per_minute_DAILD_updated/<charttype>')
def practice_per_minn_(charttype):
    mongo_uri = "mongodb://admin:" + urllib.parse.quote('F5tMazRj47cYqm33e') + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection2 = db.audio_track_master

    mydatetime=datetime.datetime.utcnow()
    today_min=datetime.datetime.combine(mydatetime,datetime.time.min)
    today_max=datetime.datetime.combine(mydatetime, datetime.time.max)

    start_today=today_min.strftime('%Y-%m-%d %H:%M:%S')
    end_today=today_max.strftime('%Y-%m-%d %H:%M:%S')

    charttype=str(charttype).title()

    if charttype=='Practice':
        threshold=.5


        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]
        
        ######################  USER PRACTICE 2019-2020(LSY) ############################################
        df1 = DataFrame(list(collection2.aggregate([
            {"$match":
            {"$and" :[
                {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{'$ne':""}},

                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                
                {"MODIFIED_DATE":{"$gte": today_min
                                             ,"$lte" : today_max
                                    }},
                {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},


                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
        practice_cond_dictonary_list[0],
                    practice_cond_dictonary_list[1],
                     threshcond[0],

            {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  
                    'Users_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                        'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))

        df2 = DataFrame(list(collection2.aggregate([{"$match":
            {"$and" :[
                {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{'$ne':""}},

                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                
                {"MODIFIED_DATE":{"$gte": today_min
                                             ,"$lte" : today_max
                                    }},
                {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},


                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}},                
            ]}},
                                                practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],

              {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  
                            'Parents_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                                'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))

        schoology = DataFrame(list(collection2.aggregate([
                    {"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                            { "USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                            { "USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                            {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": today_min
                                                 ,"$lte" : today_max
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},

        practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],

                  {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  
                            'Parents_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                                'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))
            #     print(schoology,"schoology")
                                      ########clever################################

        clever = DataFrame(list(collection2.aggregate([{"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                             { "USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.schoology_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.canvas_user_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": today_min
                                                 ,"$lte" : today_max
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},
        practice_cond_dictonary_list[0],
                    practice_cond_dictonary_list[1],
                     threshcond[0],
           {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
        
        
        
        canvas = DataFrame(list(collection2.aggregate([{"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                             { "USER_ID._id":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.schoology_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.clever_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": today_min
                                                 ,"$lte" : today_max
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},
        practice_cond_dictonary_list[0],
                    practice_cond_dictonary_list[1],
                     threshcond[0],
           {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))

        ########Ratingss################################
        collection4= db.audio_feedback
        ratings=DataFrame(list(collection4.aggregate([

        {"$match":
             {'$and': [
                    {"USER.IS_DISABLED":{"$ne":"Y"}},
                      {"USER.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                     {"USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},

                    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'RATING':{'$ne':0}},
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
              practice_cond_dictonary_list[0],
                    practice_cond_dictonary_list[1],
        #              threshcond[0],
           {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                                'date':{'$first':'$MODIFIED_DATE'},
                      'ratings':{'$sum':1}}},
                        {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
            'ratings':'$ratings'}}, 
                        {"$sort":{'Practice_date':1}}])))


        df1['Practice_date']=pd.to_datetime(df1['Practice_date'], format="%Y-%m-%d %H:%M")
        df1['Practice_date']=df1['Practice_date']-timedelta(hours=4)
        df5=df1.sort_values(by='Practice_date')
        time_range=[]
        # start = '2021-10-12 00:00:00'
        # end = "2021-10-12 23:59:59"
        delta = datetime.timedelta(seconds=60)
        start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
        end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
        t = start
        while t <= end :
            x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
            t += delta
            time_range.append(x)

        df9 = pd.DataFrame(time_range,columns = ["Practice_date"])
        df9['Practice_date']=pd.to_datetime(df9['Practice_date'])

        df10=pd.merge(df5,df9, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

        df10['Practice_date']=df10['Practice_date'].astype(np.int64)/int(1e6)

        csy_users_list=df10[['Practice_date','Users_Practice_CSY']].values.astype(int).tolist()   


        # ratings
        ratings['Practice_date']=pd.to_datetime(ratings['Practice_date'], format="%Y-%m-%d %H:%M")
        ratings['Practice_date']=ratings['Practice_date']-timedelta(hours=4)
        df5ratings=ratings.sort_values(by='Practice_date')
        time_range=[]
        # start = '2021-10-12 00:00:00'
        # end = "2021-10-12 23:59:59"
        delta = datetime.timedelta(seconds=60)
        start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
        end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
        t = start
        while t <= end :
            x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
            t += delta
            time_range.append(x)

        df9ratings = pd.DataFrame(time_range,columns = ["Practice_date"])
        df9ratings['Practice_date']=pd.to_datetime(df9ratings['Practice_date'])

        df_rating=pd.merge(df5ratings,df9ratings, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

        df_rating['Practice_date']=df_rating['Practice_date'].astype(np.int64)/int(1e6)

        ratings=df_rating[['Practice_date','ratings']].values.astype(int).tolist()   


        # Clever

        if 'Practice_date' in list(clever.columns):
            clever['Practice_date']=pd.to_datetime(clever['Practice_date'])
            clever['Practice_date']=clever['Practice_date']-timedelta(hours=4)
            clever_sort=clever.sort_values(by='Practice_date')
        else:
            time_range=[]
        #     start = '2021-10-12 00:00:00'
        #     end = "2021-10-12 23:59:59"
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)
            clever=pd.DataFrame(time_range, columns=['Practice_date'])
            clever['Parents_Practice_CSY'] = 0
            clever_sort=clever.sort_values(by='Practice_date')
            
            
            
        # Canvas

        if 'Practice_date' in list(canvas.columns):
            canvas['Practice_date']=pd.to_datetime(canvas['Practice_date'], format='%Y-%m-%d %H:%M')
            canvas['Practice_date']=canvas['Practice_date']-timedelta(hours=4)
            canvas_sort=canvas.sort_values(by='Practice_date')
        else:
            time_range=[]
        #     start = '2021-10-12 00:00:00'
        #     end = "2021-10-12 23:59:59"
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)
            canvas=pd.DataFrame(time_range, columns=['Practice_date'])
            canvas['Parents_Practice_CSY'] = 0
            canvas_sort=canvas.sort_values(by='Practice_date')

        # Schoology

        if 'Practice_date' in list(schoology.columns):
            schoology['Practice_date']=pd.to_datetime(schoology['Practice_date'], format='%Y-%m-%d %H:%M')
            schoology['Practice_date']=schoology['Practice_date']-timedelta(hours=4)
            schoology_sort=schoology.sort_values(by='Practice_date')
        else:
            time_range=[]
        #     start = '2021-10-12 00:00:00'
        #     end = "2021-10-12 23:59:59"
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)
            schoology=pd.DataFrame(time_range, columns=['Practice_date'])
            schoology['Parents_Practice_CSY'] = 0
            schoology_sort=schoology.sort_values(by='Practice_date')



        # Parents 
        df2['Practice_date'] = pd.to_datetime(df2['Practice_date'])
        df2['Practice_date']=df2['Practice_date']-timedelta(hours=4)
        df6=df2.sort_values(by='Practice_date')

        time_range=[]
        # start = '2021-10-12 00:00:00'
        # end = "2021-10-12 23:59:59"
        delta = datetime.timedelta(seconds=60)
        start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
        end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
        t = start
        while t <= end :
            x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
            t += delta
            time_range.append(x)

        df_parents=pd.DataFrame(time_range, columns=['Practice_date'])
        # # df_parents['value']=0
        parents_datetime=pd.to_datetime(df_parents['Practice_date'])

        parents=pd.merge(df6,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')
        parents['Practice_date']=parents['Practice_date'].astype(np.int64)/int(1e6)
        parents_final=parents[['Practice_date','Parents_Practice_CSY']].values.astype(int).tolist()


        # cleverr
        clever['Practice_date']=pd.to_datetime(clever['Practice_date'])
        clever_csy1=pd.merge(clever,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')


        clever_csy1['Practice_date']=clever_csy1['Practice_date'].astype(np.int64)/int(1e6)
        clever_parents_users=clever_csy1[["Practice_date","Parents_Practice_CSY"]].values.astype(int).tolist()
        
        
        # canvas
        canvas_sort['Practice_date']=pd.to_datetime(canvas_sort['Practice_date'])
        canvas_csy1= pd.merge(canvas_sort,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')


        canvas_csy1['Practice_date']=canvas_csy1['Practice_date'].astype(np.int64)/int(1e6)
        canvas_parents_users=canvas_csy1[["Practice_date","Parents_Practice_CSY"]].values.astype(int).tolist()



        # schoologyyy
        schoology_sort['Practice_date']=pd.to_datetime(schoology_sort['Practice_date'])
        schoology_csy1= pd.merge(schoology_sort,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')


        schoology_csy1['Practice_date']=schoology_csy1['Practice_date'].astype(np.int64)/int(1e6)
        schoology_parents_users=schoology_csy1[["Practice_date","Parents_Practice_CSY"]].values.astype(int).tolist()



        temp={'data':{'teachers_practices':csy_users_list, 'Parents_practices':parents_final, 'Canvas':canvas_parents_users,'Clever':clever_parents_users, 'schoology':schoology_parents_users, 'ratings':ratings}}

        return json.dumps(temp)


    else:
        
        ######################  USER PRACTICE 2019-2020(LSY) ############################################
        df1 = DataFrame(list(collection2.aggregate([
            {"$match":
            {"$and" :[
                {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{'$ne':""}},

                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                
                {"MODIFIED_DATE":{"$gte": today_min
                                             ,"$lte" : today_max
                                    }},
                {'USER_ID.ROLE_ID._id':{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},


                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}]}},
#         practice_cond_dictonary_list[0],
#                     practice_cond_dictonary_list[1],
#                      threshcond[0],

            {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  
                    'Users_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                        'Users_Practice_CSY':'$Users_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))

        df2 = DataFrame(list(collection2.aggregate([{"$match":
            {"$and" :[
                {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                    {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
                    {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
                {'USER_ID.EMAIL_ID':{'$ne':""}},

                {"USER_ID._id":{"$not":{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                
                {"MODIFIED_DATE":{"$gte": today_min
                                             ,"$lte" : today_max
                                    }},
                {'USER_ID.ROLE_ID._id':{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},


                {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                    {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}},                
            ]}},
#                                                 practice_cond_dictonary_list[0],
#                             practice_cond_dictonary_list[1],
#                              threshcond[0],

              {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  
                            'Parents_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                                'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))

        schoology = DataFrame(list(collection2.aggregate([
                    {"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                            { "USER_ID._id":{"$not":{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                            { "USER_ID._id":{"$not":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}}},
                            {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": today_min
                                                 ,"$lte" : today_max
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},

#         practice_cond_dictonary_list[0],
#                             practice_cond_dictonary_list[1],
#                              threshcond[0],

                  {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  
                            'Parents_Practice_CSY':{'$sum':1}}},
                    {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                                'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
                    {"$sort":{'Practice_date':1}}])))
            #     print(schoology,"schoology")
                                      ########clever################################

        clever = DataFrame(list(collection2.aggregate([{"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                             { "USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.schoology_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.canvas_user_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": today_min
                                                 ,"$lte" : today_max
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},
#         practice_cond_dictonary_list[0],
#                     practice_cond_dictonary_list[1],
#                      threshcond[0],
           {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))
        
        
        
        canvas = DataFrame(list(collection2.aggregate([{"$match":
                    {"$and" :[
                        {'USER_ID.IS_DISABLED':{'$ne':'Y'}},
                            {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}}, 
                            {'USER_ID.EMAIL_ID':{'$ne':""}},
                             { "USER_ID._id":{"$in":db.canvas_user_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.schoology_master.distinct( "USER_ID._id")}},
                           {"USER_ID._id":{"$nin":db.clever_master.distinct( "USER_ID._id")}},
                            {"MODIFIED_DATE":{"$gte": today_min
                                                 ,"$lte" : today_max
                                            }},
                        {'USER_ID.USER_NAME':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : 'test', '$options' : 'i'}}},
                            {'USER_ID.EMAIL_ID':{"$not": {'$regex' : '1gen', '$options' : 'i'}}},
                              {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                            {'USER_ID.schoolId.NAME':{"$not":{"$regex":'blocked', '$options':'i'}}}

                ]}},
#         practice_cond_dictonary_list[0],
#                     practice_cond_dictonary_list[1],
#                      threshcond[0],
           {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                        'date':{'$first':'$MODIFIED_DATE'},  
                    'Parents_Practice_CSY':{'$sum':1}}},
            {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
                        'Parents_Practice_CSY':'$Parents_Practice_CSY'}}, 
            {"$sort":{'Practice_date':1}}])))

        ########Ratingss################################
        collection4= db.audio_feedback
        ratings=DataFrame(list(collection4.aggregate([

        {"$match":
             {'$and': [
                    {"USER.IS_DISABLED":{"$ne":"Y"}},
                      {"USER.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},
                     {"USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},

                    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'RATING':{'$ne':0}},
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
#               practice_cond_dictonary_list[0],
#                     practice_cond_dictonary_list[1],
        #              threshcond[0],
           {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}, 'month':{'$month':'$MODIFIED_DATE'}},
                                'date':{'$first':'$MODIFIED_DATE'},
                      'ratings':{'$sum':1}}},
                        {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
            'ratings':'$ratings'}}, 
                        {"$sort":{'Practice_date':1}}])))


        df1['Practice_date']=pd.to_datetime(df1['Practice_date'], format="%Y-%m-%d %H:%M")
        df1['Practice_date']=df1['Practice_date']-timedelta(hours=4)
        df5=df1.sort_values(by='Practice_date')
        time_range=[]
        # start = '2021-10-12 00:00:00'
        # end = "2021-10-12 23:59:59"
        delta = datetime.timedelta(seconds=60)
        start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
        end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
        t = start
        while t <= end :
            x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
            t += delta
            time_range.append(x)

        df9 = pd.DataFrame(time_range,columns = ["Practice_date"])
        df9['Practice_date']=pd.to_datetime(df9['Practice_date'])

        df10=pd.merge(df5,df9, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

        df10['Practice_date']=df10['Practice_date'].astype(np.int64)/int(1e6)

        csy_users_list=df10[['Practice_date','Users_Practice_CSY']].values.astype(int).tolist()   


        # ratings
        ratings['Practice_date']=pd.to_datetime(ratings['Practice_date'], format="%Y-%m-%d %H:%M")
        ratings['Practice_date']=ratings['Practice_date']-timedelta(hours=4)
        df5ratings=ratings.sort_values(by='Practice_date')
        time_range=[]
        # start = '2021-10-12 00:00:00'
        # end = "2021-10-12 23:59:59"
        delta = datetime.timedelta(seconds=60)
        start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
        end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
        t = start
        while t <= end :
            x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
            t += delta
            time_range.append(x)

        df9ratings = pd.DataFrame(time_range,columns = ["Practice_date"])
        df9ratings['Practice_date']=pd.to_datetime(df9ratings['Practice_date'])

        df_rating=pd.merge(df5ratings,df9ratings, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

        df_rating['Practice_date']=df_rating['Practice_date'].astype(np.int64)/int(1e6)

        ratings=df_rating[['Practice_date','ratings']].values.astype(int).tolist()   


        # Clever

        if 'Practice_date' in list(clever.columns):
            clever['Practice_date']=pd.to_datetime(clever['Practice_date'])
            clever['Practice_date']=clever['Practice_date']-timedelta(hours=4)
            clever_sort=clever.sort_values(by='Practice_date')
        else:
            time_range=[]
        #     start = '2021-10-12 00:00:00'
        #     end = "2021-10-12 23:59:59"
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)
            clever=pd.DataFrame(time_range, columns=['Practice_date'])
            clever['Parents_Practice_CSY'] = 0
            clever_sort=clever.sort_values(by='Practice_date')
            
            
            
        # Canvas

        if 'Practice_date' in list(canvas.columns):
            canvas['Practice_date']=pd.to_datetime(canvas['Practice_date'], format='%Y-%m-%d %H:%M')
            canvas['Practice_date']=canvas['Practice_date']-timedelta(hours=4)
            canvas_sort=canvas.sort_values(by='Practice_date')
        else:
            time_range=[]
        #     start = '2021-10-12 00:00:00'
        #     end = "2021-10-12 23:59:59"
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)
            canvas=pd.DataFrame(time_range, columns=['Practice_date'])
            canvas['Parents_Practice_CSY'] = 0
            canvas_sort=canvas.sort_values(by='Practice_date')

        # Schoology

        if 'Practice_date' in list(schoology.columns):
            schoology['Practice_date']=pd.to_datetime(schoology['Practice_date'], format='%Y-%m-%d %H:%M')
            schoology['Practice_date']=schoology['Practice_date']-timedelta(hours=4)
            schoology_sort=schoology.sort_values(by='Practice_date')
        else:
            time_range=[]
        #     start = '2021-10-12 00:00:00'
        #     end = "2021-10-12 23:59:59"
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)
            schoology=pd.DataFrame(time_range, columns=['Practice_date'])
            schoology['Parents_Practice_CSY'] = 0
            schoology_sort=schoology.sort_values(by='Practice_date')



        # Parents 
        df2['Practice_date'] = pd.to_datetime(df2['Practice_date'])
        df2['Practice_date']=df2['Practice_date']-timedelta(hours=4)
        df6=df2.sort_values(by='Practice_date')

        time_range=[]
        # start = '2021-10-12 00:00:00'
        # end = "2021-10-12 23:59:59"
        delta = datetime.timedelta(seconds=60)
        start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
        end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
        t = start
        while t <= end :
            x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
            t += delta
            time_range.append(x)

        df_parents=pd.DataFrame(time_range, columns=['Practice_date'])
        # # df_parents['value']=0
        parents_datetime=pd.to_datetime(df_parents['Practice_date'])

        parents=pd.merge(df6,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')
        parents['Practice_date']=parents['Practice_date'].astype(np.int64)/int(1e6)
        parents_final=parents[['Practice_date','Parents_Practice_CSY']].values.astype(int).tolist()


        # cleverr
        clever['Practice_date']=pd.to_datetime(clever['Practice_date'])
        clever_csy1=pd.merge(clever,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')


        clever_csy1['Practice_date']=clever_csy1['Practice_date'].astype(np.int64)/int(1e6)
        clever_parents_users=clever_csy1[["Practice_date","Parents_Practice_CSY"]].values.astype(int).tolist()
        
        
        # canvas
        canvas_sort['Practice_date']=pd.to_datetime(canvas_sort['Practice_date'])
        canvas_csy1= pd.merge(canvas_sort,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')


        canvas_csy1['Practice_date']=canvas_csy1['Practice_date'].astype(np.int64)/int(1e6)
        canvas_parents_users=canvas_csy1[["Practice_date","Parents_Practice_CSY"]].values.astype(int).tolist()



        # schoologyyy
        schoology_sort['Practice_date']=pd.to_datetime(schoology_sort['Practice_date'])
        schoology_csy1= pd.merge(schoology_sort,parents_datetime, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')


        schoology_csy1['Practice_date']=schoology_csy1['Practice_date'].astype(np.int64)/int(1e6)
        schoology_parents_users=schoology_csy1[["Practice_date","Parents_Practice_CSY"]].values.astype(int).tolist()



        temp={'data':{'teachers_practices':csy_users_list, 'Parents_practices':parents_final, 'Canvas':canvas_parents_users,'Clever':clever_parents_users, 'schoology':schoology_parents_users, 'ratings':ratings}}

        return json.dumps(temp)



@app.route('/Program_wise_per_minute_DAILD_updated/<charttype>')
def practice_per_min_program(charttype):
    mongo_uri = "mongodb://admin:" + urllib.parse.quote('F5tMazRj47cYqm33e') + "@35.88.43.45:27017/"
    client = pymongo.MongoClient(mongo_uri)
    db = client.compass
    collection2 = db.audio_track_master

    mydatetime=datetime.datetime.utcnow()
    today_min=datetime.datetime.combine(mydatetime,datetime.time.min)
    today_max=datetime.datetime.combine(mydatetime, datetime.time.max)

    start_today=today_min.strftime('%Y-%m-%d %H:%M:%S')
    end_today=today_max.strftime('%Y-%m-%d %H:%M:%S')

    charttype=str(charttype).title()

    if charttype=='Practice':
        threshold=.5


        threshcond=[{'$match':{'Completion_Percentage':{'$gte':threshold}}}]

        dtf=DataFrame(list(db.program_master.aggregate([
        {"$match":{"$and":[
        {"PROGRAM_ID":{"$nin":[5,6,7]}},]}},
        {'$project':{'_id':'$PROGRAM_ID','PROGRAM_NAME':'$PROGRAM_NAME'}},
        {'$sort':{'_id':1}}])))
        progname_=dtf['PROGRAM_NAME'].tolist()

        ######################  USER PRACTICE 2019-2020(LSY) ############################################
        df_elem = DataFrame(list(collection2.aggregate([
            {"$match":
             {'$and': [
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},{"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},         
                 {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$regex':'elementary', '$options':'i'}},
            {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$in':progname_}},         
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
                            practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],
            {"$group":{'_id':{'minute':{'$minute':'$MODIFIED_DATE'}}, 'date':{'$first':'$MODIFIED_DATE'},
                       'program_id':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
        'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},'practicecount':{'$sum':1}}},
             {"$project":{'_id':0,'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
         'program_id':'$program_id','PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},

            {'$sort':{'Practice_date':1}}
            ]    

        )))

        df_middle = DataFrame(list(collection2.aggregate([
            {"$match":
             {'$and': [
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},{"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},         
                 {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$regex':'middle', '$options':'i'}},
            {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$in':progname_}},         
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
                            practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],
            {"$group":{'_id':{'minute':{'$minute':'$MODIFIED_DATE'}}, 'date':{'$first':'$MODIFIED_DATE'},
                       'program_id':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
        'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},'practicecount':{'$sum':1}}},
             {"$project":{'_id':0,'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
         'program_id':'$program_id','PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},

            {'$sort':{'Practice_date':1}}
            ]    

        )))

        df_high = DataFrame(list(collection2.aggregate([
            {"$match":
             {'$and': [
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},{"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},         
                 {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$regex':'high', '$options':'i'}},
            {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$in':progname_}},         
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
                            practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],
            {"$group":{'_id':{'minute':{'$minute':'$MODIFIED_DATE'}}, 'date':{'$first':'$MODIFIED_DATE'},
                       'program_id':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
        'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},'practicecount':{'$sum':1}}},
             {"$project":{'_id':0,'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
         'program_id':'$program_id','PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},

            {'$sort':{'Practice_date':1}}
            ]    )))

        df_early = DataFrame(list(collection2.aggregate([
            {"$match":
             {'$and': [
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},{"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},         
                 {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$regex':'Early Learning', '$options':'i'}},
            {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$in':progname_}},         
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
                            practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],
            {"$group":{'_id':{'minute':{'$minute':'$MODIFIED_DATE'}}, 'date':{'$first':'$MODIFIED_DATE'},
                       'program_id':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
        'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},'practicecount':{'$sum':1}}},
             {"$project":{'_id':0,'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
         'program_id':'$program_id','PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},

            {'$sort':{'Practice_date':1}}
            ]    

        )))

        df_wellness = DataFrame(list(collection2.aggregate([
            {"$match":
             {'$and': [
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},{"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},         
                 {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':{'$in':[5,6,7,8,10]}},
            {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$in':progname_}},         
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
                            practice_cond_dictonary_list[0],
                            practice_cond_dictonary_list[1],
                             threshcond[0],
            {"$group":{'_id':{'minute':{'$minute':'$MODIFIED_DATE'}}, 'date':{'$first':'$MODIFIED_DATE'},
                       'program_id':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
        'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},'practicecount':{'$sum':1}}},
             {"$project":{'_id':0,'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
         'program_id':'$program_id','PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},

            {'$sort':{'Practice_date':1}}
            ]            )))


        ########Ratingss################################
        collection4= db.audio_feedback
        df_ratings=DataFrame(list(collection4.aggregate([
        {"$match":
             {'$and': [
                    {"USER.IS_DISABLED":{"$ne":"Y"}},{"USER.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'RATING':{'$ne':0}},{'MODIFIED_DATE':{'$gte':today_min,'$lte':today_max}},
                    ]}},
                  practice_cond_dictonary_list[0],
                        practice_cond_dictonary_list[1],
                         threshcond[0],
           {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}},
           'date':{'$first':'$MODIFIED_DATE'},'program_id':{'$first':'$AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
           'ratings':{'$sum':1}}},
           {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
            'ratings':'$ratings'}}, 
           {"$sort":{'Practice_date':1}}])))

        # ELEMENTARY
        if 'Practice_date' in list(df_elem.columns):
            df_elem.loc[(df_elem['program_id']==2)|(df_elem['program_id']==16),'program_id']=12
            df_elem['Practice_date']=pd.to_datetime(df_elem['Practice_date'], format="%Y-%m-%d %H:%M")
            df_elem['Practice_date']=df_elem['Practice_date']-timedelta(hours=4)
            df5=df_elem.sort_values(by='Practice_date')
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9 = pd.DataFrame(time_range,columns = ["Practice_date"])
            df9['Practice_date']=pd.to_datetime(df9['Practice_date'])

            df10=pd.merge(df5,df9, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

            df10['Practice_date']=df10['Practice_date'].astype(np.int64)/int(1e6)

            csy_users_list=df10[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   

        else:
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9=pd.DataFrame(time_range, columns=['Practice_date'])
            df9['teacherspracticecount']=0
            df9=df9.sort_values(by='Practice_date')
            df9['Practice_date']=pd.to_datetime(df9['Practice_date'])
            csy_users_list=df9[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   




#         # RATINGS
#         df_ratings['Practice_date']=pd.to_datetime(df_ratings['Practice_date'], format="%Y-%m-%d %H:%M")
#         df5ratings=df_ratings.sort_values(by='Practice_date')
#         time_range=[]
#         delta = datetime.timedelta(seconds=60)
#         start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
#         end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
#         t = start
#         while t <= end :
#             x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
#             t += delta
#             time_range.append(x)

#         df9ratings = pd.DataFrame(time_range,columns = ["Practice_date"])
#         df9ratings['Practice_date']=pd.to_datetime(df9ratings['Practice_date'])

#         df_rating=pd.merge(df5ratings,df9ratings, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

#         df_rating['Practice_date']=df_rating['Practice_date'].astype(np.int64)/int(1e6)

#         ratings=df_rating[['Practice_date','ratings']].values.astype(int).tolist()   


        # MIDDLE

        if 'Practice_date' in list(df_middle.columns):
            df_middle.loc[(df_middle['program_id']==3)&(df_middle['program_id']==17),'program_id']=13

            df_middle['Practice_date']=pd.to_datetime(df_middle['Practice_date'], format="%Y-%m-%d %H:%M")
            df_middle['Practice_date']=df_middle['Practice_date']-timedelta(hours=4)
            df6=df_middle.sort_values(by='Practice_date')
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_middle = pd.DataFrame(time_range,columns = ["Practice_date"])
            df9_middle['Practice_date']=pd.to_datetime(df9_middle['Practice_date'])

            df10middle=pd.merge(df6,df9_middle, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

            df10middle['Practice_date']=df10middle['Practice_date'].astype(np.int64)/int(1e6)

            middle=df10middle[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   

        else:
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_middle=pd.DataFrame(time_range, columns=['Practice_date'])
            df9_middle['teacherspracticecount']=0
            df9_middle=df9_middle.sort_values(by='Practice_date')
            df9_middle['Practice_date']=pd.to_datetime(df9_middle['Practice_date'])
            middle=df9_middle[['Practice_date','teacherspracticecount']].values.astype(int).tolist() 


        # HIGH

        if 'Practice_date' in list(df_high.columns):
            df_high.loc[(df_high['program_id']==4)&(df_high['program_id']==14),'program_id']=9

            df_high['Practice_date']=pd.to_datetime(df_high['Practice_date'], format="%Y-%m-%d %H:%M")
            df_high['Practice_date']=df_high['Practice_date']-timedelta(hours=4)
            df7=df_high.sort_values(by='Practice_date')
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_high = pd.DataFrame(time_range,columns = ["Practice_date"])
            df9_high['Practice_date']=pd.to_datetime(df9_high['Practice_date'])

            df10high=pd.merge(df7,df9_high, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

            df10high['Practice_date']=df10high['Practice_date'].astype(np.int64)/int(1e6)

            high=df10high[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   

        else:
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_high=pd.DataFrame(time_range, columns=['Practice_date'])
            df9_high['teacherspracticecount']=0
            df9_high=df9_high.sort_values(by='Practice_date')
            df9_high['Practice_date']=pd.to_datetime(df9_high['Practice_date'])
            high=df9_high[['Practice_date','teacherspracticecount']].values.astype(int).tolist() 



        # early learning 
        if 'Practice_date' in list(df_early.columns):
            df_early.loc[(df_early['program_id']==1)&(df_early['program_id']==15),'program_id']=11

            df_early['Practice_date']=pd.to_datetime(df_early['Practice_date'], format="%Y-%m-%d %H:%M")
            df_early['Practice_date']=df_early['Practice_date']-timedelta(hours=4)
            df8=df_early.sort_values(by='Practice_date')
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_early = pd.DataFrame(time_range,columns = ["Practice_date"])
            df9_early['Practice_date']=pd.to_datetime(df9_early['Practice_date'])

            df10early=pd.merge(df8,df9_early, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

            df10early['Practice_date']=df10early['Practice_date'].astype(np.int64)/int(1e6)

            early=df10early[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   

        else:
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_early = pd.DataFrame(time_range,columns = ["Practice_date"])

            df9_early=df9_early.sort_values(by='Practice_date')
            df9_early['teacherspracticecount']=0
            df9_early['Practice_date']=pd.to_datetime(df9_early['Practice_date'])
            df9_early['Practice_date']=df9_early['Practice_date'].astype(np.int64)/int(1e6)

            early=df9_early[['Practice_date','teacherspracticecount']].values.astype(int).tolist() 


        #  WELLNESS   
        if 'Practice_date' in list(df_wellness.columns):
            df_wellness.loc[(df_wellness['program_id']==5 )& (df_wellness['program_id']==6 )& (df_wellness['program_id']==7) & (df_wellness['program_id']==8),'program_id']=10
            df_wellness['Practice_date']=pd.to_datetime(df_wellness['Practice_date'], format="%Y-%m-%d %H:%M")
            df_wellness['Practice_date']=df_wellness['Practice_date']-timedelta(hours=4)
            df99=df_wellness.sort_values(by='Practice_date')
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_wellness = pd.DataFrame(time_range,columns = ["Practice_date"])
            df9_wellness['Practice_date']=pd.to_datetime(df9_wellness['Practice_date'])

            df10wellness=pd.merge(df99,df9_wellness, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

            df10wellness['Practice_date']=df10wellness['Practice_date'].astype(np.int64)/int(1e6)

            wellness=df10wellness[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   

        else:
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_wellness = pd.DataFrame(time_range,columns = ["Practice_date"])

            df9_wellness=df9_wellness.sort_values(by='Practice_date')
            df9_wellness['teacherspracticecount']=0
            df9_wellness['Practice_date']=pd.to_datetime(df9_wellness['Practice_date'])
            df9_wellness['Practice_date']=df9_wellness['Practice_date'].astype(np.int64)/int(1e6)

            wellness=df9_wellness[['Practice_date','teacherspracticecount']].values.astype(int).tolist() 



        temp={'data':{'elementary':csy_users_list, 'middle':middle, 'high':high, 'early_learning':early, 'wellness':wellness}}

        return json.dumps(temp)

    else:
        dtf=DataFrame(list(db.program_master.aggregate([
        {"$match":{"$and":[
        {"PROGRAM_ID":{"$nin":[5,6,7]}},]}},
        {'$project':{'_id':'$PROGRAM_ID','PROGRAM_NAME':'$PROGRAM_NAME'}},
        {'$sort':{'_id':1}}])))
        progname_=dtf['PROGRAM_NAME'].tolist()

        ######################  USER PRACTICE 2019-2020(LSY) ############################################
        df_elem = DataFrame(list(collection2.aggregate([
            {"$match":
             {'$and': [
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},{"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},         
                 {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$regex':'elementary', '$options':'i'}},
            {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$in':progname_}},         
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
        #                     practice_cond_dictonary_list[0],
        #                     practice_cond_dictonary_list[1],
        #                      threshcond[0],
            {"$group":{'_id':{'minute':{'$minute':'$MODIFIED_DATE'}}, 'date':{'$first':'$MODIFIED_DATE'},
                       'program_id':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
        'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},'practicecount':{'$sum':1}}},
             {"$project":{'_id':0,'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
         'program_id':'$program_id','PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},

            {'$sort':{'Practice_date':1}}
            ]    

        )))

        df_middle = DataFrame(list(collection2.aggregate([
            {"$match":
             {'$and': [
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},{"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},         
                 {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$regex':'middle', '$options':'i'}},
            {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$in':progname_}},         
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
        #                     practice_cond_dictonary_list[0],
        #                     practice_cond_dictonary_list[1],
        #                      threshcond[0],
            {"$group":{'_id':{'minute':{'$minute':'$MODIFIED_DATE'}}, 'date':{'$first':'$MODIFIED_DATE'},
                       'program_id':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
        'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},'practicecount':{'$sum':1}}},
             {"$project":{'_id':0,'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
         'program_id':'$program_id','PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},

            {'$sort':{'Practice_date':1}}
            ]    

        )))

        df_high = DataFrame(list(collection2.aggregate([
            {"$match":
             {'$and': [
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},{"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},         
                 {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$regex':'high', '$options':'i'}},
            {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$in':progname_}},         
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
        #                     practice_cond_dictonary_list[0],
        #                     practice_cond_dictonary_list[1],
        #                      threshcond[0],
            {"$group":{'_id':{'minute':{'$minute':'$MODIFIED_DATE'}}, 'date':{'$first':'$MODIFIED_DATE'},
                       'program_id':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
        'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},'practicecount':{'$sum':1}}},
             {"$project":{'_id':0,'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
         'program_id':'$program_id','PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},

            {'$sort':{'Practice_date':1}}
            ]    )))

        df_early = DataFrame(list(collection2.aggregate([
            {"$match":
             {'$and': [
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},{"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},         
                 {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$regex':'Early Learning', '$options':'i'}},
            {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$in':progname_}},         
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
        #                     practice_cond_dictonary_list[0],
        #                     practice_cond_dictonary_list[1],
        #                      threshcond[0],
            {"$group":{'_id':{'minute':{'$minute':'$MODIFIED_DATE'}}, 'date':{'$first':'$MODIFIED_DATE'},
                       'program_id':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
        'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},'practicecount':{'$sum':1}}},
             {"$project":{'_id':0,'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
         'program_id':'$program_id','PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},

            {'$sort':{'Practice_date':1}}
            ]    

        )))

        df_wellness = DataFrame(list(collection2.aggregate([
            {"$match":
             {'$and': [
                    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},{"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                               {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},         
                 {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID':{'$in':[5,6,7,8,10]}},
            {'PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME':{'$in':progname_}},         
                 {'MODIFIED_DATE':{'$gte':today_min,
                                     '$lte':today_max
                                     }},
                    ]}},
        #                     practice_cond_dictonary_list[0],
        #                     practice_cond_dictonary_list[1],
        #                      threshcond[0],
            {"$group":{'_id':{'minute':{'$minute':'$MODIFIED_DATE'}}, 'date':{'$first':'$MODIFIED_DATE'},
                       'program_id':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
        'PROGRAM_NAME':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'},'practicecount':{'$sum':1}}},
             {"$project":{'_id':0,'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}},
         'program_id':'$program_id','PROGRAM_NAME':'$PROGRAM_NAME', 'teacherspracticecount':'$practicecount'}},

            {'$sort':{'Practice_date':1}}
            ]            )))


        ########Ratingss################################
        collection4= db.audio_feedback
        df_ratings=DataFrame(list(collection4.aggregate([
        {"$match":
             {'$and': [
                    {"USER.IS_DISABLED":{"$ne":"Y"}},{"USER.IS_BLOCKED":{"$ne":"Y"}},
                 {'USER.schoolId.BLOCKED_BY_CAP':{'$ne':'Y'}},{"USER.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                  {'USER.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                   {'USER.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'USER.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'RATING':{'$ne':0}},{'MODIFIED_DATE':{'$gte':today_min,'$lte':today_max}},
                    ]}},
        #           practice_cond_dictonary_list[0],
        #                 practice_cond_dictonary_list[1],
        #                  threshcond[0],
           {'$group':{'_id':{'day':{'$minute':'$MODIFIED_DATE'}},
           'date':{'$first':'$MODIFIED_DATE'},'program_id':{'$first':'$AUDIO_ID.PROGRAM_ID.PROGRAM_ID'},
           'ratings':{'$sum':1}}},
           {'$project':{'_id':0, 'Practice_date':{"$dateToString":{"format":"%Y-%m-%d %H:%M","date":'$date'}}, 
            'ratings':'$ratings'}}, 
           {"$sort":{'Practice_date':1}}])))

        # ELEMENTARY
        if 'Practice_date' in list(df_elem.columns):
            df_elem.loc[(df_elem['program_id']==2)|(df_elem['program_id']==16),'program_id']=12
            df_elem['Practice_date']=pd.to_datetime(df_elem['Practice_date'], format="%Y-%m-%d %H:%M")
            df_elem['Practice_date']=df_elem['Practice_date']-timedelta(hours=4)
            df5=df_elem.sort_values(by='Practice_date')
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9 = pd.DataFrame(time_range,columns = ["Practice_date"])
            df9['Practice_date']=pd.to_datetime(df9['Practice_date'])

            df10=pd.merge(df5,df9, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

            df10['Practice_date']=df10['Practice_date'].astype(np.int64)/int(1e6)

            csy_users_list=df10[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   

        else:
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9=pd.DataFrame(time_range, columns=['Practice_date'])
            df9['teacherspracticecount']=0
            df9=df9.sort_values(by='Practice_date')
            df9['Practice_date']=pd.to_datetime(df9['Practice_date'])
            csy_users_list=df9[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   




        # RATINGS
        df_ratings['Practice_date']=pd.to_datetime(df_ratings['Practice_date'], format="%Y-%m-%d %H:%M")

        df5ratings=df_ratings.sort_values(by='Practice_date')
        time_range=[]
        delta = datetime.timedelta(seconds=60)
        start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
        end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
        t = start
        while t <= end :
            x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
            t += delta
            time_range.append(x)

        df9ratings = pd.DataFrame(time_range,columns = ["Practice_date"])
        df9ratings['Practice_date']=pd.to_datetime(df9ratings['Practice_date'])

        df_rating=pd.merge(df5ratings,df9ratings, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

        df_rating['Practice_date']=df_rating['Practice_date'].astype(np.int64)/int(1e6)

        ratings=df_rating[['Practice_date','ratings']].values.astype(int).tolist()   


        # MIDDLE

        if 'Practice_date' in list(df_middle.columns):
            df_middle.loc[(df_middle['program_id']==3)&(df_middle['program_id']==17),'program_id']=13

            df_middle['Practice_date']=pd.to_datetime(df_middle['Practice_date'], format="%Y-%m-%d %H:%M")
            df_middle['Practice_date']=df_middle['Practice_date']-timedelta(hours=4)
            df6=df_middle.sort_values(by='Practice_date')
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_middle = pd.DataFrame(time_range,columns = ["Practice_date"])
            df9_middle['Practice_date']=pd.to_datetime(df9_middle['Practice_date'])

            df10middle=pd.merge(df6,df9_middle, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

            df10middle['Practice_date']=df10middle['Practice_date'].astype(np.int64)/int(1e6)

            middle=df10middle[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   

        else:
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_middle=pd.DataFrame(time_range, columns=['Practice_date'])
            df9_middle['teacherspracticecount']=0
            df9_middle=df9_middle.sort_values(by='Practice_date')
            df9_middle['Practice_date']=pd.to_datetime(df9_middle['Practice_date'])
            middle=df9_middle[['Practice_date','teacherspracticecount']].values.astype(int).tolist() 


        # HIGH

        if 'Practice_date' in list(df_high.columns):
            df_high.loc[(df_high['program_id']==4)&(df_high['program_id']==14),'program_id']=9

            df_high['Practice_date']=pd.to_datetime(df_high['Practice_date'], format="%Y-%m-%d %H:%M")
            df_high['Practice_date']=df_high['Practice_date']-timedelta(hours=4)
            df7=df_high.sort_values(by='Practice_date')
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_high = pd.DataFrame(time_range,columns = ["Practice_date"])
            df9_high['Practice_date']=pd.to_datetime(df9_high['Practice_date'])

            df10high=pd.merge(df7,df9_high, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

            df10high['Practice_date']=df10high['Practice_date'].astype(np.int64)/int(1e6)

            high=df10high[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   

        else:
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_high=pd.DataFrame(time_range, columns=['Practice_date'])
            df9_high['teacherspracticecount']=0
            df9_high=df9_high.sort_values(by='Practice_date')
            df9_high['Practice_date']=pd.to_datetime(df9_high['Practice_date'])
            high=df9_high[['Practice_date','teacherspracticecount']].values.astype(int).tolist() 



        # early learning 
        if 'Practice_date' in list(df_early.columns):
            df_early.loc[(df_early['program_id']==1)&(df_early['program_id']==15),'program_id']=11

            df_early['Practice_date']=pd.to_datetime(df_early['Practice_date'], format="%Y-%m-%d %H:%M")
            df_early['Practice_date']=df_early['Practice_date']-timedelta(hours=4)
            df8=df_early.sort_values(by='Practice_date')
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_early = pd.DataFrame(time_range,columns = ["Practice_date"])
            df9_early['Practice_date']=pd.to_datetime(df9_early['Practice_date'])

            df10early=pd.merge(df8,df9_early, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

            df10early['Practice_date']=df10early['Practice_date'].astype(np.int64)/int(1e6)

            early=df10early[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   

        else:
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_early = pd.DataFrame(time_range,columns = ["Practice_date"])

            df9_early=df9_early.sort_values(by='Practice_date')
            df9_early['teacherspracticecount']=0
            df9_early['Practice_date']=pd.to_datetime(df9_early['Practice_date'])
            df9_early['Practice_date']=df9_early['Practice_date'].astype(np.int64)/int(1e6)

            early=df9_early[['Practice_date','teacherspracticecount']].values.astype(int).tolist() 


        #  WELLNESS   
        if 'Practice_date' in list(df_wellness.columns):
            df_wellness.loc[(df_wellness['program_id']==5 )& (df_wellness['program_id']==6 )& (df_wellness['program_id']==7) & (df_wellness['program_id']==8),'program_id']=10
            df_wellness['Practice_date']=pd.to_datetime(df_wellness['Practice_date'], format="%Y-%m-%d %H:%M")
            df_wellness['Practice_date']=df_wellness['Practice_date']-timedelta(hours=4)
            df99=df_wellness.sort_values(by='Practice_date')
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_wellness = pd.DataFrame(time_range,columns = ["Practice_date"])
            df9_wellness['Practice_date']=pd.to_datetime(df9_wellness['Practice_date'])

            df10wellness=pd.merge(df99,df9_wellness, on='Practice_date', how='right').fillna(0).sort_values(by='Practice_date')   

            df10wellness['Practice_date']=df10wellness['Practice_date'].astype(np.int64)/int(1e6)

            wellness=df10wellness[['Practice_date','teacherspracticecount']].values.astype(int).tolist()   

        else:
            time_range=[]
            delta = datetime.timedelta(seconds=60)
            start = datetime.datetime.strptime(start_today,'%Y-%m-%d %H:%M:%S')
            end = datetime.datetime.strptime(end_today,'%Y-%m-%d %H:%M:%S' )
            t = start
            while t <= end :
                x=datetime.datetime.strftime(t,'%Y-%m-%d %H:%M:%S')
                t += delta
                time_range.append(x)

            df9_wellness = pd.DataFrame(time_range,columns = ["Practice_date"])

            df9_wellness=df9_wellness.sort_values(by='Practice_date')
            df9_wellness['teacherspracticecount']=0
            df9_wellness['Practice_date']=pd.to_datetime(df9_wellness['Practice_date'])
            df9_wellness['Practice_date']=df9_wellness['Practice_date'].astype(np.int64)/int(1e6)

            wellness=df9_wellness[['Practice_date','teacherspracticecount']].values.astype(int).tolist() 



        temp={'data':{'elementary':csy_users_list, 'middle':middle, 'high':high, 'early_learning':early, 'wellness':wellness,'ratings':ratings}}

        return json.dumps(temp)



# mini d360

# cards

@app.route('/mini_districtcardsinfo/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_district_count_cards_(LOCAl_DISTRICT,startdate,enddate):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection1 = db.user_master
    collection2=db.audio_track_master
    collection3=db.login_logs
    collection4=db.school_master

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

    df1_1 = DataFrame(list(collection1.aggregate([
    {"$match":
     {'$and': [
            {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'EMAIL_ID':{'$ne':''}},         

    {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
    {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
    {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

         {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                       

     {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'},        'user_id':{'$first':'$_id'}}},
                      {'$project':{'_id':1,'name':'$ID', 'user_id':'$user_id'}},

                  {'$sort':{'name':1}}   

    #     {'$group':{'_id':'$_id','ID':{'$addToSet':'$schoolId._id'},'dn':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},

              ])))


    schoolid=df1_1['_id'].tolist()
    userid=df1_1['user_id'].tolist()



    df1 = DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'EMAIL_ID':{'$ne':''}},

                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

         {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                       
            {'$group':{'_id':'','ID':{'$addToSet':'$schoolId._id'},'dn':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'school_count':{'$size':'$ID'},'district':'$dn'}}
                  ])))


    df10 = DataFrame(list(collection4.aggregate([
    {"$match":{'$or':[{"LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}},

       {'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}}              
                     ]}},

    {'$project':{'_id':0,'CATEGORY':1,'LOCAl_DISTRICT':1,'PARTNER_CATEGORY':1,'STATE':1, 'SUB_CATEGORY':1}} ])))                  


    if 'LOCAl_DISTRICT' not in df10:
        df10['LOCAl_DISTRICT']=0

    elif 'SUB_CATEGORY' not in df10:
        df10['SUB_CATEGORY']=0


    #     Teachers
    df2 = DataFrame(list(collection1.aggregate([ {"$match":
         {'$and': [
              {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

      {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                                                                  
            {'$group':{'_id':'','ID':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':1,'teacher_count':{'$size':'$ID'}}}
                  ])))

    #     Parents
    df5 = DataFrame(list(collection1.aggregate([ {"$match":
         {'$and': [
              {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},

                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

         {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                                                               
            {'$group':{'_id':'','ID':{'$addToSet':'$_id'}}},
                  {'$project':{'_id':1,'family_count':{'$size':'$ID'}}}
                  ])))
    today1= datetime.datetime.utcnow()

    tod1= today1+ timedelta(hours=4)
    start1= tod1-timedelta(days=30)

    #     CSY Teachers
    df3=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
          {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'USER_ID.EMAIL_ID':{'$ne':''}},

                        #   {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
            #  "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},

    {'USER_ID.schoolId._id':{'$in':schoolid}},

                 {'MODIFIED_DATE':{'$gte':csy_first_date()}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
                  {'$project':{'_id':1,'engd_teacher_csy':{'$size':'$pc'}}}])))

    #     LSY teachers
    df33=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
          {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'USER_ID.EMAIL_ID':{'$ne':''}},

                #   {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
            #  "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},

                 {'MODIFIED_DATE':{'$gte':LSY_Date()}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
                  {'$project':{'_id':1,'engd_teacher_lsy':{'$size':'$pc'}}}])))

    #     CSY Parents
    df333=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
          {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'USER_ID.EMAIL_ID':{'$ne':''}},
            #        {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
            #  "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},


                 {'MODIFIED_DATE':{'$gte':csy_first_date()}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
                  {'$project':{'_id':1,'engd_parent_csy':{'$size':'$pc'}}}])))

    #     LSY Parents
    df3333=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
          {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
        {'USER_ID.schoolId._id':{'$in':schoolid}},

                #   {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
            #  "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},

                 {'MODIFIED_DATE':{'$gte':LSY_Date()}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID._id'}}},
                  {'$project':{'_id':1,'engd_parent_lsy':{'$size':'$pc'}}}])))


    # Ratings
    df4=DataFrame(list(db.audio_feedback.aggregate([{"$match":
         {'$and': [
                  {"USER._id":{"$in":userid}},
               { 'RATING':{'$ne':0}}, 
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
         ]}},
            {'$group':{'_id':'','rating':{'$avg':'$RATING'}}},
                  {'$project':{'_id':1,'rating':'$rating'}}])))


    df6=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},

            #   {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
            #  "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions_t':'$pc','MINDFUL_MINUTES_t':'$MINDFUL_MINUTES'}}])))

    df7=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
             {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},

                #   {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
            #  "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions_p':'$pc','MINDFUL_MINUTES_p':'$MINDFUL_MINUTES'}}])))

    df77=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [

                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    {'USER_ID.schoolId._id':{'$in':schoolid}},

                    # {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
            #  "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},


             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$sum':1},'MINDFUL_MINUTES':{'$sum':{'$round':[{'$divide':[{'$subtract':['$CURSOR_END','$cursorStart']}, 60]},2]}}}},
                  {'$project':{'_id':1,'practice_sessions':'$pc','MINDFUL_MINUTES':'$MINDFUL_MINUTES'}}])))




    df0=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [

                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'USER_ID.EMAIL_ID':{'$ne':''}},
        {'USER_ID.schoolId._id':{'$in':schoolid}},

                #   {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
            #  "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
                 {'MODIFIED_DATE':{'$gte':csy_first_date()}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID.schoolId._id'}}},
                  {'$project':{'_id':1,'engdschool_csy':{'$size':'$pc'}}}])))


    df00=DataFrame(list(collection2.aggregate([
     {"$match":
         {'$and': [
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

                 {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {'USER_ID.schoolId._id':{'$in':schoolid}},

                # {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
            #  "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
                 {'MODIFIED_DATE':{'$gte':LSY_Date()}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'','pc':{'$addToSet':'$USER_ID.schoolId._id'}}},
                  {'$project':{'_id':1,'engdschool_lsy':{'$size':'$pc'}}}])))


    engd_parent_lsy=[0]
    try:
        engd_parent_lsy=df3333['engd_parent_lsy']
    except:
        engd_parent_lsy=[0]
    engd_parent_csy=[0]
    try:
        engd_parent_csy=df333['engd_parent_csy']
    except:
        engd_parent_csy=[0]

    engd_teacher_csy=[0]
    try:
        engd_teacher_csy=df3['engd_teacher_csy']
    except:
        engd_teacher_csy=[0]
    engd_teacher_lsy=[0]
    try:
        engd_teacher_lsy=df33['engd_teacher_lsy']
    except:
        engd_teacher_lsy=[0]




    engdschool_lsy=[0]
    try:
        engdschool_lsy=df00['engdschool_lsy']
    except:
        engdschool_lsy=[0]
    rating=[0]
    try:
        rating=df4['rating']
    except:
        rating=[0]

    engdschool_csy=[0]
    try:
        engdschool_csy=df0['engdschool_csy']
    except:
        engdschool_csy=[0]
    sc=[0]
    try:
        sc=df1['school_count']
    except:
        sc=[0]

    tc=[0]
    try:
        tc=df2['teacher_count']
    except:
        tc=[0]

    pct=[0]
    try:
        pct=df6['practice_sessions_t']
    except:
        pct=[0]
    pcp=[0]
    try:
        pcp=df7['practice_sessions_p']
    except:
        pcp=[0]

    mmt=[0]
    try:
        mmt=df6['MINDFUL_MINUTES_t']
    except:
        mmt=[0]
    mmp=[0]
    try:
        mmp=df7['MINDFUL_MINUTES_p']
    except:
        mmp=[0]     


    mm=[0]
    try:
        mm=df77['MINDFUL_MINUTES']
    except:
        mm=[0]
    pc=[0]
    try:
        pc=df77['practice_sessions']
    except:
        pc=[0]

    lc=[0]
    try:
        lc=df4['logins']
    except:
        lc=[0]

    fc=[0]
    try:
        fc=df5['family_count']
    except:
        fc=[0]

    dn=[0]
    try:
        dn=df1['district']
    except:
        dn=[0]


    ca=[0]
    try:
        ca=df10['CATEGORY']
    except:
        ca=[0]

    Pa=[0]
    try:
        Pa=df10['PARTNER_CATEGORY']
    except:
        Pa=[0] 
    state=[0]
    try:
        state=df10['STATE']
    except:
        state=[0]


    if df10['LOCAl_DISTRICT'][0]==0:
        ld= df10['SUB_CATEGORY']
        X=str(ld[0])

    elif df10['LOCAl_DISTRICT'][0]!=0:
        ld= df10['LOCAl_DISTRICT']
        X=str(ld[0])
        if str(ld[0])=="NW":
            X="North West"
        elif str(ld[0])=="NE":
            X="North East"
        else:
            pass

    data={"schoolcount":str(sc[0]),"engd_teacher_lsy":str(engd_teacher_lsy[0]),"engd_teacher_csy":str(engd_teacher_csy[0]),
    "engd_parent_csy":str(engd_parent_csy[0]),"engd_parent_lsy":str(engd_parent_lsy[0]), "engaged_school_csy":str(engdschool_csy[0]),"engaged_school_lsy":str(engdschool_lsy[0]),"teachercount":str(tc[0]),"familycount":str(fc[0]),"teacherpracticecount":str(pct[0]),"parentspracticecount":str(pcp[0]),
    'MINDFUL_MINUTES':str(round(int(mm[0]))),'rating':str(round(rating[0],1)),'state':str(state[0]),'MINDFUL_MINUTES_Teacher':str(round(int(mmt[0]))),'MINDFUL_MINUTES_parent':str(round(int(mmp[0]))),'district':X,"practicecount":str(pc[0]),'category':str(ca[0]),'partnercategory':str(Pa[0])}
    return json.dumps(data)






@app.route('/minidistrictschooltable/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_district_school_table(LOCAl_DISTRICT,startdate,enddate):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    from flask import request
    collection2=db.school_master
    collection=db.user_master
    collection1=db.audio_track_master
    collection3=db.subscription_master
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
    

    df2=DataFrame(list(collection.aggregate([{"$match":
         {'$and': [
#         {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},


    # //               {'IS_ADMIN':'Y'},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},

                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'date':{'$min':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
                      'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},



            {'$project':{'_id':1,'usercount':{'$size':'$ID'},'Created_date':'$date','country':1,'State':1,'school_name':1,'city':1}},



  
                                            ])))

    ids=df2['_id'].tolist()


    df3 = DataFrame(list(collection1.aggregate([
    {"$match":
         {'$and': [
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
    # //        
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    #                  
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','ID':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},'prog':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}}},
                  {'$project':{'_id':1,'Practice_Count':'$ID','program':1,'last_practice_date':'$last_practice_date'}},
                   ]))).fillna(0)
    if df3.empty==True:
        df3=pd.DataFrame({'_id':ids})
        df3['last_practice_date'] = pd.Series(['NO PRACTICE' for x in range(len(df3.index))])
        df3['Practice_Count'] = pd.Series([0 for x in range(len(df3.index))])
#         df3['Mindful_Minutes_overall'] = pd.Series([0 for x in range(len(df0.index))])
    column3 =['_id','last_practice_date']
    for i in column3:
        df3=df3.fillna('')
        if i not in df3.columns:
            df3[i] = 'No info' 
    df_ = DataFrame(list(collection1.aggregate([
    {"$match":
         {'$and': [
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
    # //        
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'MODIFIED_DATE':{"$gte": csy_first_date(),
                              }},
    #                  
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','ID':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},'prog':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}}},
                  {'$project':{'_id':1,'Practice_Count_csy':'$ID'}},
                   ]))).fillna(0)
    if df_.empty==True:
        df_=pd.DataFrame({'_id':ids})
#         df_['last_practice_date'] = pd.Series(['NO PRACTICE' for x in range(len(df_.index))])
        df_['Practice_Count_csy'] = pd.Series([0 for x in range(len(df_.index))])
#         df3['Mindful_Minutes_overall'] = pd.Series([0 for x in range(len(df0.index))])
#     column_ =['_id','Practice_Count_csy']
#     for i in column_:
#         df_=df_.fillna('')
#         if i not in df_.columns:
#             df_[i] = 'No info' 
    df__ = DataFrame(list(collection1.aggregate([
    {"$match":
         {'$and': [
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
    # //        
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
             {'MODIFIED_DATE':{"$gte": LSY_Date() ,
                               "$lte": csy_first_date()
                             }},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','ID':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}},'prog':{'$first':'$PROGRAM_AUDIO_ID.PROGRAM_ID.PROGRAM_NAME'}}},
                  {'$project':{'_id':1,'Practice_Count_lsy':'$ID'}},
                   ])))
    if df__.empty==True:
        df__=pd.DataFrame({'_id':ids})
#         df_['last_practice_date'] = pd.Series(['NO PRACTICE' for x in range(len(df_.index))])
        df__['Practice_Count_lsy'] = pd.Series([0 for x in range(len(df__.index))])
#         df3['Mindful_Minutes_overall'] = pd.Series([0 for x in range(len(df0.index))])
#     column__ =['_id','Practice_Count_lsy']
#     for i in column_:
#         df__=df__.fillna('')
#         if i not in df__.columns:
#             df__[i] = 'No info' 
    df4 = DataFrame(list(collection3.aggregate([
    {"$match":
         {'$and': [
#              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},  
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
#              {'USER_ID.CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
    #                  
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID.schoolId._id','subsdate':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$SUBSCRIPTION_EXPIRE_DATE'}}}}},
                  {'$project':{'_id':1,'program':1,'Subscription_expire_date':'$subsdate'}},
                   ])))
    df5=pd.merge(df2,df3, how='left', on='_id')
    dff=pd.merge(df5,df_, how='left', on='_id')
    dfff=pd.merge(dff,df__, how='left', on='_id')
    df=pd.merge(dfff,df4, how='left', on='_id')
    df.rename(columns = { '_id': 'schoolid_'}, inplace = True)
    df['school_name'].fillna("NO INFO", inplace=True)
    df['country'].fillna("NO INFO", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count_lsy=df.Practice_Count_lsy.fillna(0)
    df.Practice_Count_csy=df.Practice_Count_csy.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
    df.Practice_Count_csy=df.Practice_Count_csy.astype('int64')
    df.Practice_Count_lsy=df.Practice_Count_lsy.astype('int64')
    df.usercount=df.usercount.fillna(0)
    df.usercount=df.usercount.astype('int64')   
    df['school_name'].replace("",'NO INFO', inplace=True)
    df['city'].replace("",'NO INFO', inplace=True)
    df['State'].replace("",'NO INFO', inplace=True)
    df['country'].replace("",'NO INFO', inplace=True)
    
    df['city'].fillna("NO INFO", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['State'].fillna("NO INFO", inplace=True)
    df['State'].replace("NULL","NO INFO", inplace=True)
   
    df['Created_date']=df['Created_date'].fillna(0)
    df['last_practice_date']=df['last_practice_date'].fillna('NO PRACTICE')
    df['Subscription_expire_date']=df['Subscription_expire_date'].fillna('No Info')
    df['label'] = np.where(df['Practice_Count_csy']!= 0, 'ENGAGED IN CSY', 'ENGAGED IN LSY')
    df.loc[(df['Practice_Count_lsy']==0) & (df['Practice_Count_csy']== 0), 'label']='INACTIVE'

    if "export" in request.args:
        try:
            df1=df[['school_name','country','State','city','Practice_Count',
                    'Practice_Count_csy','Practice_Count_lsy','usercount',
                    'Created_date','last_practice_date','Subscription_expire_date','label']]
            csv = df1.to_csv(index=False)
            return Response(
                csv,
                mimetype="text/csv",
                headers={"Content-disposition":
                        "attachment; filename=SchoolData.csv"})
        except:
            return jsonify("Unauthorized Access")   
    else:
        data=[]
        for i,j,k,l,m,n,o,p,r,s,q,x,z in zip(df['school_name'].tolist(),df['country'].tolist(),df['State'].tolist(),df['city'].tolist(),df['Practice_Count'].tolist(),df['Practice_Count_csy'].tolist(),df['Practice_Count_lsy'].tolist(),df['Created_date'].tolist(),df['last_practice_date'].tolist(),df['usercount'].tolist(),df['Subscription_expire_date'].tolist(),df['label'].tolist(),df['schoolid_'].tolist()):
            data.append([i,j,k,l,m,n,o,p,r,s,q,x,z])
        temp={"data":data}
        #     return df

        return json.dumps(temp,default=str)

# mini_district_school_table_parent

@app.route('/minidistrictusertableparent/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_district_table_parent(LOCAl_DISTRICT,startdate,enddate):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 

    
    collection2=db.school_master
    collection=db.user_master
    collection1=db.audio_track_master
    collection3=db.subscription_master
#     district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

    from datetime import datetime


    

    df2=DataFrame(list(collection.aggregate([{"$match":
         {'$and': [
            {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                 {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$_id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'school_id':{'$first':'$schoolId._id'},'user_name':{'$first':'$USER_NAME'},'EMAIL':{'$first':'$EMAIL_ID'},'date':{'$first':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
                      'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},


            {'$project':{'_id':1,'Created_date':'$date','country':1,'State':1,'user_name':1,'EMAIL':1,'school_name':1,'city':1,'school_id':'$school_id'}}])))
    a=df2['_id'].tolist()
    b=[0]*len(a)
    c=['No Practice']*len(a)
    
    
    df3=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'user_id':'$user','Practice_Count':'$pc','last_practice_date':1}}])))
    
    if df3.empty is True:
        df3=pd.DataFrame(list(zip(a, b,c)),
               columns =['_id', 'Practice_Count','last_practice_date'])
    else:
        df3

    df_=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
             {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
             {'MODIFIED_DATE':{"$gte": csy_first_date() ,
                             }},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'Practice_Count_csy':'$pc'}}])))
    if df_.empty is True:
        df_=pd.DataFrame(list(zip(a, b)),
               columns =['_id', 'Practice_Count_csy'])
    else:
        df_

    df__=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
             {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
             {'MODIFIED_DATE':{"$gte": LSY_Date() ,
                               "$lte": csy_first_date()
                             }},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'Practice_Count_lsy':'$pc',}}])))

    if df__.empty is True:
        df__=pd.DataFrame(list(zip(a, b)),
               columns =['_id', 'Practice_Count_lsy'])
    else:
        df__



#     df4 = DataFrame(list(collection3.aggregate([
#     {"$match":
#          {'$and': [
#                  {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
#                 {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#                   {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#                  {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#                 { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     #             {'USER_ID._id':{'$in':user}},
#             {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},

#                  {'USER_ID.EMAIL_ID':{'$ne':''}},
# #              {'USER_ID.CREATED_DATE':{"$gte": myDatetime1 ,
# #                              "$lte":myDatetime2}},
# #     #                  
#                  {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#                            {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                              {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
#             {'$group':{'_id':'$USER_ID._id','subsdate':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$SUBSCRIPTION_EXPIRE_DATE'}}}}},
#                   {'$project':{'_id':1,'Subscription_expire_date':'$subsdate'}},
#                    ])))

    df5=pd.merge(df2,df3, how='left', on='_id')
    dff=pd.merge(df5,df_, how='left', on='_id')
    df=pd.merge(dff,df__, how='left', on='_id')
#     df=pd.merge(df5,df4, how='left', on='_id')
    df


    df['country'].fillna("NO INFO", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
    df.Practice_Count_lsy=df.Practice_Count_lsy.fillna(0)
    df.Practice_Count_csy=df.Practice_Count_csy.fillna(0)
#     df.Practice_Count=df.Practice_Count.astype('int64')
    df.Practice_Count_csy=df.Practice_Count_csy.astype('int64')
    df.Practice_Count_lsy=df.Practice_Count_lsy.astype('int64')

    df['school_name'].replace("",'NO INFO', inplace=True)
    df['city'].replace("",'NO INFO', inplace=True)
    df['State'].replace("",'NO INFO', inplace=True)
    df['country'].replace("",'NO INFO', inplace=True)
    df['user_name'].replace("",'NO INFO', inplace=True)
    df['EMAIL'].replace("",'NO INFO', inplace=True)
    df['city'].fillna("NO INFO", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['State'].fillna("NO INFO", inplace=True)
    df['State'].replace("NULL","NO INFO", inplace=True)



    df['Created_date']=df['Created_date'].fillna(0)
    df['last_practice_date']=df['last_practice_date'].fillna('NO PRACTICE')
    df['label'] = np.where(df['Practice_Count_csy']!= 0, 'ENGAGED IN CSY', 'ENGAGED IN LSY')
    df.loc[(df['Practice_Count_lsy']==0) & (df['Practice_Count_csy']== 0), 'label']='INACTIVE'
#     df['Subscription_expire_date']=df['Subscription_expire_date'].fillna('No Info')

    if "export" in request.args:
        try:
            df1=df[['user_name','EMAIL','school_name','country','State','city','Practice_Count',
                    'Practice_Count_csy','Practice_Count_lsy',
                    'Created_date','last_practice_date','label']]
            csv = df1.to_csv(index=False)
            return Response(
                csv,
                mimetype="text/csv",
                headers={"Content-disposition":
                        "attachment; filename=ParentData.csv"})
        except:
            return jsonify("Unauthorized Access")    
    else:
        data=[]
        for i,j,k,l,m,n,o,p,r,q,s,x,z in zip(df['user_name'].tolist(),df['school_name'].tolist(),df['country'].tolist(),
                                             df['State'].tolist(),df['city'].tolist(),df['Practice_Count'].tolist(),df['Practice_Count_csy'].tolist(),
                                             df['Practice_Count_lsy'].tolist(),df['Created_date'].tolist(),df['last_practice_date'].tolist(),df['EMAIL'].tolist(),
                                             df['label'].tolist(),df['school_id'].tolist()):
            data.append([i,j,k,l,m,n,o,p,r,q,s,x,z])
        temp={"data":data}
    #     return df
        return json.dumps(temp,default=str)

# mini_district_school_table_teachers

@app.route('/minidistrictusertableteacher/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_district_user_table_teacher(LOCAl_DISTRICT,startdate,enddate):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 

    
    collection2=db.school_master
    collection=db.user_master
    collection1=db.audio_track_master
    collection3=db.subscription_master
#     district=disdic[districtid]
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

    from datetime import datetime


    

    df2=DataFrame(list(collection.aggregate([{"$match":
         {'$and': [
            {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    #                 {'_id':{'$in':user}},
    # //               {'IS_ADMIN':'Y'},
              {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#              {'CREATED_DATE':{"$gte": myDatetime1 ,
#                              "$lte":myDatetime2}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$_id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'school_id':{'$first':'$schoolId._id'},'user_name':{'$first':'$USER_NAME'},'EMAIL':{'$first':'$EMAIL_ID'},'date':{'$first':{"$dateToString": { "format": "%Y-%m-%d", "date":'$CREATED_DATE'}}},'country':{'$first':'$schoolId.COUNTRY'},
                      'State':{'$first':'$schoolId.STATE'},'city':{'$first':'$schoolId.CITY'}}},


            {'$project':{'_id':1,'Created_date':'$date','country':1,'State':1,'user_name':1,'EMAIL':1,'school_name':1,'city':1,'school_id':'$school_id'}},])))


    a=df2['_id'].tolist()
    b=[0]*len(a)
    c=['No Practice']*len(a)
    df3=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
              {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
             {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'user_id':'$user','Practice_Count':'$pc','last_practice_date':1}}])))
    if df3.empty is True:
        df3=pd.DataFrame(list(zip(a, b,c)),
               columns =['_id', 'Practice_Count','last_practice_date'])
    else:
        df3
    df_=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
             {'MODIFIED_DATE':{"$gte": csy_first_date() ,
                             }},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'Practice_Count_csy':'$pc'}}])))
    if df_.empty is True:
        df_=pd.DataFrame(list(zip(a, b)),
               columns =['_id', 'Practice_Count_csy'])
    else:
        df_

    df__=DataFrame(list(collection1.aggregate([
     {"$match":
         {'$and': [
              {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
                {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
                  {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
                 {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    # //             {'USER_ID.IS_PORTAL':'Y'},
                 {'USER_ID.EMAIL_ID':{'$ne':''}},
    #                  {'USER_ID.DISTRICT_ID._id':{'$eq':ObjectId(""+districtid+"")}},
                                {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
    #              {'USER_ID.DISTRICT_ID.DISTRICT_NAME':'Sarasota County'},
#                  {'MODIFIED_DATE':{'$gte':datetime(2020,8,1)}},
            {'MODIFIED_DATE':{"$gte": LSY_Date() ,
                               "$lte": csy_first_date()
                             }},
    # //              {'EMAIL_ID':{'$regex':'broward','$options':'i'}},
                 {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$USER_ID._id','user':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'last_practice_date':{'$max':{"$dateToString": { "format": "%Y-%m-%d", "date":'$MODIFIED_DATE'}}}}},
                  {'$project':{'_id':1,'Practice_Count_lsy':'$pc',}}])))
    if df__.empty is True:
        df__=pd.DataFrame(list(zip(a, b)),
               columns =['_id', 'Practice_Count_lsy'])
    else:
        df__





    df5=pd.merge(df2,df3, how='left', on='_id')
    dff=pd.merge(df5,df_, how='left', on='_id')
    df=pd.merge(dff,df__, how='left', on='_id')
#     df=pd.merge(df5,df4, how='left', on='_id')
    df


    df['country'].fillna("NO INFO", inplace=True)
    df.Practice_Count=df.Practice_Count.fillna(0)
    df.Practice_Count=df.Practice_Count.astype('int64')
    df.Practice_Count_lsy=df.Practice_Count_lsy.fillna(0)
    df.Practice_Count_csy=df.Practice_Count_csy.fillna(0)
#     df.Practice_Count=df.Practice_Count.astype('int64')
    df.Practice_Count_csy=df.Practice_Count_csy.astype('int64')
    df.Practice_Count_lsy=df.Practice_Count_lsy.astype('int64')

    df['school_name'].replace("",'NO INFO', inplace=True)
    df['city'].replace("",'NO INFO', inplace=True)
    df['State'].replace("",'NO INFO', inplace=True)
    df['country'].replace("",'NO INFO', inplace=True)
    df['user_name'].replace("",'NO INFO', inplace=True)
    df['EMAIL'].replace("",'NO INFO', inplace=True)
    df['city'].fillna("NO INFO", inplace=True)
    df['city'].replace("NULL","NO INFO", inplace=True)
    df['State'].fillna("NO INFO", inplace=True)
    df['State'].replace("NULL","NO INFO", inplace=True)



    df['Created_date']=df['Created_date'].fillna(0)
    df['last_practice_date']=df['last_practice_date'].fillna('NO PRACTICE')
    df['label'] = np.where(df['Practice_Count_csy']!= 0, 'ENGAGED IN CSY', 'ENGAGED IN LSY')
    df.loc[(df['Practice_Count_lsy']==0) & (df['Practice_Count_csy']== 0), 'label']='INACTIVE'
#     df['Subscription_expire_date']=df['Subscription_expire_date'].fillna('No Info')
    if "export" in request.args:
        try:
            df1=df[['user_name','EMAIL','school_name','country','State','city','Practice_Count',
                    'Practice_Count_csy','Practice_Count_lsy',
                    'Created_date','last_practice_date','label']]
            csv = df1.to_csv(index=False)
            return Response(
                csv,
                mimetype="text/csv",
                headers={"Content-disposition":
                        "attachment; filename=TeacherData.csv"})
        except:
            return jsonify("Unauthorized Access")  
    else:

        data=[]
        for i,j,k,l,m,n,o,p,r,q,s,x,z in zip(df['user_name'].tolist(),df['school_name'].tolist(),df['country'].tolist(),df['State'].tolist(),df['city'].tolist(),df['Practice_Count'].tolist(),
                                             df['Practice_Count_csy'].tolist(),df['Practice_Count_lsy'].tolist(),df['Created_date'].tolist(),
                                             df['last_practice_date'].tolist(),df['EMAIL'].tolist(),
                                             df['label'].tolist(),df['school_id'].tolist()):
            data.append([i,j,k,l,m,n,o,p,r,q,s,x,z])
        temp={"data":data}
    #     return df
        return json.dumps(temp,default=str)
    
    




# Overall Heatmap

@app.route('/mini_districtheatmap_overall/<districtid>/<startdate>/<enddate>')
def mini_heat_district(LOCAl_DISTRICT,startdate,enddate):
    
    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
                                             
                  {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                                                                

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                  {'$sort':{'name':1}}
                      ])))

    ids=list(df['_id'])
    
    
    df22=DataFrame(list(collection.aggregate([
    {"$match":
    {'$and':[
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
    {'MODIFIED_DATE':{"$gte":myDatetime1 ,"$lte":myDatetime2}}]}},
        
    {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
    {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
    { '$sort' : { 'name' : 1,'month'  :1} },
    ])))

    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)

    dislist=list(set(df1["name"]))

    df2=df1[["name","month","active_user_count","practice_count"]]

    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])

    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =active_user_count
        
    data=collections.OrderedDict(sorted(data.items()))
    data={'meanTemp':data}

    
    return json.dumps(data)


# Family Heatmap
@app.route('/mini_districtheatmap_family/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_heat_district_family(LOCAl_DISTRICT,startdate,enddate):
    
    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
                  {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                                                                                                                   

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                  {'$sort':{'name':1}}
                      ])))

    ids=list(df['_id'])
    
    
    df22=DataFrame(list(collection.aggregate([
    {"$match":
    {'$and':[
         {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
    {'MODIFIED_DATE':{"$gte":myDatetime1 ,"$lte":myDatetime2}}]}},
        
    {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
    {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
    { '$sort' : { 'name' : 1,'month'  :1} },
    ])))

    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)

    dislist=list(set(df1["name"]))

    df2=df1[["name","month","active_user_count","practice_count"]]

    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])

    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =active_user_count
        
    data=collections.OrderedDict(sorted(data.items()))
    data={'meanTemp':data}

    
    return json.dumps(data)


# Teacher Heatmap
@app.route('/mini_districtheatmap_classroom/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_heat_district_classroom(LOCAl_DISTRICT,startdate,enddate):
    
    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
                  {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                                                                      

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                  {'$sort':{'name':1}}
                      ])))

    ids=list(df['_id'])
    
    
    df22=DataFrame(list(collection.aggregate([
    {"$match":
    {'$and':[
         {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
    {'MODIFIED_DATE':{"$gte":myDatetime1 ,"$lte":myDatetime2}}]}},
        
    {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
    {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
    { '$sort' : { 'name' : 1,'month'  :1} },
    ])))

    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)

    dislist=list(set(df1["name"]))

    df2=df1[["name","month","active_user_count","practice_count"]]

    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])

    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =active_user_count
        
    data=collections.OrderedDict(sorted(data.items()))
    data={'meanTemp':data}

    
    return json.dumps(data)

# Practice History
@app.route('/mini_district_practice_history/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_districtuser_practice_90days(LOCAl_DISTRICT,startdate,enddate):
    
    from datetime import datetime
    from datetime import timedelta
    
    today1= datetime.utcnow()
    tod1= today1+ timedelta(hours=4)
    start1= tod1-timedelta(days=90)
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection1= db.user_master
    
    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
    
    df_user=DataFrame(list(db.user_master.aggregate([{"$match":
             {'$and': [            
                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
                                                     
              {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                       
                                                           

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                  {'$sort':{'name':1}}
                      ])))

    ids=list(df_user['_id'])
   
    
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},
        {"USER_ID.schoolId._id":{'$in':ids}},
         {'MODIFIED_DATE':{"$gte": myDatetime1 ,"$lte":myDatetime2}},
        {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'user_count':'$pc'}},
    { '$sort' : { '_id' : 1} }    
              ])))
    
    
    if df1.empty:
        df1=pd.DataFrame({'_id':[],'user_count':[]})
    
    df2 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
         {'USER_ID.schoolId._id':{'$in':ids}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
             {'USER_ID.EMAIL_ID':{'$ne':''}},

         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'teachers':'$pc'}},
    { '$sort' : { '_id' : 1} }
    


              ])))
    if df2.empty:
        df2=pd.DataFrame({'_id':[],'teachers':[]})
    
    df3 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
         {'USER_ID.schoolId._id':{'$in':ids}},
         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'parents':'$pc'}},
    { '$sort' : { '_id' : 1} }
    


              ])))
    if df3.empty:
        df3=pd.DataFrame({'_id':[],'parents':[]})
    
    df4 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
{'USER_ID.schoolId._id':{'$in':ids}}  ,       
         
         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'clever':'$pc'}},
    { '$sort' : { '_id' : 1} }
    


              ])))
    if df4.empty:
        df4=pd.DataFrame({'_id':[],'clever':[]})
    
    
    df5 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
            {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},


             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":ids}},
         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'scoology':'$pc'}},
    { '$sort' : { '_id' : 1} }
    


              ])))
    if df5.empty:
        df5=pd.DataFrame({'_id':[],'scoology':[]})
        
        
        
    df6= pd.merge(df1,df2,on='_id',how='left')
    df7= pd.merge(df6,df3,on='_id',how='left')
    df8= pd.merge(df7,df4,on='_id',how='left')
    DF= pd.merge(df8,df5,on='_id',how='left')
    DF=DF.fillna(0)
    DF.rename(columns = { '_id': 'date'}, inplace = True)
    
    
    if DF.empty == True:
        date=[]
        teachers=[]
    else:
        date=DF['date'].tolist()

        T=DF['teachers'].tolist()
        P=DF['parents'].tolist()
        C=DF['clever'].tolist()
        S=DF['scoology'].tolist()
        uc=DF['user_count'].tolist()


    data={'Date':date,'Teachers':T,'Parents':P,'Clever':C,'Scoology':S}
    return json.dumps(data)

# Playback by Month
@app.route('/mini_district_monthwisepracticedistrict/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_districtmonthwisepc(LOCAl_DISTRICT,startdate,enddate):
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection2= db.user_master
    collection = db.audio_track_master

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)
    pre_start= myDatetime1 - relativedelta(years=1)
    print(pre_start)
    pre_end=myDatetime2 - relativedelta(years=1)
    print(pre_end)
    
    df_user=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [            
                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                  {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                                         

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                  {'$sort':{'name':1}}
                      ])))

    ids=list(df_user['_id'])
   
    df0= DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":ids}},
        {'MODIFIED_DATE':{"$gte": pre_start ,
                             "$lte":pre_end}},

         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'practice_count_lsy':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    if df0.empty:
        df0=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'practice_count_lsy':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    
    df1= DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},

         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":ids}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'practice_count':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    if df1.empty:
        df1=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'practice_count':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    df2 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
      {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
        
         {'USER_ID.EMAIL_ID':{'$ne':''}},
        {"USER_ID.schoolId._id":{"$in":ids}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'teachers':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    if df2.empty:
        df2=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'teachers':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    df3 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
      {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":ids}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'parents':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    if df3.empty:
        df3=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'parents':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    df4 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
      {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
                 {"USER_ID.schoolId._id":{"$in":ids}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'clever':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    if df4.empty:
        df4=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'clever':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    df5 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
      {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{"$in":db.schoology_master.distinct("USER_ID._id")}},
            {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
                 {"USER_ID.schoolId._id":{"$in":ids}},


         {'USER_ID.EMAIL_ID':{'$ne':''}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':{'$month':'$MODIFIED_DATE'},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
          {'$project':{'_id':1,'scoology':'$pc'}},
    { '$sort' : { '_id' : 1} }
              ])))
    
    
    if df5.empty:
        df5=pd.DataFrame({'_id':[1,2,3,4,5,6,7,8,9,10,11,12],'scoology':[0,0,0,0,0,0,0,0,0,0,0,0]})
    
    df6= pd.merge(df1,df2,on='_id',how='left')
    df66= pd.merge(df6,df0,on='_id',how='left')
    df7= pd.merge(df66,df3,on='_id',how='left')
    df8= pd.merge(df7,df4,on='_id',how='left')
    df= pd.merge(df8,df5,on='_id',how='left')

    df.rename(columns = { '_id': 'Month'}, inplace = True)

    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 


# Create the pandas DataFrame 
    df9 = pd.DataFrame(data, columns = ['Monthname', 'Month']) 

    DF=pd.merge(df9,df, on='Month',how='left')
    DF=DF.fillna(0)


    if df.empty == True:
        Month=['Aug','Sep','Oct','Nov','Dec','Jan','Feb','Mar','Apr','May','Jun','Jul',]

        T=[0,0,0,0,0,0,0,0,0,0,0,0]
    else:
        Month=DF['Monthname'].tolist()
        
        T=DF['teachers'].tolist()
        P=DF['parents'].tolist()
        C=DF['clever'].tolist()
        S=DF['scoology'].tolist()
        pc=DF['practice_count'].tolist()
        lsy=DF['practice_count_lsy'].tolist()


    data={'monthname':Month,'Teachers':T,'Parents':P,'Clever':C,'Scoology':S,'lsy':lsy}
    return json.dumps(data)


# Top 20 school user count

@app.route('/mini_district_schoolwiseusercounttop20/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_districtschwiseucc(LOCAl_DISTRICT,startdate,enddate):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.user_master

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

    df1 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                {'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    
          {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                       
                  
    
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'user_count':{'$size':'$ID'},'name':'$NAME','district':'$district'}},
                   { '$sort' : { 'user_count' : -1}},
              {'$limit':20}
                  ])))
    if df1.empty:
        df1=pd.DataFrame({'_id':[],'user_count':[]})
    else:
        df1
    school=df1['_id'].tolist()
        
    df0 = DataFrame(list(db.audio_track_master.aggregate([
    {"$match":
    {'$and': [
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
          {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
         {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},

       {'USER_ID.schoolId._id':{'$in':school}},
         {'USER_ID.EMAIL_ID':{'$ne':''}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

         {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
    {'$group':{'_id':'$USER_ID.schoolId._id','pc':{'$addToSet':'$USER_ID._id'},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
          {'$project':{'_id':1,'active':{'$size':'$pc'}}},
    { '$sort' : { 'active' : -1} },
         {'$limit':20}
          ])))
    if df0.empty:
        df0=pd.DataFrame({'_id':[],'active':[]})
    
    df2 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"_id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"_id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'teachers':{'$size':'$ID'}}},
                   { '$sort' : { 'teachers' : -1}},

                  ])))
    if df2.empty:
        df2=pd.DataFrame({'_id':[],'teachers':[]})
    
    df3 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'EMAIL_ID':{'$ne':''}},
#                    
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'parents':{'$size':'$ID'}}},
                   { '$sort' : { 'parents' : -1}},

                  ])))
    if df3.empty:
        df3=pd.DataFrame({'_id':[],'parents':[]})
    
    
    df4 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"_id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"_id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
                {"IS_DISABLED":{"$ne":"Y"}},
             
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'EMAIL_ID':{'$ne':''}},
#                      
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'clever':{'$size':'$ID'}}},
                   { '$sort' : { 'clever' : -1}},

                  ])))
    if df4.empty:
        df4=pd.DataFrame({'_id':[],'clever':[]})
    
    
    df5 = DataFrame(list(collection.aggregate([
    {"$match":
         {'$and': [
             {'ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"_id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
            {"_id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
            {'$group':{'_id':'$schoolId._id','ID':{'$addToSet':'$_id'},'NAME':{'$first':'$schoolId.NAME'},'district':{'$first':'$DISTRICT_ID.DISTRICT_NAME'}}},
                  {'$project':{'_id':1,'scoology':{'$size':'$ID'}}},
                   { '$sort' : { 'scoology' : -1}},
#               {'$limit':20}
                  ])))
    if df5.empty:
        df5=pd.DataFrame({'_id':[],'scoology':[]})
    
    
    df6= pd.merge(df1,df0,on='_id',how='left')
    df9= pd.merge(df6,df2,on='_id',how='left')
    df7=pd.merge(df9,df3,on='_id',how='left')
    df8=pd.merge(df7,df4,on='_id',how='left')
    df=pd.merge(df8,df5,on='_id',how='left')
    
    df=df.fillna(0)
    df

 

    if df.empty == True:
        
        schname=[]
        teacher=[]
        parent=[]
        clever=[]
        scoology=[]
        active=[]
      
    else:
        schname=df['name'].tolist()
        teacher=df['teachers'].tolist()
        parent=df['parents'].tolist()
        clever=df['clever'].tolist()
        scoology=df['scoology'].tolist()
        active=df['active'].tolist()
   
    data={'schname':schname,'Teachers':teacher,'Parents':parent,'Clever':clever,'Scoology':scoology,'active':active}
    
    return json.dumps(data)

# Top 20 champions in CSY
@app.route('/mini_district_top20userspractisinginfo/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_district_topusers_practice(LOCAl_DISTRICT,startdate,enddate):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)


    collection1 = db.user_master
    
    df_user=DataFrame(list(collection1.aggregate([{"$match":
             {'$and': [            
                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
                                                  
                  {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                       
                                                    

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                  {'$sort':{'name':1}}
                      ])))

    ids=list(df_user['_id'])
   
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [

            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
             {"USER_ID.schoolId._id":{"$in":ids}},
                {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':'$USER_ID._id','pc':{'$sum':1}}},
              {'$project':{'_id':1,'practice_count':'$pc'}},
    { '$sort' : { 'practice_count' : -1} }


              ])))
    if df1.empty == True:

        schname=[]
        pc=[]
        
    else:

        df2=DataFrame(list(collection1.aggregate([{"$match":
         {'$and': [

                {"IS_DISABLED":{"$ne":"Y"}},
                  {"IS_BLOCKED":{"$ne":"Y"}},
                 {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                 {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

            {'$group':{'_id':'$_id','ID':{'$addToSet':'$_id'},'school_name':{'$first':'$schoolId.NAME'},'user_name':{'$first':'$USER_NAME'}
                      }},


            {'$project':{'_id':1,'user_name':1,'school_name':1}},]))).fillna('No info')

        df=pd.merge(df1,df2, how='left', on='_id')
        df
        if df.empty == True:

            schname=[]
            pc=[]

        else:
            df["users"] = df["user_name"] +','+' ' + df["school_name"]
            schname=df['users'].tolist()
            pc=df['practice_count'].tolist()

    data={'schname':schname[0:20],'practicecount':pc[0:20]}

    return json.dumps(data)

# Sentiment analysis

@app.route('/mini_district_districtsentimentdonut_csy/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_district_dis_sentiment_pie(LOCAl_DISTRICT,startdate,enddate):
    clean_list=[]
    news_headlines_senti = []
    news_headlines_dict = {}
    pnews_headlines=0
    nnews_headlines=0
    nenews_headlines = 0
    today = date.today()
    d1 = today.strftime("%Y-%m-%d")
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)


    df1=DataFrame(list(db.user_master.aggregate([
        {"$match":
         {
            '$and':[
             {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}
            ]

         }},

          {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                       

        {'$project':{'_id':'$_id','school':'$schoolId._id' }}
        ])))


    userid=df1['_id'].tolist() 
    x=['NA','N/A','n.a','.\n',"a\\n","a\n","v\n","v\\n","0-",'na\n','na','Write a feedback (optional)','Na','k,n/l','[pppppppppppsz']
    user=[
    {"$match":{'$and':[ {'USER._id':{'$in':userid}},
                    {'COMMENT':{'$exists':1}},
                       {'COMMENT':{'$ne':''}},
                       {'COMMENT':{'$ne':None}},
                        {'COMMENT':{'$nin':x}},

         {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}
                         ,
                        ]}},
    { "$project": { "USER_ID": "$USER._id", "USER_NAME": "$USER.USER_NAME","_id":0, "EMAIL": "$USER.EMAIL_ID", "RATING":1,
    "LAST_COMMENT_DATE": "$MODIFIED_DATE", "AUDIO_NAME": "$AUDIO_ID.AUDIO_NAME", "NARRATOR_NAME": "$AUDIO_ID.NARRATEDBY",
    "COMMENT":1, "PROGRAM_NAME": "$AUDIO_ID.PROGRAM_ID.PROGRAM_NAME"}}
    ]
    update=list(collection.aggregate(user))
    df=pd.DataFrame(update).fillna("no info")

    if df.empty is True:
        word_chart={'donut':{'pos':0,'neg':0,'neu':0},'text':['pos','neg','neu']}
        return json.dumps(word_chart)
    else:

        text=df["COMMENT"].to_list()
        df=df[['COMMENT']]
        df = df.sample(frac=1.0).reset_index(drop=True)
        for i in df['COMMENT'].tolist():
            df = df[df.COMMENT.str.len()!=1] 

        import nltk
        nltk.download('vader_lexicon')

        from nltk.sentiment.vader import SentimentIntensityAnalyzer
        sia = SentimentIntensityAnalyzer()
        df['Positivity'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['pos'])
        df['Negativity'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['neg'])
        df['Neutrality'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['neu'])
        df['Compound'] = df['COMMENT'].apply(lambda x: sia.polarity_scores(x)['compound'])
        pd.pandas.set_option('display.max_rows',None)  
        neg=df[df['Compound']<0]
        pos=df[df['Compound']>0]
        neu=df[df['Compound']==0]
        neg_sentiment=round(100*(len(neg)/(len(neu)+len(neg)+len(pos))),2)
        pos_sentiment=round(100*(len(pos)/(len(neu)+len(neg)+len(pos))),2)
        neu_sentiment=round(100*(len(neu)/(len(neu)+len(neg)+len(pos))),2)
        word_chart={'donut':{'pos':pos_sentiment,'neg':neg_sentiment,'neu':neu_sentiment},'text':['pos','neg','neu']}
        return json.dumps(word_chart)


@app.route('/mini_district_districtfeedbackrating_csy/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_district_dis_schoolrating_csy__(LOCAl_DISTRICT,startdate,enddate):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection = db.audio_feedback

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

    df1=DataFrame(list(db.user_master.aggregate([
        {"$match":
         {
            '$and':[

             {"IS_DISABLED":{"$ne":"Y"}},
              {"IS_BLOCKED":{"$ne":"Y"}},
             {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                {'EMAIL_ID':{'$ne':''}},
                 {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
             { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
         { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                           {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                             {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]

         }},
        {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                       
        
        
        {'$project':{'_id':'$_id','school':'$schoolId._id' }}
        ])))
    
  
    user=df1['_id'].tolist() 


    df = DataFrame(list(collection.aggregate([
     {"$match":{'$and':[
           {'USER._id':{'$in':user}},

        {'RATING':{'$ne':0}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}},

     ]}},

    {'$group':{'_id':'$RATING' ,'count':{'$sum':1}}},
           {'$sort':{'_id':-1}}

    ])))

    if df.empty is True:
        temp={"donut":0}

        return json.dumps(temp)
    
    else:
        
        df['_id']=df['_id'].replace({5:'five', 4:'four',3:'three',2:'two',1:'one'})

        dff=df.set_index("_id")["count"].to_dict()

        dff={str(k):int(v) for k,v in dff.items()}

        temp={"donut":dff}

        return json.dumps(temp)


# last 90 days practice history
@app.route('/mini_district_last90daysuserpractising/<LOCAl_DISTRICT>')
def mini_district_last_practice_90days_(LOCAl_DISTRICT):
    
    from datetime import datetime
    from datetime import timedelta
    
    today1= datetime.utcnow()
    tod1= today1+ timedelta(hours=4)
    start1= tod1-timedelta(days=90)
    
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master

    df_user=DataFrame(list(db.user_master.aggregate([{"$match":
             {'$and': [            
                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
     {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'}, 
    "LOCAl_DISTRICT":{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
                  {'$sort':{'name':1}}
                      ])))

    ids=list(df_user['_id'])
    
    
    df1 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
# //               {'IS_ADMIN':'Y'},
# //             {'USER_ID.IS_PORTAL':'Y'},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":ids}},
         {'MODIFIED_DATE':{"$gte": start1}},
             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'user_count':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

              ])))
    if df1.empty:
        df1=pd.DataFrame({'_id':[],'user_count':[]})
    
    df2 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":ids}},
         {'MODIFIED_DATE':{"$gte": start1}},

             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'teachers':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

              ])))
    if df2.empty:
        df2=pd.DataFrame({'_id':[],'teachers':[]})
    
    df3 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":ids}},
         {'MODIFIED_DATE':{"$gte": start1}},

             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'parents':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

              ])))
    if df3.empty:
        df3=pd.DataFrame({'_id':[],'parents':[]})
    
    df4 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{'$not':{"$in":db.schoology_master.distinct( "USER_ID._id")}}},
            {"USER_ID._id":{"$in":db.clever_master.distinct( "USER_ID._id")}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
                  {"USER_ID.schoolId._id":{"$in":ids}},
         {'MODIFIED_DATE':{"$gte": start1}},

             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'clever':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df4.empty:
        df4=pd.DataFrame({'_id':[],'clever':[]})
    
    
    df5 = DataFrame(list(collection.aggregate([
    {"$match":
     {'$and': [
    {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID._id":{"$in":db.schoology_master.distinct( "USER_ID._id")}},
            {"USER_ID._id":{'$not':{"$in":db.clever_master.distinct( "USER_ID._id")}}},
            {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
              {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
               {"USER_ID.schoolId._id":{"$in":ids}},  
      
             {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
            { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
            {'USER_ID.schoolId._id':{'$ne':None}},
             {'USER_ID.EMAIL_ID':{'$ne':''}},
         {'MODIFIED_DATE':{"$gte":start1}},

             {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
        {'$group':{'_id':{"$dateToString": { "format": "%Y-%m-%d", "date": "$MODIFIED_DATE"}},'pc':{'$sum':1},'district':{'$first':'$USER_ID.DISTRICT_ID.DISTRICT_NAME'}}},
              {'$project':{'_id':1,'scoology':'$pc'}},
    { '$sort' : { '_id' : 1} }
    

# //               {'$count':'count'}
              ])))
    if df5.empty:
        df5=pd.DataFrame({'_id':[],'scoology':[]})
        
        
        
    df6= pd.merge(df1,df2,on='_id',how='left')
    df7= pd.merge(df6,df3,on='_id',how='left')
    df8= pd.merge(df7,df4,on='_id',how='left')
    DF= pd.merge(df8,df5,on='_id',how='left')
    DF=DF.fillna(0)
    # df['SCH_CREATED_DATE']=pd.to_datetime(df['SCH_CREATED_DATE'])
    DF.rename(columns = { '_id': 'date'}, inplace = True)
    
    
    if DF.empty == True:
        date=[]
        teachers=[]
    else:
        date=DF['date'].tolist()

        T=DF['teachers'].tolist()
        P=DF['parents'].tolist()
        C=DF['clever'].tolist()
        S=DF['scoology'].tolist()
        uc=DF['user_count'].tolist()


    data={'Date':date,'Teachers':T,'Parents':P,'Clever':C,'Scoology':S}
    return json.dumps(data)


# Family Wise Playback Heat Map
@app.route('/mini_districtheatmappracfamily/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_district_heat_district_family_prac(LOCAl_DISTRICT,startdate,enddate):
    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},                  
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
               {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                       
                                                  

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
               {'$sort':{'name':1}}

                      ])))

    ids=list(df['_id'])
    
    
    df22=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            
             {'USER_ID.ROLE_ID._id' :{'$eq':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    # df2
    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =practice_count
    data=collections.OrderedDict(sorted(data.items()))
    df['_id']=df['_id'].astype(str)
    schoolid=  df['_id'].tolist()
    schoolname=  df['name'].tolist()
    data={'meanTemp':data,'schoolid':dict(zip(schoolname,schoolid))}
    return json.dumps(data)



# Teacher Wise Playback Heat Map 
@app.route('/mini_districtheatmappracclassroom/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_district_heat_district_classroom_prac(LOCAl_DISTRICT,startdate,enddate):
    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
                                             
                     {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                       
                                            

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
               {'$sort':{'name':1}}

                      ])))

    ids=list(df['_id'])
    
    
    df22=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
            
             {'USER_ID.ROLE_ID._id' :{'$ne':ObjectId("5f155b8a3b6800007900da2b")}},
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    # df2
    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =practice_count
    data=collections.OrderedDict(sorted(data.items()))
    df['_id']=df['_id'].astype(str)
    schoolid=  df['_id'].tolist()
    schoolname=  df['name'].tolist()
    data={'meanTemp':data,'schoolid':dict(zip(schoolname,schoolid))}
    return json.dumps(data)


# Overall Parctice Heatmap
@app.route('/mini_districtheatmappracOverall/<LOCAl_DISTRICT>/<startdate>/<enddate>')
def mini_district_heat_district_Overall_prac(LOCAl_DISTRICT,startdate,enddate):
    import collections
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass 
    collection = db.audio_track_master
    collection2=db.user_master

    myDatetime1 = dateutil.parser.parse(startdate)
    myDatetime2 = dateutil.parser.parse(enddate)

   

    df=DataFrame(list(collection2.aggregate([{"$match":
             {'$and': [
                

                    {"IS_DISABLED":{"$ne":"Y"}},
                      {"IS_BLOCKED":{"$ne":"Y"}},
                     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
                    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
                    {'schoolId._id':{'$ne':None}},
                     {'EMAIL_ID':{'$ne':''}},
                     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},
                                             
                 {'$match':{'$or':[
                    {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':'lausd', '$options':'i'},
                    'LOCAl_DISTRICT':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}},   

                    {"schoolId._id":{"$in":db.school_master.distinct("_id", {"IS_PORTAL": "Y",
                    'CATEGORY':{'$regex':'San Bernardino County', '$options':'i'},
                    'SUB_CATEGORY':{'$regex':LOCAl_DISTRICT, '$options':'i'}})}}           

                    ]}},                                                                                                                       
                                                

                {'$group':{'_id':'$schoolId._id','ID':{'$first':'$schoolId.NAME'}}},
                      {'$project':{'_id':1,'name':'$ID'}},
               {'$sort':{'name':1}}

                      ])))

    ids=list(df['_id'])
    
    
    df22=DataFrame(list(collection.aggregate([
    {"$match":
        {'$and': [
                        
            {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    {'USER_ID.schoolId._id':{'$in':ids}},
        {'MODIFIED_DATE':{"$gte": myDatetime1 ,
                             "$lte":myDatetime2}}]}},


            {'$group':{'_id':{'school':'$USER_ID.schoolId._id','month':{'$month':'$MODIFIED_DATE'}},'uc':{'$addToSet':'$USER_ID._id'},'pc':{'$sum':1},'NAME':{'$first':'$USER_ID.schoolId.NAME'}}},
                  {'$project':{'_id':0,'_id':'$_id.school','month':'$_id.month','active_user_count':{'$size':'$uc'},'school':'$NAME','practice_count':'$pc'}},
        { '$sort' : { 'name' : 1,'month'  :1} },


    # //               {'$count':'count'}
                  ])))
    # df2
    if df22.empty is True:
        df["month"]=0
        df["active_user_count"]=0
        df["practice_count"]=0
        df1=df
    else:
        df2=pd.merge(df,df22, on='_id',how='left')
        df1=df2
    df1=df1.sort_values(by=['name'], ascending=True)
    # x=df1[df1['NAME_DISTRICT']=="Belleville School District"]
    dislist=list(set(df1["name"]))
    # print(len(dislist))
    df2=df1[["name","month","active_user_count","practice_count"]]
    # print(df2)
    overall=pd.DataFrame(columns=["name","month","active_user_count","practice_count"])
    # overall
    result=[]
    for k in dislist:
    #     print(k)
        df45=df2[df2["name"]==k]
        df45.reset_index()
    #     print(df45)
        for i in range(1,13):
            if i in list(df45["month"]):
                pass
            else:
                a=max(list(df45.index))
                df45.loc[a+i] = [k] +[i]+[0]+[0]
  
        sorted_df =df45.sort_values(by=['month'], ascending=True)
    #     sorted_df1=sorted_df.reset_index()
        result.append(sorted_df)
        DF = pd.concat(result)
    data = [['Aug', 8], ['Sep', 9], ['Oct', 10],['Nov', 11], ['Dec', 12], ['Jan', 1],['Feb', 2], ['Mar', 3], ['Apr', 4],['May', 5], ['Jun', 6], ['Jul', 7]] 

    df9 = pd.DataFrame(data, columns = ['Monthname', 'month']) 

    finaldf=pd.merge(df9,DF, on='month',how='left')
    #     finaldf=finaldf.sort_values(by=['name'])


    data={}
    for i in dislist:


        schoolname= finaldf[(finaldf.name ==i)].reset_index(drop = True)
        active_user_count = schoolname['active_user_count'].tolist()
        practice_count = schoolname['practice_count'].tolist()


        data[i] =practice_count
    data=collections.OrderedDict(sorted(data.items()))
    df['_id']=df['_id'].astype(str)
    schoolid=  df['_id'].tolist()
    schoolname=  df['name'].tolist()
    data={'meanTemp':data,'schoolid':dict(zip(schoolname,schoolid))}
    return json.dumps(data)


# @app.route('/active-teacher_d360/<districtid>/<idd>/<startdate>/<enddate>')
# def weekly_active_teacherss_(districtid,idd,startdate,enddate):
#     username = urllib.parse.quote_plus('admin')
#     password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
#     client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
#     db=client.compass
#     collection= db.audio_track_master

#     district=disdic[districtid]
#     school=idd
# #     school='5f2bca28ba0be61b0c1cd54f'
#     myDatetime1 = dateutil.parser.parse(startdate)
#     myDatetime2 = dateutil.parser.parse(enddate)


#     user_master=DataFrame(list(db.user_master.aggregate([{"$match":
#     {'$and': [
#     {"IS_DISABLED":{"$ne":"Y"}},
#       {"IS_BLOCKED":{"$ne":"Y"}},
#      {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#     { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

#     {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#     # {'schoolId._id':ObjectId(idd)},    
#     {'schoolId._id':{'$ne':None}},
#      {'EMAIL_ID':{'$ne':''}},
#      {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#                {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#                  {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

#     {'$group':{'_id':'$schoolId._id','Schoolname':{'$first':'$schoolId.NAME'}}}

#       ])))



#     df55 = DataFrame(list(collection.aggregate([
#     {"$match":
#     {'$and': [
#     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#     {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_ID.schoolId._id':{'$ne':None}},
#     {'USER_ID.EMAIL_ID':{'$ne':''}},
#      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#     {'USER_ID.schoolId._id':ObjectId(school)},     
#     {'MODIFIED_DATE':{"$gte": csy_first_date()
#     #              "$lte":myDatetime2
#                      }},

#     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#          {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},


#     {'$project':{'_id':'$USER_ID._id', 'practice_date':{"$dateToString":{"format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }},
#                  'week': {'$week': "$MODIFIED_DATE" },
#                 'school':'$USER_ID.schoolId._id', 'schoolname':'$USER_ID.schoolId.NAME',
#     'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
#                     ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}}   ,          


#     {"$match":{'Completion_Percentage':{"$gte":.5}}},

#     {'$group':{'_id':'$school', 'active_users':{'$addToSet':'$_id'}}},
#     {'$project':{'_id':1, 'active_users':{'$size':'$active_users'}}}    

#     ])))   



#     df5 = DataFrame(list(collection.aggregate([
#     {"$match":
#     {'$and': [
#     {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
#     {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
#     {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
#     { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
#     {'USER_ID.schoolId._id':{'$ne':None}},
#     {'USER_ID.EMAIL_ID':{'$ne':''}},
#      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
#         {'USER_ID.schoolId._id':ObjectId(school)},  
#     {'MODIFIED_DATE':{"$gte": csy_first_date()
#     #              "$lte":myDatetime2
#                      }},

#     {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
#     {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
#        {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
#          {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},


#     {'$project':{'_id':'$USER_ID._id', 'practice_date':{"$dateToString":{"format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }},
#                  'week': {'$week': "$MODIFIED_DATE" },
#                 'school':'$USER_ID.schoolId._id', 'schoolname':'$USER_ID.schoolId.NAME',
#     'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
#                     ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}}   ,          


#     {"$match":{'Completion_Percentage':{"$gte":.5}}},


#     { '$sort' : { '_id' : 1} }

#     ])))

#     df6=df5.groupby(['_id','practice_date','week','school','schoolname'], as_index=False).sum()

#     df7=df6.sort_values(by=['school','week'], ascending=False)

#     df8=df7.groupby(['school','_id','week'], as_index=False).agg({'practice_date':'count'}).sort_values(['school','week'], ascending=False)


#     def legend(row):
#         if row['practice_date']==1:
#             return '1 x/week'
#         elif (row['practice_date']>=2) & (row['practice_date']<=4):
#             return '2-4 x/week'
#         else:
#             return 'Daily'


#     df8['legend']= df8.apply(legend, axis=1)

#     df9=df8.groupby(['school','week','legend'], as_index=False).agg({'_id':'count'})

#     df10=pd.merge(df9,df55, left_on='school', right_on='_id', how='left')

#     df11=df10.groupby(['school','week'], as_index=False).agg({'_id_x':'sum'})

#     df12=pd.merge(df11, df55, left_on='school', right_on='_id', how='left')
#     df12['diffrenece']=df12['active_users']-df12['_id_x']

#     def legend(row):
#         if row['diffrenece']!=0:
#             return ('Not Used')

#     df12['legend']=df12.apply(legend, axis=1)

#     df13=pd.concat([df10,df12]).sort_values(['school','week'])
#     df13=df13[['school','week','legend','_id_x','active_users','diffrenece']]

#     df13['diffrenece'].fillna(df13['_id_x'], inplace=True)


#     df13=df13.rename(columns={'diffrenece':'Teachers'})

#     df14=df13[['school', 'week', 'legend','Teachers']]
#     df14['Teachers']=df14['Teachers'].astype(int)
#     # df14=df13[df13['school']==ObjectId('5f2bca46ba0be61b0c1d37c4')]

#     df15=df14.groupby(['school', 'week'], as_index=False).agg(list)

#     legenddd=['Daily', '2-4 x/week', '1 x/week','Not Used']

#     for i in range(len(df15)):
#         if legenddd != df15['legend'][i]:
#             missing=set(legenddd)-set(df15['legend'][i])
#             df15['legend'][i].extend(missing)

#     for j in range(len(df15)):
#         if len(df15['legend'][j]) != len(df15['Teachers'][j]):
#             diff=len(df15['legend'][j])- len(df15['Teachers'][j])
#             zeros=[0.0]*diff
#             str(zeros)
#             df15['Teachers'][j].extend(zeros)

#     df15['new_legend']=np.zeros(len(df15), dtype=int)
#     for w in range(len(df15)):
#         not_none=list(filter(lambda a:a!= None, df15['legend'][w]))
#         df15['new_legend'][w]=not_none



#     legend_list=['Daily','2-4 x/week','1 x/week','Not Used']

#     d={k:v for v,k in enumerate(legend_list)}
#     df15['empty_list'] = np.empty((len(df15), 0)).tolist()

#     for i in range(len(df15)):
#         dictionary=dict(zip(df15['new_legend'][i], df15['Teachers'][i]))
#         from collections import OrderedDict
#         dictionary22=OrderedDict([(el,dictionary[el]) for el in legend_list])
#         x=list(dictionary22.values())
#         df15['empty_list'][i]=x

#     for j in range(len(df15)):
#         given_list=df15['new_legend'][j]
#         given_list.sort(key=d.get)

#     df15['weeks_']= np.zeros(len(df15), dtype=int)

#     for k in range(len(df15)):
#         if (1<=df15['week'][k]<=30):
#             xx=22+df15['week'][k]
#             df15['weeks_'][k]=xx
#         elif(31<=df15['week'][k]<=52):
#             xy=30-df15['week'][k]
#             df15['weeks_'][k]=xy

#     df15['weeks_']=abs(df15['weeks_'])   
#     df15=df15.sort_values(by=['weeks_'], ascending=True)

#     df15['empty_list']=df15['empty_list'].astype(str).str.replace(r'\[|\]|', '')

#     df15['new_legend']=df15['new_legend'].str.join(",")

#     df16=df15[['school','weeks_','new_legend','empty_list']]
#     df16['weeks_']='Week '+ df16['weeks_'].astype(str)

#     df17=pd.merge(df16, user_master, how='left', left_on='school', right_on='_id')

#     dataa=[]
#     for l in range(len(df17)):
#         data=[df17['Schoolname'][l], df17['weeks_'][l], df17['empty_list'][l]]
#         dataa.append(data)

#     list1=[]
#     for ll in range(len(dataa)):
#         dataa[ll][2]=dataa[ll][2].split(',')
#         qq=[int(float(x)) for x in dataa[ll][2]]
#         m=dataa[ll][0:2]+qq
#         list1.append(m)


#     temp={'data':list1, 'schools':user_master['Schoolname'].tolist()}

#     return json.dumps(temp)


@app.route('/active_teachersSchoolSearch/<idd>')
def active_teachers_schoolsearch(idd):
    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection= db.audio_track_master

#     district=disdic[districtid]
    school=idd
#     school='5f2bca28ba0be61b0c1cd54f'
#     myDatetime1 = dateutil.parser.parse(startdate)
#     myDatetime2 = dateutil.parser.parse(enddate)


    user_master=DataFrame(list(db.user_master.aggregate([{"$match":
    {'$and': [
    {"IS_DISABLED":{"$ne":"Y"}},
      {"IS_BLOCKED":{"$ne":"Y"}},
     {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

#     {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" })}},
#         "CATEGORY":{'$regex':district, '$options':'i'}})}},
    {'schoolId._id':ObjectId(idd)},    
    {'schoolId._id':{'$ne':None}},
     {'EMAIL_ID':{'$ne':''}},
     {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
               {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                 {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

    {'$group':{'_id':'$schoolId._id','Schoolname':{'$first':'$schoolId.NAME'}}}

      ])))



    df55 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.schoolId._id':{'$ne':None}},
    {'USER_ID.EMAIL_ID':{'$ne':''}},
#      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y"})}} ,
#         "CATEGORY":{'$regex':district, '$options':'i'}})}},
    {'USER_ID.schoolId._id':ObjectId(school)},     
    {'MODIFIED_DATE':{"$gte": csy_first_date()
    #              "$lte":myDatetime2
                     }},

    {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},


    {'$project':{'_id':'$USER_ID._id', 'practice_date':{"$dateToString":{"format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }},
                 'week': {'$week': "$MODIFIED_DATE" },
                'school':'$USER_ID.schoolId._id', 'schoolname':'$USER_ID.schoolId.NAME',
    'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                    ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}}   ,          


    {"$match":{'Completion_Percentage':{"$gte":.5}}},

    {'$group':{'_id':'$school', 'active_users':{'$addToSet':'$_id'}}},
    {'$project':{'_id':1, 'active_users':{'$size':'$active_users'}}}    

    ])))   



    df5 = DataFrame(list(collection.aggregate([
    {"$match":
    {'$and': [
    {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
    {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
    {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
    {'USER_ID.schoolId._id':{'$ne':None}},
    {'USER_ID.EMAIL_ID':{'$ne':''}},
#      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
        {'USER_ID.schoolId._id':ObjectId(school)},  
    {'MODIFIED_DATE':{"$gte": csy_first_date()
    #              "$lte":myDatetime2
                     }},

    {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
    {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},


    {'$project':{'_id':'$USER_ID._id', 'practice_date':{"$dateToString":{"format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }},
                 'week': {'$week': "$MODIFIED_DATE" },
                'school':'$USER_ID.schoolId._id', 'schoolname':'$USER_ID.schoolId.NAME',
    'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                    ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}}   ,          


    {"$match":{'Completion_Percentage':{"$gte":.5}}},


    { '$sort' : { '_id' : 1} }

    ])))

    df6=df5.groupby(['_id','practice_date','week','school','schoolname'], as_index=False).sum()

    df7=df6.sort_values(by=['school','week'], ascending=False)

    df8=df7.groupby(['school','_id','week'], as_index=False).agg({'practice_date':'count'}).sort_values(['school','week'], ascending=False)


    def legend(row):
        if row['practice_date']==1:
            return '1 x/week'
        elif (row['practice_date']>=2) & (row['practice_date']<=4):
            return '2-4 x/week'
        else:
            return 'Daily'


    df8['legend']= df8.apply(legend, axis=1)

    df9=df8.groupby(['school','week','legend'], as_index=False).agg({'_id':'count'})

    df10=pd.merge(df9,df55, left_on='school', right_on='_id', how='left')

    df11=df10.groupby(['school','week'], as_index=False).agg({'_id_x':'sum'})

    df12=pd.merge(df11, df55, left_on='school', right_on='_id', how='left')
    df12['diffrenece']=df12['active_users']-df12['_id_x']

    def legend(row):
        if row['diffrenece']!=0:
            return ('Not Used')

    df12['legend']=df12.apply(legend, axis=1)

    df13=pd.concat([df10,df12]).sort_values(['school','week'])
    df13=df13[['school','week','legend','_id_x','active_users','diffrenece']]

    df13['diffrenece'].fillna(df13['_id_x'], inplace=True)


    df13=df13.rename(columns={'diffrenece':'Teachers'})

    df14=df13[['school', 'week', 'legend','Teachers']]
    df14['Teachers']=df14['Teachers'].astype(int)
    # df14=df13[df13['school']==ObjectId('5f2bca46ba0be61b0c1d37c4')]

    df15=df14.groupby(['school', 'week'], as_index=False).agg(list)

    legenddd=['Daily', '2-4 x/week', '1 x/week','Not Used']

    for i in range(len(df15)):
        if legenddd != df15['legend'][i]:
            missing=set(legenddd)-set(df15['legend'][i])
            df15['legend'][i].extend(missing)

    for j in range(len(df15)):
        if len(df15['legend'][j]) != len(df15['Teachers'][j]):
            diff=len(df15['legend'][j])- len(df15['Teachers'][j])
            zeros=[0.0]*diff
            str(zeros)
            df15['Teachers'][j].extend(zeros)

    df15['new_legend']=np.zeros(len(df15), dtype=int)
    for w in range(len(df15)):
        not_none=list(filter(lambda a:a!= None, df15['legend'][w]))
        df15['new_legend'][w]=not_none



    legend_list=['Daily','2-4 x/week','1 x/week','Not Used']

    d={k:v for v,k in enumerate(legend_list)}
    df15['empty_list'] = np.empty((len(df15), 0)).tolist()

    for i in range(len(df15)):
        dictionary=dict(zip(df15['new_legend'][i], df15['Teachers'][i]))
        from collections import OrderedDict
        dictionary22=OrderedDict([(el,dictionary[el]) for el in legend_list])
        x=list(dictionary22.values())
        df15['empty_list'][i]=x

    for j in range(len(df15)):
        given_list=df15['new_legend'][j]
        given_list.sort(key=d.get)

    df15['weeks_']= np.zeros(len(df15), dtype=int)

    for k in range(len(df15)):
        if (1<=df15['week'][k]<=30):
            xx=22+df15['week'][k]
            df15['weeks_'][k]=xx
        elif(31<=df15['week'][k]<=52):
            xy=30-df15['week'][k]
            df15['weeks_'][k]=xy

    df15['weeks_']=abs(df15['weeks_'])   
    df15=df15.sort_values(by=['weeks_'], ascending=True)

    df15['empty_list']=df15['empty_list'].astype(str).str.replace(r'\[|\]|', '')

    df15['new_legend']=df15['new_legend'].str.join(",")

    df16=df15[['school','weeks_','new_legend','empty_list']]
    df16['weeks_']='Week '+ df16['weeks_'].astype(str)

    df17=pd.merge(df16, user_master, how='left', left_on='school', right_on='_id')

    dataa=[]
    for l in range(len(df17)):
        data=[df17['Schoolname'][l], df17['weeks_'][l], df17['empty_list'][l]]
        dataa.append(data)

    list1=[]
    for ll in range(len(dataa)):
        dataa[ll][2]=dataa[ll][2].split(',')
        qq=[int(float(x)) for x in dataa[ll][2]]
        m=dataa[ll][0:2]+qq
        list1.append(m)

    
    each_list=list1[0][2:]
    total_teachers=sum(each_list)    
    
    yscale=(total_teachers)+2    

    temp={'data':list1, 'yscale':int(yscale)}

    return json.dumps(temp)
    
@app.route('/active_teachers_on_SchoolSearch/<idd>/<chart_type>')
def active_teachers_school_search(idd,chart_type):

    username = urllib.parse.quote_plus('admin')
    password = urllib.parse.quote_plus('F5tMazRj47cYqm33e')
    client = MongoClient("mongodb://%s:%s@35.88.43.45:27017/" % (username, password))
    db=client.compass
    collection= db.audio_track_master
    school=idd
    #     district=disdic[districtid]    
    #     myDatetime1 = dateutil.parser.parse(startdate)
    #     myDatetime2 = dateutil.parser.parse(enddate)

#     chart_type='Absolute_count'
#     chart_type=str(chart_type).title()
    
    if chart_type=='Absolute_count': 
        
        user_master=DataFrame(list(db.user_master.aggregate([{"$match":
        {'$and': [
        {"IS_DISABLED":{"$ne":"Y"}},
          {"IS_BLOCKED":{"$ne":"Y"}},
         {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

        #     {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" })}},
        #         "CATEGORY":{'$regex':district, '$options':'i'}})}},
        {'schoolId._id':ObjectId(idd)},    
        {'schoolId._id':{'$ne':None}},
         {'EMAIL_ID':{'$ne':''}},
         {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$schoolId._id','Schoolname':{'$first':'$schoolId.NAME'}}}

          ])))

        df55 = DataFrame(list(collection.aggregate([
        {"$match":
        {'$and': [
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
        {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
        {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},
        #      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y"})}} ,
        #         "CATEGORY":{'$regex':district, '$options':'i'}})}},
        {'USER_ID.schoolId._id':ObjectId(school)},     
        {'MODIFIED_DATE':{"$gte": csy_first_date()
        #              "$lte":myDatetime2
                         }},

        {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},


        {'$project':{'_id':'$USER_ID._id', 'practice_date':{"$dateToString":{"format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }},
                     'week': {'$week': "$MODIFIED_DATE" },
                    'school':'$USER_ID.schoolId._id', 'schoolname':'$USER_ID.schoolId.NAME',
        'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}}   ,          


        {"$match":{'Completion_Percentage':{"$gte":.5}}},

        {'$group':{'_id':'$school', 'active_users':{'$addToSet':'$_id'}}},
        {'$project':{'_id':1, 'active_users':{'$size':'$active_users'}}}    

        ])))   

        df5 = DataFrame(list(collection.aggregate([
        {"$match":
        {'$and': [
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
        {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
        {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},
        #      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
            {'USER_ID.schoolId._id':ObjectId(school)},  
        {'MODIFIED_DATE':{"$gte": csy_first_date()
        #              "$lte":myDatetime2
                         }},

        {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},


        {'$project':{'_id':'$USER_ID._id', 'practice_date':{"$dateToString":{"format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }},
                     'week': {'$week': "$MODIFIED_DATE" },
                    'school':'$USER_ID.schoolId._id', 'schoolname':'$USER_ID.schoolId.NAME',
        'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}}   ,          


        {"$match":{'Completion_Percentage':{"$gte":.5}}},


        { '$sort' : { '_id' : 1} }

        ])))

        df6=df5.groupby(['_id','practice_date','week','school','schoolname'], as_index=False).sum()

        df7=df6.sort_values(by=['school','week'], ascending=False)

        df8=df7.groupby(['school','_id','week'], as_index=False).agg({'practice_date':'count'}).sort_values(['school','week'], ascending=False)


        def legend(row):
            if row['practice_date']==1:
                return '1 x/week'
            elif (row['practice_date']>=2) & (row['practice_date']<=4):
                return '2-4 x/week'
            else:
                return 'Daily'


        df8['legend']= df8.apply(legend, axis=1)

        df9=df8.groupby(['school','week','legend'], as_index=False).agg({'_id':'count'})

        df10=pd.merge(df9,df55, left_on='school', right_on='_id', how='left')

        df11=df10.groupby(['school','week'], as_index=False).agg({'_id_x':'sum'})

        df12=pd.merge(df11, df55, left_on='school', right_on='_id', how='left')
        df12['diffrenece']=df12['active_users']-df12['_id_x']

        def legend(row):
            if row['diffrenece']!=0:
                return ('Not Used')

        df12['legend']=df12.apply(legend, axis=1)

        df13=pd.concat([df10,df12]).sort_values(['school','week'])
        df13=df13[['school','week','legend','_id_x','active_users','diffrenece']]

        df13['diffrenece'].fillna(df13['_id_x'], inplace=True)


        df13=df13.rename(columns={'diffrenece':'Teachers'})

        df14=df13[['school', 'week', 'legend','Teachers']]
        df14['Teachers']=df14['Teachers'].astype(int)

        df15=df14.groupby(['school', 'week'], as_index=False).agg(list)

        legenddd=['Daily', '2-4 x/week', '1 x/week','Not Used']

        for i in range(len(df15)):
            if legenddd != df15['legend'][i]:
                missing=set(legenddd)-set(df15['legend'][i])
                df15['legend'][i].extend(missing)

        for j in range(len(df15)):
            if len(df15['legend'][j]) != len(df15['Teachers'][j]):
                diff=len(df15['legend'][j])- len(df15['Teachers'][j])
                zeros=[0.0]*diff
                str(zeros)
                df15['Teachers'][j].extend(zeros)

        df15['new_legend']=np.zeros(len(df15), dtype=int)
        for w in range(len(df15)):
            not_none=list(filter(lambda a:a!= None, df15['legend'][w]))
            df15['new_legend'][w]=not_none


        legend_list=['Daily','2-4 x/week','1 x/week','Not Used']

        d={k:v for v,k in enumerate(legend_list)}
        df15['empty_list'] = np.empty((len(df15), 0)).tolist()

        for i in range(len(df15)):
            dictionary=dict(zip(df15['new_legend'][i], df15['Teachers'][i]))
            from collections import OrderedDict
            dictionary22=OrderedDict([(el,dictionary[el]) for el in legend_list])
            x=list(dictionary22.values())
            df15['empty_list'][i]=x

        for j in range(len(df15)):
            given_list=df15['new_legend'][j]
            given_list.sort(key=d.get)

        df15['weeks_']= np.zeros(len(df15), dtype=int)

        for k in range(len(df15)):
            if (1<=df15['week'][k]<=30):
                xx=22+df15['week'][k]
                df15['weeks_'][k]=xx
            elif(31<=df15['week'][k]<=52):
                xy=30-df15['week'][k]
                df15['weeks_'][k]=xy

        df15['weeks_']=abs(df15['weeks_'])   
        df15=df15.sort_values(by=['weeks_'], ascending=True)

        df15['empty_list']=df15['empty_list'].astype(str).str.replace(r'\[|\]|', '')

        df15['new_legend']=df15['new_legend'].str.join(",")

        df16=df15[['school','weeks_','new_legend','empty_list']]
        df16['weeks_']='Week '+ df16['weeks_'].astype(str)

        df17=pd.merge(df16, user_master, how='left', left_on='school', right_on='_id')

        dataa=[]
        for l in range(len(df17)):
            data=[df17['Schoolname'][l], df17['weeks_'][l], df17['empty_list'][l]]
            dataa.append(data)

        list1=[]
        for ll in range(len(dataa)):
            dataa[ll][2]=dataa[ll][2].split(',')
            qq=[int(float(x)) for x in dataa[ll][2]]
            m=dataa[ll][0:2]+qq
            list1.append(m)

            each_list=list1[0][2:]
            total_teachers=sum(each_list)    

            yscale=(total_teachers)+2    

        temp={'data':list1, 'yscale':int(yscale)}
#         print(temp)
        return json.dumps(temp)
    

    else:
        
        user_master=DataFrame(list(db.user_master.aggregate([{"$match":
        {'$and': [
        {"IS_DISABLED":{"$ne":"Y"}},
          {"IS_BLOCKED":{"$ne":"Y"}},
         {"INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},

        #     {"schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" })}},
        #         "CATEGORY":{'$regex':district, '$options':'i'}})}},
        {'schoolId._id':ObjectId(idd)},    
        {'schoolId._id':{'$ne':None}},
         {'EMAIL_ID':{'$ne':''}},
         {'schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'schoolId.BLOCKED_BY_CAP':{'$exists':False}},
                   {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                     {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},

        {'$group':{'_id':'$schoolId._id','Schoolname':{'$first':'$schoolId.NAME'}}}

          ])))


        df55 = DataFrame(list(collection.aggregate([
        {"$match":
        {'$and': [
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
        {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
        {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},
        #      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y"})}} ,
        #         "CATEGORY":{'$regex':district, '$options':'i'}})}},
        {'USER_ID.schoolId._id':ObjectId(school)},     
        {'MODIFIED_DATE':{"$gte": csy_first_date()
        #              "$lte":myDatetime2
                         }},

        {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},


        {'$project':{'_id':'$USER_ID._id', 'practice_date':{"$dateToString":{"format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }},
                     'week': {'$week': "$MODIFIED_DATE" },
                    'school':'$USER_ID.schoolId._id', 'schoolname':'$USER_ID.schoolId.NAME',
        'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}}   ,          


        {"$match":{'Completion_Percentage':{"$gte":.5}}},

        {'$group':{'_id':'$school', 'active_users':{'$addToSet':'$_id'}}},
        {'$project':{'_id':1, 'active_users':{'$size':'$active_users'}}}    

        ])))   

        df5 = DataFrame(list(collection.aggregate([
        {"$match":
        {'$and': [
        {"USER_ID.IS_DISABLED":{"$ne":"Y"}},
        {"USER_ID.IS_BLOCKED":{"$ne":"Y"}},
        {"USER_ID.INCOMPLETE_SIGNUP":{"$ne":"Y"}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        { 'USER_ID.USER_NAME':{"$not":{"$regex":"1gen",'$options':'i'}}},
        {'USER_ID.schoolId._id':{'$ne':None}},
        {'USER_ID.EMAIL_ID':{'$ne':''}},
        #      {"USER_ID.schoolId._id":{"$in":db.school_master.distinct( "_id", { "IS_PORTAL": "Y" ,"CATEGORY":{'$regex':district, '$options':'i'}})}},
            {'USER_ID.schoolId._id':ObjectId(school)},  
        {'MODIFIED_DATE':{"$gte": csy_first_date()
        #              "$lte":myDatetime2
                         }},

        {'USER_ID.schoolId.NAME':{"$not":{"$regex":"test",'$options':'i'}}},
        {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':False}},
           {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
             {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}}]}},


        {'$project':{'_id':'$USER_ID._id', 'practice_date':{"$dateToString":{"format": "%Y-%m-%d", "date": "$MODIFIED_DATE" }},
                     'week': {'$week': "$MODIFIED_DATE" },
                    'school':'$USER_ID.schoolId._id', 'schoolname':'$USER_ID.schoolId.NAME',
        'Completion_Percentage':{"$round":[{"$divide":[{"$subtract":
                        ['$CURSOR_END','$cursorStart']},'$PROGRAM_AUDIO_ID.AUDIO_LENGTH']},2]}}}   ,          


        {"$match":{'Completion_Percentage':{"$gte":.5}}},


        { '$sort' : { '_id' : 1} }

        ])))

        df6=df5.groupby(['_id','practice_date','week','school','schoolname'], as_index=False).sum()

        df7=df6.sort_values(by=['school','week'], ascending=False)

        df8=df7.groupby(['school','_id','week'], as_index=False).agg({'practice_date':'count'}).sort_values(['school','week'], ascending=False)


        def legend(row):
            if row['practice_date']==1:
                return '1 x/week'
            elif (row['practice_date']>=2) & (row['practice_date']<=4):
                return '2-4 x/week'
            else:
                return 'Daily'


        df8['legend']= df8.apply(legend, axis=1)

        df9=df8.groupby(['school','week','legend'], as_index=False).agg({'_id':'count'})

        df10=pd.merge(df9,df55, left_on='school', right_on='_id', how='left')

        df11=df10.groupby(['school','week'], as_index=False).agg({'_id_x':'sum'})

        df12=pd.merge(df11, df55, left_on='school', right_on='_id', how='left')
        df12['diffrenece']=df12['active_users']-df12['_id_x']

        def legend(row):
            if row['diffrenece']!=0:
                return ('Not Used')

        df12['legend']=df12.apply(legend, axis=1)

        df13=pd.concat([df10,df12]).sort_values(['school','week'])
        df13=df13[['school','week','legend','_id_x','active_users','diffrenece']]

        df13['diffrenece'].fillna(df13['_id_x'], inplace=True)


        df13=df13.rename(columns={'diffrenece':'Teachers'})

        df14=df13[['school', 'week', 'legend','Teachers']]
        df14['Teachers']=df14['Teachers'].astype(int)

        df15=df14.groupby(['school', 'week'], as_index=False).agg(list)

        legenddd=['Daily', '2-4 x/week', '1 x/week','Not Used']

        for i in range(len(df15)):
            if legenddd != df15['legend'][i]:
                missing=set(legenddd)-set(df15['legend'][i])
                df15['legend'][i].extend(missing)

        for j in range(len(df15)):
            if len(df15['legend'][j]) != len(df15['Teachers'][j]):
                diff=len(df15['legend'][j])- len(df15['Teachers'][j])
                zeros=[0.0]*diff
                str(zeros)
                df15['Teachers'][j].extend(zeros)

        df15['new_legend']=np.zeros(len(df15), dtype=int)
        for w in range(len(df15)):
            not_none=list(filter(lambda a:a!= None, df15['legend'][w]))
            df15['new_legend'][w]=not_none



        legend_list=['Daily','2-4 x/week','1 x/week','Not Used']

        d={k:v for v,k in enumerate(legend_list)}
        df15['empty_list'] = np.empty((len(df15), 0)).tolist()

        for i in range(len(df15)):
            dictionary=dict(zip(df15['new_legend'][i], df15['Teachers'][i]))
            from collections import OrderedDict
            dictionary22=OrderedDict([(el,dictionary[el]) for el in legend_list])
            x=list(dictionary22.values())
            df15['empty_list'][i]=x

        for j in range(len(df15)):
            given_list=df15['new_legend'][j]
            given_list.sort(key=d.get)

        df15['weeks_']= np.zeros(len(df15), dtype=int)

        for k in range(len(df15)):
            if (1<=df15['week'][k]<=30):
                xx=22+df15['week'][k]
                df15['weeks_'][k]=xx
            elif(31<=df15['week'][k]<=52):
                xy=30-df15['week'][k]
                df15['weeks_'][k]=xy

        df15['weeks_']=abs(df15['weeks_'])   
        df15=df15.sort_values(by=['weeks_'], ascending=True)

        df15['empty_list']=df15['empty_list'].astype(str).str.replace(r'\[|\]|', '')

        df15['new_legend']=df15['new_legend'].str.join(",")

        df16=df15[['school','weeks_','new_legend','empty_list']]
        df16['weeks_']='Week '+ df16['weeks_'].astype(str)

        df17=pd.merge(df16, user_master, how='left', left_on='school', right_on='_id')

        dataa=[]
        for l in range(len(df17)):
            data=[df17['Schoolname'][l], df17['weeks_'][l], df17['empty_list'][l]]
            dataa.append(data)

        list1=[]
        for ll in range(len(dataa)):
            dataa[ll][2]=dataa[ll][2].split(',')
            qq=[int(float(x)) for x in dataa[ll][2]]
            m=dataa[ll][0:2]+qq
            list1.append(m)

        each_list=list1[0][2:]
        total_teachers=sum(each_list)    

        yscale=(total_teachers)+2    

        for i in range(len(list1)):
            each_list=list1[i][2:]
            total_teachers=sum(each_list)
            list1[i][2:]=[round((x/total_teachers)*100) for x in each_list]

        temp={'data':list1, 'yscale':100}
        return json.dumps(temp)




@app.route('/questcardschart')
def _21dayquest():
    QUEST_OBTAINED_USER=pd.DataFrame(list(db_live.user_master.aggregate([{"$match":{
             '$and':[{ 'USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'IS_DISABLED':{"$ne":'Y'}},
              {'IS_BLOCKED':{"$ne":'Y'}},
              {'schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'schoolId.BLOCKED_BY_CAP':{'$exists':0}},
              {'IS_QUEST_OBTAINED':'Y'}
              ]}},

              {'$project':{
                  '_id':0,
                  'USER_ID':'$_id',
                  'QUEST_OBTAIN_DATE':'$QUEST_OBTAINED_DATE',

                  }}

              ])))

    QUEST_OBTAINED_USER=QUEST_OBTAINED_USER[QUEST_OBTAINED_USER['QUEST_OBTAIN_DATE'].notnull()].reset_index(drop=True)

    quest_history=pd.DataFrame(list(db_live.user_quest_history.aggregate([{"$match":{
             '$and':[{ 'USER_ID.USER_NAME':{"$not":{"$regex":"test",'$options':'i'}}},
                       {'USER_ID.EMAIL_ID':{"$not":{"$regex":"test",'$options':'i'}}},
                         {'USER_ID.EMAIL_ID':{"$not":{"$regex":"1gen",'$options':'i'}}},
              {'USER_ID.INCOMPLETE_SIGNUP':{"$ne":'Y'}},
              {'USER_ID.IS_DISABLED':{"$ne":'Y'}},
              {'USER_ID.IS_BLOCKED':{"$ne":'Y'}},
              {'USER_ID.schoolId.NAME':{'$not':{"$regex":'Blocked','$options':'i'}}},
              {'USER_ID.schoolId.BLOCKED_BY_CAP':{'$exists':0}}]}},
                                         {'$project':{
                                             '_id':0,
                                             'USER_ID':'$USER_ID._id',                                         
                                             'QUEST_OBTAIN_DATE':'$QUEST_OBT_IN_DATE'
                                                                                  }}
                                         ])))

    def date_to_string(dates):
        date_=dates.strftime('%Y-%m-%d')
        return date_
    def quest_last_day(dates):
        last_date=(dates+relativedelta(days=41)).strftime("%Y-%m-%d")
        return last_date

    QUEST_OBTAINED_USER['QUEST_START_DAY']=QUEST_OBTAINED_USER['QUEST_OBTAIN_DATE'].apply(date_to_string)
    QUEST_OBTAINED_USER['QUEST_FINISH_DAY']=QUEST_OBTAINED_USER['QUEST_OBTAIN_DATE'].apply(quest_last_day)
    quest_history['QUEST_START_DAY']=quest_history['QUEST_OBTAIN_DATE'].apply(date_to_string)
    quest_history['QUEST_FINISH_DAY']=quest_history['QUEST_OBTAIN_DATE'].apply(quest_last_day)


    qh_no_entry=list(set(QUEST_OBTAINED_USER['USER_ID'])-set(quest_history['USER_ID']))

    quest_data=pd.concat([QUEST_OBTAINED_USER,quest_history],ignore_index=True)

    quest_data_final=quest_data.drop_duplicates(subset=['USER_ID','QUEST_START_DAY'],keep='first').reset_index(drop=True)

    def all_practice_dates(startdate,enddate):
        dates=list(pd.date_range(startdate,enddate).strftime("%Y-%m-%d"))
        return dates

    quest_data_final['POSSIBLE_PRACTICE_DAYS']=''
    for i in range(len(quest_data_final)):
        quest_data_final['POSSIBLE_PRACTICE_DAYS'][i]=all_practice_dates(quest_data_final['QUEST_START_DAY'][i],quest_data_final['QUEST_FINISH_DAY'][i])


    practice_info=pd.DataFrame(list(db_live.audio_track_master.aggregate([{"$match":{
             '$and':[
             {'USER_ID._id':{'$in':list(quest_data_final['USER_ID'])}},
             {'MODIFIED_DATE':{'$gte':datetime.datetime(2021,1,1)}}


             ]}},

      {'$group':{
          '_id':'$USER_ID._id',
          'practice_dates':{'$addToSet':{ '$dateToString': { 'format': "%Y-%m-%d", 'date': "$MODIFIED_DATE" } }}



      }}])))

    practice_info['practice_dates']=[sorted(i) for i in practice_info['practice_dates']]

    practice_info=practice_info.rename(columns={'_id':'USER_ID'})

    quest_data_final_1=quest_data_final.merge(practice_info,how='left',on='USER_ID')

    quest_data_final_1['practice_dates']=quest_data_final_1['practice_dates'].fillna("").apply(list)

    _21_day_practice_dates=[]
    for i in range(len(quest_data_final_1)):
        all_dates=list(set(quest_data_final_1['POSSIBLE_PRACTICE_DAYS'][i]).intersection(quest_data_final_1['practice_dates'][i]))
        _21_day_practice_dates.append(all_dates)

    quest_data_final_1['_21_day_practice_dates']=_21_day_practice_dates

    quest_data_final_1['total_days_practiced_21Q']=[len(i) for i in quest_data_final_1['_21_day_practice_dates']]

    quest_completed_status=[]
    for i in range(len(quest_data_final_1)):
        if (quest_data_final_1['QUEST_FINISH_DAY'][i]<=datetime.datetime.now().strftime("%Y-%m-%d")) &(quest_data_final_1['total_days_practiced_21Q'][i]<21):
            quest_completed_status.append('No')
        elif (quest_data_final_1['QUEST_FINISH_DAY'][i]<=datetime.datetime.now().strftime("%Y-%m-%d")) &(quest_data_final_1['total_days_practiced_21Q'][i]>=21):
            quest_completed_status.append('Yes')
        elif (quest_data_final_1['QUEST_FINISH_DAY'][i]>=datetime.datetime.now().strftime("%Y-%m-%d")) &(quest_data_final_1['total_days_practiced_21Q'][i]>=21):
            quest_completed_status.append('Yes')

        else:
            quest_completed_status.append('Ongoing')





    quest_data_final_1['QUEST_COMPLETED_STATUS']=quest_completed_status

    quest_count=quest_data_final_1.groupby('USER_ID')['QUEST_START_DAY'].apply(list).reset_index()

    quest_count['TOTAL_QUEST']=quest_count['QUEST_START_DAY'].apply(len)

    overall_pair=[]
    for i in range(len(quest_count)):
        all_pair=[(quest_count['QUEST_START_DAY'][i][p1], quest_count['QUEST_START_DAY'][i][p2]) for p1 in range(len(quest_count['QUEST_START_DAY'][i])) for p2 in range(p1+1,len(quest_count['QUEST_START_DAY'][i]))]
        overall_pair.append(all_pair)

    no_completion_data=[]
    for i in range(len(overall_pair)):
        for j in range(len(overall_pair[i])):
            if abs((pd.to_datetime(overall_pair[i][j][1])-pd.to_datetime(overall_pair[i][j][0])).days)<21:
                try:
                    rejected_date=min(overall_pair[i][j])
                    df_dict={'USER_ID':quest_count['USER_ID'][i],'rejected_date':rejected_date}
                    no_completion_data.append(df_dict)
                except:
                    pass
                else:
                    pass






    for i in range(len(no_completion_data)):
        quest_data_final_1.loc[(quest_data_final_1['USER_ID']==no_completion_data[i].get('USER_ID'))&(quest_data_final_1['QUEST_START_DAY']==no_completion_data[i].get('rejected_date')),'NEW_QUEST_STATUS']='No'

    quest_data_final_1.loc[quest_data_final_1['NEW_QUEST_STATUS'].isnull(),'NEW_QUEST_STATUS']=quest_data_final_1['QUEST_COMPLETED_STATUS']


    qh_um=pd.DataFrame(list(db_live.user_master.aggregate([{'$match':{'$and':[
        {'_id':{'$in':list(quest_data_final_1['USER_ID'])}}


    ]}},

                                                          {'$project':{'_id':0,
                                                                      'USER_ID':'$_id',
                                                                       'USER_NAME':'$USER_NAME',
                                                                       'EMAIL_ID':'$EMAIL_ID',
                                                                       'SCHOOL_ID':'$schoolId._id',
                                                                       'SCHOOL_NAME':'$schoolId.NAME',
                                                                       'CHANNEL':'$UTM_MEDIUM',
                                                                       'SIGNUP':'$CREATED_DATE'

                                                                      }}
                                                          ])))

    quest_history_data_new_final=quest_data_final_1.merge(qh_um,how='left',on='USER_ID')

    quest_history_data_new_final.rename(columns={'NEW_QUEST_STATUS':'QUEST_STATUS'},inplace=True)

    quest_history_data_new_final.loc[(quest_history_data_new_final['QUEST_STATUS']=='No')&(quest_history_data_new_final['total_days_practiced_21Q']>=21),'QUEST_STATUS']='Yes'

    columns_required=['USER_ID','USER_NAME', 'EMAIL_ID', 'SCHOOL_ID', 'SCHOOL_NAME', 'SIGNUP',
            'CHANNEL', 'QUEST_START_DAY', 'QUEST_FINISH_DAY',
            'POSSIBLE_PRACTICE_DAYS', 'practice_dates', '_21_day_practice_dates',
            'total_days_practiced_21Q', 'QUEST_STATUS'
            ]

    quest_history_data_new_final=quest_history_data_new_final[columns_required]

    quest_history_data_new_final=quest_history_data_new_final[quest_history_data_new_final['SIGNUP'].notnull()].reset_index(drop=True)

    quest_history_data_new_final['CHANNEL']=quest_history_data_new_final['CHANNEL'].fillna('Other')
    quest_history_data_new_final['CHANNEL']=quest_history_data_new_final['CHANNEL'].replace(['NULL','null',None,'Null'],'Other')

    quest_history_data_new_final['CHANNEL']=quest_history_data_new_final['CHANNEL'].str.lower().str.title()

    channel_data=quest_history_data_new_final['CHANNEL'].value_counts().reset_index().rename(columns={'index':'Channel',
                                                                                                     'CHANNEL':'Count'
                                                                                                     })

    incomplete_trend=quest_history_data_new_final[quest_history_data_new_final['QUEST_STATUS']=='No']['total_days_practiced_21Q'].value_counts().reset_index().rename(columns={'index':'Days',
                                                                                                     'total_days_practiced_21Q':'Count'
                                                                                                     })

    quest_days=pd.DataFrame({'Days':list(range(0,21))})

    incomplete_trend_new=quest_days.merge(incomplete_trend,how='left',on='Days').fillna(0)

    temp={'TOTAL_QUEST':len(quest_history_data_new_final),
         'QUEST_COMPLETED':len(quest_history_data_new_final[quest_history_data_new_final['QUEST_STATUS']=='Yes']),
          'USER_ACTIVATED':len(set(quest_history_data_new_final['USER_ID'])),
          'USER_COMPLETED':len(set(quest_history_data_new_final[quest_history_data_new_final['QUEST_STATUS']=='Yes']['USER_ID'])),
          'USER_PRACTICED':len(set(quest_history_data_new_final[quest_history_data_new_final['total_days_practiced_21Q']!=0]['USER_ID'])),
         'Channel_Chart':{'x_axis':channel_data['Channel'].tolist(),'y_axis':channel_data['Count'].tolist()},
          'Incomplete_Trend':{'x_axis':list(incomplete_trend_new['Days']),
                             'y_axis':list(incomplete_trend_new['Count'])
                             }
         }

    return json.dumps(temp)


@app.route("/insightcorner")
def insights__():
    googleSheetId = '1OMpKtOM5RIN0Mjs9BcVYqRFLpyDa1CygxLEKloNa1I8'
    worksheetName = 'Sheet1'
    URL = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv&sheet={1}'.format(googleSheetId,worksheetName)
    dff=pd.read_csv(URL)

    df1=dff.groupby(['Insights','Page'])['Observation'].apply(list).reset_index()

    temp=[]
    for i in range(len(df1)):
        dict_={'Insights':df1['Insights'][i],'Observations':df1['Observation'][i]}
        temp.append(dict_)
    return json.dumps(temp)


@app.route('/googleanalyticsinsights')
def googleanlytics_():
    from apiclient.discovery import build
    from oauth2client.service_account import ServiceAccountCredentials
    from textwrap import wrap

    SCOPES = ['https://www.googleapis.com/auth/analytics.readonly']
    KEY_FILE_LOCATION = 'api-access-347005-fb5071f3d0b0.json'
    VIEW_ID = '116868648'


    def initialize_analyticsreporting():
        credentials = ServiceAccountCredentials.from_json_keyfile_name(KEY_FILE_LOCATION, SCOPES)
        analytics = build('analyticsreporting', 'v4', credentials=credentials)
        return analytics

    # Bounce rate in last 6 months
    def bouncerate6m(analytics):    
        return analytics.reports().batchGet(
          body={
            'reportRequests': [
            {
              'viewId': VIEW_ID,
              'dateRanges': [{'startDate':(datetime.datetime.utcnow()-relativedelta(months=6)).strftime("%Y-%m-%d"), 'endDate': datetime.datetime.utcnow().strftime("%Y-%m-%d")}],
                'samplingLevel':'LARGE',
              'metrics': [{'expression': 'ga:bounceRate'}]
                ,
              'dimensions': [{'name': 'ga:yearMonth'}]                        
            }]
          }
            ).execute()

    bounce_rate_6m=pd.DataFrame(bouncerate6m(initialize_analyticsreporting())['reports'][0]['data']['rows'])

    year=[]
    month=[]
    for i in range(len(bounce_rate_6m)):
        splited_list=wrap(bounce_rate_6m['dimensions'][i][0],4)
        year.append(splited_list[0])
        month.append(splited_list[1])

    month_name=[calendar.month_abbr[int(i)] for i in month]    

    def extract_value(dicts):
        value=dicts['values'][0]
        return value

    values=[round(float(extract_value(i[0])),2) for i in bounce_rate_6m['metrics']]

    bounce_rate_6m['year']=year
    bounce_rate_6m['month']=month_name
    bounce_rate_6m['values']=values

    def bouncerate7d(analytics):    
        return analytics.reports().batchGet(
          body={
            'reportRequests': [
            {
              'viewId': VIEW_ID,
              'dateRanges': [{'startDate':(datetime.datetime.utcnow()-relativedelta(days=6)).strftime("%Y-%m-%d"), 'endDate': datetime.datetime.utcnow().strftime("%Y-%m-%d")}],
                'samplingLevel':'LARGE',
              'metrics': [{'expression': 'ga:bounceRate'}]
                ,
              'dimensions': [{'name': 'ga:date'}]                        
            }]
          }
            ).execute()

    bounce_rate_7d=pd.DataFrame(bouncerate7d(initialize_analyticsreporting())['reports'][0]['data']['rows'])


    date_7d=[pd.to_datetime(i[0]).strftime("%Y-%m-%d") for i in bounce_rate_7d['dimensions']]
    values_7d=[round(float(extract_value(i[0])),2) for i in bounce_rate_7d['metrics']]


    bounce_rate_7d['date']=date_7d
    bounce_rate_7d['values_7d']=values_7d

    def usertype_(analytics):    
        return analytics.reports().batchGet(
          body={
            'reportRequests': [
            {
              'viewId': VIEW_ID,
              'dateRanges': [{'startDate':(datetime.datetime.utcnow()-relativedelta(days=29)).strftime("%Y-%m-%d"), 'endDate': datetime.datetime.utcnow().strftime("%Y-%m-%d")}],
                'samplingLevel':'LARGE',
              'metrics': [{'expression': 'ga:users'}]
                ,
              'dimensions': [{'name': 'ga:userType'}]                        
            }]
          }
            ).execute()

    usertype_df=pd.DataFrame(usertype_(initialize_analyticsreporting())['reports'][0]['data']['rows'])

    usertype=[i[0] for i in usertype_df['dimensions']]
    values_usertype=[float(extract_value(i[0])) for i in usertype_df['metrics']]
    usertype_df['User_Type']=usertype
    usertype_df['Values']=values_usertype
    usertype_df['Percent']=round(usertype_df['Values']/sum(usertype_df['Values'])*100,2)


    def pageloadtime(analytics):    
        return analytics.reports().batchGet(
          body={
            'reportRequests': [
            {
              'viewId': VIEW_ID,
              'dateRanges': [{'startDate':(datetime.datetime.utcnow()-relativedelta(days=6)).strftime("%Y-%m-%d"), 'endDate': datetime.datetime.utcnow().strftime("%Y-%m-%d")}],
                'samplingLevel':'LARGE',
              'metrics': [{'expression': 'ga:avgPageLoadTime'}]
                ,
              'dimensions': [{'name': 'ga:date'}]                        
            }]
          }
            ).execute()
    pageloadtime_7d_df=pd.DataFrame(pageloadtime(initialize_analyticsreporting())['reports'][0]['data']['rows'])
    date_pageload_7d=[pd.to_datetime(i[0]).strftime("%Y-%m-%d") for i in pageloadtime_7d_df['dimensions']]
    values_pageload_7d=[round(float(extract_value(i[0])),2) for i in pageloadtime_7d_df['metrics']]
    pageloadtime_7d_df['date']=date_pageload_7d
    pageloadtime_7d_df['Values']=values_pageload_7d

    temp=[{'Insights':'Show me the trend of bounce rate in last 6 months',
         'x_axis':list(bounce_rate_6m['month']),
          'y_axis':list(bounce_rate_6m['values'])
         },    
        {'Insights':'Show me the trend of bounce rate in last 7 days',
         'x_axis':list(bounce_rate_7d['date']),
          'y_axis':list(bounce_rate_7d['values_7d'])
         },
         {'Insights':'Show me the user breakdown of users in last 30 days',
         'x_axis':list(usertype_df['User_Type']),
          'y_axis':list(usertype_df['Percent'])},

          {'Insights':'Show me the trend of average page load time in last 7 days',
         'x_axis':list(pageloadtime_7d_df['date']),
          'y_axis':list(pageloadtime_7d_df['Values'])
         }
         ]
    
    return json.dumps(temp)


#  ukraine donation data fetch api is added 

@app.route('/downloadukrainedonation')
def ukrainedonationdata():
    from flask import Flask, make_response
        
    import pyexcel as pe
    from io import StringIO
    client_live= MongoClient('mongodb://admin:F5tMazRj47cYqm33e@54.202.61.130:27017/')
    db_live=client_live.compass
    ukraine_campaign_data=pd.DataFrame(list(db_live.campaign_payment.aggregate(
    [{'$match':{'$and':[
        {'CAMPAIGN_ID._id':ObjectId('6260122a91af2ca7047316dd')}
        ]}},
    {'$project':{
        '_id':0,
        'CAMPAIGN_ID':'$CAMPAIGN_ID._id',
        'CREATED_DATE':'$CREATED_DATE',
        'CONTRIBUTION_ID':'$CONTRIBUTION_ID._id',
        'FIRST_NAME':'$CONTRIBUTION_ID.FIRST_NAME',
        'LAST_NAME':'$CONTRIBUTION_ID.LAST_NAME',     
        'EMAIL':'$CONTRIBUTION_ID.EMAIL',
        'CONTRIBUTE_AMOUNT':'$CONTRIBUTION_ID.CONTRIBUTE_AMOUNT',
        'IS_PAYMENT_SUCCESS':'$CONTRIBUTION_ID.IS_PAYMENT_SUCCESS',
        'PAYMENT_TYPE':'$PAYMENT_TYPE',
        'CONTRIBUITION_CREATED_DATE':'$CONTRIBUTION_ID.CREATED_DATE',
        'PAYMENT_DATE':'$CONTRIBUTION_ID.PAYMENT_DATE',
        'PAYPAL_TOKEN':'$PAYPAL_TOKEN',
        'PAYPAL_TRX_ID':'$PAYPAL_TRX_ID',
        'PAYPAL_PAYERID':'$PAYPAL_PAYERID',
        'SQUARE_TRX_ID':'$SQUARE_TRX_ID'
        }}   
        ]

    )))    
    ukraine_campaign_data.loc[ukraine_campaign_data['PAYMENT_DATE'].isnull(),'PAYMENT_DATE']=ukraine_campaign_data['CONTRIBUITION_CREATED_DATE']
    # ukraine_campaign_data['DONATION_TIME']=[i.strftime("%Y-%m-%d %H:%M:%S") for i in ukraine_campaign_data['CONTRIBUITION_CREATED_DATE']]
    ukraine_campaign_data.fillna('',inplace=True)
    ukraine_campaign_data['CONTRIBUTOR_NAME']=ukraine_campaign_data['FIRST_NAME']+" "+ukraine_campaign_data['LAST_NAME']
    ukraine_campaign_data['DONATION_TIME']=[i.strftime("%Y-%m-%d %H:%M:%S") for i in ukraine_campaign_data['PAYMENT_DATE']]
    ukraine_campaign_data=ukraine_campaign_data[['CONTRIBUTOR_NAME', 'EMAIL', 'CONTRIBUTE_AMOUNT', 'IS_PAYMENT_SUCCESS',
        'PAYMENT_TYPE', 'CONTRIBUITION_CREATED_DATE', 'PAYPAL_TRX_ID',
        'PAYPAL_PAYERID','SQUARE_TRX_ID', 'DONATION_TIME']]

    data=ukraine_campaign_data.values.tolist()
    data.insert(0,list(ukraine_campaign_data.columns))
    todays=datetime.datetime.now().strftime("%Y_%b_%d")
    
    sheet = pe.Sheet(data)
    io = StringIO()
    sheet.save_to_memory("csv", io)
    output = make_response(io.getvalue())
    output.headers["Content-Disposition"] = "attachment; filename="+str(todays)+"_Ukraine_Donation_Data.csv"
    output.headers["Content-type"] = "text/csv"
    return output


@app.route('/Family_SURVEY')
def Family_SURVEY():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('Family_SURVEY.html')
@app.route('/Bill_later')
def Bill_later():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('Bill_later.html')

@app.route('/Weekly_Analytics')
def Weekly_Analytics12():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('Weekly_Analytics.html')

@app.route('/School_Revenue')
def School_Revenue():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('School_Revenue.html')

@app.route('/feedback_Analyitcs_family')
def feedbackfamily():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('feedback_Analyitcs_family.html')


@app.route('/dailyweekly')
def dailyweekly():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('dailyweekly.html')

@app.route('/pracbifurcation')
def pracbifurcation():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('pracbifurcation.html')

@app.route('/Practice_streak')
def Practice_streak():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('Practice_streak.html')

@app.route('/schoolsummary')
def schoolsummary():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('schoolsummary.html')

@app.route('/Donation')
def Donation():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('Donation.html')
    
@app.route('/Disctrictfilter')
def Disctrictfilter():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('Disctrictfilter.html')

@app.route('/district _race')
def district_race():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('district _race.html')
@app.route('/familycard')
def Journey_score2():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('familycard.html')

@app.route('/audio_analytics')
def audio_analytics():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('audio_analytics.html')

@app.route('/tunein')
def tunein():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('tunein.html')

@app.route('/ddt')
def ddt():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('ddt.html')

@app.route('/mobile_sub')
def mobile_sub():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('mobile_sub.html')


@app.route('/partner')
def partner():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('partner.html')

@app.route('/fastt')
def fastt():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('fastt.html')

@app.route('/21daystreak')
def daystreak():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('21daystreak.html')

@app.route('/sentiment')
def sentiment():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('sentiment.html')

@app.route('/School_Search_comparison')
def School_Search_comparison():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('School_Search_comparison.html')

@app.route('/NameEScore')
def NameEScore():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('NameEScore.html')

@app.route('/d1districts')
def d1districts():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('d1districts.html')

@app.route('/schoolengagement')
def schoolengagement():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('schoolengagement.html')

@app.route('/awsmain')
def awsmain():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('awsmain.html')
@app.route('/callibration')
def callibration():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('callibration.html')

@app.route('/Login_analytics')
def loginAnalytics():
    if not g.user:
        return redirect(url_for('login'))
        
    return render_template('login_analytics.html')

@app.route('/Journey_score')
def reportcard():
    if not g.user:
        return redirect(url_for('login'))
    
    return render_template('Journey_score.html')
@app.route("/logout")
def logout():
    session.pop('user_id', None)
    return render_template('login.html')

@app.route('/Day_In_Life')
def Day_In_Life():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('dayinlife.html')

@app.route('/Local_Disctrictfilter')
def Local_Disctrictfilter():
    if not g.user:
        return redirect(url_for('login'))
    return render_template('Local_Disctrictfilter.html')
    

if __name__ == '__main__':
   app.run(debug=True)
